description,diff,concern_count,shas,types
"lint using dagger

Signed-off-by: Andrea Luzzardi <aluzzardi@gmail.com> | don't consider cases where there are no txids","diff --git a/.github/workflows/lint.yml b/.github/workflows/lint.yml
index 16aa393..bdb0d6f 100644
--- a/.github/workflows/lint.yml
+++ b/.github/workflows/lint.yml
@@ -3,9 +3,9 @@ on:
   push:
     branches: [main]
     paths:
-      - '**.go'
-      - '**.md'
-      - '.github/workflows/lint.yml'
+      - ""**.go""
+      - ""**.md""
+      - "".github/workflows/lint.yml""
   pull_request:
   # Enable manual trigger for easy ad-hoc debugging
   # https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#onworkflow_dispatchinputs
@@ -42,8 +42,11 @@ jobs:
     runs-on: ubuntu-latest
     steps:
       - uses: actions/checkout@v3
+      - uses: actions/setup-go@v3
+        with:
+          go-version: 1.19
       - name: ""Lint markdown""
-        uses: avto-dev/markdown-lint@v1
+        uses: magefile/mage-action@v2
         with:
-          config: "".markdownlint.yaml""
-          args: ./docs README.md
+          version: latest
+          args: lint:markdown
diff --git a/magefile.go b/magefile.go
index 4ac385b..f5dec4c 100644
--- a/magefile.go
+++ b/magefile.go
@@ -20,10 +20,50 @@ type Lint mg.Namespace
 
 // Run all lint targets
 func (t Lint) All(ctx context.Context) error {
-	mg.Deps(t.Codegen)
+	mg.Deps(
+		t.Codegen,
+		t.Markdown,
+	)
 	return nil
 }
 
+// Markdown lint
+func (Lint) Markdown(ctx context.Context) error {
+	c, err := dagger.Connect(ctx, dagger.WithLogOutput(os.Stderr))
+	if err != nil {
+		return err
+	}
+	defer c.Close()
+
+	workdir := c.Host().Workdir().Read()
+
+	src, err := workdir.ID(ctx)
+	if err != nil {
+		return err
+	}
+
+	cfg, err := workdir.File("".markdownlint.yaml"").ID(ctx)
+	if err != nil {
+		return err
+	}
+
+	_, err = c.Container().
+		From(""tmknom/markdownlint:0.31.1"").
+		WithMountedDirectory(""/src"", src).
+		WithMountedFile(""/src/.markdownlint.yaml"", cfg).
+		WithWorkdir(""/src"").
+		Exec(dagger.ContainerExecOpts{
+			Args: []string{
+				""-c"",
+				"".markdownlint.yaml"",
+				""--"",
+				""./docs"",
+				""README.md"",
+			},
+		}).ExitCode(ctx)
+	return err
+}
+
 // Lint SDK code generation
 func (Lint) Codegen(ctx context.Context) error {
 	c, err := dagger.Connect(ctx, dagger.WithLogOutput(os.Stderr))

diff --git a/src/main.rs b/src/main.rs
index 25d9580..9ba4e38 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -441,6 +441,9 @@ fn main() {
             let mut delta_tx_fees = vec![];
             let empty_txids = vec![];
             let txids = tx_mined_deltas.get(&delta).unwrap_or(&empty_txids);
+            if txids.len() == 0 {
+                continue;
+            }
             for txid in txids.iter() {
                 delta_tx_fees.push(*tx_fees.get(txid).unwrap_or(&0));
             }
",2,"[""bb00890fa896936d0be09cc5e5f411fb5e64aa5f"", ""37a1b5bbb5270befcee5d9b9621af196c787a61f""]","[""cicd"", ""fix""]"
"convert `run_tag_values_test_case` to a function | ensure ""dist"" dirs exist","diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/scripts/prepare.js b/scripts/prepare.js
index 9eb8cb8..f285825 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -68,6 +68,9 @@ async function prepare() {
     names.push(json.name)
   }
 
+  // Ensure all ""dist"" directories exist.
+  dirs.forEach(dir => fs.ensureDirSync(join(dir, distId)))
+
   log(``)
   for (let i = 0; i < names.length; i++) {
     const dir = dirs[i]
",2,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""ca060bf255a55b99000ddf0c67f7422f28b735a6""]","[""refactor"", ""build""]"
Fix typo | simplify loadFiles code,"diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/frontend/app/player/web/network/loadFiles.ts b/frontend/app/player/web/network/loadFiles.ts
index ec174fc..d164333 100644
--- a/frontend/app/player/web/network/loadFiles.ts
+++ b/frontend/app/player/web/network/loadFiles.ts
@@ -1,43 +1,33 @@
 import APIClient from 'App/api_client';
 
-const NO_NTH_FILE = ""nnf""
-const NO_UNPROCESSED_FILES = ""nuf""
+const NO_FILE_OK = ""No-file-but-this-is-ok""
+const NO_BACKUP_FILE = ""No-efs-file""
 
 export const loadFiles = (
   urls: string[],
   onData: (data: Uint8Array) => void,
 ): Promise<void> => {
-  const firstFileURL = urls[0]
-  urls = urls.slice(1)
-  if (!firstFileURL) {
+  if (!urls.length) {
     return Promise.reject(""No urls provided"")
   }
-  return window.fetch(firstFileURL)
-  .then(r => {
-    return processAPIStreamResponse(r, true)
-  })
-  .then(onData)
-  .then(() =>
-    urls.reduce((p, url) =>
-      p.then(() =>
-        window.fetch(url)
-        .then(r => {
-          return processAPIStreamResponse(r, false)
-        })
-        .then(onData)
-      ),
-      Promise.resolve(),
-    )
+  return urls.reduce((p, url, index) =>
+    p.then(() =>
+      window.fetch(url)
+      .then(r => {
+        return processAPIStreamResponse(r, index===0)
+      })
+      .then(onData)
+    ),
+    Promise.resolve(),
   )
   .catch(e => {
-    if (e === NO_NTH_FILE) {
+    if (e === NO_FILE_OK) {
       return
     }
     throw e
   })
 }
 
-
 export async function requestEFSDom(sessionId: string) {
   return await requestEFSMobFile(sessionId + ""/dom.mob"")
 }
@@ -50,21 +40,18 @@ async function requestEFSMobFile(filename: string) {
   const api = new APIClient()
   const res = await api.fetch('/unprocessed/' + filename)
   if (res.status >= 400) {
-    throw NO_UNPROCESSED_FILES
+    throw NO_BACKUP_FILE
   }
   return await processAPIStreamResponse(res, false)
 }
 
-const processAPIStreamResponse = (response: Response, isFirstFile: boolean) => {
+const processAPIStreamResponse = (response: Response, canBeMissed: boolean) => {
   return new Promise<ArrayBuffer>((res, rej) => {
-    if (response.status === 404 && !isFirstFile) {
-      return rej(NO_NTH_FILE)
+    if (response.status === 404 && canBeMissed) {
+      return rej(NO_FILE_OK)
     }
     if (response.status >= 400) {
-      return rej(
-        isFirstFile ? `no start file. status code ${ response.status }`
-        : `Bad endfile status code ${response.status}`
-      )
+      return rej(`Bad file status code ${response.status}. Url: ${response.url}`)
     }
     res(response.arrayBuffer())
   }).then(buffer => new Uint8Array(buffer))
",2,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""983fef55ef08ca2ca25349bb2d5bdff10ecf89f4""]","[""docs"", ""refactor""]"
"update drone | exception for non-executable processes

related to #36","diff --git a/.drone.yml b/.drone.yml
index 53e3329..306516b 100644
--- a/.drone.yml
+++ b/.drone.yml
@@ -21,10 +21,10 @@ steps:
         from_secret: docker_username
       password:
         from_secret: docker_password
-      tags: pg
+      tags: latest
     when: 
       branch:
-        - pg
+        - master
       event: 
         - push
   - 
@@ -40,14 +40,14 @@ steps:
       port: 22
       script: 
         - ""sleep 10""
-        - ""docker pull rsschool/api:pg""
+        - ""docker pull rsschool/api:latest""
         - ""docker-compose stop api""
         - ""docker-compose rm -f api""
         - ""docker-compose up -d api""
         - ""docker system prune -f""
     when: 
       branch: 
-        - pg
+        - master
       event: 
         - push
 volumes:

diff --git a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
index 3c68047..4668708 100644
--- a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
+++ b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
@@ -80,4 +80,22 @@ public class DeployBpmnResourceTest
             .execute();
     }
 
+    @Test
+    public void shouldNotDeployNonExecutableModel()
+    {
+        // given
+        final TngpClient client = clientRule.getClient();
+        final WorkflowsClient workflowService = client.workflows();
+
+        // then
+        exception.expect(BrokerRequestException.class);
+        exception.expectMessage(containsString(""ERROR 203""));
+        exception.expect(BrokerRequestExceptionMatcher.brokerException(1, 1));
+
+        // when
+        workflowService.deploy()
+            .bpmnModelInstance(Bpmn.createProcess().startEvent().endEvent().done())
+            .execute();
+    }
+
 }
",2,"[""88129ee45b1d49bc4ff887f3b488464cc7097e29"", ""21c004b3c40bd3d68f0d32d173a29632765666c8""]","[""build"", ""test""]"
"replace api call which requires auth token in public page

re #4694

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nc-gui/composables/useSharedView.ts b/packages/nc-gui/composables/useSharedView.ts
index cb0c5ea..f67a6c9 100644
--- a/packages/nc-gui/composables/useSharedView.ts
+++ b/packages/nc-gui/composables/useSharedView.ts
@@ -17,7 +17,7 @@ export function useSharedView() {
 
   const { appInfo } = $(useGlobal())
 
-  const { loadProject } = useProject()
+  const { project } = useProject()
 
   const appInfoDefaultLimit = appInfo.defaultLimit || 25
 
@@ -76,7 +76,16 @@ export function useSharedView() {
 
     await setMeta(viewMeta.model)
 
-    await loadProject(true, viewMeta.project_id)
+    // if project is not defined then set it with an object containing base
+    if (!project.value?.bases)
+      project.value = {
+        bases: [
+          {
+            id: viewMeta.base_id,
+            type: viewMeta.client,
+          },
+        ],
+      }
 
     const relatedMetas = { ...viewMeta.relatedMetas }
     Object.keys(relatedMetas).forEach((key) => setMeta(relatedMetas[key]))
",1,"[""4986a5892fb00bd5a6b2065ad8cfefbc36052dd7""]","[""fix""]"
add postgres-driver typings | add gitignore.nix to dep update matrix,"diff --git a/packages/cubejs-postgres-driver/driver/index.d.ts b/packages/cubejs-postgres-driver/driver/index.d.ts
new file mode 100644
index 0000000..47dcada
--- /dev/null
+++ b/packages/cubejs-postgres-driver/driver/index.d.ts
@@ -0,0 +1,8 @@
+import { PoolConfig } from ""pg"";
+
+declare module ""@cubejs-backend/postgres-driver"" {
+  class PostgresDriver {
+    constructor(options?: PoolConfig);
+  }
+  export = PostgresDriver;
+}
diff --git a/packages/cubejs-postgres-driver/package.json b/packages/cubejs-postgres-driver/package.json
index 9db5a20..1e9a236 100644
--- a/packages/cubejs-postgres-driver/package.json
+++ b/packages/cubejs-postgres-driver/package.json
@@ -12,6 +12,7 @@
     ""node"": "">=8.11.1""
   },
   ""main"": ""driver/PostgresDriver.js"",
+  ""typings"": ""driver/index.d.ts"",
   ""scripts"": {
     ""lint"": ""eslint **/*.js""
   },

diff --git a/.github/workflows/update-deps.yml b/.github/workflows/update-deps.yml
index e0ccd62..1236f58 100644
--- a/.github/workflows/update-deps.yml
+++ b/.github/workflows/update-deps.yml
@@ -13,6 +13,7 @@ jobs:
           - nixpkgs
           - poetry2nix
           - pre-commit-hooks
+          - gitignore.nix
     steps:
       - name: Checkout
         uses: actions/checkout@v2
",2,"[""364d9bf18b2ce73c04d5ec3a70aefa3e6b83cc12"", ""c444fdb9e85ce44c5c0c99addc777dd7b6085153""]","[""feat"", ""cicd""]"
"verify process responses for deploy command

Tests should generally only fail for 1 reason, but the first test case
(`shouldDeployResourceFromFile`) verifies multiple unrelated things.

To align with the other test cases in this class, it makes sense that
this test case only verifies that the gateway service was called with a
specific request.

We can extract the verification of the response into a separate test.
This can also be applied to the shouldDeployMultipleResources test case.","diff --git a/clients/java/src/test/java/io/camunda/zeebe/client/process/DeployResourceTest.java b/clients/java/src/test/java/io/camunda/zeebe/client/process/DeployResourceTest.java
index 1d96c74..b65d9f3 100644
--- a/clients/java/src/test/java/io/camunda/zeebe/client/process/DeployResourceTest.java
+++ b/clients/java/src/test/java/io/camunda/zeebe/client/process/DeployResourceTest.java
@@ -22,7 +22,6 @@ import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
 import io.camunda.zeebe.client.api.command.ClientException;
 import io.camunda.zeebe.client.api.response.DeploymentEvent;
-import io.camunda.zeebe.client.api.response.Process;
 import io.camunda.zeebe.client.impl.command.StreamUtil;
 import io.camunda.zeebe.client.impl.response.ProcessImpl;
 import io.camunda.zeebe.client.util.ClientTest;
@@ -35,7 +34,6 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.util.List;
 import org.junit.Test;
 
 public final class DeployResourceTest extends ClientTest {
@@ -49,25 +47,15 @@ public final class DeployResourceTest extends ClientTest {
   @Test
   public void shouldDeployResourceFromFile() {
     // given
-    final long key = 123L;
-    final String filename = DeployResourceTest.class.getResource(BPMN_1_FILENAME).getPath();
-    gatewayService.onDeployResourceRequest(
-        key, deployedResource(deployedProcess(BPMN_1_PROCESS_ID, 12, 423, filename)));
-    final Process expected = new ProcessImpl(423, BPMN_1_PROCESS_ID, 12, filename);
+    final String path = DeployResourceTest.class.getResource(BPMN_1_FILENAME).getPath();
 
     // when
-    final DeploymentEvent response =
-        client.newDeployCommand().addResourceFile(filename).send().join();
+    client.newDeployCommand().addResourceFile(path).send().join();
 
     // then
-    assertThat(response.getKey()).isEqualTo(key);
-
-    final List<Process> processes = response.getProcesses();
-    assertThat(processes).containsOnly(expected);
-
     final DeployResourceRequest request = gatewayService.getLastRequest();
     final Resource resource = request.getResources(0);
-    assertThat(resource.getName()).isEqualTo(filename);
+    assertThat(resource.getName()).isEqualTo(path);
     assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
   }
 
@@ -114,7 +102,6 @@ public final class DeployResourceTest extends ClientTest {
     // then
     final DeployResourceRequest request = gatewayService.getLastRequest();
     final Resource resource = request.getResources(0);
-
     assertThat(resource.getName()).isEqualTo(filename);
     assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
   }
@@ -135,7 +122,6 @@ public final class DeployResourceTest extends ClientTest {
     // then
     final DeployResourceRequest request = gatewayService.getLastRequest();
     final Resource resource = request.getResources(0);
-
     assertThat(resource.getName()).isEqualTo(filename);
     assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
   }
@@ -152,7 +138,6 @@ public final class DeployResourceTest extends ClientTest {
     // then
     final DeployResourceRequest request = gatewayService.getLastRequest();
     final Resource resource = request.getResources(0);
-
     assertThat(resource.getName()).isEqualTo(filename);
     assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
   }
@@ -174,7 +159,6 @@ public final class DeployResourceTest extends ClientTest {
     // then
     final DeployResourceRequest request = gatewayService.getLastRequest();
     final Resource resource = request.getResources(0);
-
     assertThat(resource.getName()).isEqualTo(filename);
     assertThat(resource.getContent().toByteArray()).isEqualTo(expectedBytes);
   }
@@ -183,13 +167,58 @@ public final class DeployResourceTest extends ClientTest {
   public void shouldDeployMultipleResources() {
     // given
     final long key = 345L;
-
     final String filename1 = BPMN_1_FILENAME.substring(1);
     final String filename2 = BPMN_2_FILENAME.substring(1);
+    gatewayService.onDeployResourceRequest(
+        key,
+        deployedResource(deployedProcess(BPMN_1_PROCESS_ID, 1, 1, filename1)),
+        deployedResource(deployedProcess(BPMN_2_PROCESS_ID, 1, 2, filename2)));
 
-    final Process expected1 = new ProcessImpl(1, BPMN_1_PROCESS_ID, 1, filename1);
-    final Process expected2 = new ProcessImpl(2, BPMN_2_PROCESS_ID, 1, filename2);
+    // when
+    client
+        .newDeployCommand()
+        .addResourceFromClasspath(filename1)
+        .addResourceFromClasspath(filename2)
+        .send()
+        .join();
 
+    // then
+    final DeployResourceRequest request = gatewayService.getLastRequest();
+    assertThat(request.getResourcesList()).hasSize(2);
+
+    final Resource resource1 = request.getResources(0);
+    assertThat(resource1.getName()).isEqualTo(filename1);
+    assertThat(resource1.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
+
+    final Resource resource2 = request.getResources(1);
+    assertThat(resource2.getName()).isEqualTo(filename2);
+    assertThat(resource2.getContent().toByteArray()).isEqualTo(getBytes(BPMN_2_FILENAME));
+  }
+
+  @Test
+  public void shouldDeployProcessAsResource() {
+    // given
+    final long key = 123L;
+    final String filename = DeployResourceTest.class.getResource(BPMN_1_FILENAME).getPath();
+    gatewayService.onDeployResourceRequest(
+        key, deployedResource(deployedProcess(BPMN_1_PROCESS_ID, 12, 423, filename)));
+
+    // when
+    final DeploymentEvent response =
+        client.newDeployCommand().addResourceFile(filename).send().join();
+
+    // then
+    assertThat(response.getKey()).isEqualTo(key);
+    assertThat(response.getProcesses())
+        .containsExactly(new ProcessImpl(423, BPMN_1_PROCESS_ID, 12, filename));
+  }
+
+  @Test
+  public void shouldDeployMultipleProcessesAsResources() {
+    // given
+    final long key = 345L;
+    final String filename1 = BPMN_1_FILENAME.substring(1);
+    final String filename2 = BPMN_2_FILENAME.substring(1);
     gatewayService.onDeployResourceRequest(
         key,
         deployedResource(deployedProcess(BPMN_1_PROCESS_ID, 1, 1, filename1)),
@@ -206,21 +235,10 @@ public final class DeployResourceTest extends ClientTest {
 
     // then
     assertThat(response.getKey()).isEqualTo(key);
-
-    final List<Process> processes = response.getProcesses();
-    assertThat(processes).containsOnly(expected1, expected2);
-
-    final DeployResourceRequest request = gatewayService.getLastRequest();
-    assertThat(request.getResourcesList()).hasSize(2);
-
-    Resource resource = request.getResources(0);
-
-    assertThat(resource.getName()).isEqualTo(filename1);
-    assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_1_FILENAME));
-
-    resource = request.getResources(1);
-    assertThat(resource.getName()).isEqualTo(filename2);
-    assertThat(resource.getContent().toByteArray()).isEqualTo(getBytes(BPMN_2_FILENAME));
+    assertThat(response.getProcesses())
+        .containsExactly(
+            new ProcessImpl(1, BPMN_1_PROCESS_ID, 1, filename1),
+            new ProcessImpl(2, BPMN_2_PROCESS_ID, 1, filename2));
   }
 
   @Test
",1,"[""390eadc270d027493722cdbe9c8f4140d027e473""]","[""test""]"
Publish crates | wire up fixed null encoding,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7b98b44..f17ad6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,9 @@
 
 - **(css/parser)** Fix parsing of at rules (#3328) ([506a310](https://github.com/swc-project/swc/commit/506a31078aaebf50129658f096bbd5929995205f))
 
+
+- **(es/compat)** Fix regression of `destructuring` (#3326) ([6d1ad36](https://github.com/swc-project/swc/commit/6d1ad368aca53ee64a63ae565cd015909f2f4458))
+
 ### Performance
 
 
diff --git a/Cargo.lock b/Cargo.lock
index 3c6598b..4baa252 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2652,7 +2652,7 @@ dependencies = [
 
 [[package]]
 name = ""swc""
-version = ""0.116.15""
+version = ""0.116.16""
 dependencies = [
  ""ahash"",
  ""anyhow"",
@@ -3097,7 +3097,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms""
-version = ""0.113.3""
+version = ""0.113.4""
 dependencies = [
  ""pretty_assertions 0.7.2"",
  ""sourcemap"",
@@ -3157,7 +3157,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms_compat""
-version = ""0.68.2""
+version = ""0.68.3""
 dependencies = [
  ""ahash"",
  ""arrayvec 0.7.2"",
@@ -3366,7 +3366,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecmascript""
-version = ""0.110.14""
+version = ""0.110.15""
 dependencies = [
  ""swc_ecma_ast"",
  ""swc_ecma_codegen"",
diff --git a/crates/swc/Cargo.toml b/crates/swc/Cargo.toml
index 756cfc8..2f02d22 100644
--- a/crates/swc/Cargo.toml
+++ b/crates/swc/Cargo.toml
@@ -9,7 +9,7 @@ include = [""Cargo.toml"", ""src/**/*.rs""]
 license = ""Apache-2.0""
 name = ""swc""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.116.15""
+version = ""0.116.16""
 
 [lib]
 name = ""swc""
@@ -55,7 +55,7 @@ swc_ecma_loader = {version = ""0.27.0"", path = ""../swc_ecma_loader"", features = [
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env""}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", features = [
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", features = [
   ""compat"",
   ""module"",
   ""optimization"",
@@ -64,11 +64,11 @@ swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", fea
   ""typescript"",
 ]}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat""}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat""}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization""}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils""}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit""}
-swc_ecmascript = {version = ""0.110.14"", path = ""../swc_ecmascript""}
+swc_ecmascript = {version = ""0.110.15"", path = ""../swc_ecmascript""}
 swc_node_comments = {version = ""0.4.0"", path = ""../swc_node_comments""}
 swc_plugin_runner = {version = ""0.30.0"", path = ""../swc_plugin_runner"", optional = true}
 swc_visit = {version = ""0.3.0"", path = ""../swc_visit""}
diff --git a/crates/swc_ecma_transforms/Cargo.toml b/crates/swc_ecma_transforms/Cargo.toml
index 1604f4e..a0aafae 100644
--- a/crates/swc_ecma_transforms/Cargo.toml
+++ b/crates/swc_ecma_transforms/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.113.3""
+version = ""0.113.4""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -28,7 +28,7 @@ swc_common = {version = ""0.17.0"", path = ""../swc_common""}
 swc_ecma_ast = {version = ""0.65.0"", path = ""../swc_ecma_ast""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat"", optional = true}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat"", optional = true}
 swc_ecma_transforms_module = {version = ""0.74.0"", path = ""../swc_ecma_transforms_module"", optional = true}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization"", optional = true}
 swc_ecma_transforms_proposal = {version = ""0.74.0"", path = ""../swc_ecma_transforms_proposal"", optional = true}
diff --git a/crates/swc_ecma_transforms_compat/Cargo.toml b/crates/swc_ecma_transforms_compat/Cargo.toml
index 0ea6609..58374e3 100644
--- a/crates/swc_ecma_transforms_compat/Cargo.toml
+++ b/crates/swc_ecma_transforms_compat/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms_compat""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.68.2""
+version = ""0.68.3""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
diff --git a/crates/swc_ecmascript/Cargo.toml b/crates/swc_ecmascript/Cargo.toml
index 63680a0..775208a 100644
--- a/crates/swc_ecmascript/Cargo.toml
+++ b/crates/swc_ecmascript/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecmascript""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.110.14""
+version = ""0.110.15""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -39,7 +39,7 @@ swc_ecma_dep_graph = {version = ""0.58.0"", path = ""../swc_ecma_dep_graph"", option
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier"", optional = true}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser"", optional = true, default-features = false}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env"", optional = true}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", optional = true}
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", optional = true}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils"", optional = true}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit"", optional = true}
 

diff --git a/read_buffer/src/row_group.rs b/read_buffer/src/row_group.rs
index 91c9fb5..ca77f3c 100644
--- a/read_buffer/src/row_group.rs
+++ b/read_buffer/src/row_group.rs
@@ -958,24 +958,15 @@ impl From<RecordBatch> for RowGroup {
                 }
                 Some(InfluxColumnType::Field(_)) => {
                     let column_data = match arrow_column.data_type() {
-                        arrow::datatypes::DataType::Int64 => Column::from(
-                            arrow_column
-                                .as_any()
-                                .downcast_ref::<arrow::array::Int64Array>()
-                                .unwrap(),
-                        ),
-                        arrow::datatypes::DataType::Float64 => Column::from(
-                            arrow_column
-                                .as_any()
-                                .downcast_ref::<arrow::array::Float64Array>()
-                                .unwrap(),
-                        ),
-                        arrow::datatypes::DataType::UInt64 => Column::from(
-                            arrow_column
-                                .as_any()
-                                .downcast_ref::<arrow::array::UInt64Array>()
-                                .unwrap(),
-                        ),
+                        arrow::datatypes::DataType::Int64 => {
+                            Column::from(arrow::array::Int64Array::from(arrow_column.data()))
+                        }
+                        arrow::datatypes::DataType::Float64 => {
+                            Column::from(arrow::array::Float64Array::from(arrow_column.data()))
+                        }
+                        arrow::datatypes::DataType::UInt64 => {
+                            Column::from(arrow::array::UInt64Array::from(arrow_column.data()))
+                        }
                         dt => unimplemented!(
                             ""data type {:?} currently not supported for field columns"",
                             dt
",2,"[""af53b9487f74ff28438928903fb1f2db93fe4fa8"", ""28b596b8834d1b51be3ac6a2ac30df28f37702d8""]","[""build"", ""refactor""]"
remove unnecessary start argument from `range`,"diff --git a/ibis/backends/dask/tests/execution/test_window.py b/ibis/backends/dask/tests/execution/test_window.py
index 75a7331..6bfc5e3 100644
--- a/ibis/backends/dask/tests/execution/test_window.py
+++ b/ibis/backends/dask/tests/execution/test_window.py
@@ -489,7 +489,7 @@ def test_project_list_scalar(npartitions):
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pandas/tests/execution/test_window.py b/ibis/backends/pandas/tests/execution/test_window.py
index 8f292b3..effa372 100644
--- a/ibis/backends/pandas/tests/execution/test_window.py
+++ b/ibis/backends/pandas/tests/execution/test_window.py
@@ -436,7 +436,7 @@ def test_project_list_scalar():
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pyspark/tests/test_basic.py b/ibis/backends/pyspark/tests/test_basic.py
index 3850919..14fe677 100644
--- a/ibis/backends/pyspark/tests/test_basic.py
+++ b/ibis/backends/pyspark/tests/test_basic.py
@@ -19,7 +19,7 @@ from ibis.backends.pyspark.compiler import _can_be_replaced_by_column_name  # no
 def test_basic(con):
     table = con.table(""basic_table"")
     result = table.compile().toPandas()
-    expected = pd.DataFrame({""id"": range(0, 10), ""str_col"": ""value""})
+    expected = pd.DataFrame({""id"": range(10), ""str_col"": ""value""})
 
     tm.assert_frame_equal(result, expected)
 
@@ -28,9 +28,7 @@ def test_projection(con):
     table = con.table(""basic_table"")
     result1 = table.mutate(v=table[""id""]).compile().toPandas()
 
-    expected1 = pd.DataFrame(
-        {""id"": range(0, 10), ""str_col"": ""value"", ""v"": range(0, 10)}
-    )
+    expected1 = pd.DataFrame({""id"": range(10), ""str_col"": ""value"", ""v"": range(10)})
 
     result2 = (
         table.mutate(v=table[""id""])
@@ -44,8 +42,8 @@ def test_projection(con):
         {
             ""id"": range(0, 20, 2),
             ""str_col"": ""value"",
-            ""v"": range(0, 10),
-            ""v2"": range(0, 10),
+            ""v"": range(10),
+            ""v2"": range(10),
         }
     )
 
",1,"[""15f8d95754a0b6865ea475ca9e515272a07bf6ba""]","[""refactor""]"
"[gn win] link comctl32.lib to fix component build | remove broken link

Fixes #1785 | reject deploy signal process for tenant","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/docs/content/Caching/Caching.md b/docs/content/Caching/Caching.md
index d873a52..9706dda 100644
--- a/docs/content/Caching/Caching.md
+++ b/docs/content/Caching/Caching.md
@@ -135,8 +135,9 @@ If nothing is found in the cache, the query is executed in the database and the 
 is returned as well as updating the cache.
 
 If an existing value is present in the cache and the `refreshKey` value for
-the query hasn't changed, the cached value will be returned. Otherwise, a
-[query renewal](#in-memory-cache-force-query-renewal) will be performed.
+the query hasn't changed, the cached value will be returned. Otherwise, a SQL query will be executed either against the pre-aggregations storage or the source database to populate the cache with the results and return them.
+
+
 
 ### Refresh Keys
 

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/multitenancy/TenantAwareSignalEventTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/multitenancy/TenantAwareSignalEventTest.java
new file mode 100644
index 0000000..125b292
--- /dev/null
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/multitenancy/TenantAwareSignalEventTest.java
@@ -0,0 +1,303 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.processing.multitenancy;
+
+import static io.camunda.zeebe.protocol.record.Assertions.assertThat;
+
+import io.camunda.zeebe.engine.util.EngineRule;
+import io.camunda.zeebe.model.bpmn.Bpmn;
+import io.camunda.zeebe.protocol.record.RejectionType;
+import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
+import io.camunda.zeebe.protocol.record.intent.SignalIntent;
+import io.camunda.zeebe.protocol.record.value.TenantOwned;
+import io.camunda.zeebe.test.util.Strings;
+import io.camunda.zeebe.test.util.record.RecordingExporter;
+import io.camunda.zeebe.test.util.record.RecordingExporterTestWatcher;
+import java.time.Duration;
+import org.junit.Before;
+import org.junit.ClassRule;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.TestWatcher;
+
+public class TenantAwareSignalEventTest {
+
+  @ClassRule public static final EngineRule ENGINE = EngineRule.singlePartition();
+
+  @Rule public final TestWatcher testWatcher = new RecordingExporterTestWatcher();
+  private String processId;
+  private String signalName;
+
+  @Before
+  public void setup() {
+    processId = Strings.newRandomValidBpmnId();
+    signalName = ""signal-%s"".formatted(processId);
+  }
+
+  @Test
+  public void shouldBroadcastSignalForDefaultTenant() {
+    // given
+    ENGINE
+        .deployment()
+        .withXmlResource(
+            Bpmn.createExecutableProcess(processId)
+                .startEvent(""signal-start"")
+                .signal(signalName)
+                .endEvent()
+                .done())
+        .withTenantId(TenantOwned.DEFAULT_TENANT_IDENTIFIER)
+        .deploy();
+
+    // when
+    final var broadcasted = ENGINE.signal().withSignalName(signalName).broadcast();
+
+    // then
+    assertThat(broadcasted)
+        .describedAs(""Expect that signal was broadcasted successful"")
+        .hasIntent(SignalIntent.BROADCASTED);
+
+    assertThat(
+            RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_ACTIVATED)
+                .withBpmnProcessId(processId)
+                .withElementId(""signal-start"")
+                .getFirst())
+        .describedAs(""Expect that process instance was created"")
+        .isNotNull();
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent(""signal-start"")
+                    .signal(signalName)
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-start' of type 'SIGNAL' 'START_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalCatchEventForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent()
+                    .intermediateCatchEvent(""signal-catch"")
+                    .signal(signalName)
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-catch' of type 'SIGNAL' 'INTERMEDIATE_CATCH_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void
+      shouldRejectDeployProcessWithSignalCatchEventAttachedToEventBasedGatewayForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent()
+                    .eventBasedGateway()
+                    .intermediateCatchEvent(""signal-catch-attached"")
+                    .signal(signalName)
+                    .endEvent()
+                    .moveToLastGateway()
+                    .intermediateCatchEvent()
+                    .timerWithDuration(Duration.ofMinutes(10))
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-catch-attached' of type 'SIGNAL' 'INTERMEDIATE_CATCH_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalEventSubProcessEventForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .eventSubProcess(
+                        ""signal-sub"",
+                        sub ->
+                            sub.startEvent(""signal-start-event-sub"").signal(signalName).endEvent())
+                    .startEvent()
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-start-event-sub' of type 'SIGNAL' 'START_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalBoundaryEventForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent()
+                    .manualTask()
+                    .boundaryEvent(""signal-boundary"")
+                    .signal(signalName)
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-boundary' of type 'SIGNAL' 'BOUNDARY_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalThrowEventForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent()
+                    .intermediateThrowEvent(""signal-throw"")
+                    .signal(signalName)
+                    .endEvent()
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-throw' of type 'SIGNAL' 'INTERMEDIATE_THROW_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+
+  @Test
+  public void shouldRejectDeployProcessWithSignalEndEventForSpecificTenant() {
+    // when
+    final var rejection =
+        ENGINE
+            .deployment()
+            .withXmlResource(
+                Bpmn.createExecutableProcess(processId)
+                    .startEvent()
+                    .endEvent(""signal-end"")
+                    .signal(signalName)
+                    .done())
+            .withTenantId(""custom-tenant"")
+            .expectRejection()
+            .deploy();
+
+    // then
+    assertThat(rejection)
+        .hasRejectionType(RejectionType.INVALID_ARGUMENT)
+        .hasRejectionReason(
+            """"""
+            Expected to deploy new resources, but encountered the following errors:
+            `process.xml`: - Process: %s
+                - ERROR: Processes belonging to custom tenants are not allowed to contain elements \
+            unsupported with multi-tenancy. Only the default tenant '<default>' supports these \
+            elements currently: ['signal-end' of type 'SIGNAL' 'END_EVENT']. \
+            See https://github.com/camunda/zeebe/issues/12653 for more details.
+            """"""
+                .formatted(processId));
+  }
+}
",3,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""c351088bce98594c740a39546ce3655c91554a5d"", ""ca346bb77e7f1fb041a2d64a28ed925ed2625101""]","[""build"", ""docs"", ""test""]"
