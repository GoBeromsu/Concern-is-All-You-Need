commit_message,diff,concern_count,shas,types,reason
"move toolbar to tab content level

Signed-off-by: Pranav C <pranavxc@gmail.com>
updates the readme to improve the readability and contributing sections","diff --git a/packages/nc-gui-v2/components.d.ts b/packages/nc-gui-v2/components.d.ts
index f6be04b..cf555ef 100644
--- a/packages/nc-gui-v2/components.d.ts
+++ b/packages/nc-gui-v2/components.d.ts
@@ -201,6 +201,7 @@ declare module '@vue/runtime-core' {
     MdiThumbUp: typeof import('~icons/mdi/thumb-up')['default']
     MdiTrashCan: typeof import('~icons/mdi/trash-can')['default']
     MdiTwitter: typeof import('~icons/mdi/twitter')['default']
+    MdiUpload: typeof import('~icons/mdi/upload')['default']
     MdiUploadOutline: typeof import('~icons/mdi/upload-outline')['default']
     MdiViewListOutline: typeof import('~icons/mdi/view-list-outline')['default']
     MdiWhatsapp: typeof import('~icons/mdi/whatsapp')['default']
diff --git a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
index c2c87d3..27c0acc 100644
--- a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
+++ b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
@@ -132,7 +132,7 @@ async function changeLockType(type: LockType) {
   <div>
     <a-dropdown>
       <a-button v-t=""['c:actions']"" class=""nc-actions-menu-btn nc-toolbar-btn"">
-        <div class=""flex gap-2 align-center"">
+        <div class=""flex gap-2 items-center"">
           <component
             :is=""viewIcons[selectedView?.type].icon""
             class=""nc-view-icon group-hover:hidden""
@@ -311,6 +311,6 @@ async function changeLockType(type: LockType) {
 
 <style scoped>
 .nc-locked-menu-item > div {
-  @apply grid grid-cols-[30px,auto] gap-2  p-2 align-center;
+  @apply grid grid-cols-[30px,auto] gap-2  p-2 items-center;
 }
 </style>
diff --git a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
index 5fa555f..d498871 100644
--- a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
+++ b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
@@ -36,7 +36,7 @@ const {isOpen} =useSidebar()
 
     <SmartsheetToolbarSearchData v-if=""(isGrid || isGallery) && !isPublic"" class=""shrink mr-2 ml-2"" />
 
-    <ToggleDrawer v-if=""!isOpen""/>
+    <ToggleDrawer class=""mr-2""/>
 
 
   </div>
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
index 896ad62..77aee05 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
@@ -99,6 +99,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
     class=""relative shadow-md h-full""
     theme=""light""
   >
+    <!--
     <Toolbar
       v-if=""isOpen""
       class=""min-h-[var(--toolbar-height)] max-h-[var(--toolbar-height)]""
@@ -128,7 +129,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
         <div v-if=""!isForm"" class=""dot"" />
       </template>
     </Toolbar>
-
+-->
     <div v-if=""isOpen"" class=""flex-1 flex flex-col"">
       <MenuTop @open-modal=""openModal"" @deleted=""loadViews"" @sorted=""loadViews"" />
 
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
index 3e3d78a..8441450 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
@@ -4,7 +4,7 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
 </script>
 
 <template>
-  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
+<!--  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
     <template #title> Toggle sidebar</template>
 
     <div class=""nc-sidebar-right-item hover:after:(bg-primary bg-opacity-75) group nc-sidebar-add-row"">
@@ -14,5 +14,11 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
         @click=""toggle(!isOpen)""
       />
     </div>
-  </a-tooltip>
+  </a-tooltip>-->
+
+  <a-button @click=""toggle(!isOpen)"" size=""small"">
+  <div class=""flex items-center gap-2"">  <MdiMenu/> Views
+  </div>
+  </a-button>
+
 </template>
diff --git a/packages/nc-gui-v2/components/tabs/Smartsheet.vue b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
index 4181996..7b7ec36 100644
--- a/packages/nc-gui-v2/components/tabs/Smartsheet.vue
+++ b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
@@ -83,11 +83,11 @@ watch(isLocked, (nextValue) => (treeViewIsLockedInj.value = nextValue), { immedi
 
             <SmartsheetForm v-else-if=""isForm"" />
           </div>
+          <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
         </div>
       </template>
     </div>
 
-    <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
   </div>
 </template>
 

diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 
",2,"[""bf95d5d0b34d32ef2684488feb3de01cb824b2b4"", ""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6""]","[""refactor"", ""docs""]","1. The code changes include restructuring Vue component logic related to toolbars (moving and commenting out code, adjusting class names, etc.) and significant updates to documentation files (README.md and CONTRIBUTING.md), improving readability and contribution instructions.
2. The Vue component changes align with the 'refactor' label as they reorganize UI structure and improve code clarity without changing external behavior, while the documentation file edits align with the 'docs' label, as they exclusively enhance documentation content and instructions.
3. 'refactor' is appropriate for the component-level UI restructuring because no new features or bug fixes are introduced, only internal organization is improved; 'docs' is correct for the README and CONTRIBUTING changes as they are purely textual/documentation edits, not affecting code logic or behavior. No other labels (such as 'feat', 'fix', or 'test') are suitable given the nature of the changes.
4. The 'refactor' label accurately captures the internal code reorganization in the UI components, and the 'docs' label correctly reflects the documentation improvements, together covering the full scope of this commit."
"skip if related view/hook/column of a filter is not found

Signed-off-by: Pranav C <pranavxc@gmail.com>
Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
index 1515f88..6c250bd 100644
--- a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
+++ b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
@@ -21,7 +21,13 @@ export default async function ({ ncMeta }: NcUpgraderCtx) {
     } else {
       continue;
     }
-    if (filter.project_id != model.project_id) {
+
+    // skip if related model is not found
+    if (!model) {
+      continue;
+    }
+
+    if (filter.project_id !== model.project_id) {
       await ncMeta.metaUpdate(
         null,
         null,

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",2,"[""ab1e60a97c6d5c688dacbd23bca40cb8f20c4ac3"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""fix"", ""feat""]","1. The change in 'ncFilterUpgrader.ts' adds a check to skip processing if a related model is not found, preventing errors from missing dependencies; the changes in 'config.go', 'name.go', and 'defaults.go' introduce and apply the ability to specify a release name template in configuration and default pipeline logic.
2. The first change addresses a bug by ensuring the code safely handles missing related models, aligning with the 'fix' label definition; the second set of changes adds a new feature by introducing a configurable release name, matching the 'feat' label.
3. 'fix' is appropriate for the filter upgrader change because it resolves a potential runtime fault rather than adding new capability or refactoring; 'feat' is correct for the release name template additions since they introduce new user-facing functionality, not merely restructuring or documentation.
4. The assignment of 'fix' for the error-handling logic and 'feat' for the new configuration option accurately reflects the motivation and essence of each code unit in the commit."
add tests for ProfilePage methods,"diff --git a/client/src/components/Profile/PreScreeningIviewCard.tsx b/client/src/components/Profile/PreScreeningIviewCard.tsx
index f84392a..2031203 100644
--- a/client/src/components/Profile/PreScreeningIviewCard.tsx
+++ b/client/src/components/Profile/PreScreeningIviewCard.tsx
@@ -27,7 +27,7 @@ type State = {
   isPreScreeningIviewModalVisible: boolean;
 };
 
-class CoreJSIviewsCard extends React.PureComponent<Props, State> {
+class PreScreeningIviewsCard extends React.PureComponent<Props, State> {
   state = {
     courseIndex: 0,
     isPreScreeningIviewModalVisible: false,
@@ -98,4 +98,4 @@ class CoreJSIviewsCard extends React.PureComponent<Props, State> {
   }
 }
 
-export default CoreJSIviewsCard;
+export default PreScreeningIviewsCard;
diff --git a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
index 7b73c3f..54b378c 100644
--- a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
@@ -1,7 +1,7 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
 exports[`PreScreeningIviewCard Should render correctly 1`] = `
-<CoreJSIviewsCard
+<PreScreeningIviewsCard
   data={
     Array [
       Object {
@@ -3015,5 +3015,5 @@ exports[`PreScreeningIviewCard Should render correctly 1`] = `
       </div>
     </Card>
   </CommonCard>
-</CoreJSIviewsCard>
+</PreScreeningIviewsCard>
 `;
diff --git a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
index 079d966..95f3e49 100644
--- a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
+++ b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
@@ -4,7 +4,6 @@ import { shallowToJson } from 'enzyme-to-json';
 import { NextRouter } from 'next/router';
 import { Session } from 'components/withSession';
 import { ProfilePage } from '../index';
-// import { GeneralInfo } from '../../../../../common/models/profile';
 
 jest.mock('next/config', () => () => ({}));
 jest.mock('services/user', () => ({
@@ -12,80 +11,378 @@ jest.mock('services/user', () => ({
       getProfileInfo() {
         return jest.fn();
       }
+      saveProfileInfo() {
+        return jest.fn();
+      }
     },
   }),
 );
 
-describe('ProfilePage', () => {
-  const profile = {
-    generalInfo: {
-      name: 'Dzmitry Petrov',
-      githubId: 'petrov',
-      aboutMyself: 'Test',
+const profile = {
+  permissionsSettings: {
+    isProfileVisible: { all: true },
+    isAboutVisible: { mentor: true, student: false, all: false },
+    isEducationVisible: { mentor: true, student: false, all: false },
+    isEnglishVisible: { student: false, all: false },
+    isEmailVisible: { student: false, all: false },
+    isTelegramVisible: { student: false, all: false },
+    isSkypeVisible: { student: false, all: false },
+    isPhoneVisible: { student: false, all: false },
+    isContactsNotesVisible: { student: true, all: false },
+    isLinkedInVisible: { mentor: true, student: false, all: false },
+    isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+    isMentorStatsVisible: { mentor: true, student: true, all: false },
+    isStudentStatsVisible: { student: false, all: false },
+  },
+  generalInfo: {
+    aboutMyself: 'Test',
+    educationHistory: [{
+      graduationYear: '2019',
+      faculty: 'TT',
+      university: 'Test',
+    }],
+    englishLevel: 'a2+',
+    locationId: 456,
+    locationName: 'Brest',
+  },
+  contacts: {},
+  mentorStats: [
+    {},
+  ],
+  studentStats: [
+    {
+      courseFullName: 'test',
+      courseName: 'test',
       locationName: 'Minsk',
-      locationId: '1',
-      educationHistory: null,
-      englishLevel: 'a2+',
-    },
-    permissionsSettings: {
-      isProfileVisible: { all: true },
-      isAboutVisible: { mentor: true, student: false, all: false },
-      isEducationVisible: { mentor: true, student: false, all: false },
-      isEnglishVisible: { student: false, all: false },
-      isEmailVisible: { student: false, all: false },
-      isTelegramVisible: { student: false, all: false },
-      isSkypeVisible: { student: false, all: false },
-      isPhoneVisible: { student: false, all: false },
-      isContactsNotesVisible: { student: true, all: false },
-      isLinkedInVisible: { mentor: true, student: false, all: false },
-      isPublicFeedbackVisible: { mentor: true, student: true, all: false },
-      isMentorStatsVisible: { mentor: true, student: true, all: false },
-      isStudentStatsVisible: { student: false, all: false },
-    },
-    contacts: {
-      phone: '+375292123456',
-      email: 'petro@gmail.com',
-      skype: 'petro:live',
-      telegram: 'petro',
-      notes: 'discord: @petro, instagram: @petro12',
-    },
-    isPermissionsSettingsChanged: true,
-    isProfileSettingsChanged: true,
-  };
-  const session = {
-    id: 2020,
-    githubId: 'mikhama',
-    isAdmin: true,
-    isHirer: false,
-    isActivist: false,
-    roles: {
-      1: 'mentor',
-      2: 'student',
-      11: 'mentor',
-    },
-    coursesRoles: {
-      13: [
-        'manager',
+      tasks: [
+        {
+          interviewFormAnswers: {},
+        },
       ],
     },
-  } as Session;
-  const router = {
-    query: {
-      githubId: 'petrov',
-    },
-    asPath: '/#edit/',
-  } as unknown as NextRouter;
+  ],
+  publicFeedback: [
+    {},
+  ],
+  stageInterviewFeedback: [
+    {},
+  ],
+};
+const session = {
+  id: 2020,
+  githubId: 'mikhama',
+  isAdmin: true,
+  isHirer: false,
+  isActivist: false,
+  roles: {
+    1: 'mentor',
+    2: 'student',
+    11: 'mentor',
+  },
+  coursesRoles: {
+    13: [
+      'manager',
+    ],
+  },
+} as Session;
+const router = {
+  query: {
+    githubId: 'petrov',
+  },
+  asPath: '/#edit/',
+} as unknown as NextRouter;
+const state = {
+  profile,
+  isInitialPermissionsSettingsChanged: false,
+  isInitialProfileSettingsChanged: false,
+};
 
+describe('ProfilePage', () => {
   describe('Should render correctly', () => {
-    it('if full info about profile is in the state', () => {
+    it('if full profile info is in the state', () => {
       const wrapper = shallow(
         <ProfilePage
           session={session}
           router={router}
         />,
       );
-      wrapper.setState({ profile });
+      wrapper.setState(state);
       expect(shallowToJson(wrapper)).toMatchSnapshot();
     });
   });
+
+  const wrapper = shallow(
+    <ProfilePage
+      session={session}
+      router={router}
+    />,
+  );
+  const instance = wrapper.instance();
+  describe('onPermissionsSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if permissions for student role were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEmailVisible',
+          role: 'student',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEmailVisible).toEqual({
+          student: true, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for mentor role were changed', async () => {
+        const event = {
+          target: {
+            checked: false,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isLinkedInVisible',
+          role: 'mentor',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isLinkedInVisible).toEqual({
+          mentor: false, student: false, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for all roles were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEducationVisible',
+          role: 'all',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEducationVisible).toEqual({
+          mentor: true, student: true, all: true,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('onProfileSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if ""profile.generalInfo.location"" was changed', async () => {
+        const event = {
+          id: 123,
+          name: 'Minsk',
+        }
+        const path = 'generalInfo.location';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.locationId).toBe(123);
+        expect(wrapper.state().profile.generalInfo.locationName).toBe('Minsk');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if ""profile.generalInfo.englishLevel"" was changed', async () => {
+        const event = 'b2+';
+        const path = 'generalInfo.englishLevel';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.englishLevel).toBe('b2+');
+      });
+      it('if field added to ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'add',
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([
+          {
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          },
+          {
+            graduationYear: null,
+            faculty: null,
+            university: null,
+          },
+        ]);
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if field deleted from ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'delete',
+          index: 0,
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([]);
+      });
+      it('if some other field was changed', async () => {
+        const event = {
+          target: {
+            value: 'Hello everyone, my name is Mike.',
+          }
+        };
+        const path = 'generalInfo.aboutMyself';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.aboutMyself).toEqual('Hello everyone, my name is Mike.');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('changeProfilePageMode', () => {
+    describe('Should set state correctly', () => {
+      it('if mode = ""edit"" was passed', async () => {
+        const mode = 'edit';
+        wrapper.setState({ ...state, isEditingModeEnabled: false });
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+      });
+      it('if mode = ""view"" was passed', async () => {
+        const mode = 'view';
+        wrapper.setState({ ...state, isEditingModeEnabled: true });
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+      });
+    });
+  });
+  describe('saveProfile', () => {
+    it('Should set state correctly', async () => {
+      const profile = {
+        generalInfo: {
+          aboutMyself: 'Hello',
+          educationHistory: [{
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          }],
+          englishLevel: 'c1',
+          locationId: 778,
+          locationName: 'Hrodna',
+        },
+        contacts: {
+          telegram: 'test',
+        },
+        permissionsSettings: {
+          isProfileVisible: { all: true },
+          isAboutVisible: { mentor: true, student: false, all: false },
+          isEducationVisible: { mentor: true, student: false, all: false },
+          isEnglishVisible: { student: true, all: true },
+          isEmailVisible: { student: true, all: true },
+          isTelegramVisible: { student: true, all: true },
+          isSkypeVisible: { student: true, all: false },
+          isPhoneVisible: { student: true, all: false },
+          isContactsNotesVisible: { student: true, all: false },
+          isLinkedInVisible: { mentor: true, student: false, all: false },
+          isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+          isMentorStatsVisible: { mentor: true, student: true, all: false },
+          isStudentStatsVisible: { student: false, all: false },
+        },
+      };
+      wrapper.setState({
+        ...state,
+        profile,
+        isInitialPermissionsSettingsChanged: true,
+        isInitialProfileSettingsChanged: true,
+      });
+      await instance.saveProfile();
+      expect(wrapper.state().isSaving).toBe(false);
+      expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(false);
+      expect(wrapper.state().isInitialProfileSettingsChanged).toBe(false);
+      expect(wrapper.state().initialPermissionsSettings).toEqual(profile.permissionsSettings);
+      expect(wrapper.state().initialProfileSettings).toEqual(profile);
+    });
+  });
+  describe('hadStudentCoreJSInterview', () => {
+    describe('Should return', () => {
+      it('""true"" if student has an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {
+                interviewFormAnswers: {},
+              },
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(true);
+      });
+      it('""false"" if student has not an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(false);
+      });
+    });
+  });
+  describe('getStudentCoreJSInterviews', () => {
+    it('Should return info about CoreJS interviews', () => {
+      const studentStats = [
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          locationName: 'Minsk',
+          tasks: [
+            {},
+            {},
+            {
+              interviewer: {
+                name: 'Dima Petrov',
+                githubId: 'dip',
+              },
+              comment: 'Test',
+              score: 9,
+              interviewFormAnswers: {},
+            },
+            {},
+          ],
+        },
+      ];
+      const result = instance.getStudentCoreJSInterviews(studentStats);
+      expect(result).toEqual([
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          interview: {
+            answers: {},
+            interviewer: {
+              name: 'Dima Petrov',
+              githubId: 'dip',
+            },
+            comment: 'Test',
+            score: 9,
+          },
+          locationName: 'Minsk',
+        },
+      ]);
+    });
+  });
 });
diff --git a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
index fbd133c..729b2de 100644
--- a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
+++ b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
@@ -1,6 +1,6 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
-exports[`ProfilePage Should render correctly if  1`] = `
+exports[`ProfilePage Should render correctly if full profile info is in the state 1`] = `
 <Fragment>
   <LoadingScreen
     show={true}
@@ -50,12 +50,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -135,12 +139,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -220,12 +228,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -305,12 +317,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -387,15 +403,7 @@ exports[`ProfilePage Should render correctly if  1`] = `
             }
           >
             <ContactsCard
-              data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
+              data={Object {}}
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
               onProfileSettingsChange={[Function]}
@@ -461,84 +469,22 @@ exports[`ProfilePage Should render correctly if  1`] = `
               }
             />
           </div>
-        </Masonry>
-        <JSXStyle
-          id=""3803498300""
-        >
-          div.jsx-3803498300{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-left:-16px;width:auto;}
-        </JSXStyle>
-        <JSXStyle
-          id=""110195169""
-        >
-          div.jsx-110195169{padding-left:16px;background-clip:padding-box;}
-        </JSXStyle>
-      </div>
-    </Spin>
-  </LoadingScreen>
-</Fragment>
-`;
-
-exports[`ProfilePage Should render correctly if full info about profile is in the state 1`] = `
-<Fragment>
-  <LoadingScreen
-    show={true}
-  >
-    <Header
-      isProfileEditingModeEnabled={false}
-      isProfilePage={false}
-      isSaveButtonVisible={false}
-      onChangeProfilePageMode={[Function]}
-      onSaveClick={[Function]}
-      username=""mikhama""
-    />
-    <Spin
-      delay={200}
-      size=""default""
-      spinning={false}
-      wrapperClassName=""""
-    >
-      <div
-        style={
-          Object {
-            ""padding"": 10,
-          }
-        }
-      >
-        <Masonry
-          breakpointCols={
-            Object {
-              ""1100"": 3,
-              ""500"": 1,
-              ""700"": 2,
-              ""default"": 4,
-            }
-          }
-          className=""jsx-3803498300""
-          columnClassName=""jsx-110195169""
-        >
           <div
-            key=""card-0""
+            key=""card-5""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <MainCard
+            <PublicFeedbackCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -602,28 +548,30 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-1""
+            key=""card-6""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <AboutCard
+            <StudentStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""locationName"": ""Minsk"",
+                    ""tasks"": Array [
+                      Object {
+                        ""interviewFormAnswers"": Object {},
+                      },
+                    ],
+                  },
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -687,28 +635,21 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-2""
+            key=""card-7""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EnglishCard
+            <MentorStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -772,170 +713,44 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-3""
+            key=""card-8""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EducationCard
+            <CoreJSIviewsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""interview"": Object {
+                      ""answers"": Object {},
+                      ""comment"": undefined,
+                      ""interviewer"": undefined,
+                      ""score"": undefined,
+                    },
+                    ""locationName"": ""Minsk"",
+                  },
+                ]
               }
             />
           </div>
           <div
-            key=""card-4""
+            key=""card-9""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <ContactsCard
+            <PreScreeningIviewsCard
               data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {},
+                ]
               }
             />
           </div>
",1,"[""11ffd5174bd61a2939ae58d2b2d43284302ae490""]","[""test""]","1. The commit adds and updates test logic for the ProfilePage component, including new and expanded Jest/Enzyme test cases, and updates related snapshot files to reflect changes in test structure and expected outputs.
2. These changes are entirely within test files and snapshot files, focusing on verifying component methods and rendering, which directly aligns with the 'test' object label definition for modifications dedicated to testing logic.
3. The 'test' label is appropriate because the modifications are exclusively for test artifacts; no production code logic, documentation, build, or CI/CD configuration files are affected, and the intent is not to fix a bug or refactor but to expand test coverage.
4. The 'test' label correctly represents that this commit is solely concerned with adding and updating test logic and related snapshots for the ProfilePage component."
"build improvements
reintroduce timeout for assertion

The timeout had been removed by a previous commit. Without the timeout the test might be flaky.
Also removed obsolete code","diff --git a/.travis.yml b/.travis.yml
index 9e1b926..3144244 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -1,5 +1,6 @@
 language: node_js
 dist: trusty
+sudo: required
 node_js:
   - '6.9.5'
 before_install:
diff --git a/e2e/schematics/command-line.test.ts b/e2e/schematics/command-line.test.ts
index 16d8b34..ea91494 100644
--- a/e2e/schematics/command-line.test.ts
+++ b/e2e/schematics/command-line.test.ts
@@ -68,8 +68,6 @@ describe('Command line', () => {
 
       updateFile('apps/myapp/src/app/app.component.spec.ts', `import '@nrwl/mylib';`);
 
-      updateRunAffectedToWorkInE2ESetup();
-
       const affectedApps = runCommand('npm run affected:apps -- --files=""libs/mylib/index.ts""');
       expect(affectedApps).toContain('myapp');
       expect(affectedApps).not.toContain('myapp2');
@@ -147,11 +145,3 @@ describe('Command line', () => {
     1000000
   );
 });
-
-function updateRunAffectedToWorkInE2ESetup() {
-  const runAffected = readFile('node_modules/@nrwl/schematics/src/command-line/affected.js');
-  const newRunAffected = runAffected
-    .replace('ng build', '../../node_modules/.bin/ng build')
-    .replace('ng e2e', '../../node_modules/.bin/ng e2e');
-  updateFile('node_modules/@nrwl/schematics/src/command-line/affected.js', newRunAffected);
-}
diff --git a/e2e/schematics/workspace.test.ts b/e2e/schematics/workspace.test.ts
index 8a41070..8749926 100644
--- a/e2e/schematics/workspace.test.ts
+++ b/e2e/schematics/workspace.test.ts
@@ -82,7 +82,7 @@ describe('Nrwl Convert to Nx Workspace', () => {
 
   it('should generate a workspace and not change dependencies or devDependencies if they already exist', () => {
     // create a new AngularCLI app
-    runNgNew('--skip-install');
+    runNgNew();
     const nxVersion = '0.0.0';
     const schematicsVersion = '0.0.0';
     const ngrxVersion = '0.0.0';
diff --git a/e2e/utils.ts b/e2e/utils.ts
index 422d866..a03104f 100644
--- a/e2e/utils.ts
+++ b/e2e/utils.ts
@@ -17,8 +17,7 @@ export function newProject(): void {
     copyMissingPackages();
     execSync('mv ./tmp/proj ./tmp/proj_backup');
   }
-  execSync('cp -r ./tmp/proj_backup ./tmp/proj');
-  setUpSynLink();
+  execSync('cp -a ./tmp/proj_backup ./tmp/proj');
 }
 
 export function copyMissingPackages(): void {
@@ -26,14 +25,9 @@ export function copyMissingPackages(): void {
   modulesToCopy.forEach(m => copyNodeModule(projectName, m));
 }
 
-export function setUpSynLink(): void {
-  execSync(`ln -s ../@nrwl/schematics/src/command-line/nx.js tmp/${projectName}/node_modules/.bin/nx`);
-  execSync(`chmod +x tmp/${projectName}/node_modules/.bin/nx`);
-}
-
 function copyNodeModule(path: string, name: string) {
   execSync(`rm -rf tmp/${path}/node_modules/${name}`);
-  execSync(`cp -r node_modules/${name} tmp/${path}/node_modules/${name}`);
+  execSync(`cp -a node_modules/${name} tmp/${path}/node_modules/${name}`);
 }
 
 export function runCLI(
@@ -43,7 +37,7 @@ export function runCLI(
   }
 ): string {
   try {
-    return execSync(`../../node_modules/.bin/ng ${command}`, {
+    return execSync(`./node_modules/.bin/ng ${command}`, {
       cwd: `./tmp/${projectName}`
     })
       .toString()
@@ -67,7 +61,7 @@ export function newLib(name: string): string {
 }
 
 export function runSchematic(command: string): string {
-  return execSync(`../../node_modules/.bin/schematics ${command}`, {
+  return execSync(`./node_modules/.bin/schematics ${command}`, {
     cwd: `./tmp/${projectName}`
   }).toString();
 }
diff --git a/package.json b/package.json
index bef54f8..9186a58 100644
--- a/package.json
+++ b/package.json
@@ -6,7 +6,7 @@
   ""private"": true,
   ""scripts"": {
     ""build"": ""./scripts/build.sh"",
-    ""e2e"": ""yarn build && ./scripts/e2e.sh"",
+    ""e2e"": ""./scripts/e2e.sh"",
     ""format"": ""./scripts/format.sh"",
     ""linknpm"": ""./scripts/link.sh"",
     ""package"": ""./scripts/package.sh"",
@@ -14,7 +14,7 @@
     ""copy"": ""./scripts/copy.sh"",
     ""test:schematics"": ""yarn build && ./scripts/test_schematics.sh"",
     ""test:nx"": ""yarn build && ./scripts/test_nx.sh"",
-    ""test"": ""yarn build && ./scripts/test_nx.sh && ./scripts/test_schematics.sh"",
+    ""test"": ""yarn linknpm && ./scripts/test_nx.sh && ./scripts/test_schematics.sh"",
     ""checkformat"": ""./scripts/check-format.sh"",
     ""publish_npm"": ""./scripts/publish.sh""
   },
diff --git a/packages/schematics/src/collection/workspace/index.ts b/packages/schematics/src/collection/workspace/index.ts
index 8f8897f..c70d161 100644
--- a/packages/schematics/src/collection/workspace/index.ts
+++ b/packages/schematics/src/collection/workspace/index.ts
@@ -254,20 +254,7 @@ function moveFiles(options: Schema) {
 
 function copyAngularCliTgz() {
   return (host: Tree) => {
-    copyFile(
-      path.join(
-        'node_modules',
-        '@nrwl',
-        'schematics',
-        'src',
-        'collection',
-        'application',
-        'files',
-        '__directory__',
-        '.angular_cli.tgz'
-      ),
-      '.'
-    );
+    copyFile(path.join(__dirname, '..', 'application', 'files', '__directory__', '.angular_cli.tgz'), '.');
     return host;
   };
 }
diff --git a/packages/schematics/src/command-line/affected.ts b/packages/schematics/src/command-line/affected.ts
index b7f9173..89a4f72 100644
--- a/packages/schematics/src/command-line/affected.ts
+++ b/packages/schematics/src/command-line/affected.ts
@@ -1,5 +1,7 @@
 import { execSync } from 'child_process';
 import { getAffectedApps, parseFiles } from './shared';
+import * as path from 'path';
+import * as resolve from 'resolve';
 
 export function affected(args: string[]): void {
   const command = args[0];
@@ -39,7 +41,7 @@ function build(apps: string[], rest: string[]) {
   if (apps.length > 0) {
     console.log(`Building ${apps.join(', ')}`);
     apps.forEach(app => {
-      execSync(`ng build ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
+      execSync(`${ngPath()} build ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
     });
   } else {
     console.log('No apps to build');
@@ -50,9 +52,13 @@ function e2e(apps: string[], rest: string[]) {
   if (apps.length > 0) {
     console.log(`Testing ${apps.join(', ')}`);
     apps.forEach(app => {
-      execSync(`ng e2e ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
+      execSync(`${ngPath()} e2e ${rest.join(' ')} -a=${app}`, { stdio: [0, 1, 2] });
     });
   } else {
-    console.log('No apps to tst');
+    console.log('No apps to test');
   }
 }
+
+function ngPath() {
+  return `${path.dirname(path.dirname(path.dirname(resolve.sync('@angular/cli', { basedir: __dirname }))))}/bin/ng`;
+}
diff --git a/scripts/build.sh b/scripts/build.sh
index ac533b5..9b8891b 100755
--- a/scripts/build.sh
+++ b/scripts/build.sh
@@ -3,6 +3,8 @@
 rm -rf build
 ngc
 rsync -a --exclude=*.ts packages/ build/packages
+chmod +x build/packages/schematics/bin/create-nx-workspace.js
+chmod +x build/packages/schematics/src/command-line/nx.js
 rm -rf build/packages/install
 cp README.md build/packages/schematics
 cp README.md build/packages/nx
\ No newline at end of file

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
index d0ee4f3..c2ab83c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -13,6 +13,7 @@ import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTI
 import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
 import static java.util.function.Predicate.isEqual;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.ArgumentMatchers.eq;
@@ -30,7 +31,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.streamprocessor.StreamProcessor.Phase;
 import io.camunda.zeebe.streamprocessor.StreamProcessorMode;
-import org.awaitility.Awaitility;
 import org.junit.Rule;
 import org.junit.Test;
 import org.mockito.InOrder;
@@ -71,7 +71,7 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayUntilEnd);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING));
 
@@ -163,7 +163,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
 
     // when
@@ -210,7 +210,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
     streamProcessor.pauseProcessing().join();
     replayContinuously.writeBatch(
@@ -244,7 +244,7 @@ public final class StreamProcessorReplayModeTest {
     // then
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> {
               final var lastProcessedPosition = getLastProcessedPosition(replayContinuously);
@@ -273,8 +273,7 @@ public final class StreamProcessorReplayModeTest {
 
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
-        .until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
+    await().until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
 
     // then
     assertThat(replayContinuously.getLastSuccessfulProcessedRecordPosition())
@@ -285,7 +284,6 @@ public final class StreamProcessorReplayModeTest {
   @Test
   public void shouldNotSetLastProcessedPositionIfLessThanSnapshotPosition() {
     // given
-    final var commandPositionBeforeSnapshot = 1L;
     final var snapshotPosition = 2L;
 
     startStreamProcessor(replayContinuously);
@@ -298,23 +296,20 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayContinuously);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPLAY));
 
-    final var eventPosition =
-        replayContinuously.writeEvent(
-            ELEMENT_ACTIVATING,
-            RECORD,
-            writer -> writer.sourceRecordPosition(commandPositionBeforeSnapshot));
-
     // then
     final var lastProcessedPositionState = replayContinuously.getLastProcessedPositionState();
 
-    assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
-        .describedAs(
-            ""Expected that the last processed position is not less than the snapshot position"")
-        .isEqualTo(snapshotPosition);
+    await()
+        .untilAsserted(
+            () ->
+                assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
+                    .describedAs(
+                        ""Expected that the last processed position is not less than the snapshot position"")
+                    .isEqualTo(snapshotPosition));
   }
 
   private StreamProcessor startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
",2,"[""e0a977b2d316e7612b5d72cb02cd7d78e75dbc55"", ""0d23f1b3ed22e615b9611bb4eae01d2241e64dff""]","[""build"", ""refactor""]","1. The commit modifies the CI configuration file (.travis.yml), build scripts (scripts/build.sh), package.json scripts, source code (packages/schematics/src/collection/workspace/index.ts, packages/schematics/src/command-line/affected.ts), test utilities (e2e/utils.ts), and a Java test file (StreamProcessorReplayModeTest.java), including reintroducing a timeout in a test and removing obsolete code.
2. The changes to .travis.yml, scripts/build.sh, and package.json scripts are related to build and CI/CD configuration, while the test file changes (StreamProcessorReplayModeTest.java) reintroduce a timeout for stability and remove unused code, aligning with 'refactor' for code cleanup and non-functional improvement.
3. The 'build' label is appropriate only for changes strictly affecting build configuration or scripts, while 'refactor' fits for codebase improvements that do not alter external behavior; however, the test file changes are better classified as 'test' or 'refactor' depending on whether they add new tests or just improve existing ones, but here the main motivation is to stabilize tests and remove obsolete code, fitting 'refactor'.
4. The assigned labels 'build' and 'refactor' are appropriate as the commit includes both build-system adjustments and non-behavioral code restructuring, excluding labels like 'feat', 'fix', or 'test' because no new features, bug fixes, or new tests are added."
"fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>
tests","diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.

diff --git a/client/src/components/Profile/__test__/EducationCard.test.tsx b/client/src/components/Profile/__test__/EducationCard.test.tsx
index 44b6e00..14539dd 100644
--- a/client/src/components/Profile/__test__/EducationCard.test.tsx
+++ b/client/src/components/Profile/__test__/EducationCard.test.tsx
@@ -53,7 +53,7 @@ describe('EducationCard', () => {
   });
 
   describe('filterPermissions', () => {
-    it('should left only contacts in ""permissionsSettings"" object', () => {
+    it('should left only ""isEducationVisible"" in ""permissionsSettings"" object', () => {
       const permissionsSettings = {
         isProfileVisible: { all: true },
         isAboutVisible: { all: true, mentor: true, student: true },
diff --git a/client/src/components/Profile/__test__/MainCard.test.tsx b/client/src/components/Profile/__test__/MainCard.test.tsx
index 8fb2840..552804b 100644
--- a/client/src/components/Profile/__test__/MainCard.test.tsx
+++ b/client/src/components/Profile/__test__/MainCard.test.tsx
@@ -3,6 +3,8 @@ import { shallow } from 'enzyme';
 import { shallowToJson } from 'enzyme-to-json';
 import MainCard from '../MainCard';
 
+// TODO: Known Issue: https://stackoverflow.com/questions/59942808/how-can-i-use-jest-coverage-in-next-js-styled-jsx
+
 describe('MainCard', () => {
   describe('Should render correctly', () => {
     it('if is editing mode disabled', () => {
@@ -21,49 +23,89 @@ describe('MainCard', () => {
       );
       expect(shallowToJson(output)).toMatchSnapshot();
     });
+    it('if is editing mode enabled', () => {
+      const output = shallow(
+        <MainCard
+          data={{
+            name: 'Petr Pervyi',
+            githubId: 'piter',
+            locationName: 'SPB',
+            locationId: '1',
+          }}
+          isEditingModeEnabled={true}
+          onPermissionsSettingsChange={() => {}}
+          onProfileSettingsChange={() => {}}
+        />,
+      );
+      expect(shallowToJson(output)).toMatchSnapshot();
+    });
   });
 
-  // const wrapper = shallow(
-  //   <MainCard
-  //     data={{
-  //       name: 'Petr Pervyi',
-  //       githubId: 'piter',
-  //       locationName: 'SPB',
-  //       locationId: '1',
-  //     }}
-  //     isEditingModeEnabled={false}
-  //     onPermissionsSettingsChange={() => {}}
-  //     onProfileSettingsChange={() => {}}
-  //   />);
-  // const instance = wrapper.instance();
-  // describe('showVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //     instance.showVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideVisibilitySettings', () => {
-  //   it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
-  //     instance.state.isVisibilitySettingsVisible = true;
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(true);
-  //     instance.hideVisibilitySettings();
-  //     expect(instance.state.isVisibilitySettingsVisible).toBe(false);
-  //   });
-  // });
-  // describe('showProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //     instance.showProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //   });
-  // });
-  // describe('hideProfileSettings', () => {
-  //   it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
-  //     instance.state.isProfileSettingsVisible = true;
-  //     expect(instance.state.isProfileSettingsVisible).toBe(true);
-  //     instance.hideProfileSettings();
-  //     expect(instance.state.isProfileSettingsVisible).toBe(false);
-  //   });
-  // });
+  const wrapper = shallow(
+    <MainCard
+      data={{
+        name: 'Petr Pervyi',
+        githubId: 'piter',
+        locationName: 'SPB',
+        locationId: '1',
+      }}
+      isEditingModeEnabled={false}
+      onPermissionsSettingsChange={() => {}}
+      onProfileSettingsChange={() => {}}
+    />);
+  const instance = wrapper.instance();
+  describe('showVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""true""', () => {
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+      instance.showVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+    });
+  });
+  describe('hideVisibilitySettings', () => {
+    it('should set ""state.isVisibilitySettingsVisible"" as ""false""', () => {
+      instance.state.isVisibilitySettingsVisible = true;
+      expect(instance.state.isVisibilitySettingsVisible).toBe(true);
+      instance.hideVisibilitySettings();
+      expect(instance.state.isVisibilitySettingsVisible).toBe(false);
+    });
+  });
+  describe('showProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""true""', () => {
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+      instance.showProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+    });
+  });
+  describe('hideProfileSettings', () => {
+    it('should set ""state.isProfileSettingsVisible"" as ""false""', () => {
+      instance.state.isProfileSettingsVisible = true;
+      expect(instance.state.isProfileSettingsVisible).toBe(true);
+      instance.hideProfileSettings();
+      expect(instance.state.isProfileSettingsVisible).toBe(false);
+    });
+  });
+  describe('filterPermissions', () => {
+    it('should left only ""isProfileVisible"" in ""permissionsSettings"" object', () => {
+      const permissionsSettings = {
+        isProfileVisible: { all: true },
+        isAboutVisible: { all: true, mentor: true, student: true },
+        isEducationVisible: { all: true, mentor: true, student: true },
+        isEnglishVisible: { all: false, student: false },
+        isEmailVisible: { all: true, student: true },
+        isTelegramVisible: { all: false, student: false },
+        isSkypeVisible: { all: true, student: true },
+        isPhoneVisible: { all: false, student: false },
+        isContactsNotesVisible: { all: true, student: true },
+        isLinkedInVisible: { all: false, mentor: false, student: false },
+        isPublicFeedbackVisible: { all: true, mentor: true, student: true },
+        isMentorStatsVisible: { all: true, mentor: true, student: true },
+        isStudentStatsVisible: { all: true, student: true },
+      };
+      const instance = wrapper.instance();
+      const result = instance.filterPermissions(permissionsSettings);
+      expect(result).toEqual({
+        isProfileVisible: { all: true },
+      });
+    });
+  });
 });
diff --git a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
index 40331eb..fef20dd 100644
--- a/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/MainCard.test.tsx.snap
@@ -71,3 +71,158 @@ exports[`MainCard Should render correctly if is editing mode disabled 1`] = `
   </Card>
 </Fragment>
 `;
+
+exports[`MainCard Should render correctly if is editing mode enabled 1`] = `
+<Fragment>
+  <Card
+    actions={
+      Array [
+        <ForwardRef(EditOutlined)
+          onClick={[Function]}
+        />,
+        <ForwardRef(SettingOutlined)
+          onClick={[Function]}
+        />,
+      ]
+    }
+  >
+    <GithubAvatar
+      githubId=""piter""
+      size={96}
+      style={
+        Object {
+          ""display"": ""block"",
+          ""margin"": ""0 auto 10px"",
+        }
+      }
+    />
+    <Title
+      level={1}
+      style={
+        Object {
+          ""fontSize"": 24,
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      Petr Pervyi
+    </Title>
+    <Paragraph
+      style={
+        Object {
+          ""marginBottom"": 20,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <a
+        href=""https://github.com/piter""
+        style={
+          Object {
+            ""fontSize"": 16,
+            ""marginLeft"": ""-14px"",
+          }
+        }
+        target=""_blank""
+      >
+        <ForwardRef(GithubFilled) />
+         
+        piter
+      </a>
+    </Paragraph>
+    <Paragraph
+      style={
+        Object {
+          ""margin"": 0,
+          ""textAlign"": ""center"",
+        }
+      }
+    >
+      <span
+        style={
+          Object {
+            ""marginLeft"": ""-14px"",
+          }
+        }
+      >
+        <ForwardRef(EnvironmentFilled) />
+         
+        SPB
+      </span>
+    </Paragraph>
+    <PermissionsSettingsDrawer
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+      onPermissionsSettingsChange={[Function]}
+    />
+    <ProfileSettingsDrawer
+      content={
+        <div>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Name:
+            </Text>
+          </p>
+          <p
+            style={
+              Object {
+                ""marginBottom"": 20,
+              }
+            }
+          >
+            <Input
+              onChange={[Function]}
+              placeholder=""Firstname Lastname""
+              type=""text""
+              value=""Petr Pervyi""
+            />
+          </p>
+          <p
+            style={
+              Object {
+                ""fontSize"": 18,
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <Text
+              strong={true}
+            >
+              Location:
+            </Text>
+          </p>
+          <div
+            style={
+              Object {
+                ""marginBottom"": 5,
+              }
+            }
+          >
+            <LocationSelect
+              defaultValue=""1""
+              onChange={[Function]}
+              style={
+                Object {
+                  ""width"": ""100%"",
+                }
+              }
+            />
+          </div>
+        </div>
+      }
+      hideSettings={[Function]}
+      isSettingsVisible={false}
+    />
+  </Card>
+</Fragment>
+`;
diff --git a/client/src/jest.config.js b/client/src/jest.config.js
index df39788..654f9f3 100644
--- a/client/src/jest.config.js
+++ b/client/src/jest.config.js
@@ -7,4 +7,5 @@ module.exports = {
     '^services(.*)$': '<rootDir>/services/$1',
     '^utils(.*)$': '<rootDir>/utils/$1',
   },
+  verbose: true,
 };
",2,"[""9ed3c0c4a72af977fc9150512fb6538f20a94b22"", ""f87659953e9af59bc7cb314a22dd076d988ef607""]","[""docs"", ""test""]","1. The code changes include documentation corrections in 'monorepo.md', updates to test descriptions and logic in 'EducationCard.test.tsx' and 'MainCard.test.tsx', the addition of new test cases and snapshot updates, and a configuration change in 'jest.config.js' to enable verbose output.
2. The documentation file changes align with the 'docs' label as they correct and clarify usage instructions and terminology, while all modifications within test files and snapshots, as well as the test config update, align with the 'test' label because they either improve, add, or configure tests.
3. 'docs' is appropriate for the markdown documentation change because it exclusively affects user-facing documentation, not core logic, and 'test' is correct for the test file and jest config changes since they are fully scoped to the testing infrastructure and logic; neither 'fix', 'feat', nor 'refactor' are suitable because no application logic or features are being directly changed.
4. The 'docs' and 'test' labels are appropriate because the commit is fully comprised of documentation and test-related changes, each mapped directly to their respective artifact categories."
"do not pin time in tests but only skip ahead

related to #573","diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 636cd21..76afff7 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.doRepeatedly;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
@@ -24,11 +26,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.assertj.core.util.Files;
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -38,7 +47,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -48,9 +59,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.assertj.core.util.Files;
-import org.junit.*;
-import org.junit.rules.*;
 
 public class BrokerRecoveryTest
 {
@@ -360,17 +368,12 @@ public class BrokerRecoveryTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         // wait until stream processor and scheduler process the lock task event which is not re-processed on recovery
         doRepeatedly(() ->
         {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
+            ClockUtil.addTime(Duration.ofSeconds(60)); // retriggers lock expiration check in broker
             return null;
         }).until(t -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
 
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
index 5ff1301..0ffe98d 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -23,11 +25,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -37,7 +46,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -47,9 +58,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.junit.*;
-import org.junit.experimental.categories.Category;
-import org.junit.rules.*;
 
 public class BrokerRestartTest
 {
@@ -360,11 +368,7 @@ public class BrokerRestartTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
         recordingTaskHandler.clear();
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
index 49b527d..a322fbe 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
@@ -353,7 +353,7 @@ public class TaskSubscriptionTest
         waitUntil(() -> taskHandler.getHandledTasks().size() == 1);
 
         // when
-        ClockUtil.setCurrentTime(Instant.now().plus(Duration.ofMinutes(5)));
+        ClockUtil.addTime(Duration.ofMinutes(5));
 
         // then
         waitUntil(() -> taskHandler.getHandledTasks().size() == 2);
",1,"[""7ece3a9a16780dc6c633bbd903d36ce0aefd6a8a""]","[""test""]","1. The code changes update test logic in three integration test files to use ClockUtil.addTime instead of setting the current time directly, thereby changing how time is manipulated within the tests.
2. These changes are exclusively within test files and alter only the way time is advanced during test execution, which aligns with the 'test' label as the modifications are scoped to testing logic.
3. The 'test' label is appropriate because the changes do not introduce new features, fix bugs in production code, or restructure core code logic; they only affect test behavior and do not touch documentation, CI/CD, or build artifacts.
4. The 'test' label is justified as all modifications are strictly within test code, adjusting test time control without affecting application or infrastructure code."
"README
assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>
verify the replay mode

* write a test to verify the different replay modes","diff --git a/README.md b/README.md
index 11a24b3..56e8d2a 100644
--- a/README.md
+++ b/README.md
@@ -16,7 +16,9 @@ oclif: create your own CLI
 
 # Description
 
-This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku). Most CLI tools in Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
+This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku).
+
+Most CLI tools for Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
 
 # Features
 

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
index 167444c..7494014 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
@@ -11,6 +11,9 @@ import io.camunda.zeebe.engine.state.ZbColumnFamilies;
 import io.camunda.zeebe.engine.util.EngineRule;
 import io.camunda.zeebe.engine.util.ListLogStorage;
 import io.camunda.zeebe.model.bpmn.Bpmn;
+import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
+import io.camunda.zeebe.protocol.record.value.BpmnElementType;
+import io.camunda.zeebe.test.util.record.RecordingExporter;
 import org.assertj.core.api.SoftAssertions;
 import org.awaitility.Awaitility;
 import org.junit.Rule;
@@ -27,16 +30,22 @@ public class ContinuouslyReplayTest {
   @Rule public final EngineRule processing = EngineRule.withSharedStorage(sharedStorage);
 
   @Test
-  public void shouldEndUpWithTheSameState() {
+  public void shouldBuildTheSameStateOnProcessingAndReplay() {
     // given
-
-    // when
     processing
         .deployment()
-        .withXmlResource(Bpmn.createExecutableProcess().startEvent().endEvent().done())
+        .withXmlResource(Bpmn.createExecutableProcess(""process"").startEvent().endEvent().done())
         .deploy();
 
+    // when
+    final var processInstanceKey = processing.processInstance().ofBpmnProcessId(""process"").create();
+
     // then
+    RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_COMPLETED)
+        .withProcessInstanceKey(processInstanceKey)
+        .withElementType(BpmnElementType.PROCESS)
+        .await();
+
     assertStates();
   }
 
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
new file mode 100644
index 0000000..9dd9f4c
--- /dev/null
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -0,0 +1,121 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.processing.streamprocessor;
+
+import static io.camunda.zeebe.engine.util.RecordToWrite.command;
+import static io.camunda.zeebe.engine.util.RecordToWrite.event;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTIVATE_ELEMENT;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyLong;
+import static org.mockito.ArgumentMatchers.eq;
+import static org.mockito.Mockito.inOrder;
+import static org.mockito.Mockito.never;
+import static org.mockito.Mockito.timeout;
+
+import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor.Phase;
+import io.camunda.zeebe.engine.state.EventApplier;
+import io.camunda.zeebe.engine.util.Records;
+import io.camunda.zeebe.engine.util.StreamProcessorRule;
+import io.camunda.zeebe.protocol.impl.record.value.processinstance.ProcessInstanceRecord;
+import io.camunda.zeebe.protocol.record.ValueType;
+import org.junit.Rule;
+import org.junit.Test;
+import org.mockito.InOrder;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnit;
+import org.mockito.junit.MockitoRule;
+import org.mockito.verification.VerificationWithTimeout;
+
+public final class StreamProcessorReplayModeTest {
+
+  private static final long TIMEOUT_MILLIS = 2_000L;
+  private static final VerificationWithTimeout TIMEOUT = timeout(TIMEOUT_MILLIS);
+
+  private static final int PARTITION_ID = 1;
+
+  private static final ProcessInstanceRecord RECORD = Records.processInstance(1);
+
+  @Rule
+  public final StreamProcessorRule replayUntilEnd =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.UNTIL_END);
+
+  @Rule
+  public final StreamProcessorRule replayContinuously =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.CONTINUOUSLY);
+
+  @Rule public MockitoRule mockitoRule = MockitoJUnit.rule();
+
+  @Mock private TypedRecordProcessor<?> typedRecordProcessor;
+  @Mock private EventApplier eventApplier;
+
+  @Test
+  public void shouldReplayUntilEnd() {
+    // given
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayUntilEnd);
+
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder.verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, TIMEOUT.times(1)).onRecovered(any());
+    inOrder
+        .verify(typedRecordProcessor, TIMEOUT)
+        .processRecord(anyLong(), any(), any(), any(), any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING);
+  }
+
+  @Test
+  public void shouldReplayContinuously() {
+    // given
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayContinuously);
+
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder
+        .verify(eventApplier, TIMEOUT.times(2))
+        .applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, never()).onRecovered(any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPROCESSING);
+  }
+
+  private void startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
+    streamProcessorRule
+        .withEventApplierFactory(zeebeState -> eventApplier)
+        .startTypedStreamProcessor(
+            (processors, context) ->
+                processors.onCommand(
+                    ValueType.PROCESS_INSTANCE, ACTIVATE_ELEMENT, typedRecordProcessor));
+  }
+
+  private Phase getCurrentPhase(final StreamProcessorRule streamProcessorRule) {
+    return streamProcessorRule.getStreamProcessor(PARTITION_ID).getCurrentPhase().join();
+  }
+}
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
index f626ed4..cf07b5c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
@@ -101,7 +101,6 @@ public final class EngineRule extends ExternalResource {
       new Int2ObjectHashMap<>();
 
   private long lastProcessedPosition = -1L;
-  private ReplayMode replayMode;
 
   private EngineRule(final int partitionCount) {
     this(partitionCount, null);
@@ -176,7 +175,7 @@ public final class EngineRule extends ExternalResource {
   }
 
   public EngineRule withReplayMode(final ReplayMode replayMode) {
-    this.replayMode = replayMode;
+    environmentRule.withReplayMode(replayMode);
     return this;
   }
 
@@ -194,7 +193,6 @@ public final class EngineRule extends ExternalResource {
               (processingContext) ->
                   EngineProcessors.createEngineProcessors(
                           processingContext
-                              .replayMode(replayMode)
                               .onProcessedListener(
                                   record -> {
                                     lastProcessedPosition = record.getPosition();
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
index ab44773..1f9fe26 100755
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
@@ -10,6 +10,7 @@ package io.camunda.zeebe.engine.util;
 import static io.camunda.zeebe.engine.util.StreamProcessingComposite.getLogName;
 
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecordProcessorFactory;
@@ -64,6 +65,7 @@ public final class StreamProcessorRule implements TestRule {
   private TestStreams streams;
   private StreamProcessingComposite streamProcessingComposite;
   private ListLogStorage sharedStorage = null;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public StreamProcessorRule() {
     this(new TemporaryFolder());
@@ -125,6 +127,11 @@ public final class StreamProcessorRule implements TestRule {
     return this;
   }
 
+  public StreamProcessorRule withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+    return this;
+  }
+
   public LogStreamRecordWriter getLogStreamRecordWriter(final int partitionId) {
     return streamProcessingComposite.getLogStreamRecordWriter(partitionId);
   }
@@ -317,6 +324,7 @@ public final class StreamProcessorRule implements TestRule {
     @Override
     protected void before() {
       streams = new TestStreams(tempFolder, closeables, actorSchedulerRule.get());
+      streams.withReplayMode(replayMode);
 
       int partitionId = startPartitionId;
       for (int i = 0; i < partitionCount; i++) {
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
index 18696b2..176c405 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
@@ -17,6 +17,7 @@ import static org.mockito.Mockito.when;
 
 import io.camunda.zeebe.db.ZeebeDb;
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedEventRegistry;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
@@ -79,6 +80,7 @@ public final class TestStreams {
   private boolean snapshotWasTaken = false;
 
   private Function<MutableZeebeState, EventApplier> eventApplierFactory = EventAppliers::new;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public TestStreams(
       final TemporaryFolder dataDirectory,
@@ -107,6 +109,10 @@ public final class TestStreams {
     this.eventApplierFactory = eventApplierFactory;
   }
 
+  public void withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+  }
+
   public CommandResponseWriter getMockedResponseWriter() {
     return mockCommandResponseWriter;
   }
@@ -252,6 +258,7 @@ public final class TestStreams {
             .onProcessedListener(mockOnProcessedListener)
             .streamProcessorFactory(factory)
             .eventApplierFactory(eventApplierFactory)
+            .replayMode(replayMode)
             .build();
     final var openFuture = streamProcessor.openAsync(false);
 
",3,"[""363f84c7da411468b4103da8e0b39ca48cfd8327"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""48d5d573886e9fdd0cca1cea47112c4a2f6edf52""]","[""docs"", ""build"", ""test""]","1. The commit modifies the README.md file (improving documentation), updates shell scripts related to building and deploying Helm charts, and adds/modifies Java test files to verify replay modes and related test utilities.
2. The README.md change is solely documentation, aligning with the 'docs' label; changes to build_deploy.sh and build_deploy_parallel.sh are strictly related to build and deployment scripting, matching the 'build' label; the addition and modification of Java test files (including a new test and updates to test utilities) are fully dedicated to test logic, aligning with the 'test' label.
3. Alternative labels like 'feat', 'fix', or 'refactor' are not appropriate: no new product features are introduced, no bugs are directly fixed, and no general code restructuring is performed; the changes are entirely scoped to documentation, build/deployment scripts, and test artifacts, so 'docs', 'build', and 'test' are the most accurate and specific labels for each code unit.
4. The assigned labels 'docs', 'build', and 'test' are appropriate because each code unit is fully dedicated to documentation, build scripts, or test logic, with no overlap into behavioral or feature changes."
"refactor generate_completion
add remote [skip ci]
reset padding first on PadLog

Signed-off-by: Carlos A Becker <caarlos0@users.noreply.github.com>","diff --git a/src/lib.rs b/src/lib.rs
index dfd8014..15850f7 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -1,11 +1,106 @@
 //! Generates [Nushell](https://github.com/nushell/nushell) completions for [`clap`](https://github.com/clap-rs/clap) based CLIs
 
-use clap::Command;
+use clap::{Arg, Command};
 use clap_complete::Generator;
 
 /// Generate Nushell complete file
 pub struct Nushell;
 
+enum Argument {
+    Short(char),
+    Long(String),
+    ShortAndLong(char, String),
+    Positional(String, bool),
+}
+
+struct ArgumentLine {
+    arg: Argument,
+    takes_values: bool,
+    help: Option<String>,
+}
+
+impl From<&Arg> for ArgumentLine {
+    fn from(arg: &Arg) -> Self {
+        let takes_values = arg
+            .get_num_args()
+            .map(|v| v.takes_values())
+            .unwrap_or(false);
+
+        let help = arg.get_help().map(|s| s.to_string());
+
+        if arg.is_positional() {
+            let id = arg.get_id().to_string();
+            let required = arg.is_required_set();
+            let arg = Argument::Positional(id, required);
+
+            return Self {
+                arg,
+                takes_values,
+                help,
+            };
+        }
+
+        let short = arg.get_short();
+        let long = arg.get_long();
+
+        match short {
+            Some(short) => match long {
+                Some(long) => Self {
+                    arg: Argument::ShortAndLong(short, long.into()),
+                    takes_values,
+                    help,
+                },
+                None => Self {
+                    arg: Argument::Short(short),
+                    takes_values,
+                    help,
+                },
+            },
+            None => match long {
+                Some(long) => Self {
+                    arg: Argument::Long(long.into()),
+                    takes_values,
+                    help,
+                },
+                None => unreachable!(""No short or long option found""),
+            },
+        }
+    }
+}
+
+impl ToString for ArgumentLine {
+    fn to_string(&self) -> String {
+        let mut s = String::new();
+
+        match &self.arg {
+            Argument::Short(short) => s.push_str(format!(""    -{}"", short).as_str()),
+            Argument::Long(long) => s.push_str(format!(""    --{}"", long).as_str()),
+            Argument::ShortAndLong(short, long) => {
+                s.push_str(format!(""    --{}(-{})"", long, short).as_str())
+            }
+            Argument::Positional(positional, required) => {
+                s.push_str(format!(""    {}"", positional).as_str());
+
+                if !*required {
+                    s.push('?');
+                }
+            }
+        }
+
+        if self.takes_values {
+            s.push_str("": string"");
+        }
+
+        if let Some(help) = &self.help {
+            s.push_str(format!(""\t# {}"", help).as_str());
+        }
+
+        s.push('\n');
+
+        s
+    }
+}
+
 impl Generator for Nushell {
     fn file_name(&self, name: &str) -> String {
         format!(""{}.nu"", name)
@@ -37,51 +132,18 @@ fn generate_completion(completions: &mut String, cmd: &Command, is_subcommand: b
 
     let bin_name = cmd.get_bin_name().expect(""Failed to get bin name"");
 
-    if is_subcommand {
-        completions.push_str(format!(""  export extern \""{}\"" [\n"", bin_name).as_str());
+    let name = if is_subcommand {
+        format!(r#""""{}""""#, bin_name)
     } else {
-        completions.push_str(format!(""  export extern {} [\n"", bin_name).as_str());
-    }
+        bin_name.into()
+    };
 
-    let mut s = String::new();
-    for arg in cmd.get_arguments() {
-        if arg.is_positional() {
-            s.push_str(format!(""    {}"", arg.get_id()).as_str());
-            if !arg.is_required_set() {
-                s.push('?');
-            }
-        }
-
-        let long = arg.get_long();
-        if let Some(opt) = long {
-            s.push_str(format!(""    --{}"", opt).as_str());
-        }
+    completions.push_str(format!(""  export extern {} [\n"", name).as_str());
 
-        let short = arg.get_short();
-        if let Some(opt) = short {
-            if long.is_some() {
-                s.push_str(format!(""(-{})"", opt).as_str());
-            } else {
-                s.push_str(format!(""    -{}"", opt).as_str());
-            }
-        }
-
-        if let Some(v) = arg.get_num_args() {
-            if v.takes_values() {
-                // TODO: add more types?
-                // TODO: add possible values?
-                s.push_str("": string"");
-            }
-        }
-
-        if let Some(msg) = arg.get_help() {
-            if arg.is_positional() || long.is_some() || short.is_some() {
-                s.push_str(format!(""\t# {}"", msg).as_str());
-            }
-        }
-
-        s.push('\n');
-    }
+    let s: String = cmd
+        .get_arguments()
+        .map(|arg| ArgumentLine::from(arg).to_string())
+        .collect();
 
     completions.push_str(&s);
     completions.push_str(""  ]\n\n"");

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/internal/middleware/logging/logging.go b/internal/middleware/logging/logging.go
index 1a3adc7..92c8eb5 100644
--- a/internal/middleware/logging/logging.go
+++ b/internal/middleware/logging/logging.go
@@ -35,6 +35,7 @@ func Log(title string, next middleware.Action) middleware.Action {
 func PadLog(title string, next middleware.Action) middleware.Action {
 	return func(ctx *context.Context) error {
 		defer log.ResetPadding()
+		log.ResetPadding()
 		log.IncreasePadding()
 		log.Infof(bold.Render(title))
 		log.IncreasePadding()
",3,"[""f1bc5a554af4e617c7d7508f7f16f8fd25c78c91"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""c5904a9004fca1e438168ca7334a0deefab536ff""]","[""refactor"", ""cicd"", ""fix""]","1. The changes in 'src/lib.rs' restructure the completion generation logic, introducing new structs and refactoring the argument formatting process without altering external behavior; 'internal/middleware/logging/logging.go' resets log padding before increasing it, likely fixing a bug in log formatting; '.github/workflows/ibis-rebase-nightly.yml' switches from 'git pull --rebase' to explicit remote add/fetch/rebase steps in a CI workflow.
2. The 'src/lib.rs' changes align with 'refactor' as they improve code structure and readability without changing outputs; the Go change is a 'fix' as it resolves a likely bug in log padding; the workflow YAML change is 'cicd' since it modifies CI configuration.
3. 'refactor' is appropriate for the Rust code as no new features or bug fixes are introduced; 'fix' applies to the Go change because it addresses a behavioral issue, not just restructuring; 'cicd' is correct for the workflow file as it is purely a CI configuration update, not a build system or test change.
4. The assigned labels 'refactor', 'fix', and 'cicd' are correct as each code unit's primary modification matches the respective label's definition and intent."
"rename ELECTRON_CACHE env variable to electron_config_cache (#21313)
lint source on ci","diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as

diff --git a/.travis.yml b/.travis.yml
index d56185e..96510cb 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -2,5 +2,6 @@ language: node_js
 node_js:
   - 'stable'
 script:
+  - yarn lint
   - yarn build
   - yarn test
",2,"[""f2f52c23b513dd857350f3c163f676d37189d0d3"", ""2ac99c0a66a1adc18ee4ef660608f814823dd198""]","[""docs"", ""cicd""]","1. The commit updates documentation in 'installation.md' to rename an environment variable and adds a 'yarn lint' step to the CI configuration in '.travis.yml'.
2. The documentation change directly aligns with the 'docs' label, as it only updates instructional text; the CI configuration change aligns with the 'cicd' label as it modifies the continuous integration process.
3. 'docs' is appropriate because no code logic or behavior is changed, just documentation; 'cicd' is correct because the change is isolated to a CI script, not to build logic or source code itself—no purpose or other object labels apply.
4. The 'docs' and 'cicd' labels are justified as the changes are strictly scoped to documentation and CI configuration, matching the object label definitions."
parallelize pybind11 build,"diff --git a/poetry-overrides.nix b/poetry-overrides.nix
index d37c5ed..aaaaf02 100644
--- a/poetry-overrides.nix
+++ b/poetry-overrides.nix
@@ -82,4 +82,11 @@ self: super:
     {
       patches = (attrs.patches or [ ]) ++ [ ./patches/watchdog-force-kqueue.patch ];
     });
+
+  pybind11 = super.pybind11.overridePythonAttrs (_: {
+    postBuild = ''
+      # build tests
+      make -j $NIX_BUILD_CORES -l $NIX_BUILD_CORES
+    '';
+  });
 }
",1,"[""9ab4c61975e073e214646443d088339cfdbaa88d""]","[""build""]","1. The code modifies the Nix build override for the 'pybind11' package to parallelize its build process by setting a custom 'postBuild' step using 'make -j $NIX_BUILD_CORES'.
2. This change directly affects the build configuration and process, aligning with the 'build' label, which covers updates to build systems or scripts.
3. The change does not introduce new features ('feat'), fix bugs ('fix'), restructure code ('refactor'), update documentation ('docs'), add tests ('test'), or modify CI/CD scripts ('cicd'); it solely alters build behavior.
4. The 'build' label is appropriate because the change is entirely scoped to the build system and does not impact application code, tests, documentation, or CI/CD configuration."
"add more tests for Utils.lookupPathFromDecorator
#972 External links open in the same tab","diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',

diff --git a/kofta/src/app/components/Footer.tsx b/kofta/src/app/components/Footer.tsx
index c55fae9..940f7ac 100644
--- a/kofta/src/app/components/Footer.tsx
+++ b/kofta/src/app/components/Footer.tsx
@@ -13,14 +13,14 @@ export const Footer: React.FC<FooterProps> = ({ isLogin }) => {
   return (
     <div className={`justify-between flex text-center`}>
       {isLogin ? (
-        <RegularAnchor href=""https://www.youtube.com/watch?v=hy-EhJ_tTQo"">
+        <RegularAnchor href=""https://www.youtube.com/watch?v=hy-EhJ_tTQo"" target=""_blank"">
           {t(""footer.link_1"")}
         </RegularAnchor>
       ) : null}
-      <RegularAnchor href=""https://discord.gg/wCbKBZF9cV"">
+      <RegularAnchor href=""https://discord.gg/wCbKBZF9cV"" target=""_blank"">
         {t(""footer.link_2"")}
       </RegularAnchor>
-      <RegularAnchor href=""https://github.com/benawad/dogehouse/issues"">
+      <RegularAnchor href=""https://github.com/benawad/dogehouse/issues"" target=""_blank"">
         {t(""footer.link_3"")}
       </RegularAnchor>
       {/* cramps footer on mobile @todo think about how to incorporate this without cramping footer and making the footer really tall */}
diff --git a/kofta/src/app/pages/Login.tsx b/kofta/src/app/pages/Login.tsx
index 3854b5d..1f06220 100644
--- a/kofta/src/app/pages/Login.tsx
+++ b/kofta/src/app/pages/Login.tsx
@@ -46,6 +46,7 @@ export const Login: React.FC<LoginProps> = () => {
               <a
                 href=""https://github.com/benawad/dogehouse""
                 className={`p-0 text-blue-400`}
+                target=""_blank""
               >
                 {t(""pages.login.featureText_4"")}
               </a>
",2,"[""c5e86dbc00a13a355bffadeb2db197e2fea5640f"", ""07452180fee89e98f05e1aeca68f9923d4c7ab63""]","[""test"", ""fix""]","1. The changes include adding new test cases to 'Utils.test.ts', refactoring the regex logic in 'Utils.ts', and updating anchor tags in UI components to open external links in new tabs by adding 'target=""_blank""'.
2. Adding new test cases is directly aligned with the 'test' object label, while the changes to anchor tags address the bug where external links did not open in a new tab, aligning with the 'fix' purpose label.
3. 'test' is appropriate for the new test additions because these changes are entirely within test files and focused on test logic; 'fix' is appropriate for the UI changes because they resolve a user-facing bug, and 'refactor' does not apply since the code behavior was intentionally altered, not just restructured.
4. The labels 'test' and 'fix' are correct: 'test' covers the dedicated test additions, and 'fix' covers the user-facing bug resolution for external link behavior."
"update version (nightly.0)
fixed tick interval","diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true

diff --git a/backend/services/integrations/main.go b/backend/services/integrations/main.go
index 4a5e764..35c3ff2 100644
--- a/backend/services/integrations/main.go
+++ b/backend/services/integrations/main.go
@@ -54,7 +54,7 @@ func main() {
 	sigchan := make(chan os.Signal, 1)
 	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
 
-	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL)
+	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL * time.Millisecond)
 
 	log.Printf(""Integration service started\n"")
 	manager.RequestAll()
@@ -66,7 +66,7 @@ func main() {
 			pg.Close()
 			os.Exit(0)
 		case <-tick:
-			// log.Printf(""Requesting all...\n"")
+			log.Printf(""Requesting all...\n"")
 			manager.RequestAll()
 		case event := <-manager.Events:
 			// log.Printf(""New integration event: %v\n"", *event.RawErrorEvent)
",2,"[""607ecc92b5f8c084304e406eec725b7dcfa0a562"", ""7dc3b70fe40fc7de255a28bb3098bcb8c0d35365""]","[""build"", ""fix""]","1. The changes include version updates in multiple Cargo.toml and Cargo.lock files, and a code fix in main.go where the tick interval is multiplied by time.Millisecond to correct timing behavior.
2. The version bumps in Cargo.toml and Cargo.lock align with the 'build' label, as they directly affect build configuration and dependency management; the main.go change addresses a bug in interval calculation, matching the 'fix' label definition.
3. 'build' is appropriate for the Cargo manifest and lockfile updates since these files are solely for build and dependency specification, not code logic; 'fix' is correct for the main.go change because it resolves a functional bug, not a feature addition or refactor. No other object or purpose labels apply because the changes are strictly within build metadata and a clear bugfix.
4. The assigned labels 'build' and 'fix' accurately capture the scope of this commit: build metadata updates and a specific bugfix in application logic."
"convert to record
import flux-lsp v0.5.21
add descriptions to buttons on hover","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/ui/package.json b/ui/package.json
index 7a44aad..a36fc3d 100644
--- a/ui/package.json
+++ b/ui/package.json
@@ -134,7 +134,7 @@
   ""dependencies"": {
     ""@influxdata/clockface"": ""2.3.4"",
     ""@influxdata/flux"": ""^0.5.1"",
-    ""@influxdata/flux-lsp-browser"": ""0.5.20"",
+    ""@influxdata/flux-lsp-browser"": ""0.5.21"",
     ""@influxdata/giraffe"": ""0.29.0"",
     ""@influxdata/influx"": ""0.5.5"",
     ""@influxdata/influxdb-templates"": ""0.9.0"",
diff --git a/ui/yarn.lock b/ui/yarn.lock
index 99ae766..e6e2a47 100644
--- a/ui/yarn.lock
+++ b/ui/yarn.lock
@@ -752,10 +752,10 @@
   resolved ""https://registry.yarnpkg.com/@influxdata/clockface/-/clockface-2.3.4.tgz#9c496601253e1d49cbeae29a7b9cfb54862785f6""
   integrity sha512-mmz3YElK8Ho+1onEafuas6sVhIT638JA4NbDTO3bVJgK1TG7AnU4rQP+c6fj7vZSfvrIwtOwGaMONJTaww5o6w==
 
-""@influxdata/flux-lsp-browser@0.5.20"":
-  version ""0.5.20""
-  resolved ""https://registry.yarnpkg.com/@influxdata/flux-lsp-browser/-/flux-lsp-browser-0.5.20.tgz#150d261bab869e130f6d00ee73ea4e859e8969e4""
-  integrity sha512-gUy19t/QndkJPmyv7Lb56zXxaW5v7R9TslTHt0hB0GJjo7lmYkRfkD7DELdFHrD2e/CLtcNQBnczIMIGkII8Bw==
+""@influxdata/flux-lsp-browser@0.5.21"":
+  version ""0.5.21""
+  resolved ""https://registry.yarnpkg.com/@influxdata/flux-lsp-browser/-/flux-lsp-browser-0.5.21.tgz#d5632f45e925c09bae9501a00fbef2ed55567f9e""
+  integrity sha512-lcUwKX1yj0QqGiusQFOVi7UPsvp6+qNX7Cwf9qqS5/dRwoh7c++nFVRdGNrSWlsbyRrPaAWBoZWEnghSnIf6DQ==
 
 ""@influxdata/flux@^0.5.1"":
   version ""0.5.1""

diff --git a/benchmarks/main.mjs b/benchmarks/main.mjs
index 0c2dc6b..e2f79d4 100644
--- a/benchmarks/main.mjs
+++ b/benchmarks/main.mjs
@@ -65,8 +65,9 @@ const vnode = () =>
           },
           style: style({ margin: '5px' }),
           disabled,
+          title: suite.name.split(' | ')[1],
         },
-        [suite.name],
+        [suite.name.split(' | ')[0]],
       ),
     ),
     m(
diff --git a/benchmarks/suites/appendManyRowsToLargeTable.mjs b/benchmarks/suites/appendManyRowsToLargeTable.mjs
index e6a034e..7e34ca3 100644
--- a/benchmarks/suites/appendManyRowsToLargeTable.mjs
+++ b/benchmarks/suites/appendManyRowsToLargeTable.mjs
@@ -31,7 +31,9 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('append many rows to large table');
+const suite = new benchmark.Suite(
+  'append many rows to large table | appending 1,000 to a table of 10,000 rows.',
+);
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/clearRows.mjs b/benchmarks/suites/clearRows.mjs
index ad47036..2a7711b 100644
--- a/benchmarks/suites/clearRows.mjs
+++ b/benchmarks/suites/clearRows.mjs
@@ -27,7 +27,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(row);
 });
 
-const suite = new benchmark.Suite('clear rows');
+const suite = new benchmark.Suite('clear rows | clearing a table with 1,000 rows');
 
 const hoistedVNode = m('table', undefined, [], VFlags.NO_CHILDREN);
 
diff --git a/benchmarks/suites/createManyRows.mjs b/benchmarks/suites/createManyRows.mjs
index 578f511..96c7b02 100644
--- a/benchmarks/suites/createManyRows.mjs
+++ b/benchmarks/suites/createManyRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create many rows');
+const suite = new benchmark.Suite('create many rows | creating 10,000 rows');
 
 const hoistedVNode = m(
   'div',
diff --git a/benchmarks/suites/createRows.mjs b/benchmarks/suites/createRows.mjs
index bfcc876..4d9ff57 100644
--- a/benchmarks/suites/createRows.mjs
+++ b/benchmarks/suites/createRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create rows');
+const suite = new benchmark.Suite('create rows | creating 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/partialUpdate.mjs b/benchmarks/suites/partialUpdate.mjs
index 55948a9..c5f1de3 100644
--- a/benchmarks/suites/partialUpdate.mjs
+++ b/benchmarks/suites/partialUpdate.mjs
@@ -34,7 +34,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('partial update');
+const suite = new benchmark.Suite('partial update | updating every 10th row for 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/removeRow.mjs b/benchmarks/suites/removeRow.mjs
index aeb1e9a..31c7599 100644
--- a/benchmarks/suites/removeRow.mjs
+++ b/benchmarks/suites/removeRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('remove row');
+const suite = new benchmark.Suite('remove row | removing one row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/replaceAllRows.mjs b/benchmarks/suites/replaceAllRows.mjs
index 9555ae4..7001667 100644
--- a/benchmarks/suites/replaceAllRows.mjs
+++ b/benchmarks/suites/replaceAllRows.mjs
@@ -41,7 +41,7 @@ data2.forEach(({ id, label }) => {
 
 shuffleArray(data2);
 
-const suite = new benchmark.Suite('replace all rows');
+const suite = new benchmark.Suite('replace all rows | updating all 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/selectRow.mjs b/benchmarks/suites/selectRow.mjs
index 76be216..de69359 100644
--- a/benchmarks/suites/selectRow.mjs
+++ b/benchmarks/suites/selectRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('select row');
+const suite = new benchmark.Suite('select row | highlighting a selected row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/swapRows.mjs b/benchmarks/suites/swapRows.mjs
index 2a91e74..ce52036 100644
--- a/benchmarks/suites/swapRows.mjs
+++ b/benchmarks/suites/swapRows.mjs
@@ -36,7 +36,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('swap rows');
+const suite = new benchmark.Suite('swap rows | swap 2 rows for table with 1,000 rows');
 
 const hoistedVNode = m(
   'table',
",3,"[""3346331a963766c8193170fb130adad2e658ada2"", ""bfe32bf10e9b6d699f694fbd095af0b3f2e6275f"", ""d8d0ba8ea17ed43a04f90213851d2f27056d8cf0""]","[""refactor"", ""build"", ""feat""]","1. The commit contains three types of changes: (a) refactoring a Java test class by converting an inner class to a record, (b) updating the package.json and yarn.lock to import flux-lsp v0.5.21, and (c) enhancing benchmark suite buttons by adding descriptions on hover and updating suite names for clarity.
2. The Java test class change is a structural improvement without behavioral change, matching the 'refactor' label; the dependency update in package.json/yarn.lock is a build system modification, aligning with the 'build' label; the addition of button hover descriptions and benchmark suite name updates introduce new UI capabilities, aligning with the 'feat' label.
3. 'refactor' is appropriate for the test class code change because it improves code structure without affecting functionality, not introducing new features or fixing bugs; 'build' is correct for the dependency update since it affects how the project is built and dependencies managed, not runtime code or CI scripts; 'feat' applies to the UI/benchmark enhancements because they add new user-facing descriptions and improve usability, not just documentation or refactoring.
4. The assigned labels 'refactor', 'build', and 'feat' accurately represent the distinct motivations and artifact types of the code changes in this commit, with no overlap or misclassification."
"lint README
also make dependents when running smoke tests
expose the means by which we process each reward cycle's affirmation maps at reward cycle boundaries","diff --git a/README.md b/README.md
index a163c83..9cd12bc 100644
--- a/README.md
+++ b/README.md
@@ -26,7 +26,7 @@ Ibis has three primary components:
 Ibis aims to be a future-proof solution to interacting with data using Python and can accomplish this goal through its main features:
 
 - **Familiar API**: Ibis’s API design borrows from popular APIs like pandas and dplyr that most users already know and like to use.
-- **Consistent syntax**:  Ibis aims to be universal Python API for tabular data, big or small.
+- **Consistent syntax**: Ibis aims to be universal Python API for tabular data, big or small.
 - **Deferred execution**: Ibis pushes code execution to the query engine and only moves required data into memory when it has to.
   This leads to more faster, more efficient analytics workflows
 - **Interactive mode**: Ibis also provides an interactive mode, in which users can quickly diagnose problems, do exploratory data analysis, and mock up workflows locally.

diff --git a/.github/workflows/os-smoke-test.yml b/.github/workflows/os-smoke-test.yml
index 194d108..7e41493 100644
--- a/.github/workflows/os-smoke-test.yml
+++ b/.github/workflows/os-smoke-test.yml
@@ -56,5 +56,7 @@ jobs:
         uses: JesseTG/rm@v1.0.2
         with:
           path: /Users/runner/.m2/repository/uk/co/real-logic/sbe-tool
+      - name: Build relevant modules
+        run: mvn -B -am -pl qa/integration-tests package -DskipTests -DskipChecks -T1C
       - name: Run smoke test
         run: mvn -B -pl qa/integration-tests verify -P smoke-test -DskipUTs -DskipChecks

diff --git a/src/burnchains/burnchain.rs b/src/burnchains/burnchain.rs
index 92105d6..60c608a 100644
--- a/src/burnchains/burnchain.rs
+++ b/src/burnchains/burnchain.rs
@@ -851,8 +851,26 @@ impl Burnchain {
         );
 
         burnchain_db.store_new_burnchain_block(burnchain, indexer, &block)?;
-        let block_height = block.block_height();
+        Burnchain::process_affirmation_maps(
+            burnchain,
+            burnchain_db,
+            indexer,
+            block.block_height(),
+        )?;
+
+        let header = block.header();
+        Ok(header)
+    }
 
+    /// Update the affirmation maps for the previous reward cycle's commits.
+    /// This is a no-op unless the given burnchain block height falls on a reward cycle boundary.  In that
+    /// case, the previous reward cycle's block commits' affirmation maps are all re-calculated.
+    pub fn process_affirmation_maps<B: BurnchainHeaderReader>(
+        burnchain: &Burnchain,
+        burnchain_db: &mut BurnchainDB,
+        indexer: &B,
+        block_height: u64,
+    ) -> Result<(), burnchain_error> {
         let this_reward_cycle = burnchain
             .block_height_to_reward_cycle(block_height)
             .unwrap_or(0);
@@ -872,10 +890,7 @@ impl Burnchain {
             );
             update_pox_affirmation_maps(burnchain_db, indexer, prev_reward_cycle, burnchain)?;
         }
-
-        let header = block.header();
-
-        Ok(header)
+        Ok(())
     }
 
     /// Hand off the block to the ChainsCoordinator _and_ process the sortition
",3,"[""cab2cf4d3fffb0ec2b56d455e67ac5fa992b4104"", ""2236b37bd671fdb71313cbc6ebd7633f0effba34"", ""d7972da833257c073403dec3c2ac3a7f297e328a""]","[""docs"", ""build"", ""refactor""]","1. The commit makes a minor typo fix in README.md, adds a build step to a GitHub Actions workflow, and refactors Rust code to expose and document a new method for processing affirmation maps at reward cycle boundaries.
2. The README.md change aligns with the 'docs' label as it is purely documentation-related; the workflow update aligns with 'cicd' as it modifies a CI configuration file; the Rust code change aligns with 'refactor' as it restructures code to expose logic as a public method without changing external behavior.
3. 'docs' is appropriate for the README fix because it only affects documentation, not code behavior; 'cicd' is correct for the workflow change because it is limited to a CI artifact, not the build system itself; 'refactor' is appropriate for the Rust code because it reorganizes and exposes logic without adding new features or fixing bugs.
4. The assigned labels 'docs', 'cicd', and 'refactor' accurately reflect the distinct, non-overlapping roles and motivations of each code unit in this commit."
"update version (v0.6.18)
process CommandDistribution ACKNOWLEDGED event

Adds an EventApplier for the CommandDistribution ACKNOWLEDGED event. This applier will be responsible to remove a pending distribution from the state. This will be used to mark the distribution to a specific partition as completed.
adds test for exec with http proxy

Signed-off-by: Sam Alba <samalba@users.noreply.github.com>","diff --git a/Cargo.lock b/Cargo.lock
index c32d8b4..599790e 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.30-nightly.2""
+version = ""0.1.30""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -125,7 +125,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -133,7 +133,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index baaa0ac..5082cd3 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 experimental = [""erg_common/experimental"", ""erg_parser/experimental"", ""erg_compiler/experimental""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.30-nightly.2"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.18"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.18"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.18"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.30"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index 3efbf4e..9f902fa 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.30-nightly.2""
+version = ""0.1.30""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java
new file mode 100644
index 0000000..4abf2e3
--- /dev/null
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java
@@ -0,0 +1,28 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.state.appliers;
+
+import io.camunda.zeebe.engine.state.TypedEventApplier;
+import io.camunda.zeebe.engine.state.mutable.MutableDistributionState;
+import io.camunda.zeebe.protocol.impl.record.value.distribution.CommandDistributionRecord;
+import io.camunda.zeebe.protocol.record.intent.CommandDistributionIntent;
+
+public final class CommandDistributionAcknowledgedApplier
+    implements TypedEventApplier<CommandDistributionIntent, CommandDistributionRecord> {
+
+  private final MutableDistributionState distributionState;
+
+  public CommandDistributionAcknowledgedApplier(final MutableDistributionState distributionState) {
+    this.distributionState = distributionState;
+  }
+
+  @Override
+  public void applyState(final long key, final CommandDistributionRecord value) {
+    distributionState.removePendingDistribution(key, value.getPartitionId());
+  }
+}
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
index a72309b..4793315 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
@@ -284,6 +284,9 @@ public final class EventAppliers implements EventApplier {
         CommandDistributionIntent.DISTRIBUTING,
         new CommandDistributionDistributingApplier(distributionState));
     register(
+        CommandDistributionIntent.ACKNOWLEDGED,
+        new CommandDistributionAcknowledgedApplier(distributionState));
+    register(
         CommandDistributionIntent.FINISHED,
         new CommandDistributionFinishedApplier(distributionState));
   }

diff --git a/tests/tasks.bats b/tests/tasks.bats
index e3b95c4..4cfba15 100644
--- a/tests/tasks.bats
+++ b/tests/tasks.bats
@@ -101,6 +101,14 @@ setup() {
     assert_line --partial --index 9 'actions.basicTest.stop'
 }
 
+@test ""task: #Exec with HTTP proxy"" {
+    cd ./tasks/exec
+    export HTTPS_PROXY=""https://localhost:4242/""
+    run ""$DAGGER"" ""do"" -p ./http_proxy.cue curlProxy
+    assert_failure
+    unset HTTP_PROXY
+}
+
 @test ""task: #Start #Stop params"" {
     cd ./tasks/exec
     ""$DAGGER"" ""do"" -p ./start_stop_exec.cue execParamsTest
@@ -297,4 +305,4 @@ setup() {
 
 @test ""task: #Rm"" {
     ""$DAGGER"" ""do"" -p ./tasks/rm/rm.cue test
-}
\ No newline at end of file
+}
diff --git a/tests/tasks/exec/http_proxy.cue b/tests/tasks/exec/http_proxy.cue
new file mode 100644
index 0000000..05de4b9
--- /dev/null
+++ b/tests/tasks/exec/http_proxy.cue
@@ -0,0 +1,25 @@
+package main
+
+import (
+	""dagger.io/dagger""
+	""dagger.io/dagger/core""
+)
+
+dagger.#Plan & {
+	actions: {
+		image: core.#Pull & {
+			source: ""alpine:3.15.0@sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3""
+		}
+
+		curlProxy: core.#Exec & {
+			input: image.output
+			args: [
+				""sh"", ""-c"",
+				""""""
+					apk add --no-cache curl
+					curl -sfL -o /dev/null https://www.google.com/
+					"""""",
+			]
+		}
+	}
+}
",3,"[""bb3e3d9b96e435c3b92fc208bca93d1ad7e1ad50"", ""6f4c06076abff94f8bb5c634beaba55483a78b72"", ""6c7398993bc567ec84e4573b6ededbf50b1ef606""]","[""build"", ""feat"", ""test""]","1. The commit updates version numbers in Cargo.toml and Cargo.lock, adds a new EventApplier class for handling CommandDistribution ACKNOWLEDGED events, registers it in EventAppliers.java, and introduces a new test and test fixture for exec with HTTP proxy.
2. The version bumps in Cargo.toml and Cargo.lock are build system changes, the new EventApplier and its registration introduce new feature logic, and the new test and CUE file are dedicated to testing, aligning with the 'build', 'feat', and 'test' labels respectively.
3. 'build' is correct for dependency and version updates (not 'feat' or 'refactor'), 'feat' is appropriate for adding new event handling capability (not 'fix', as it is not a bug fix, nor 'refactor', as it changes behavior), and 'test' is correct for the addition of new test logic (not 'feat', since it is not production code).
4. The assigned labels 'build', 'feat', and 'test' are appropriate as the commit contains discrete changes matching each of these categories: build system updates, new feature logic, and new tests."
"create dashboards from imported templates
switch to callback ref
add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com>","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 590f5ea..bd74e95 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,6 +1,7 @@
 ## v2.0.0-alpha.6 [unreleased]
 
 ### Features
+1. [12496](https://github.com/influxdata/influxdb/pull/12496): Add ability to import a dashboard
 
 ### Bug Fixes
 
diff --git a/ui/src/dashboards/actions/v2/index.ts b/ui/src/dashboards/actions/v2/index.ts
index ad0d13d..35babc7 100644
--- a/ui/src/dashboards/actions/v2/index.ts
+++ b/ui/src/dashboards/actions/v2/index.ts
@@ -16,6 +16,7 @@ import {
   removeDashboardLabels as removeDashboardLabelsAJAX,
   updateView as updateViewAJAX,
 } from 'src/dashboards/apis/v2'
+import {client} from 'src/utils/api'
 
 // Actions
 import {notify} from 'src/shared/actions/notifications'
@@ -25,6 +26,10 @@ import {
   DeleteTimeRangeAction,
 } from 'src/dashboards/actions/v2/ranges'
 import {setView, SetViewAction} from 'src/dashboards/actions/v2/views'
+import {
+  importDashboardSucceeded,
+  importDashboardFailed,
+} from 'src/shared/copy/notifications'
 
 // Utils
 import {
@@ -38,7 +43,7 @@ import * as copy from 'src/shared/copy/notifications'
 // Types
 import {RemoteDataState} from 'src/types'
 import {PublishNotificationAction} from 'src/types/actions/notifications'
-import {CreateCell} from '@influxdata/influx'
+import {CreateCell, IDashboardTemplate} from '@influxdata/influx'
 import {Dashboard, NewView, Cell} from 'src/types/v2'
 import {ILabel} from '@influxdata/influx'
 
@@ -201,6 +206,19 @@ export const getDashboardsAsync = () => async (
   }
 }
 
+export const createDashboardFromTemplate = (
+  template: IDashboardTemplate,
+  orgID: string
+) => async dispatch => {
+  try {
+    await client.dashboards.createFromTemplate(template, orgID)
+
+    dispatch(notify(importDashboardSucceeded()))
+  } catch (error) {
+    dispatch(notify(importDashboardFailed(error)))
+  }
+}
+
 export const importDashboardAsync = (dashboard: Dashboard) => async (
   dispatch: Dispatch<Action>
 ): Promise<void> => {
diff --git a/ui/src/dashboards/components/ImportDashboardOverlay.tsx b/ui/src/dashboards/components/ImportDashboardOverlay.tsx
index 37ef80b..84216c3 100644
--- a/ui/src/dashboards/components/ImportDashboardOverlay.tsx
+++ b/ui/src/dashboards/components/ImportDashboardOverlay.tsx
@@ -1,70 +1,80 @@
+// Libraries
 import React, {PureComponent} from 'react'
 import _ from 'lodash'
+import {connect} from 'react-redux'
 
-import Container from 'src/clockface/components/overlays/OverlayContainer'
-import Heading from 'src/clockface/components/overlays/OverlayHeading'
-import Body from 'src/clockface/components/overlays/OverlayBody'
-import DragAndDrop from 'src/shared/components/DragAndDrop'
+// Constants
 import {dashboardImportFailed} from 'src/shared/copy/notifications'
 
-import {Dashboard} from 'src/types/v2'
-import {Notification} from 'src/types/notifications'
+// Actions
+import {notify as notifyAction} from 'src/shared/actions/notifications'
+import {getDashboardsAsync} from 'src/dashboards/actions/v2'
 
-interface Props {
+// Types
+import ImportOverlay from 'src/shared/components/ImportOverlay'
+import {createDashboardFromTemplate as createDashboardFromTemplateAction} from 'src/dashboards/actions/v2'
+
+interface OwnProps {
   onDismissOverlay: () => void
-  onImportDashboard: (dashboard: Dashboard) => void
-  notify: (message: Notification) => void
+  orgID: string
+  isVisible: boolean
+}
+interface DispatchProps {
+  notify: typeof notifyAction
+  createDashboardFromTemplate: typeof createDashboardFromTemplateAction
+  populateDashboards: typeof getDashboardsAsync
 }
+
+type Props = OwnProps & DispatchProps
+
 class ImportDashboardOverlay extends PureComponent<Props> {
   constructor(props: Props) {
     super(props)
   }
 
   public render() {
-    const {onDismissOverlay} = this.props
+    const {isVisible, onDismissOverlay} = this.props
 
     return (
-      <Container maxWidth={800}>
-        <Heading title=""Import Dashboard"" onDismiss={onDismissOverlay} />
-        <Body>
-          <DragAndDrop
-            submitText=""Upload Dashboard""
-            fileTypesToAccept={this.validFileExtension}
-            handleSubmit={this.handleUploadDashboard}
-          />
-        </Body>
-      </Container>
+      <ImportOverlay
+        isVisible={isVisible}
+        onDismissOverlay={onDismissOverlay}
+        resourceName=""Dashboard""
+        onSubmit={this.handleUploadDashboard}
+      />
     )
   }
 
-  private get validFileExtension(): string {
-    return '.json'
-  }
-
-  private handleUploadDashboard = (
-    uploadContent: string,
-    fileName: string
-  ): void => {
-    const {notify, onImportDashboard, onDismissOverlay} = this.props
-    const fileExtensionRegex = new RegExp(`${this.validFileExtension}$`)
-    if (!fileName.match(fileExtensionRegex)) {
-      notify(dashboardImportFailed('Please import a JSON file'))
-      return
-    }
+  private handleUploadDashboard = async (
+    uploadContent: string
+  ): Promise<void> => {
+    const {
+      notify,
+      createDashboardFromTemplate,
+      onDismissOverlay,
+      populateDashboards,
+      orgID,
+    } = this.props
 
     try {
-      const {dashboard} = JSON.parse(uploadContent)
+      const template = JSON.parse(uploadContent)
 
-      if (!_.isEmpty(dashboard)) {
-        onImportDashboard(dashboard)
-        onDismissOverlay()
-      } else {
-        notify(dashboardImportFailed('No dashboard found in file'))
-      }
+      await createDashboardFromTemplate(template, orgID)
+      await populateDashboards()
+
+      onDismissOverlay()
     } catch (error) {
       notify(dashboardImportFailed(error))
     }
   }
 }
+const mdtp: DispatchProps = {
+  notify: notifyAction,
+  createDashboardFromTemplate: createDashboardFromTemplateAction,
+  populateDashboards: getDashboardsAsync,
+}
 
-export default ImportDashboardOverlay
+export default connect<{}, DispatchProps, OwnProps>(
+  null,
+  mdtp
+)(ImportDashboardOverlay)
diff --git a/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx b/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
index d6b299f..1ff7f47 100644
--- a/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
+++ b/ui/src/dashboards/components/dashboard_index/DashboardsIndex.tsx
@@ -2,15 +2,15 @@
 import React, {PureComponent} from 'react'
 import {InjectedRouter} from 'react-router'
 import {connect} from 'react-redux'
-import {isEmpty} from 'lodash'
+import {get} from 'lodash'
 
 // Components
 import DashboardsIndexContents from 'src/dashboards/components/dashboard_index/DashboardsIndexContents'
 import {Page} from 'src/pageLayout'
 import SearchWidget from 'src/shared/components/search_widget/SearchWidget'
 import AddResourceDropdown from 'src/shared/components/AddResourceDropdown'
-import ImportOverlay from 'src/shared/components/ImportOverlay'
 import ExportOverlay from 'src/shared/components/ExportOverlay'
+import ImportDashboardOverlay from 'src/dashboards/components/ImportDashboardOverlay'
 
 // APIs
 import {createDashboard, cloneDashboard} from 'src/dashboards/apis/v2/'
@@ -32,10 +32,7 @@ import {DEFAULT_DASHBOARD_NAME} from 'src/dashboards/constants/index'
 import {
   dashboardSetDefaultFailed,
   dashboardCreateFailed,
-  dashboardImported,
-  dashboardImportFailed,
 } from 'src/shared/copy/notifications'
-import {cantImportInvalidResource} from 'src/shared/copy/v2/notifications'
 
 // Types
 import {Notification} from 'src/types/notifications'
@@ -197,24 +194,6 @@ class DashboardIndex extends PureComponent<Props, State> {
     this.props.handleDeleteDashboard(dashboard)
   }
 
-  private handleImportDashboard = async (
-    importString: string
-  ): Promise<void> => {
-    const {notify} = this.props
-    try {
-      const resource = JSON.parse(importString)
-
-      if (isEmpty(resource)) {
-        notify(cantImportInvalidResource('Dashboard'))
-        return
-      }
-      this.handleToggleImportOverlay()
-      notify(dashboardImported())
-    } catch (error) {
-      notify(dashboardImportFailed(error))
-    }
-  }
-
   private handleFilterDashboards = (searchTerm: string): void => {
     this.setState({searchTerm})
   }
@@ -229,13 +208,13 @@ class DashboardIndex extends PureComponent<Props, State> {
 
   private get importOverlay(): JSX.Element {
     const {isImportingDashboard} = this.state
+    const {orgs} = this.props
 
     return (
-      <ImportOverlay
-        isVisible={isImportingDashboard}
-        resourceName=""Dashboard""
+      <ImportDashboardOverlay
         onDismissOverlay={this.handleToggleImportOverlay}
-        onSubmit={this.handleImportDashboard}
+        orgID={get(orgs, '0.id', '')}
+        isVisible={isImportingDashboard}
       />
     )
   }
diff --git a/ui/src/organizations/components/Dashboards.tsx b/ui/src/organizations/components/Dashboards.tsx
index 08c8402..90c2514 100644
--- a/ui/src/organizations/components/Dashboards.tsx
+++ b/ui/src/organizations/components/Dashboards.tsx
@@ -6,13 +6,10 @@ import _ from 'lodash'
 
 // Components
 import DashboardsIndexContents from 'src/dashboards/components/dashboard_index/DashboardsIndexContents'
-import {OverlayTechnology, Input, Tabs} from 'src/clockface'
+import {Input, Tabs} from 'src/clockface'
 import {Button, ComponentColor, IconFont} from '@influxdata/clockface'
 import ImportDashboardOverlay from 'src/dashboards/components/ImportDashboardOverlay'
 
-// Utils
-import {getDeep} from 'src/utils/wrappers'
-
 // APIs
 import {createDashboard, cloneDashboard} from 'src/dashboards/apis/v2/'
 
@@ -39,7 +36,7 @@ import {DEFAULT_DASHBOARD_NAME} from 'src/dashboards/constants/index'
 
 // Types
 import {Notification} from 'src/types/notifications'
-import {Links, Cell, Dashboard, AppState, Organization} from 'src/types/v2'
+import {Links, Dashboard, AppState, Organization} from 'src/types/v2'
 
 // Decorators
 import {ErrorHandling} from 'src/shared/decorators/errors'
@@ -205,46 +202,20 @@ class Dashboards extends PureComponent<Props, State> {
     this.props.handleDeleteDashboard(dashboard)
   }
 
-  private handleImportDashboard = async (
-    dashboard: Dashboard
-  ): Promise<void> => {
-    const defaultCell = {
-      x: 0,
-      y: 0,
-      w: 4,
-      h: 4,
-    }
-
-    const name = _.get(dashboard, 'name', DEFAULT_DASHBOARD_NAME)
-    const cellsWithDefaultsApplied = getDeep<Cell[]>(
-      dashboard,
-      'cells',
-      []
-    ).map(c => ({...defaultCell, ...c}))
-
-    await this.props.handleImportDashboard({
-      ...dashboard,
-      name,
-      cells: cellsWithDefaultsApplied,
-    })
-  }
-
   private handleToggleOverlay = (): void => {
     this.setState({isImportingDashboard: !this.state.isImportingDashboard})
   }
 
   private get renderImportOverlay(): JSX.Element {
-    const {notify} = this.props
     const {isImportingDashboard} = this.state
+    const {orgs} = this.props
 
     return (
-      <OverlayTechnology visible={isImportingDashboard}>
-        <ImportDashboardOverlay
-          onDismissOverlay={this.handleToggleOverlay}
-          onImportDashboard={this.handleImportDashboard}
-          notify={notify}
-        />
-      </OverlayTechnology>
+      <ImportDashboardOverlay
+        onDismissOverlay={this.handleToggleOverlay}
+        orgID={_.get(orgs, '0.id', '')}
+        isVisible={isImportingDashboard}
+      />
     )
   }
 }
diff --git a/ui/src/shared/components/ImportOverlay.tsx b/ui/src/shared/components/ImportOverlay.tsx
index 10f1d50..476fa70 100644
--- a/ui/src/shared/components/ImportOverlay.tsx
+++ b/ui/src/shared/components/ImportOverlay.tsx
@@ -10,6 +10,7 @@ import {
   OverlayHeading,
   OverlayFooter,
   Radio,
+  ComponentStatus,
 } from 'src/clockface'
 import {Button, ComponentColor} from '@influxdata/clockface'
 
@@ -93,6 +94,7 @@ export default class ImportOverlay extends PureComponent<Props, State> {
           submitText=""Upload""
           handleSubmit={this.handleSetImportContent}
           submitOnDrop={true}
+          submitOnUpload={true}
           onCancel={this.clearImportContent}
         />
       )
@@ -110,18 +112,21 @@ export default class ImportOverlay extends PureComponent<Props, State> {
   private get submitButton(): JSX.Element {
     const {resourceName} = this.props
     const {selectedImportOption, importContent} = this.state
-    if (
+    const isEnabled =
       selectedImportOption === ImportOption.Paste ||
       (selectedImportOption === ImportOption.Upload && importContent)
-    ) {
-      return (
-        <Button
-          text={`Import JSON as ${resourceName}`}
-          onClick={this.submit}
-          color={ComponentColor.Primary}
-        />
-      )
-    }
+    const status = isEnabled
+      ? ComponentStatus.Default
+      : ComponentStatus.Disabled
+
+    return (
+      <Button
+        text={`Import JSON as ${resourceName}`}
+        onClick={this.submit}
+        color={ComponentColor.Primary}
+        status={status}
+      />
+    )
   }
 
   private submit = () => {
diff --git a/ui/src/shared/copy/notifications.ts b/ui/src/shared/copy/notifications.ts
index 4492078..86700e2 100644
--- a/ui/src/shared/copy/notifications.ts
+++ b/ui/src/shared/copy/notifications.ts
@@ -799,9 +799,18 @@ export const importTaskSucceeded = (): Notification => ({
 })
 
 export const importTaskFailed = (error: string): Notification => ({
-  ...defaultSuccessNotification,
+  ...defaultErrorNotification,
   message: `Failed to import task: ${error}`,
 })
+export const importDashboardSucceeded = (): Notification => ({
+  ...defaultSuccessNotification,
+  message: `Successfully imported dashboard.`,
+})
+
+export const importDashboardFailed = (error: string): Notification => ({
+  ...defaultErrorNotification,
+  message: `Failed to import dashboard: ${error}`,
+})
 
 // Labels
 export const getLabelsFailed = (): Notification => ({

diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }

diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 
",3,"[""9114362b39f5194209cd0b330af7076333f3db77"", ""ee4bf61fb8836e249fb4ef3507dc938e70696b3f"", ""12257ce53f94dc902df4ba087de90f52d2840ad4""]","[""feat"", ""refactor"", ""docs""]","1. The code changes include adding a new dashboard import feature (new action and notification logic), refactoring the dashboard import overlay to use a callback ref and Redux, and adding a GitLab CI configuration example to the documentation.
2. The 'feat' label aligns with the addition of the dashboard import capability, 'refactor' matches the conversion to callback refs and Redux connect pattern, and 'docs' fits the addition of CI configuration documentation.
3. 'feat' is appropriate because new user-visible functionality is introduced; 'refactor' is correct as the overlay code is restructured without changing external behavior; 'docs' is justified since the CI guide is documentation, not code or build logic. No changes are strictly test, cicd, or build artifacts.
4. The assigned labels ('feat', 'refactor', 'docs') accurately represent the primary motivations and artifact types affected by the changes in this commit."
"update renovate config
fix error spacing","diff --git a/.github/workflows/renovate.yml b/.github/workflows/renovate.yml
index 710d1f6..c83d681 100644
--- a/.github/workflows/renovate.yml
+++ b/.github/workflows/renovate.yml
@@ -1,7 +1,7 @@
 name: Renovate
 on:
   schedule:
-    - cron: '0/5 * * * *'
+    - cron: '0 */8 * * *'
 jobs:
   renovate:
     runs-on: ubuntu-latest

diff --git a/cmd/infracost/main.go b/cmd/infracost/main.go
index 425aef1..fcc9eb5 100644
--- a/cmd/infracost/main.go
+++ b/cmd/infracost/main.go
@@ -149,7 +149,7 @@ Example:
 			}
 
 			if appErr.Error() != """" {
-				fmt.Fprintf(os.Stderr, ""\n%s\n"", color.HiRedString(appErr.Error()))
+				fmt.Fprintf(os.Stderr, ""%s\n"", color.HiRedString(appErr.Error()))
 			}
 		}
 
",2,"[""6132632f7517195c7333308e9c667cdb756bf0af"", ""c623b3622058b913290120b06ccdc779a4e4413d""]","[""cicd"", ""fix""]","1. The commit makes two changes: it updates the cron schedule in the Renovate GitHub Actions workflow file and adjusts the error output formatting in a Go source file by removing a leading newline in the error message.
2. The workflow file change is a modification to CI/CD configuration, matching the 'cicd' object label, while the source file change addresses a formatting bug (unwanted spacing), fitting the 'fix' purpose label.
3. 'cicd' is appropriate for the workflow change because it is entirely scoped to a CI/CD artifact, not general build or test logic; 'fix' fits the Go file change because it corrects an error in output formatting, not introducing new features (feat) or simply restructuring code (refactor).
4. The labels 'cicd' and 'fix' correctly capture the distinct nature of the changes: one is a CI/CD config update, and the other is a bug fix in code behavior."
"update drone
correct width when --no-quotes is used
fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/.drone.yml b/.drone.yml
index 53e3329..306516b 100644
--- a/.drone.yml
+++ b/.drone.yml
@@ -21,10 +21,10 @@ steps:
         from_secret: docker_username
       password:
         from_secret: docker_password
-      tags: pg
+      tags: latest
     when: 
       branch:
-        - pg
+        - master
       event: 
         - push
   - 
@@ -40,14 +40,14 @@ steps:
       port: 22
       script: 
         - ""sleep 10""
-        - ""docker pull rsschool/api:pg""
+        - ""docker pull rsschool/api:latest""
         - ""docker-compose stop api""
         - ""docker-compose rm -f api""
         - ""docker-compose up -d api""
         - ""docker system prune -f""
     when: 
       branch: 
-        - pg
+        - master
       event: 
         - push
 volumes:

diff --git a/src/output/grid.rs b/src/output/grid.rs
index 37f6c57..ce989e5 100644
--- a/src/output/grid.rs
+++ b/src/output/grid.rs
@@ -8,6 +8,8 @@ use crate::output::file_name::{Classify, Options as FileStyle};
 use crate::output::file_name::{EmbedHyperlinks, ShowIcons};
 use crate::theme::Theme;
 
+use super::file_name::QuoteStyle;
+
 #[derive(PartialEq, Eq, Debug, Copy, Clone)]
 pub struct Options {
     pub across: bool,
@@ -55,27 +57,34 @@ impl<'a> Render<'a> {
                 } else {
                     0
                 };
-
-            let space_filename_offset = if file.name.contains(' ') || file.name.contains('\'') {
-                2
-            } else {
-                0
+            let space_filename_offset = match self.file_style.quote_style {
+                QuoteStyle::QuoteSpaces if file.name.contains(' ') => 2,
+                QuoteStyle::NoQuotes => 0,
+                _ => 0, // Default case
             };
-
             let contents = filename.paint();
-            #[rustfmt::skip]
             let width = match (
                 filename.options.embed_hyperlinks,
                 filename.options.show_icons,
             ) {
-                ( EmbedHyperlinks::On, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + classification_width + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::On, ShowIcons::Never )
-                    => filename.bare_width() + classification_width + space_filename_offset,
-                ( EmbedHyperlinks::Off, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::Off, _ )
-                    => *contents.width(),
+                (
+                    EmbedHyperlinks::On,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => {
+                    filename.bare_width()
+                        + classification_width
+                        + 1
+                        + (spacing as usize)
+                        + space_filename_offset
+                }
+                (EmbedHyperlinks::On, ShowIcons::Never) => {
+                    filename.bare_width() + classification_width + space_filename_offset
+                }
+                (
+                    EmbedHyperlinks::Off,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
+                (EmbedHyperlinks::Off, _) => *contents.width(),
             };
 
             grid.add(tg::Cell {

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",3,"[""88129ee45b1d49bc4ff887f3b488464cc7097e29"", ""61eaa2d0cca9bd27d6c5f0a8f9b34200b77fdbb0"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""build"", ""fix"", ""docs""]","1. The commit updates the Drone CI configuration file (.drone.yml), corrects logic in src/output/grid.rs for width calculation with --no-quotes, and fixes documentation in monorepo.md to use the correct property name and more accurate wording.
2. The .drone.yml changes are related to build configuration (changing tags and branch triggers), aligning with the 'build' label; the src/output/grid.rs logic fix addresses incorrect width calculation, aligning with the 'fix' label; the monorepo.md changes correct documentation and property references, aligning with the 'docs' label.
3. 'build' is appropriate for .drone.yml because it affects the build system, not CI/CD workflow scripts or code logic; 'fix' is correct for the grid.rs change as it resolves a logic bug, not adding new features or simply restructuring; 'docs' is correct for monorepo.md as the changes are purely documentation corrections, not affecting code or tests.
4. The assigned labels 'build', 'fix', and 'docs' accurately reflect the nature and motivation of each code unit in the commit according to the classification rules."
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>
add automation for rebasing `*.x.x` branches
parallelize pybind11 build","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
new file mode 100644
index 0000000..3d2f064
--- /dev/null
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -0,0 +1,82 @@
+name: Update Dependencies
+on:
+  schedule:
+    # run every 24 hours at 1 AM
+    - cron: ""1 */24 * * *""
+  workflow_dispatch:
+
+jobs:
+  generate_branches:
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.set-matrix.outputs.matrix }}
+    steps:
+      - name: output branches list
+        id: set-matrix
+        run: |
+          set -euo pipefail
+
+          branches=$(git ls-remote --heads https://github.com/ibis-project/ibis.git \
+              | sed -e 's#\t# #g' -e 's#refs/heads/##g' \
+              | cut -d ' ' -f2 \
+              | grep -P '\d+\.x\.x' \
+              | xargs -I {} printf '""%s""' \
+              | jq -s '{branch: .}')
+
+          echo ""::set-output name=matrix::$branches""
+
+  niv_update:
+    runs-on: ubuntu-latest
+    needs:
+      - generate_branches
+    strategy:
+      matrix: ${{ fromJSON(needs.generate_branches.outputs.matrix) }}
+    steps:
+      - uses: actions/checkout@v3
+
+      - uses: tibdex/github-app-token@v1
+        id: generate_pr_token
+        with:
+          app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
+          private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
+
+      - uses: tibdex/github-app-token@v1
+        id: generate_pr_approval_token
+        with:
+          app_id: ${{ secrets.PR_APPROVAL_BOT_APP_ID }}
+          private_key: ${{ secrets.PR_APPROVAL_BOT_APP_PRIVATE_KEY }}
+
+      - uses: cpcloud/compare-commits-action@v5.0.19
+        id: compare_commits
+        with:
+          token: ${{ steps.generate_pr_token.outputs.token }}
+          owner: ibis-project
+          repo: ibis
+          basehead: ${{ github.sha }}...${{ steps.get_current_commit.outputs.rev }}
+          include-merge-commits: false
+
+      - uses: peter-evans/create-pull-request@v4
+        id: create_pr
+        with:
+          token: ${{ steps.generate_pr_token.outputs.token }}
+          commit-message: ""chore(${{ matrix.branch }}): rebase onto upstream""
+          branch: ""create-pull-request/rebase-${{ matrix.branch }}""
+          base: ${{ matrix.branch }}
+          delete-branch: true
+          author: ""ibis-squawk-bot[bot] <ibis-squawk-bot[bot]@users.noreply.github.com>""
+          title: ""chore(${{ matrix.branch }}): rebase onto upstream""
+          body: ${{ steps.compare_commits.outputs.differences }}
+          labels: dependencies
+
+      - uses: juliangruber/approve-pull-request-action@v1.1.1
+        if: ${{ fromJSON(steps.create_pr.outputs.pull-request-number) != null }}
+        with:
+          github-token: ${{ steps.generate_pr_approval_token.outputs.token }}
+          number: ${{ steps.create_pr.outputs.pull-request-number }}
+
+      - uses: peter-evans/enable-pull-request-automerge@v2
+        if: ${{ fromJSON(steps.create_pr.outputs.pull-request-number) != null }}
+        with:
+          token: ${{ steps.generate_pr_token.outputs.token }}
+          pull-request-number: ${{ steps.create_pr.outputs.pull-request-number }}
+          merge-method: rebase

diff --git a/poetry-overrides.nix b/poetry-overrides.nix
index d37c5ed..aaaaf02 100644
--- a/poetry-overrides.nix
+++ b/poetry-overrides.nix
@@ -82,4 +82,11 @@ self: super:
     {
       patches = (attrs.patches or [ ]) ++ [ ./patches/watchdog-force-kqueue.patch ];
     });
+
+  pybind11 = super.pybind11.overridePythonAttrs (_: {
+    postBuild = ''
+      # build tests
+      make -j $NIX_BUILD_CORES -l $NIX_BUILD_CORES
+    '';
+  });
 }
",3,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""e82254c4ca73fe55834f005f08bc2a060496f815"", ""9ab4c61975e073e214646443d088339cfdbaa88d""]","[""feat"", ""cicd"", ""build""]","1. The Vue component was updated to allow drag-and-drop reordering of attachments in the modal, a new GitHub Actions workflow was added to automate rebasing of certain branches, and the Nix build script was modified to parallelize the pybind11 build.
2. The Vue component change enables a new user-facing capability, matching the 'feat' label; the GitHub Actions YAML is a CI pipeline update, aligning with 'cicd'; the Nix build script change affects build parallelism, fitting the 'build' label.
3. 'feat' is appropriate for the Vue change as it adds functionality, not just fixing or refactoring; 'cicd' is correct for the new workflow since it is a CI config file; 'build' applies to the Nix script as it changes the build system, not application logic or CI.
4. The assigned labels 'feat', 'cicd', and 'build' accurately reflect the distinct purposes and object types of the code changes in this commit."
"fix build ordering
add descriptions to buttons on hover","diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/benchmarks/main.mjs b/benchmarks/main.mjs
index 0c2dc6b..e2f79d4 100644
--- a/benchmarks/main.mjs
+++ b/benchmarks/main.mjs
@@ -65,8 +65,9 @@ const vnode = () =>
           },
           style: style({ margin: '5px' }),
           disabled,
+          title: suite.name.split(' | ')[1],
         },
-        [suite.name],
+        [suite.name.split(' | ')[0]],
       ),
     ),
     m(
diff --git a/benchmarks/suites/appendManyRowsToLargeTable.mjs b/benchmarks/suites/appendManyRowsToLargeTable.mjs
index e6a034e..7e34ca3 100644
--- a/benchmarks/suites/appendManyRowsToLargeTable.mjs
+++ b/benchmarks/suites/appendManyRowsToLargeTable.mjs
@@ -31,7 +31,9 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('append many rows to large table');
+const suite = new benchmark.Suite(
+  'append many rows to large table | appending 1,000 to a table of 10,000 rows.',
+);
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/clearRows.mjs b/benchmarks/suites/clearRows.mjs
index ad47036..2a7711b 100644
--- a/benchmarks/suites/clearRows.mjs
+++ b/benchmarks/suites/clearRows.mjs
@@ -27,7 +27,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(row);
 });
 
-const suite = new benchmark.Suite('clear rows');
+const suite = new benchmark.Suite('clear rows | clearing a table with 1,000 rows');
 
 const hoistedVNode = m('table', undefined, [], VFlags.NO_CHILDREN);
 
diff --git a/benchmarks/suites/createManyRows.mjs b/benchmarks/suites/createManyRows.mjs
index 578f511..96c7b02 100644
--- a/benchmarks/suites/createManyRows.mjs
+++ b/benchmarks/suites/createManyRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create many rows');
+const suite = new benchmark.Suite('create many rows | creating 10,000 rows');
 
 const hoistedVNode = m(
   'div',
diff --git a/benchmarks/suites/createRows.mjs b/benchmarks/suites/createRows.mjs
index bfcc876..4d9ff57 100644
--- a/benchmarks/suites/createRows.mjs
+++ b/benchmarks/suites/createRows.mjs
@@ -7,7 +7,7 @@ import benchmark from '../benchmark';
 import { m, patch } from '../../src/index';
 import { buildData } from '../data';
 
-const suite = new benchmark.Suite('create rows');
+const suite = new benchmark.Suite('create rows | creating 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/partialUpdate.mjs b/benchmarks/suites/partialUpdate.mjs
index 55948a9..c5f1de3 100644
--- a/benchmarks/suites/partialUpdate.mjs
+++ b/benchmarks/suites/partialUpdate.mjs
@@ -34,7 +34,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('partial update');
+const suite = new benchmark.Suite('partial update | updating every 10th row for 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/removeRow.mjs b/benchmarks/suites/removeRow.mjs
index aeb1e9a..31c7599 100644
--- a/benchmarks/suites/removeRow.mjs
+++ b/benchmarks/suites/removeRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('remove row');
+const suite = new benchmark.Suite('remove row | removing one row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/replaceAllRows.mjs b/benchmarks/suites/replaceAllRows.mjs
index 9555ae4..7001667 100644
--- a/benchmarks/suites/replaceAllRows.mjs
+++ b/benchmarks/suites/replaceAllRows.mjs
@@ -41,7 +41,7 @@ data2.forEach(({ id, label }) => {
 
 shuffleArray(data2);
 
-const suite = new benchmark.Suite('replace all rows');
+const suite = new benchmark.Suite('replace all rows | updating all 1,000 rows');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/selectRow.mjs b/benchmarks/suites/selectRow.mjs
index 76be216..de69359 100644
--- a/benchmarks/suites/selectRow.mjs
+++ b/benchmarks/suites/selectRow.mjs
@@ -30,7 +30,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('select row');
+const suite = new benchmark.Suite('select row | highlighting a selected row');
 
 const hoistedVNode = m(
   'table',
diff --git a/benchmarks/suites/swapRows.mjs b/benchmarks/suites/swapRows.mjs
index 2a91e74..ce52036 100644
--- a/benchmarks/suites/swapRows.mjs
+++ b/benchmarks/suites/swapRows.mjs
@@ -36,7 +36,7 @@ data2.forEach(({ id, label }) => {
   el2.appendChild(tr);
 });
 
-const suite = new benchmark.Suite('swap rows');
+const suite = new benchmark.Suite('swap rows | swap 2 rows for table with 1,000 rows');
 
 const hoistedVNode = m(
   'table',
",2,"[""c323d59c607cabc91f17a78528d998f376f30b10"", ""d8d0ba8ea17ed43a04f90213851d2f27056d8cf0""]","[""build"", ""feat""]","1. The change in 'scripts/build.mjs' reorders build commands, affecting the build process, while the changes in the benchmarks directory modify button rendering and add descriptive titles, as well as update benchmark suite names for clarity.
2. The build script modification directly impacts the build system, aligning with the 'build' label, and the UI/benchmark changes introduce a new feature by adding descriptions to buttons, which matches the 'feat' label.
3. 'build' is appropriate for changes to build scripts since they are not CI/CD or documentation, and 'feat' is correct for UI enhancements that add new user-facing capability; 'refactor' is ruled out as behavior is changed, and 'fix' is not appropriate since no bugs are addressed.
4. The 'build' label captures the build script reordering, and the 'feat' label captures the addition of button hover descriptions, accurately reflecting the commit's changes."
"added suported tuple types
use connect instead of begin to avoid nesting transactions
updates the readme to improve the readability and contributing sections","diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/ibis/backends/duckdb/__init__.py b/ibis/backends/duckdb/__init__.py
index 2006f59..bb2028e 100644
--- a/ibis/backends/duckdb/__init__.py
+++ b/ibis/backends/duckdb/__init__.py
@@ -1180,7 +1180,7 @@ WHERE catalog_name = :database""""""
     def _register_udfs(self, expr: ir.Expr) -> None:
         import ibis.expr.operations as ops
 
-        with self.begin() as con:
+        with self.con.connect() as con:
             for udf_node in expr.op().find(ops.ScalarUDF):
                 compile_func = getattr(
                     self, f""_compile_{udf_node.__input_type__.name.lower()}_udf""

diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 
",3,"[""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""6889543bec720e7e7da66535e1012cb66edfe081"", ""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6""]","[""refactor"", ""fix"", ""docs""]","1. The changes in `src/List/Tuple.ts` update the tuple type implementation to support generics and improve type safety, the change in `ibis/backends/duckdb/__init__.py` replaces a transactional context manager to avoid nested transactions, and the updates in `.github/CONTRIBUTING.md` and `README.md` improve documentation clarity and instructions.
2. The TypeScript change is a code structure improvement without altering external behavior, matching the 'refactor' label; the Python change addresses a bug with transaction nesting, fitting the 'fix' label; the markdown file changes are solely documentation enhancements, which align with the 'docs' label.
3. 'refactor' is more appropriate than 'feat' or 'fix' for the TypeScript update because it restructures types without new features or bug fixes; 'fix' is correct for the Python change as it resolves incorrect transaction handling, not a new feature or refactor; 'docs' fits for the markdown changes since they only update documentation, not code logic.
4. The assigned labels 'refactor', 'fix', and 'docs' accurately reflect the respective motivations and artifact types of the changes in this commit, following the classification rules."
"remove duplicated variables
update README.md about the NPM package","diff --git a/packages/core/src/components/item/item.ios.scss b/packages/core/src/components/item/item.ios.scss
index 4de5455..6c4d11a 100644
--- a/packages/core/src/components/item/item.ios.scss
+++ b/packages/core/src/components/item/item.ios.scss
@@ -47,15 +47,6 @@ $item-ios-detail-push-color:              $list-ios-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-ios-detail-push-svg:                ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-ios-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Background for the divider
-$item-ios-divider-background:             #f7f7f7 !default;
-
-/// @prop - Color for the divider
-$item-ios-divider-color:                  #222 !default;
-
-/// @prop - Padding for the divider
-$item-ios-divider-padding:                5px 15px !default;
-
 
 // iOS Item
 // --------------------------------------------------
diff --git a/packages/core/src/components/item/item.md.scss b/packages/core/src/components/item/item.md.scss
index 1dd1800..3dadbc0 100644
--- a/packages/core/src/components/item/item.md.scss
+++ b/packages/core/src/components/item/item.md.scss
@@ -35,21 +35,6 @@ $item-md-detail-push-color:          $list-md-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-md-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-md-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-md-divider-color:              #858585 !default;
-
-/// @prop - Background for the divider
-$item-md-divider-background:         #fff !default;
-
-/// @prop - Font size for the divider
-$item-md-divider-font-size:          $item-md-body-text-font-size !default;
-
-/// @prop - Border bottom for the divider
-$item-md-divider-border-bottom:      1px solid $list-md-border-color !default;
-
-/// @prop - Padding for the divider
-$item-md-divider-padding:            5px 15px !default;
-
 
 .item-md {
   @include padding-horizontal($item-md-padding-start, 0);
diff --git a/packages/core/src/components/item/item.wp.scss b/packages/core/src/components/item/item.wp.scss
index 2c4aae6..07b9266 100644
--- a/packages/core/src/components/item/item.wp.scss
+++ b/packages/core/src/components/item/item.wp.scss
@@ -41,21 +41,6 @@ $item-wp-detail-push-color:          $input-wp-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-wp-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-wp-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-wp-divider-color:              $list-wp-text-color !default;
-
-/// @prop - Background for the divider
-$item-wp-divider-background:         #fff !default;
-
-/// @prop - Bodrer bottom for the divider
-$item-wp-divider-border-bottom:      1px solid $list-wp-border-color !default;
-
-/// @prop - Font size for the divider
-$item-wp-divider-font-size:          2rem !default;
-
-/// @prop - Padding for the divider
-$item-wp-divider-padding:            5px 15px !default;
-
 
 .item-wp {
   @include padding-horizontal($item-wp-padding-start, 0);

diff --git a/README.md b/README.md
index 9faf168..bbb5b5c 100644
--- a/README.md
+++ b/README.md
@@ -126,23 +126,24 @@ pacman -S git-cliff
 
 ### From NPM
 
-[git-cliff](https://www.npmjs.com/package/git-cliff) can be installed from NPM:
+
+You can install and run [git-cliff](https://www.npmjs.com/package/git-cliff) with a single command:
 
 ```sh
-yarn add -D git-cliff
+npx git-cliff@latest
 ```
 
-or:
+Also, if you want to add `git-cliff` to your project:
 
 ```sh
+# with yarn
+yarn add -D git-cliff
+
+# with npm
 npm install git-cliff --save-dev
 ```
 
-You can also use `git-cliff` directly with `npx`:
-
-```sh
-npx git-cliff
-```
+Afterwards, you can run `git-cliff` via `npm exec git-cliff` or `npx git-cliff@latest`.
 
 ### From MacPorts
 
",2,"[""cd7e8c3d3549ea05115b3f02586eeba894d86906"", ""e0177c25e13812306aab0b0991562d58b6d14767""]","[""refactor"", ""docs""]","1. The code changes remove duplicated or redundant SCSS variable definitions from multiple style files and update the README.md with improved instructions for installing and using the NPM package.
2. Removing duplicated variables in the SCSS files is a structural improvement that does not alter external behavior, aligning with the 'refactor' label; updating the README.md is a documentation change, aligning with the 'docs' label.
3. 'refactor' is appropriate for the SCSS changes because no new features are added and no bugs are directly fixed—only code quality is improved; 'docs' is the correct label for the README update because it solely modifies documentation, not code behavior or tests.
4. The 'refactor' and 'docs' labels are justified because the commit is split between codebase structure improvements (SCSS) and documentation enhancements (README), with no overlap with other label categories."
"use new freespace config for disk space recory test
cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
index 0854323..bfc7b7e 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/health/DiskSpaceRecoveryIT.java
@@ -47,7 +47,8 @@ final class DiskSpaceRecoveryIT {
           .withZeebeData(volume)
           .withEnv(""ZEEBE_BROKER_DATA_LOGSEGMENTSIZE"", ""1MB"")
           .withEnv(""ZEEBE_BROKER_NETWORK_MAXMESSAGESIZE"", ""1MB"")
-          .withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.5"");
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""10MB"")
+          .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""1MB"");
 
   private ZeebeClient client;
 
@@ -127,7 +128,9 @@ final class DiskSpaceRecoveryIT {
         ContainerEngine.builder()
             .withDebugReceiverPort(SocketUtil.getNextAddress().getPort())
             .withContainer(
-                container.withEnv(""ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK"", ""0.0001""))
+                container
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_PROCESSING"", ""16MB"")
+                    .withEnv(""ZEEBE_BROKER_DATA_DISK_FREESPACE_REPLICATION"", ""10MB""))
             .build();
 
     @BeforeEach

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",2,"[""672cd2b9775fb6dac2d522cb3f4469db47c0556b"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""test"", ""refactor""]","1. The changes update test configuration values in a Java integration test file and simplify boolean logic in a Go source file by clarifying an if-else block.
2. Modifying the test file to use new configuration values is fully scoped to test logic, aligning with the 'test' label, while the Go file's logic restructuring improves code clarity without altering behavior, fitting the 'refactor' label.
3. 'test' is appropriate for the Java file as it does not introduce new features or fix bugs but updates test setup; 'refactor' is correct for the Go file as it enhances readability without functional changes—'fix' or 'feat' do not apply since no bugs are resolved nor new capabilities added.
4. The 'test' and 'refactor' labels are justified as the commit contains both an isolated test update and a non-functional code improvement, matching the definitions and label selection rules."
"getBorderSize() missing ""width""

The correct property name to use is ""borderWidth"", not just ""border"".
""border"" works in Chrome but was breaking in Firefox.

Also had to change .ui-grid-header's box-sizing to content-box so IE11
would include the border in height calcs. AND finally IE11 was returning
fractional heights so Grid parseInt()s the returned values.
fix readme","diff --git a/src/js/core/factories/Grid.js b/src/js/core/factories/Grid.js
index dcf10af..2be7842 100644
--- a/src/js/core/factories/Grid.js
+++ b/src/js/core/factories/Grid.js
@@ -1525,7 +1525,7 @@ angular.module('ui.grid')
             var oldHeaderHeight = container.headerHeight;
             var headerHeight = gridUtil.outerElementHeight(container.header);
 
-            container.headerHeight = headerHeight;
+            container.headerHeight = parseInt(headerHeight, 10);
 
             if (oldHeaderHeight !== headerHeight) {
               rebuildStyles = true;
@@ -1534,7 +1534,9 @@ angular.module('ui.grid')
             // Get the ""inner"" header height, that is the height minus the top and bottom borders, if present. We'll use it to make sure all the headers have a consistent height
             var topBorder = gridUtil.getBorderSize(container.header, 'top');
             var bottomBorder = gridUtil.getBorderSize(container.header, 'bottom');
-            var innerHeaderHeight = headerHeight - topBorder - bottomBorder;
+            var innerHeaderHeight = parseInt(headerHeight - topBorder - bottomBorder, 10);
+
+            innerHeaderHeight  = innerHeaderHeight < 0 ? 0 : innerHeaderHeight;
 
             container.innerHeaderHeight = innerHeaderHeight;
 
diff --git a/src/js/core/services/ui-grid-util.js b/src/js/core/services/ui-grid-util.js
index 2c32cbe..cc7c36c 100644
--- a/src/js/core/services/ui-grid-util.js
+++ b/src/js/core/services/ui-grid-util.js
@@ -757,6 +757,8 @@ module.service('gridUtil', ['$log', '$window', '$document', '$http', '$templateC
       borderType = 'border';
     }
 
+    borderType += 'Width';
+
     var val = parseInt(styles[borderType], 10);
 
     if (isNaN(val)) {
diff --git a/src/less/header.less b/src/less/header.less
index 5468a43..de8ff0b 100644
--- a/src/less/header.less
+++ b/src/less/header.less
@@ -7,6 +7,7 @@
 
 .ui-grid-header {
   border-bottom: 1px solid @borderColor;
+  box-sizing: content-box;;
 }
 
 .ui-grid-top-panel {

diff --git a/crates/dagger-sdk/README.md b/crates/dagger-sdk/README.md
index ed96be1..974fb7f 100644
--- a/crates/dagger-sdk/README.md
+++ b/crates/dagger-sdk/README.md
@@ -29,9 +29,9 @@ fn main() -> eyre::Result<()> {
     let client = dagger_sdk::connect()?;
 
     let version = client
-        .container(None)
-        .from(""golang:1.19"".into())
-        .with_exec(vec![""go"".into(), ""version"".into()], None)
+        .container()
+        .from(""golang:1.19"")
+        .with_exec(vec![""go"", ""version""])
         .stdout()?;
 
     println!(""Hello from Dagger and {}"", version.trim());
",2,"[""174f25214caa10ec643db6c81aaa0f3511bf78f4"", ""04e70ce964b343e28b3dbd0c46d10ccda958ab8c""]","[""fix"", ""docs""]","1. The changes in JavaScript and LESS files fix cross-browser issues with border property usage and header height calculations, ensuring consistent behavior across Chrome, Firefox, and IE11; the README file is updated to correct example code syntax.
2. The JavaScript and LESS modifications address bugs affecting rendering and calculation logic, aligning with the 'fix' label for resolving faults; the README change aligns with the 'docs' label, as it updates documentation.
3. 'fix' is appropriate for the code and style changes because they directly resolve broken or inconsistent behavior, not adding new features ('feat') or just improving structure ('refactor'); 'docs' is correct for the README change, as it is a documentation artifact, ruling out 'test', 'cicd', or 'build'.
4. The 'fix' and 'docs' labels accurately represent the intent and artifact scope of the changes: bug fixes in code and style, and documentation correction, respectively."
"small error msg improvement

refs #1005
tests should pass now

Make the code more safe
fix unstable MessageCorrelationTest","diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/goreleaserlib/goreleaser.go b/goreleaserlib/goreleaser.go
index 28ba3f4..67ba95d 100644
--- a/goreleaserlib/goreleaser.go
+++ b/goreleaserlib/goreleaser.go
@@ -27,6 +27,15 @@ import (
 	yaml ""gopkg.in/yaml.v2""
 )
 
+var (
+	normalPadding    = cli.Default.Padding
+	increasedPadding = normalPadding * 2
+)
+
+func init() {
+	log.SetHandler(cli.Default)
+}
+
 var pipes = []pipeline.Piper{
 	defaults.Pipe{},  // load default configs
 	git.Pipe{},       // get and validate git repo state
@@ -89,17 +98,15 @@ func Release(flags Flags) error {
 		ctx.Publish = false
 	}
 	ctx.RmDist = flags.Bool(""rm-dist"")
-	logger, _ := log.Log.(*log.Logger)
-	handler, _ := logger.Handler.(*cli.Handler)
 	for _, pipe := range pipes {
-		handler.Padding = 3
+		cli.Default.Padding = normalPadding
 		log.Infof(""\033[1m%s\033[0m"", strings.ToUpper(pipe.String()))
-		handler.Padding = 6
+		cli.Default.Padding = increasedPadding
 		if err := handle(pipe.Run(ctx)); err != nil {
 			return err
 		}
 	}
-	handler.Padding = 3
+	cli.Default.Padding = normalPadding
 	return nil
 }
 
diff --git a/main.go b/main.go
index b9b961d..7ced1dd 100644
--- a/main.go
+++ b/main.go
@@ -18,7 +18,7 @@ var (
 )
 
 func init() {
-	log.SetHandler(lcli.New(os.Stdout))
+	log.SetHandler(lcli.Default)
 }
 
 func main() {

diff --git a/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java b/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
index 0f5fed9..796393c 100644
--- a/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
+++ b/broker-core/src/test/java/io/zeebe/broker/workflow/MessageCorrelationTest.java
@@ -27,7 +27,6 @@ import static io.zeebe.test.util.MsgPackUtil.asMsgPack;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.entry;
 
-import io.zeebe.UnstableTest;
 import io.zeebe.broker.test.EmbeddedBrokerRule;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.BpmnModelInstance;
@@ -50,7 +49,6 @@ import org.agrona.DirectBuffer;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
-import org.junit.experimental.categories.Category;
 import org.junit.rules.RuleChain;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
@@ -165,7 +163,7 @@ public class MessageCorrelationTest {
             ""receive-message"", WorkflowInstanceIntent.ELEMENT_ACTIVATED);
 
     final SubscribedRecord messageSubscription =
-        findMessageSubscription(testClient, MessageSubscriptionIntent.OPENED);
+        findMessageSubscription(MessageSubscriptionIntent.OPENED);
     assertThat(messageSubscription.valueType()).isEqualTo(ValueType.MESSAGE_SUBSCRIPTION);
     assertThat(messageSubscription.recordType()).isEqualTo(RecordType.EVENT);
     assertThat(messageSubscription.value())
@@ -244,7 +242,7 @@ public class MessageCorrelationTest {
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(""wf"", asMsgPack(""orderId"", ""order-123""));
 
-    testClient.receiveFirstWorkflowInstanceEvent(WorkflowInstanceIntent.ELEMENT_ACTIVATED);
+    findMessageSubscription(MessageSubscriptionIntent.OPENED);
 
     // when
     testClient.publishMessage(""order canceled"", ""order-123"", asMsgPack(""foo"", ""bar""));
@@ -308,13 +306,12 @@ public class MessageCorrelationTest {
   }
 
   @Test
-  @Category(UnstableTest.class) // => https://github.com/zeebe-io/zeebe/issues/1234
   public void shouldCorrelateMessageWithZeroTTL() throws Exception {
     // given
     final long workflowInstanceKey =
         testClient.createWorkflowInstance(""wf"", asMsgPack(""orderId"", ""order-123""));
 
-    testClient.receiveElementInState(""receive-message"", WorkflowInstanceIntent.ELEMENT_ACTIVATED);
+    findMessageSubscription(MessageSubscriptionIntent.OPENED);
 
     // when
     testClient.publishMessage(""order canceled"", ""order-123"", asMsgPack(""foo"", ""bar""), 0);
@@ -499,10 +496,9 @@ public class MessageCorrelationTest {
         .containsEntry(""activityInstanceKey"", catchEventEntered.key());
   }
 
-  private SubscribedRecord findMessageSubscription(
-      final TestPartitionClient client, final MessageSubscriptionIntent intent)
+  private SubscribedRecord findMessageSubscription(final MessageSubscriptionIntent intent)
       throws AssertionError {
-    return client
+    return testClient
         .receiveEvents()
         .filter(intent(intent))
         .findFirst()
",3,"[""a62314d9bb632be6af026686615d14b912250512"", ""5636313d7c9cfbd9f48578fd104771d65eae9720"", ""98bed2a8137930149559bc1cae9bd34a1a75e556""]","[""refactor"", ""fix"", ""test""]","1. The changes include improving an error message in a Go file, restructuring log handler setup and padding logic in Go source files, and modifying a Java test file by removing an unstable test annotation, refactoring test helper usage, and updating test logic.
2. The error message improvement and log handler changes increase safety and clarity, aligning with 'refactor' for code structure/clarity improvements; the test file modifications directly update test logic and structure, aligning with the 'test' label; the removal of the unstable annotation and test logic changes specifically address a previously unstable test, aligning with the 'fix' label for resolving test instability.
3. 'refactor' is appropriate for code clarity and safety improvements that do not alter external behavior, not 'feat' (no new features) or 'fix' (no direct bug fix in non-test logic); 'test' is correct because the Java file changes are entirely within a test file and focus on test code; 'fix' is justified because the MessageCorrelationTest was unstable and the changes directly stabilize it, which is a bug fix in the test suite.
4. The assigned labels 'refactor', 'fix', and 'test' correctly capture the code structure improvements, test stabilization, and test file modifications present in this commit."
missing transformation for T,"diff --git a/src/Tuple/Merge.ts b/src/Tuple/Merge.ts
index dfa7ce5..5ba44b7 100644
--- a/src/Tuple/Merge.ts
+++ b/src/Tuple/Merge.ts
@@ -30,7 +30,7 @@ type _MergeFlat<O extends object, O1P extends object> = {
 }
 
 type MergeDeep<T extends any[], T1 extends any[]> =
-    TupleOf<Compute<_MergeDeep<T, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
+    TupleOf<Compute<_MergeDeep<ObjectOf<T>, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
     // same principle as above, but with a little tweak
     // we keep the original `O1` to know if we can merge
     // => if `O` and `O1` have `object` fields of same name
",1,"[""c4d9e5023fa0f88ba283b37da27677ceda1cbfbb""]","[""fix""]","1. The change updates the MergeDeep type definition to ensure that T is transformed using ObjectOf before being passed to _MergeDeep, correcting the transformation logic.
2. This change directly addresses a missing transformation step that could cause incorrect behavior, aligning with the 'fix' label definition for resolving bugs or faults.
3. The change is not introducing new features ('feat') nor merely restructuring code without changing behavior ('refactor'); it specifically corrects a functional issue, ruling out alternative labels.
4. The 'fix' label is appropriate because the modification corrects an error in the type transformation logic, restoring intended behavior."
remove unused,"diff --git a/src/content/redux/modules/dictionaries.ts b/src/content/redux/modules/dictionaries.ts
index 88f7215..570d397 100644
--- a/src/content/redux/modules/dictionaries.ts
+++ b/src/content/redux/modules/dictionaries.ts
@@ -3,7 +3,6 @@ import { DictID, appConfigFactory, AppConfig } from '@/app-config'
 import isEqual from 'lodash/isEqual'
 import { saveWord } from '@/_helpers/record-manager'
 import { getDefaultSelectionInfo, SelectionInfo, isSameSelection } from '@/_helpers/selection'
-import { createActiveConfigStream } from '@/_helpers/config-manager'
 import { isContainChinese, isContainEnglish, testerPunct, isContainMinor, testerChinese, testJapanese, testKorean } from '@/_helpers/lang-check'
 import { MsgType, MsgFetchDictResult } from '@/typings/message'
 import { StoreState, DispatcherThunk, Dispatcher } from './index'
diff --git a/src/content/redux/modules/widget.ts b/src/content/redux/modules/widget.ts
index 53ad550..68e0a3d 100644
--- a/src/content/redux/modules/widget.ts
+++ b/src/content/redux/modules/widget.ts
@@ -1,9 +1,9 @@
 import * as recordManager from '@/_helpers/record-manager'
 import { StoreState, DispatcherThunk, Dispatcher } from './index'
-import appConfigFactory, { TCDirection, AppConfig, DictID } from '@/app-config'
+import appConfigFactory, { TCDirection, DictID } from '@/app-config'
 import { message, storage } from '@/_helpers/browser-api'
-import { createActiveConfigStream, createConfigIDListStream } from '@/_helpers/config-manager'
-import { MsgSelection, MsgType, MsgTempDisabledState, MsgEditWord, MsgOpenUrl, MsgFetchDictResult } from '@/typings/message'
+import { createConfigIDListStream } from '@/_helpers/config-manager'
+import { MsgType, MsgTempDisabledState, MsgEditWord, MsgOpenUrl, MsgFetchDictResult } from '@/typings/message'
 import { searchText, restoreDicts } from '@/content/redux/modules/dictionaries'
 import { SelectionInfo, getDefaultSelectionInfo } from '@/_helpers/selection'
 import { Mutable } from '@/typings/helpers'
",1,"[""a50b51999015e210918d9c8e95fd4cac347353be""]","[""refactor""]","1. The code changes remove unused imports from two TypeScript modules without altering any logic or behavior.
2. These changes align with the 'refactor' label, which covers restructuring code for cleanliness or maintainability without changing external behavior.
3. The 'refactor' label is appropriate because the modifications do not introduce new features ('feat'), fix bugs ('fix'), or affect tests, documentation, CI/CD, or build artifacts; they solely improve code quality by removing dead code.
4. Assigning 'refactor' is justified as the change is strictly about code cleanup, matching the definition precisely."
"Remove hasmany and belongsto from context menu

Signed-off-by: Pranav C <61551451+pranavxc@users.noreply.github.com>
fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
index 5bc6f67..aaa297c 100644
--- a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
+++ b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
@@ -261,37 +261,7 @@
             :size=""size""
             @input=""loadTableData""
           />
-          <!--  <v-pagination
-              v-if=""count !== Infinity""
-              style=""max-width: 100%""
-              v-model=""page""
-              :length=""Math.ceil(count / size)""
-              :total-visible=""8""
-              @input=""loadTableData""
-              color=""primary lighten-2""
-            ></v-pagination>
-            <div v-else class=""mx-auto d-flex align-center mt-n1 "" style=""max-width:250px"">
-              <span class=""caption"" style=""white-space: nowrap""> Change page:</span>
-              <v-text-field
-                class=""ml-1 caption""
-                :full-width=""false""
-                outlined
-                dense
-                hide-details
-                v-model=""page""
-                @keydown.enter=""loadTableData""
-                type=""number""
-              >
-                <template #append>
-                  <x-icon tooltip=""Change page"" small icon.class=""mt-1"" @click=""loadTableData"">mdi-keyboard-return
-                  </x-icon>
-                </template>
-              </v-text-field>
-            </div>-->
         </template>
-        <!--      <div v-else class=""d-flex justify-center py-4"">-->
-        <!--        <v-alert type=""info"" dense class=""ma-1 flex-shrink-1"">Table is empty</v-alert>-->
-        <!--      </div>-->
       </div>
 
       <spreadsheet-nav-drawer
@@ -414,9 +384,9 @@
             <span class=""caption"">Delete Selected Rows</span>
           </v-list-item>
         </template>
-        <template v-if=""meta.hasMany && meta.hasMany.length"">
+        <!--        <template v-if=""meta.hasMany && meta.hasMany.length"">
           <v-divider v-if=""isEditable && !isLocked"" />
-          <span class=""ml-3 grey--text "" style=""font-size: 9px"">Has Many</span>
+          <span class=""ml-3 grey&#45;&#45;text "" style=""font-size: 9px"">Has Many</span>
 
           <v-list-item v-for=""(hm,i) in meta.hasMany"" :key=""i"" @click=""addNewRelationTabCtxMenu(hm,'hm')"">
             <span class=""caption text-capitalize"">{{ hm._tn }}</span>
@@ -425,12 +395,12 @@
 
         <template v-if=""meta.belongsTo && meta.belongsTo.length"">
           <v-divider />
-          <span class=""ml-3 grey--text "" style=""font-size: 9px"">Belongs To</span>
+          <span class=""ml-3 grey&#45;&#45;text "" style=""font-size: 9px"">Belongs To</span>
 
           <v-list-item v-for=""(bt,i) in belongsTo"" :key=""i"" @click=""addNewRelationTabCtxMenu(bt,'bt')"">
             <span class=""caption text-capitalize"">{{ bt._rtn }}</span>
           </v-list-item>
-        </template>
+        </template>-->
       </v-list>
     </v-menu>
     <v-dialog

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",2,"[""7dbbb64c45506ef634180638db800b6d9535523d"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""refactor"", ""docs""]","1. The code changes include removing commented-out UI logic from a Vue component and updating documentation in a Markdown file to rename a configuration property and clarify related instructions.
2. The removal of commented code in the Vue file aligns with the 'refactor' label as it improves code cleanliness and maintainability without altering external behavior, while the Markdown edits are strictly documentation updates, matching the 'docs' label.
3. 'refactor' is appropriate for the Vue file because the change does not introduce new features ('feat'), fix bugs ('fix'), or affect tests, CI/CD, or build systems; 'docs' is correct for the Markdown file as it only updates documentation, not code or configuration logic.
4. The assigned labels 'refactor' and 'docs' accurately represent the intent and scope of the changes: codebase cleanup and documentation correction, respectively."
"verify property exist in row object

Signed-off-by: Pranav C <pranavxc@gmail.com>
add fallible peek_last_token()
spring version, core version","diff --git a/packages/nc-gui/components/smartsheet/Grid.vue b/packages/nc-gui/components/smartsheet/Grid.vue
index 8ff5b1d..e83e2ab 100644
--- a/packages/nc-gui/components/smartsheet/Grid.vue
+++ b/packages/nc-gui/components/smartsheet/Grid.vue
@@ -534,7 +534,7 @@ const saveOrUpdateRecords = async (args: { metaValue?: TableType; viewMetaValue?
       currentRow.rowMeta.changed = false
       for (const field of (args.metaValue || meta.value)?.columns ?? []) {
         if (isVirtualCol(field)) continue
-        if (currentRow.row[field.title!] !== currentRow.oldRow[field.title!]) {
+        if (field.title! in currentRow.row && currentRow.row[field.title!] !== currentRow.oldRow[field.title!]) {
           await updateOrSaveRow(currentRow, field.title!, {}, args)
         }
       }

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",3,"[""c6403b62f8dc0e5bfe25a1c6306fb7040ca447ae"", ""63eab619e6166eb6cab948028a7b89bf059dd878"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""fix"", ""refactor"", ""build""]","1. The commit includes a Vue component change to check property existence before comparison (Grid.vue), Rust parser changes adding a fallible method and new error variant (errors.rs, mod.rs), and updates to Java build dependency versions (pom.xml files).
2. The Vue and Rust changes address bug-prone logic—checking property existence prevents runtime errors (fix), and the parser refactor introduces a safer method (peek_last_token) and new error handling, improving code structure (refactor). The pom.xml modifications update dependencies and plugin versions, directly affecting the build process (build).
3. The 'fix' label is justified for the Vue logic correction, which prevents errors; 'refactor' fits the Rust parser improvements that restructure error handling and token access without changing external behavior; 'build' is appropriate for the dependency version bumps, as these only affect build configuration. No object labels like 'test', 'docs', or 'cicd' are involved, and no new user-facing features are added, so 'feat' is excluded.
4. The assigned labels 'fix', 'refactor', and 'build' accurately reflect the bug fix, code restructuring, and build system updates present in this commit."
Handle different events.,"diff --git a/src/notebook/epics/kernel-launch.js b/src/notebook/epics/kernel-launch.js
index 9075d7c..9f16e67 100644
--- a/src/notebook/epics/kernel-launch.js
+++ b/src/notebook/epics/kernel-launch.js
@@ -113,6 +113,12 @@ export function newKernelObservable(kernelSpec: KernelInfo, cwd: string) {
           observer.error({ type: 'ERROR', payload: error, err: true });
           observer.complete();
         });
+        spawn.on('exit', () => {
+          observer.complete();
+        });
+        spawn.on('disconnect', () => {
+          observer.complete();
+        });
       });
   });
 }
",1,"[""a280a52c8309465276c3509848ddcddbe19732b6""]","[""fix""]","1. The code change adds event listeners for 'exit' and 'disconnect' events on the 'spawn' process, ensuring that observer.complete() is called when these events occur.
2. This update handles previously unhandled process events, preventing potential issues where the observer might not be completed—directly aligning with the 'fix' label which is for resolving bugs or faults.
3. The change is not introducing new functionality ('feat') or restructuring code without behavioral changes ('refactor'), but rather corrects a behavioral oversight, ruling out alternative labels.
4. The 'fix' label is appropriate because the change addresses a bug by ensuring all relevant process terminations are handled properly."
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.
correct code comment","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/server/src/db.rs b/server/src/db.rs
index bfc5e17..0fb4d55 100644
--- a/server/src/db.rs
+++ b/server/src/db.rs
@@ -389,7 +389,7 @@ impl Db {
             let partition = LockableCatalogPartition::new(Arc::clone(&self), partition);
 
             // Do lock dance to get a write lock on the partition as well
-            // as on all of the chunks
+            // as on the to-be-dropped chunk.
             let partition = partition.read();
 
             let chunk = self.lockable_chunk(table_name, partition_key, chunk_id)?;
",2,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""cccdd8a43fea7614f78b6f1dcf1765100928a3db""]","[""test"", ""docs""]","1. The changes include modifying a test scenario in a Java test file to adapt to new FEEL engine behavior and correcting a code comment in a Rust source file.
2. Adjusting the test logic and behavior aligns with the 'test' label, as the changes are dedicated to test files; updating a comment aligns with the 'docs' label, as it only affects documentation within the code.
3. 'test' is appropriate for the Java file since it only modifies test logic without affecting production code, ruling out 'fix', 'feat', or 'refactor'; 'docs' is appropriate for the Rust file as only a comment is changed, not code logic, ruling out other labels.
4. The 'test' and 'docs' labels accurately represent the changes, as the commit is fully scoped to test logic updates and documentation correction."
retry uploading pdb files on appveyor (#21561),"diff --git a/appveyor.yml b/appveyor.yml
index 9aca21e..8b54543 100644
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -146,12 +146,12 @@ build_script:
   - ps: >-
       if ($env:GN_CONFIG -eq 'release') {
         python electron\script\zip-symbols.py
-        appveyor PushArtifact out/Default/symbols.zip
+        appveyor-retry appveyor PushArtifact out/Default/symbols.zip
       } else {
         # It's useful to have pdb files when debugging testing builds that are
         # built on CI.
         7z a pdb.zip out\Default\*.pdb
-        appveyor PushArtifact pdb.zip
+        appveyor-retry appveyor PushArtifact pdb.zip
       }
   - python electron/script/zip_manifests/check-zip-manifest.py out/Default/dist.zip electron/script/zip_manifests/dist_zip.win.%TARGET_ARCH%.manifest
 test_script:
",1,"[""7152173d26293f4638920b17ce2dfa8ae995193b""]","[""cicd""]","1. The change modifies the 'appveyor.yml' CI configuration file to wrap artifact upload commands with 'appveyor-retry', enabling retry logic for uploading pdb and symbol files during the build process.
2. This update is strictly scoped to a CI configuration script, directly aligning with the 'cicd' label, which is defined for changes to CI configuration files or scripts.
3. The label 'cicd' is appropriate because the modification does not alter build logic, code behavior, or add features; it only changes how CI handles artifact uploads, ruling out 'build', 'fix', or 'feat'.
4. The 'cicd' label accurately reflects that the commit is dedicated to improving CI artifact upload reliability by altering CI configuration."
"move toolbar to tab content level

Signed-off-by: Pranav C <pranavxc@gmail.com>
update the formatting for python integration example","diff --git a/packages/nc-gui-v2/components.d.ts b/packages/nc-gui-v2/components.d.ts
index f6be04b..cf555ef 100644
--- a/packages/nc-gui-v2/components.d.ts
+++ b/packages/nc-gui-v2/components.d.ts
@@ -201,6 +201,7 @@ declare module '@vue/runtime-core' {
     MdiThumbUp: typeof import('~icons/mdi/thumb-up')['default']
     MdiTrashCan: typeof import('~icons/mdi/trash-can')['default']
     MdiTwitter: typeof import('~icons/mdi/twitter')['default']
+    MdiUpload: typeof import('~icons/mdi/upload')['default']
     MdiUploadOutline: typeof import('~icons/mdi/upload-outline')['default']
     MdiViewListOutline: typeof import('~icons/mdi/view-list-outline')['default']
     MdiWhatsapp: typeof import('~icons/mdi/whatsapp')['default']
diff --git a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
index c2c87d3..27c0acc 100644
--- a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
+++ b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
@@ -132,7 +132,7 @@ async function changeLockType(type: LockType) {
   <div>
     <a-dropdown>
       <a-button v-t=""['c:actions']"" class=""nc-actions-menu-btn nc-toolbar-btn"">
-        <div class=""flex gap-2 align-center"">
+        <div class=""flex gap-2 items-center"">
           <component
             :is=""viewIcons[selectedView?.type].icon""
             class=""nc-view-icon group-hover:hidden""
@@ -311,6 +311,6 @@ async function changeLockType(type: LockType) {
 
 <style scoped>
 .nc-locked-menu-item > div {
-  @apply grid grid-cols-[30px,auto] gap-2  p-2 align-center;
+  @apply grid grid-cols-[30px,auto] gap-2  p-2 items-center;
 }
 </style>
diff --git a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
index 5fa555f..d498871 100644
--- a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
+++ b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
@@ -36,7 +36,7 @@ const {isOpen} =useSidebar()
 
     <SmartsheetToolbarSearchData v-if=""(isGrid || isGallery) && !isPublic"" class=""shrink mr-2 ml-2"" />
 
-    <ToggleDrawer v-if=""!isOpen""/>
+    <ToggleDrawer class=""mr-2""/>
 
 
   </div>
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
index 896ad62..77aee05 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
@@ -99,6 +99,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
     class=""relative shadow-md h-full""
     theme=""light""
   >
+    <!--
     <Toolbar
       v-if=""isOpen""
       class=""min-h-[var(--toolbar-height)] max-h-[var(--toolbar-height)]""
@@ -128,7 +129,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
         <div v-if=""!isForm"" class=""dot"" />
       </template>
     </Toolbar>
-
+-->
     <div v-if=""isOpen"" class=""flex-1 flex flex-col"">
       <MenuTop @open-modal=""openModal"" @deleted=""loadViews"" @sorted=""loadViews"" />
 
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
index 3e3d78a..8441450 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
@@ -4,7 +4,7 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
 </script>
 
 <template>
-  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
+<!--  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
     <template #title> Toggle sidebar</template>
 
     <div class=""nc-sidebar-right-item hover:after:(bg-primary bg-opacity-75) group nc-sidebar-add-row"">
@@ -14,5 +14,11 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
         @click=""toggle(!isOpen)""
       />
     </div>
-  </a-tooltip>
+  </a-tooltip>-->
+
+  <a-button @click=""toggle(!isOpen)"" size=""small"">
+  <div class=""flex items-center gap-2"">  <MdiMenu/> Views
+  </div>
+  </a-button>
+
 </template>
diff --git a/packages/nc-gui-v2/components/tabs/Smartsheet.vue b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
index 4181996..7b7ec36 100644
--- a/packages/nc-gui-v2/components/tabs/Smartsheet.vue
+++ b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
@@ -83,11 +83,11 @@ watch(isLocked, (nextValue) => (treeViewIsLockedInj.value = nextValue), { immedi
 
             <SmartsheetForm v-else-if=""isForm"" />
           </div>
+          <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
         </div>
       </template>
     </div>
 
-    <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
   </div>
 </template>
 

diff --git a/website/docs/integration/python.md b/website/docs/integration/python.md
index 064cae3..b6b720d 100644
--- a/website/docs/integration/python.md
+++ b/website/docs/integration/python.md
@@ -13,6 +13,7 @@ header = ""All notable changes to this project will be documented in this file.""
 body = ""...""
 footer = ""<!-- generated by git-cliff -->""
 # see [changelog] section for more keys
+
 [tool.git-cliff.git]
 conventional_commits = true
 commit_parsers = []
",2,"[""bf95d5d0b34d32ef2684488feb3de01cb824b2b4"", ""3ee672483790ec71c700907a6e93af4698492026""]","[""refactor"", ""docs""]","1. The code changes include moving the toolbar component to a different level in the Vue component hierarchy, updating class names for alignment (e.g., 'align-center' to 'items-center'), commenting out and replacing some UI logic, and making a minor formatting change in a Python documentation file.
2. The restructuring of Vue components and UI logic without changing external behavior aligns with the 'refactor' label, while the formatting update in the markdown documentation file aligns with the 'docs' label.
3. 'refactor' is appropriate because the main codebase changes improve structure and component placement without adding features or fixing bugs, and 'docs' is correct for the documentation formatting change; 'feat' and 'fix' are not applicable as there is no new functionality or bug resolution, and 'test', 'cicd', and 'build' do not apply as no test, CI/CD, or build artifacts are modified.
4. The 'refactor' label captures the code restructuring in the application, and the 'docs' label captures the documentation formatting update, matching the intended scope of each change."
"added resize observer, this will replace window.resize if available","diff --git a/engine/src/Utils/EventListeners.ts b/engine/src/Utils/EventListeners.ts
index 9e7b189..a29cab4 100644
--- a/engine/src/Utils/EventListeners.ts
+++ b/engine/src/Utils/EventListeners.ts
@@ -47,6 +47,7 @@ export class EventListeners {
 
     private canPush: boolean;
     private resizeTimeout?: NodeJS.Timeout;
+    private resizeObserver?: ResizeObserver;
 
     /**
      * Events listener constructor
@@ -144,7 +145,31 @@ export class EventListeners {
         }
 
         if (options.interactivity.events.resize) {
-            manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            if (typeof ResizeObserver !== ""undefined"") {
+                if (this.resizeObserver && !add) {
+                    if (container.canvas.element) {
+                        this.resizeObserver.unobserve(container.canvas.element);
+                    }
+
+                    this.resizeObserver.disconnect();
+
+                    delete this.resizeObserver;
+                } else if (!this.resizeObserver && add && container.canvas.element) {
+                    this.resizeObserver = new ResizeObserver((entries) => {
+                        const entry = entries.find((e) => e.target === container.canvas.element);
+
+                        if (!entry) {
+                            return;
+                        }
+
+                        this.handleWindowResize();
+                    });
+
+                    this.resizeObserver.observe(container.canvas.element);
+                }
+            } else {
+                manageListener(window, Constants.resizeEvent, this.resizeHandler, add);
+            }
         }
 
         if (document) {
",1,"[""4197f2654e8767039dbfd66eca34f261ee3d88c8""]","[""feat""]","1. The code introduces a new ResizeObserver-based mechanism for resize event handling, falling back to the previous window.resize listener if ResizeObserver is unavailable.
2. This modification adds a new capability—using ResizeObserver for resize detection—matching the 'feat' label's definition of introducing new features.
3. The change is not a bug fix ('fix'), nor is it a pure code restructuring without behavior change ('refactor'); it is also not isolated to documentation, tests, CI, or build artifacts.
4. The 'feat' label is appropriate because the commit adds a new feature (ResizeObserver support) to the codebase."
"use new, public `quay.io/influxdb/iox` image
updated test to use rows for action items

references #279","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 3ae6728..a5f2d2f 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -12,7 +12,7 @@
 # The CI for every PR and merge to main runs tests, fmt, lints and compiles debug binaries
 #
 # On main if all these checks pass it will then additionally compile in ""release"" mode and
-# publish a docker image to quay.io/influxdb/fusion:$COMMIT_SHA
+# publish a docker image to quay.io/influxdb/iox:$COMMIT_SHA
 #
 # Manual CI Image:
 #
@@ -317,11 +317,11 @@ jobs:
   #
   # Uses the latest ci_image (influxdb/rust below) to build a release binary and
   # copies it to a minimal container image based upon `rust:slim-buster`. This
-  # minimal image is then pushed to `quay.io/influxdb/fusion:${BRANCH}` with '/'
+  # minimal image is then pushed to `quay.io/influxdb/iox:${BRANCH}` with '/'
   # repaced by '.' - as an example:
   #
   #   git branch: dom/my-awesome-feature/perf
-  #   container: quay.io/influxdb/fusion:dom.my-awesome-feature.perf
+  #   container: quay.io/influxdb/iox:dom.my-awesome-feature.perf
   #
   # Subsequent CI runs will overwrite the tag if you push more changes, so watch
   # out for parallel CI runs!
@@ -365,7 +365,7 @@ jobs:
           sudo apt-get update
           sudo apt-get install -y docker.io
       - run: |
-          echo ""$QUAY_PASS"" | docker login quay.io --username $QUAY_USER --password-stdin
+          echo ""$QUAY_INFLUXDB_IOX_PASS"" | docker login quay.io --username $QUAY_INFLUXDB_IOX_USER --password-stdin
       - run:
           # Docker has functionality to support per-Dockerfile .dockerignore
           # This was added in https://github.com/moby/buildkit/pull/901
@@ -379,8 +379,8 @@ jobs:
           echo sha256sum after build is
           sha256sum target/release/influxdb_iox
           COMMIT_SHA=$(git rev-parse --short HEAD)
-          docker build -t quay.io/influxdb/fusion:$COMMIT_SHA -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/fusion:$COMMIT_SHA
+          docker build -t quay.io/influxdb/iox:$COMMIT_SHA -f docker/Dockerfile.iox .
+          docker push quay.io/influxdb/iox:$COMMIT_SHA
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags

diff --git a/ionic/components/card/test/advanced/main.html b/ionic/components/card/test/advanced/main.html
index 7c56a7d..c19ea12 100644
--- a/ionic/components/card/test/advanced/main.html
+++ b/ionic/components/card/test/advanced/main.html
@@ -19,16 +19,20 @@
       </p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left>
-        <icon star></icon>
-        Star
-      </button>
-      <button clear item-right class=""activated"">
-        <icon share></icon>
-        Share.activated
-      </button>
-    </ion-item>
+    <ion-row no-padding>
+      <ion-col>
+        <button clear small>
+          <icon star></icon>
+          Star
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small class=""activated"">
+          <icon share></icon>
+          Share.activated
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
@@ -51,19 +55,24 @@
       <p>Hello. I am a paragraph.</p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left danger class=""activated"">
-        <icon star></icon>
-        Favorite.activated
-      </button>
-      <button clear item-left danger>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <ion-note item-right>
-        Right Note
-      </ion-note>
-    </ion-item>
+    <ion-row center no-padding>
+      <ion-col width-75>
+        <button clear small danger class=""activated"">
+          <icon star></icon>
+          Favorite.activated
+        </button>
+        <button clear small danger>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small>
+          <icon share></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
   </ion-card>
 
   <ion-card>
@@ -76,20 +85,27 @@
       This card was breaking the border radius.
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left dark>
-        <icon star></icon>
-        Favorite
-      </button>
-      <button clear item-right dark>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <button clear item-right dark>
-        <icon share-alt></icon>
-        Share
-      </button>
-    </ion-item>
+    <ion-row text-center no-padding>
+      <ion-col>
+        <button clear small dark>
+          <icon star></icon>
+          Favorite
+        </button>
+      </ion-col>
+
+      <ion-col>
+        <button clear small dark>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col>
+        <button clear small dark>
+          <icon share-alt></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
",2,"[""f751bb5426b87f82096d620f1cd6203badf45d58"", ""19feaea1885eb015759b5c7a5d785521f2b8a212""]","[""cicd"", ""test""]","1. The changes update the CircleCI configuration file to use a new Docker image repository and credentials, and modify an HTML test file to use rows and columns for action items instead of item-based layouts.
2. The CircleCI config changes directly update CI pipeline behavior, aligning with the 'cicd' label, while the HTML file is a dedicated test artifact being modified for layout, aligning with the 'test' label.
3. 'cicd' is appropriate for changes to CI configuration rather than 'build' (not build scripts), and 'test' is correct for modifying test markup rather than 'feat', 'fix', or 'refactor' (no new features or bugfixes, and only test code is affected).
4. The assigned labels 'cicd' and 'test' are appropriate because each change is fully scoped to its respective artifact category: CI configuration and test code."
"handle default_branch_monthly_cost having no cost

Closes https://github.com/infracost/infracost-gh-action/issues/17
fix test

Write another record so the commit position is updated and we can take a snapshot
better layout for block and segment","diff --git a/scripts/ci/diff.sh b/scripts/ci/diff.sh
index 7472273..fa48e4b 100755
--- a/scripts/ci/diff.sh
+++ b/scripts/ci/diff.sh
@@ -112,7 +112,12 @@ echo ""$default_branch_output"" > default_branch_infracost.txt
 default_branch_monthly_cost=$(cat default_branch_infracost.txt | awk '/OVERALL TOTAL/ { gsub("","",""""); printf(""%.2f"",$NF) }')
 echo ""::set-output name=default_branch_monthly_cost::$default_branch_monthly_cost""
 
-percent_diff=$(echo ""scale=4; $current_branch_monthly_cost / $default_branch_monthly_cost * 100 - 100"" | bc)
+if [ $(echo ""$default_branch_monthly_cost > 0"" | bc -l) = 1 ]; then
+  percent_diff=$(echo ""scale=4; $current_branch_monthly_cost / $default_branch_monthly_cost * 100 - 100"" | bc)
+else
+  echo ""Default branch has no cost, setting percent_diff=100 to force a comment""
+  percent_diff=100
+fi
 absolute_percent_diff=$(echo $percent_diff | tr -d -)
 
 if [ $(echo ""$absolute_percent_diff > $percentage_threshold"" | bc -l) = 1 ]; then

diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
index 24f1316..881c727 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java
@@ -70,6 +70,14 @@ public class ReaderCloseTest {
             .getCluster()
             .getNodeId();
     clusteringRule.forceClusterToHaveNewLeader(followerId);
+    // because of https://github.com/camunda-cloud/zeebe/issues/8329
+    // we need to add another record so we can do a snapshot
+    clientRule
+        .getClient()
+        .newPublishMessageCommand()
+        .messageName(""test"")
+        .correlationKey(""test"")
+        .send();
 
     // when
     clusteringRule.triggerAndWaitForSnapshots();
@@ -78,6 +86,7 @@ public class ReaderCloseTest {
     for (final Broker broker : clusteringRule.getBrokers()) {
       assertThatFilesOfDeletedSegmentsDoesNotExist(broker);
     }
+    assertThat(leaderId).isNotEqualTo(clusteringRule.getLeaderForPartition(1).getNodeId());
   }
 
   private void assertThatFilesOfDeletedSegmentsDoesNotExist(final Broker leader)

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",3,"[""9474f58b44a35321e9157ca9890c589a7b3729b2"", ""47df74d40becf915a9d89cdb887abd259b77def0"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""fix"", ""test"", ""docs""]","1. The change to 'scripts/ci/diff.sh' adds a check to handle cases where 'default_branch_monthly_cost' is zero, fixing a potential division by zero bug. The update in 'qa/integration-tests/src/test/java/io/camunda/zeebe/it/clustering/ReaderCloseTest.java' adds an extra record and assertion to the test logic. Multiple files under 'docs/docs/' are either added or modified, updating and reorganizing documentation, and 'docs/sidebars.js' is updated to reference new doc files.
2. The 'scripts/ci/diff.sh' change addresses a bug, matching the 'fix' label. The test file change is a clear example of test logic modification, matching the 'test' label. The multiple documentation file changes and sidebar update are strictly documentation-related, aligning with the 'docs' label.
3. 'fix' is correct for the shell script because it resolves a behavioral bug, not a feature addition or refactor. 'test' is correct for the Java test file since the change is limited to test logic, not production code. 'docs' is appropriate for all documentation and sidebar changes, as they exclusively affect documentation artifacts, not code or build/test logic.
4. The assigned labels 'fix', 'test', and 'docs' comprehensively and accurately reflect the scope and intent of the changes in this commit, with each label applied to a distinct artifact type or purpose."
"verify the replay mode

* write a test to verify the different replay modes
replace tuple with record
add a branch name to Slack notifications (#14793)","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
index 167444c..7494014 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
@@ -11,6 +11,9 @@ import io.camunda.zeebe.engine.state.ZbColumnFamilies;
 import io.camunda.zeebe.engine.util.EngineRule;
 import io.camunda.zeebe.engine.util.ListLogStorage;
 import io.camunda.zeebe.model.bpmn.Bpmn;
+import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
+import io.camunda.zeebe.protocol.record.value.BpmnElementType;
+import io.camunda.zeebe.test.util.record.RecordingExporter;
 import org.assertj.core.api.SoftAssertions;
 import org.awaitility.Awaitility;
 import org.junit.Rule;
@@ -27,16 +30,22 @@ public class ContinuouslyReplayTest {
   @Rule public final EngineRule processing = EngineRule.withSharedStorage(sharedStorage);
 
   @Test
-  public void shouldEndUpWithTheSameState() {
+  public void shouldBuildTheSameStateOnProcessingAndReplay() {
     // given
-
-    // when
     processing
         .deployment()
-        .withXmlResource(Bpmn.createExecutableProcess().startEvent().endEvent().done())
+        .withXmlResource(Bpmn.createExecutableProcess(""process"").startEvent().endEvent().done())
         .deploy();
 
+    // when
+    final var processInstanceKey = processing.processInstance().ofBpmnProcessId(""process"").create();
+
     // then
+    RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_COMPLETED)
+        .withProcessInstanceKey(processInstanceKey)
+        .withElementType(BpmnElementType.PROCESS)
+        .await();
+
     assertStates();
   }
 
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
new file mode 100644
index 0000000..9dd9f4c
--- /dev/null
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -0,0 +1,121 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.processing.streamprocessor;
+
+import static io.camunda.zeebe.engine.util.RecordToWrite.command;
+import static io.camunda.zeebe.engine.util.RecordToWrite.event;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTIVATE_ELEMENT;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyLong;
+import static org.mockito.ArgumentMatchers.eq;
+import static org.mockito.Mockito.inOrder;
+import static org.mockito.Mockito.never;
+import static org.mockito.Mockito.timeout;
+
+import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor.Phase;
+import io.camunda.zeebe.engine.state.EventApplier;
+import io.camunda.zeebe.engine.util.Records;
+import io.camunda.zeebe.engine.util.StreamProcessorRule;
+import io.camunda.zeebe.protocol.impl.record.value.processinstance.ProcessInstanceRecord;
+import io.camunda.zeebe.protocol.record.ValueType;
+import org.junit.Rule;
+import org.junit.Test;
+import org.mockito.InOrder;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnit;
+import org.mockito.junit.MockitoRule;
+import org.mockito.verification.VerificationWithTimeout;
+
+public final class StreamProcessorReplayModeTest {
+
+  private static final long TIMEOUT_MILLIS = 2_000L;
+  private static final VerificationWithTimeout TIMEOUT = timeout(TIMEOUT_MILLIS);
+
+  private static final int PARTITION_ID = 1;
+
+  private static final ProcessInstanceRecord RECORD = Records.processInstance(1);
+
+  @Rule
+  public final StreamProcessorRule replayUntilEnd =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.UNTIL_END);
+
+  @Rule
+  public final StreamProcessorRule replayContinuously =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.CONTINUOUSLY);
+
+  @Rule public MockitoRule mockitoRule = MockitoJUnit.rule();
+
+  @Mock private TypedRecordProcessor<?> typedRecordProcessor;
+  @Mock private EventApplier eventApplier;
+
+  @Test
+  public void shouldReplayUntilEnd() {
+    // given
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayUntilEnd);
+
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder.verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, TIMEOUT.times(1)).onRecovered(any());
+    inOrder
+        .verify(typedRecordProcessor, TIMEOUT)
+        .processRecord(anyLong(), any(), any(), any(), any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING);
+  }
+
+  @Test
+  public void shouldReplayContinuously() {
+    // given
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayContinuously);
+
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder
+        .verify(eventApplier, TIMEOUT.times(2))
+        .applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, never()).onRecovered(any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPROCESSING);
+  }
+
+  private void startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
+    streamProcessorRule
+        .withEventApplierFactory(zeebeState -> eventApplier)
+        .startTypedStreamProcessor(
+            (processors, context) ->
+                processors.onCommand(
+                    ValueType.PROCESS_INSTANCE, ACTIVATE_ELEMENT, typedRecordProcessor));
+  }
+
+  private Phase getCurrentPhase(final StreamProcessorRule streamProcessorRule) {
+    return streamProcessorRule.getStreamProcessor(PARTITION_ID).getCurrentPhase().join();
+  }
+}
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
index f626ed4..cf07b5c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
@@ -101,7 +101,6 @@ public final class EngineRule extends ExternalResource {
       new Int2ObjectHashMap<>();
 
   private long lastProcessedPosition = -1L;
-  private ReplayMode replayMode;
 
   private EngineRule(final int partitionCount) {
     this(partitionCount, null);
@@ -176,7 +175,7 @@ public final class EngineRule extends ExternalResource {
   }
 
   public EngineRule withReplayMode(final ReplayMode replayMode) {
-    this.replayMode = replayMode;
+    environmentRule.withReplayMode(replayMode);
     return this;
   }
 
@@ -194,7 +193,6 @@ public final class EngineRule extends ExternalResource {
               (processingContext) ->
                   EngineProcessors.createEngineProcessors(
                           processingContext
-                              .replayMode(replayMode)
                               .onProcessedListener(
                                   record -> {
                                     lastProcessedPosition = record.getPosition();
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
index ab44773..1f9fe26 100755
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
@@ -10,6 +10,7 @@ package io.camunda.zeebe.engine.util;
 import static io.camunda.zeebe.engine.util.StreamProcessingComposite.getLogName;
 
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecordProcessorFactory;
@@ -64,6 +65,7 @@ public final class StreamProcessorRule implements TestRule {
   private TestStreams streams;
   private StreamProcessingComposite streamProcessingComposite;
   private ListLogStorage sharedStorage = null;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public StreamProcessorRule() {
     this(new TemporaryFolder());
@@ -125,6 +127,11 @@ public final class StreamProcessorRule implements TestRule {
     return this;
   }
 
+  public StreamProcessorRule withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+    return this;
+  }
+
   public LogStreamRecordWriter getLogStreamRecordWriter(final int partitionId) {
     return streamProcessingComposite.getLogStreamRecordWriter(partitionId);
   }
@@ -317,6 +324,7 @@ public final class StreamProcessorRule implements TestRule {
     @Override
     protected void before() {
       streams = new TestStreams(tempFolder, closeables, actorSchedulerRule.get());
+      streams.withReplayMode(replayMode);
 
       int partitionId = startPartitionId;
       for (int i = 0; i < partitionCount; i++) {
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
index 18696b2..176c405 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
@@ -17,6 +17,7 @@ import static org.mockito.Mockito.when;
 
 import io.camunda.zeebe.db.ZeebeDb;
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedEventRegistry;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
@@ -79,6 +80,7 @@ public final class TestStreams {
   private boolean snapshotWasTaken = false;
 
   private Function<MutableZeebeState, EventApplier> eventApplierFactory = EventAppliers::new;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public TestStreams(
       final TemporaryFolder dataDirectory,
@@ -107,6 +109,10 @@ public final class TestStreams {
     this.eventApplierFactory = eventApplierFactory;
   }
 
+  public void withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+  }
+
   public CommandResponseWriter getMockedResponseWriter() {
     return mockCommandResponseWriter;
   }
@@ -252,6 +258,7 @@ public final class TestStreams {
             .onProcessedListener(mockOnProcessedListener)
             .streamProcessorFactory(factory)
             .eventApplierFactory(eventApplierFactory)
+            .replayMode(replayMode)
             .build();
     final var openFuture = streamProcessor.openAsync(false);
 

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
index fa6f8d4..2185b1e 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
@@ -37,7 +37,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceCreationIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.protocol.record.value.BpmnElementType;
 import io.camunda.zeebe.util.Either;
-import io.camunda.zeebe.util.collection.Tuple;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
@@ -236,21 +235,22 @@ public final class CreateProcessInstanceProcessor
     return startInstructions.stream()
         .map(
             instruction ->
-                Tuple.of(
+                new ElementIdAndType(
                     instruction.getElementId(),
                     process.getElementById(instruction.getElementIdBuffer()).getElementType()))
-        .filter(elementTuple -> UNSUPPORTED_ELEMENT_TYPES.contains(elementTuple.getRight()))
+        .filter(
+            elementIdAndType -> UNSUPPORTED_ELEMENT_TYPES.contains(elementIdAndType.elementType))
         .findAny()
         .map(
-            elementTypeTuple ->
+            elementIdAndType ->
                 Either.left(
                     new Rejection(
                         RejectionType.INVALID_ARGUMENT,
                         (""Expected to create instance of process with start instructions but the element with id '%s' targets unsupported element type '%s'. ""
                                 + ""Supported element types are: %s"")
                             .formatted(
-                                elementTypeTuple.getLeft(),
-                                elementTypeTuple.getRight(),
+                                elementIdAndType.elementId,
+                                elementIdAndType.elementType,
                                 Arrays.stream(BpmnElementType.values())
                                     .filter(
                                         elementType ->
@@ -493,4 +493,6 @@ public final class CreateProcessInstanceProcessor
   }
 
   record Rejection(RejectionType type, String reason) {}
+
+  record ElementIdAndType(String elementId, BpmnElementType elementType) {}
 }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",3,"[""48d5d573886e9fdd0cca1cea47112c4a2f6edf52"", ""bb2ccc1a778452aebf233cf78b20f1f4bab4354b"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""test"", ""refactor"", ""cicd""]","1. The changes include adding a new test class to verify replay modes, updating an existing test for clarity, and making supportive modifications to test utilities, as well as a minor refactor replacing a tuple with a record in production logic, and updating CI/CD scripts to include branch names in Slack notifications.
2. The addition of a new test class and modifications to test utility classes are fully dedicated to testing and align with the 'test' label; the tuple-to-record replacement in production code is a structural improvement without altering behavior, aligning with 'refactor'; the CI/CD script changes in '.circleci/config.yml' and 'vsts.yml' are exclusively to notification logic and configuration, aligning with 'cicd'.
3. 'test' is appropriate because the changes in test files and utilities are solely for test logic (not production features or fixes); 'refactor' is correct because the tuple-to-record change is a code structure improvement, not a feature or bug fix; 'cicd' is correct because the changes in pipeline scripts are configuration-only, not build logic or documentation.
4. The assigned labels 'test', 'refactor', and 'cicd' accurately capture the essence and motivation of each code unit in this commit according to the classification instructions."
"bundle and tree shake assets with webpack
add spacing in comment fix lint (#8555)
remove ubuntu-latest from job title where that is the only os","diff --git a/package.json b/package.json
index c8051d2..b0a97fb 100644
--- a/package.json
+++ b/package.json
@@ -60,6 +60,7 @@
     ""babel-cli"": ""^6.16.0"",
     ""babel-core"": ""^6.16.0"",
     ""babel-eslint"": ""^7.0.0"",
+    ""babel-loader"": ""^6.2.5"",
     ""babel-plugin-transform-class-properties"": ""^6.10.2"",
     ""babel-plugin-transform-flow-strip-types"": ""^6.14.0"",
     ""babel-preset-es2015-node6"": ""^0.3.0"",
@@ -82,6 +83,7 @@
     ""eslint-plugin-react"": ""^6.3.0"",
     ""flow-bin"": ""^0.33.0"",
     ""jsdom"": ""^9.4.2"",
+    ""json-loader"": ""^0.5.4"",
     ""jsx-chai"": ""^4.0.0"",
     ""mocha"": ""^3.0.2"",
     ""mock-require"": ""^1.3.0"",
@@ -91,6 +93,8 @@
     ""rimraf"": ""^2.5.2"",
     ""sinon"": ""^1.17.6"",
     ""sinon-chai"": ""^2.8.0"",
-    ""watch"": ""^1.0.0""
+    ""source-map-support"": ""^0.4.3"",
+    ""watch"": ""^1.0.0"",
+    ""webpack"": ""^1.13.2""
   }
 }
diff --git a/webpack.config.js b/webpack.config.js
new file mode 100644
index 0000000..0ca6da1
--- /dev/null
+++ b/webpack.config.js
@@ -0,0 +1,44 @@
+const webpack = require('webpack');
+const path = require('path');
+const fs = require('fs');
+
+const nodeModules = {
+  zmq: 'commonjs zmq',
+  jmp: 'commonjs jmp',
+  github: 'commonjs github',
+};
+
+module.exports = {
+  entry: './src/notebook/index.js',
+  target: 'electron-renderer',
+  output: {
+    path: path.join(__dirname, 'app', 'build'),
+    filename: 'webpacked-notebook.js'
+  },
+  module: {
+    loaders: [
+      { test: /\.js$/, exclude: /node_modules/, loaders: ['babel'] },
+      { test: /\.json$/, loader: 'json-loader' },
+    ]
+  },
+  resolve: {
+    extensions: ['', '.js', '.jsx'],
+    root: path.join(__dirname, 'app'),
+    // Webpack 1
+    modulesDirectories: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+      path.resolve(__dirname, 'node_modules'),
+    ],
+    // Webpack 2
+    modules: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+    ],
+  },
+  externals: nodeModules,
+  plugins: [
+    new webpack.IgnorePlugin(/\.(css|less)$/),
+    new webpack.BannerPlugin('require(""source-map-support"").install();',
+                             { raw: true, entryOnly: false })
+  ],
+  devtool: 'sourcemap'
+};

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",3,"[""4ab28fc2e63e975a0c77e18ae644f34fa5f8771a"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""build"", ""docs"", ""cicd""]","1. The changes include adding webpack and related loaders to package.json, introducing a new webpack.config.js for asset bundling, fixing a lint issue by adding spacing in a comment within a test file, and updating job names in a GitHub Actions workflow to remove redundant OS mentions.
2. Adding and configuring webpack in package.json and creating webpack.config.js directly affect the build system, aligning with the 'build' label; the comment spacing fix in a test file is a documentation-only change, aligning with 'docs'; the workflow job name edits are scoped to CI configuration, aligning with 'cicd'.
3. 'build' is correct for dependency and config changes related to asset bundling (not 'feat', as no new user-facing feature is introduced, nor 'refactor', as behavior is changed via new build logic); 'docs' is appropriate for the comment formatting fix (not 'test', as no test logic was altered); 'cicd' is correct for workflow name changes (not 'build', since the functional role is CI configuration, not build logic).
4. The assigned labels 'build', 'docs', and 'cicd' are each appropriate because the code units are distinctly scoped to build tooling, documentation formatting, and CI configuration respectively, with no overlap or ambiguity."
"common routine for browser timezone

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>
path correction

Signed-off-by: Pranav C <pranavxc@gmail.com>
ensure ""dist"" dirs exist","diff --git a/tests/playwright/tests/db/timezone.spec.ts b/tests/playwright/tests/db/timezone.spec.ts
index c966c2b..a30c7e4 100644
--- a/tests/playwright/tests/db/timezone.spec.ts
+++ b/tests/playwright/tests/db/timezone.spec.ts
@@ -6,6 +6,7 @@ import { Api, UITypes } from 'nocodb-sdk';
 import { ProjectsPage } from '../../pages/ProjectsPage';
 import { isMysql, isPg, isSqlite } from '../../setup/db';
 import { getKnexConfig } from '../utils/config';
+import { getBrowserTimezoneOffset } from '../utils/general';
 let api: Api<any>, records: any[];
 
 const columns = [
@@ -680,11 +681,7 @@ test.describe.serial('External DB - DateTime column', async () => {
     await dashboard.rootPage.waitForTimeout(2000);
 
     // get timezone offset
-    const timezoneOffset = new Date().getTimezoneOffset();
-    const hours = Math.floor(Math.abs(timezoneOffset) / 60);
-    const minutes = Math.abs(timezoneOffset % 60);
-    const sign = timezoneOffset <= 0 ? '+' : '-';
-    const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+    const formattedOffset = getBrowserTimezoneOffset();
 
     await dashboard.treeView.openBase({ title: 'datetimetable' });
     await dashboard.treeView.openTable({ title: 'MyTable' });
@@ -844,11 +841,7 @@ test.describe('Ext DB MySQL : DB Timezone configured as HKT', () => {
     }
 
     // get timezone offset
-    const timezoneOffset = new Date().getTimezoneOffset();
-    const hours = Math.floor(Math.abs(timezoneOffset) / 60);
-    const minutes = Math.abs(timezoneOffset % 60);
-    const sign = timezoneOffset <= 0 ? '+' : '-';
-    const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+    const formattedOffset = getBrowserTimezoneOffset();
 
     // connect after timezone is set
     await connectToExtDb(context);
diff --git a/tests/playwright/tests/utils/general.ts b/tests/playwright/tests/utils/general.ts
index 56a9e1a..45e9c6c 100644
--- a/tests/playwright/tests/utils/general.ts
+++ b/tests/playwright/tests/utils/general.ts
@@ -50,4 +50,14 @@ function getDefaultPwd() {
   return 'Password123.';
 }
 
-export { getTextExcludeIconText, isSubset, getIconText, getDefaultPwd };
+function getBrowserTimezoneOffset() {
+  // get timezone offset
+  const timezoneOffset = new Date().getTimezoneOffset();
+  const hours = Math.floor(Math.abs(timezoneOffset) / 60);
+  const minutes = Math.abs(timezoneOffset % 60);
+  const sign = timezoneOffset <= 0 ? '+' : '-';
+  const formattedOffset = `${sign}${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}`;
+  return formattedOffset;
+}
+
+export { getTextExcludeIconText, isSubset, getIconText, getDefaultPwd, getBrowserTimezoneOffset };

diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
index 3afce9b..8425b00 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetMetaSakilaSqliteProject.ts
@@ -1,11 +1,9 @@
 import { promises as fs } from 'fs';
 import axios from 'axios';
+import path from 'path'
 
 const sqliteFilePath = (parallelId: string) => {
-  const rootDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '',
-  );
+  const rootDir = process.cwd()
 
   return `${rootDir}/test_sakila_${parallelId}.db`;
 };
@@ -78,10 +76,10 @@ const deleteSqliteFileIfExists = async (parallelId: string) => {
 };
 
 const seedSakilaSqliteFile = async (parallelId: string) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '/tests',
-  );
+  const testsDir =  path.join(
+    process.cwd(),
+    'tests'
+  );;
 
   await fs.copyFile(
     `${testsDir}/sqlite-sakila-db/sakila.db`,
diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
index 6bcd3f1..e4ed112 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetMysqlSakilaProject.ts
@@ -1,4 +1,5 @@
 import { promises as fs } from 'fs';
+import path from 'path';
 import axios from 'axios';
 import { knex } from 'knex';
 import Audit from '../../../models/Audit';
@@ -85,10 +86,7 @@ const resetSakilaMysql = async (
   parallelId: string,
   isEmptyProject: boolean,
 ) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
-    '/tests',
-  );
+  const testsDir = path.join(process.cwd(), '/tests');
 
   try {
     await knex.raw(`DROP DATABASE test_sakila_${parallelId}`);
diff --git a/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts b/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
index 1a042c3..73923ef 100644
--- a/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
+++ b/packages/nocodb-nest/src/modules/test/TestResetService/resetPgSakilaProject.ts
@@ -1,6 +1,7 @@
 import { promises as fs } from 'fs';
 import axios from 'axios';
 import { knex } from 'knex';
+import path from 'path'
 import Audit from '../../../models/Audit';
 import type Project from '../../../models/Project';
 
@@ -78,8 +79,8 @@ const isSakilaPgToBeReset = async (parallelId: string, project?: Project) => {
 };
 
 const resetSakilaPg = async (parallelId: string, isEmptyProject: boolean) => {
-  const testsDir = __dirname.replace(
-    '/src/modules/test/TestResetService',
+  const testsDir = path.join(
+    process.cwd(),
     '/tests',
   );
 

diff --git a/scripts/prepare.js b/scripts/prepare.js
index 9eb8cb8..f285825 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -68,6 +68,9 @@ async function prepare() {
     names.push(json.name)
   }
 
+  // Ensure all ""dist"" directories exist.
+  dirs.forEach(dir => fs.ensureDirSync(join(dir, distId)))
+
   log(``)
   for (let i = 0; i < names.length; i++) {
     const dir = dirs[i]
",3,"[""7d3e9b3a98b02f6cb1f3444dc7e3a0459aeb26a7"", ""974e033a3ca7484290a04201ee33856a25da0942"", ""ca060bf255a55b99000ddf0c67f7422f28b735a6""]","[""test"", ""fix"", ""build""]","1. The changes include refactoring test utilities to use a shared timezone function, correcting test file path handling in reset scripts, and updating a build script to ensure 'dist' directories exist.
2. Updates to test logic and utilities (timezone function, path corrections in test support scripts) directly relate to the 'test' label, while the build script change (ensuring 'dist' directories) aligns with the 'build' label, and the path corrections in reset scripts address potential runtime errors, justifying the 'fix' label.
3. 'test' is appropriate because the majority of changes are within test files or test utilities, 'fix' is justified for resolving path handling bugs in reset scripts, and 'build' is warranted for the script ensuring build artifacts; alternative labels like 'refactor' or 'feat' are not suitable since no new feature or pure code restructuring is present, and the changes are not documentation or CI-related.
4. The assigned labels 'test', 'fix', and 'build' correctly reflect the changes made to test logic/utilities, bug fixes in test support scripts, and build system improvements, respectively."
"add jackson dependencies for zb-bpmn-model
autostart feature fixed
conditionals and iterators in rsx","diff --git a/parent/pom.xml b/parent/pom.xml
index d475131..6290e66 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -35,6 +35,7 @@
     <version.mockito>1.8.5</version.mockito>
     <version.assertj>3.8.0</version.assertj>
     <version.msgpack>0.8.13</version.msgpack>
+    <version.jackson>2.9.0</version.jackson>
     <version.jmh>1.11.2</version.jmh>
     <version.sbe>1.5.6</version.sbe>
     <version.slf4j>1.7.23</version.slf4j>
@@ -64,6 +65,18 @@
       </dependency>
 
       <dependency>
+        <groupId>com.fasterxml.jackson.core</groupId>
+        <artifactId>jackson-databind</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
+        <groupId>com.fasterxml.jackson.dataformat</groupId>
+        <artifactId>jackson-dataformat-yaml</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
         <groupId>org.msgpack</groupId>
         <artifactId>msgpack-core</artifactId>
         <version>${version.msgpack}</version>

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/packages/interpreter/src/interpreter.js b/packages/interpreter/src/interpreter.js
index 2f5c06f..58613ea 100644
--- a/packages/interpreter/src/interpreter.js
+++ b/packages/interpreter/src/interpreter.js
@@ -172,7 +172,7 @@ export class Interpreter {
         node.style = {};
       }
       node.style[name] = value;
-    } else if (ns != null || ns != undefined) {
+    } else if (ns != null && ns != undefined) {
       node.setAttributeNS(ns, name, value);
     } else {
       switch (name) {
@@ -266,7 +266,7 @@ export class Interpreter {
         this.AssignId(edit.path, edit.id);
         break;
       case ""CreateElement"":
-        if (edit.namespace !== null || edit.namespace !== undefined) {
+        if (edit.namespace !== null && edit.namespace !== undefined) {
           this.CreateElementNs(edit.name, edit.id, edit.namespace);
         } else {
           this.CreateElement(edit.name, edit.id);
diff --git a/packages/rsx/src/lib.rs b/packages/rsx/src/lib.rs
index 09c6bd6..d974a6c 100644
--- a/packages/rsx/src/lib.rs
+++ b/packages/rsx/src/lib.rs
@@ -245,7 +245,11 @@ impl<'a> DynamicContext<'a> {
                 quote! { ::dioxus::core::TemplateNode::Text(#text) }
             }
 
-            BodyNode::Text(_) | BodyNode::RawExpr(_) | BodyNode::Component(_) => {
+            BodyNode::RawExpr(_)
+            | BodyNode::Text(_)
+            | BodyNode::ForLoop(_)
+            | BodyNode::IfChain(_)
+            | BodyNode::Component(_) => {
                 let ct = self.dynamic_nodes.len();
                 self.dynamic_nodes.push(root);
                 self.node_paths.push(self.current_path.clone());
diff --git a/packages/rsx/src/node.rs b/packages/rsx/src/node.rs
index 4013c9c..7b4bd23 100644
--- a/packages/rsx/src/node.rs
+++ b/packages/rsx/src/node.rs
@@ -5,7 +5,7 @@ use quote::{quote, ToTokens, TokenStreamExt};
 use syn::{
     parse::{Parse, ParseStream},
     spanned::Spanned,
-    token, Expr, LitStr, Result,
+    token, Block, Expr, ExprIf, LitStr, Pat, Result,
 };
 
 /*
@@ -20,6 +20,8 @@ Parse
 pub enum BodyNode {
     Element(Element),
     Component(Component),
+    ForLoop(ForLoop),
+    IfChain(ExprIf),
     Text(IfmtInput),
     RawExpr(Expr),
 }
@@ -35,6 +37,8 @@ impl BodyNode {
             BodyNode::Component(component) => component.name.span(),
             BodyNode::Text(text) => text.source.span(),
             BodyNode::RawExpr(exp) => exp.span(),
+            BodyNode::ForLoop(fl) => fl.for_token.span(),
+            BodyNode::IfChain(f) => f.if_token.span(),
         }
     }
 }
@@ -89,6 +93,28 @@ impl Parse for BodyNode {
             }
         }
 
+        // Transform for loops into into_iter calls
+        if stream.peek(Token![for]) {
+            let _f = stream.parse::<Token![for]>()?;
+            let pat = stream.parse::<Pat>()?;
+            let _i = stream.parse::<Token![in]>()?;
+            let expr = stream.parse::<Box<Expr>>()?;
+            let body = stream.parse::<Block>()?;
+
+            return Ok(BodyNode::ForLoop(ForLoop {
+                for_token: _f,
+                pat,
+                in_token: _i,
+                expr,
+                body,
+            }));
+        }
+
+        // Transform unterminated if statements into terminated optional if statements
+        if stream.peek(Token![if]) {
+            return Ok(BodyNode::IfChain(stream.parse()?));
+        }
+
         Ok(BodyNode::RawExpr(stream.parse::<Expr>()?))
     }
 }
@@ -104,6 +130,104 @@ impl ToTokens for BodyNode {
             BodyNode::RawExpr(exp) => tokens.append_all(quote! {
                  __cx.fragment_from_iter(#exp)
             }),
+            BodyNode::ForLoop(exp) => {
+                let ForLoop {
+                    pat, expr, body, ..
+                } = exp;
+
+                tokens.append_all(quote! {
+                     __cx.fragment_from_iter(
+                        (#expr).into_iter().map(|#pat| {
+                            #body
+                        })
+                     )
+                })
+            }
+            BodyNode::IfChain(chain) => {
+                if is_if_chain_terminated(chain) {
+                    tokens.append_all(quote! {
+                         __cx.fragment_from_iter(#chain)
+                    });
+                } else {
+                    let ExprIf {
+                        cond,
+                        then_branch,
+                        else_branch,
+                        ..
+                    } = chain;
+
+                    let mut body = TokenStream2::new();
+
+                    body.append_all(quote! {
+                        if #cond {
+                            Some(#then_branch)
+                        }
+                    });
+
+                    let mut elif = else_branch;
+
+                    while let Some((_, ref branch)) = elif {
+                        match branch.as_ref() {
+                            Expr::If(ref eelif) => {
+                                let ExprIf {
+                                    cond,
+                                    then_branch,
+                                    else_branch,
+                                    ..
+                                } = eelif;
+
+                                body.append_all(quote! {
+                                    else if #cond {
+                                        Some(#then_branch)
+                                    }
+                                });
+
+                                elif = else_branch;
+                            }
+                            _ => {
+                                body.append_all(quote! {
+                                    else {
+                                        #branch
+                                    }
+                                });
+                                break;
+                            }
+                        }
+                    }
+
+                    body.append_all(quote! {
+                        else { None }
+                    });
+
+                    tokens.append_all(quote! {
+                        __cx.fragment_from_iter(#body)
+                    });
+                }
+            }
+        }
+    }
+}
+
+#[derive(PartialEq, Eq, Clone, Debug, Hash)]
+pub struct ForLoop {
+    pub for_token: Token![for],
+    pub pat: Pat,
+    pub in_token: Token![in],
+    pub expr: Box<Expr>,
+    pub body: Block,
+}
+
+fn is_if_chain_terminated(chain: &ExprIf) -> bool {
+    let mut current = chain;
+    loop {
+        if let Some((_, else_block)) = &current.else_branch {
+            if let Expr::If(else_if) = else_block.as_ref() {
+                current = else_if;
+            } else {
+                return true;
+            }
+        } else {
+            return false;
         }
     }
 }
",3,"[""fab09655d5cc30727289cc3f26e5396fce235cd3"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""6b473cbdc5997af47c56a2a74f5b64da6d4c2ad7""]","[""build"", ""fix"", ""feat""]","1. The changes in 'parent/pom.xml' add new Jackson dependencies and version properties, which update the build configuration for dependency management; the changes in 'core/main/src/Core/Container.ts' set 'firstStart' to true instead of false to fix autostart behavior; the changes in 'packages/interpreter/src/interpreter.js' correct logical conditions from '||' to '&&', fixing namespace and attribute assignment logic; the changes in 'packages/rsx/src/lib.rs' and 'packages/rsx/src/node.rs' add support for conditionals and iterators in RSX, introducing new parsing and code generation capabilities.
2. Adding dependencies and version properties in the pom.xml directly aligns with the 'build' label, as it affects build system configuration; the fixes in 'Container.ts' and 'interpreter.js' address specific bugs, matching the 'fix' label; the RSX changes introduce new features (conditionals and iterators), fitting the 'feat' label.
3. 'build' is appropriate for the pom.xml changes because they do not alter code behavior but the build/dependency setup; 'fix' is correct for the bug corrections in logic and autostart, as these resolve faulty behavior; 'feat' is justified for the RSX enhancements, as they add new parsing and code generation capabilities. No 'refactor', 'docs', 'test', or 'cicd' labels are relevant because there is no structural code improvement without behavior change, documentation, test, or CI/CD modification.
4. The assigned labels 'build', 'fix', and 'feat' are appropriate because the commit contains clear and separate changes to build configuration, bug fixes, and new feature additions, each matching the corresponding label definitions."
autostart feature fixed,"diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",1,"[""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""fix""]","1. The commit removes unused imports in two TypeScript files and changes the assignment of 'this.firstStart' from false to true in the Container class.
2. The core change is the update of 'this.firstStart' to true, which addresses a logic error related to the autostart feature, directly aligning with the 'fix' label for resolving bugs.
3. While the import removals could be seen as 'refactor', the presence of a behavioral correction (fixing the autostart bug) takes precedence per the instructions; the main intent is to resolve faulty behavior, not just improve code structure.
4. The 'fix' label is appropriate as the commit's primary purpose is to correct a bug in the autostart feature, which outweighs minor code cleanup."
"fix build
rename ELECTRON_CACHE env variable to electron_config_cache (#21313)","diff --git a/server/Dockerfile b/server/Dockerfile
index 2f203bb..a84c31e 100755
--- a/server/Dockerfile
+++ b/server/Dockerfile
@@ -9,9 +9,11 @@ ENV TZ utc
 WORKDIR /src
 
 COPY package.json /src
+COPY package-lock.json /src
+COPY tsconfig.json /src
 RUN npm install --production --no-optional
 
 COPY public /src/public
 COPY dist /src
 
-CMD [ ""node"", ""./server/index.js"" ]
+CMD [ ""node"", ""-r"", ""tsconfig-paths/register"", ""./server/index.js"" ]
diff --git a/server/package-lock.json b/server/package-lock.json
index 6cacfa2..236f1bb 100644
--- a/server/package-lock.json
+++ b/server/package-lock.json
@@ -2164,8 +2164,7 @@
     ""@types/json5"": {
       ""version"": ""0.0.29"",
       ""resolved"": ""https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz"",
-      ""integrity"": ""sha1-7ihweulOEdK4J7y+UnC86n8+ce4="",
-      ""dev"": true
+      ""integrity"": ""sha1-7ihweulOEdK4J7y+UnC86n8+ce4=""
     },
     ""@types/jsonwebtoken"": {
       ""version"": ""8.3.5"",
@@ -9246,8 +9245,7 @@
     ""strip-bom"": {
       ""version"": ""3.0.0"",
       ""resolved"": ""https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz"",
-      ""integrity"": ""sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM="",
-      ""dev"": true
+      ""integrity"": ""sha1-IzTBjpx1n3vdVv3vfprj1YjmjtM=""
     },
     ""strip-final-newline"": {
       ""version"": ""2.0.0"",
@@ -9524,7 +9522,6 @@
       ""version"": ""3.9.0"",
       ""resolved"": ""https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.9.0.tgz"",
       ""integrity"": ""sha512-dRcuzokWhajtZWkQsDVKbWyY+jgcLC5sqJhg2PSgf4ZkH2aHPvaOY8YWGhmjb68b5qqTfasSsDO9k7RUiEmZAw=="",
-      ""dev"": true,
       ""requires"": {
         ""@types/json5"": ""^0.0.29"",
         ""json5"": ""^1.0.1"",
@@ -9536,7 +9533,6 @@
           ""version"": ""1.0.1"",
           ""resolved"": ""https://registry.npmjs.org/json5/-/json5-1.0.1.tgz"",
           ""integrity"": ""sha512-aKS4WQjPenRxiQsC93MNfjx+nbF4PAdYzmd/1JIj8HYzqfbu86beTuNgXDzPknWk0n0uARlyewZo4s++ES36Ow=="",
-          ""dev"": true,
           ""requires"": {
             ""minimist"": ""^1.2.0""
           }
@@ -9544,8 +9540,7 @@
         ""minimist"": {
           ""version"": ""1.2.5"",
           ""resolved"": ""https://registry.npmjs.org/minimist/-/minimist-1.2.5.tgz"",
-          ""integrity"": ""sha512-FM9nNUYrRBAELZQT3xeZQ7fmMOBg6nWNmJKTcgsJeaLstP/UODVpGsr5OhXhhXg6f+qtJ8uiZ+PUxkDWcgIXLw=="",
-          ""dev"": true
+          ""integrity"": ""sha512-FM9nNUYrRBAELZQT3xeZQ7fmMOBg6nWNmJKTcgsJeaLstP/UODVpGsr5OhXhhXg6f+qtJ8uiZ+PUxkDWcgIXLw==""
         }
       }
     },
diff --git a/server/package.json b/server/package.json
index 35426e9..896e9b3 100644
--- a/server/package.json
+++ b/server/package.json
@@ -41,6 +41,7 @@
     ""pino-cloudwatch"": ""0.7.0"",
     ""pino-multi-stream"": ""4.2.0"",
     ""reflect-metadata"": ""0.1.13"",
+    ""tsconfig-paths"": ""3.9.0"",
     ""typeorm"": ""0.2.37""
   },
   ""devDependencies"": {
@@ -69,7 +70,6 @@
     ""pino-pretty"": ""3.6.1"",
     ""ts-jest"": ""27.0.7"",
     ""ts-node-dev"": ""1.1.8"",
-    ""tsconfig-paths"": ""3.9.0"",
     ""typescript"": ""4.3.5""
   },
   ""jest-junit"": {

diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as
",2,"[""a827777f41e90b6332c191d05bae8db525de6f38"", ""f2f52c23b513dd857350f3c163f676d37189d0d3""]","[""build"", ""docs""]","1. The changes update the Dockerfile to include additional files and modify the node command, adjust dependencies in package.json and package-lock.json (moving 'tsconfig-paths' from devDependencies to dependencies), and update documentation in installation.md to refer to the correct environment variable ('electron_config_cache').
2. The Dockerfile and dependency changes affect how the application is built and run, aligning with the 'build' label; the documentation change is strictly a text update, aligning with the 'docs' label.
3. 'build' is appropriate because all server-related changes (Dockerfile, dependencies) are for build/runtime configuration, not for CI/CD scripts or core logic changes, and 'docs' is correct for the markdown file update since it only affects documentation; no purpose label (feat, fix, refactor) is appropriate as there is no new feature, bug fix, or refactoring of logic.
4. The 'build' label captures all changes to build configuration and dependencies, while the 'docs' label correctly covers the documentation update, matching the classification rules."
add link to roadmap,"diff --git a/packages/plugin-core/README.md b/packages/plugin-core/README.md
index 3c25c9b..c7506d4 100644
--- a/packages/plugin-core/README.md
+++ b/packages/plugin-core/README.md
@@ -187,6 +187,10 @@ When the workspace opens, it will show dialogue to install the recommended exten
 
 See [[FAQ]] to answers for common questions.
 
+# Roadmap
+
+Check out our [public roadmap](https://github.com/orgs/dendronhq/projects/1) to see the features we're working on and to vote for what you want to see next. 
+
 
 # Contributing
 
",1,"[""94202f01e44c58bee4419044f8a18ac5f1a50dff""]","[""docs""]","1. The change adds a new section to the README.md file that provides a link to the project's public roadmap.
2. This modification is exclusively to documentation content, aligning directly with the 'docs' label, which covers updates to documentation or text.
3. The 'docs' label is appropriate because the change does not introduce new features (feat), fix bugs (fix), restructure code (refactor), or affect tests, CI/CD, or build systems; it is solely an informational/documentation update.
4. The 'docs' label accurately reflects that the commit's purpose is to update project documentation by adding a roadmap link."
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.
new ShowDebug parameter

calculate each segment timing
new parameter to show/hide segment debug information
set-poshprompt updated with the new showDebug parameter

Force disabled segment to be visible for debug purpose
bundle and tree shake assets with webpack","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/engine.go b/engine.go
index 6cc1ff3..4617ceb 100644
--- a/engine.go
+++ b/engine.go
@@ -67,6 +67,9 @@ func (e *engine) renderText(text string) {
 	prefix := e.activeSegment.getValue(Prefix, "" "")
 	postfix := e.activeSegment.getValue(Postfix, "" "")
 	e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""%s%s%s"", prefix, text, postfix))
+	if *e.env.getArgs().Debug {
+		e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""(%s:%s)"", e.activeSegment.Type, e.activeSegment.timing))
+	}
 }
 
 func (e *engine) renderSegmentText(text string) {
@@ -107,13 +110,11 @@ func (e *engine) setStringValues(segments []*Segment) {
 	wg.Add(len(segments))
 	defer wg.Wait()
 	cwd := e.env.getcwd()
+	debug := *e.env.getArgs().Debug
 	for _, segment := range segments {
 		go func(s *Segment) {
 			defer wg.Done()
-			err := s.mapSegmentWithWriter(e.env)
-			if err == nil && !s.hasValue(IgnoreFolders, cwd) && s.enabled() {
-				s.stringValue = s.string()
-			}
+			s.setStringValue(e.env, cwd, debug)
 		}(segment)
 	}
 }
diff --git a/main.go b/main.go
index 56ae8a5..d67a640 100644
--- a/main.go
+++ b/main.go
@@ -14,6 +14,7 @@ type args struct {
 	Config      *string
 	Shell       *string
 	PWD         *string
+	Debug       *bool
 }
 
 func main() {
@@ -42,6 +43,10 @@ func main() {
 			""pwd"",
 			"""",
 			""the path you are working in""),
+		Debug: flag.Bool(
+			""debug"",
+			false,
+			""Print debug information""),
 	}
 	flag.Parse()
 	env := &environment{
diff --git a/packages/powershell/oh-my-posh/oh-my-posh.psm1 b/packages/powershell/oh-my-posh/oh-my-posh.psm1
index 9234fc6..1450eb3 100644
--- a/packages/powershell/oh-my-posh/oh-my-posh.psm1
+++ b/packages/powershell/oh-my-posh/oh-my-posh.psm1
@@ -5,6 +5,7 @@
 
 $global:PoshSettings = New-Object -TypeName PSObject -Property @{
     Theme = ""$PSScriptRoot\themes\jandedobbeleer.json"";
+    ShowDebug = $false
 }
 
 function Get-PoshCommand {
@@ -36,9 +37,14 @@ function Set-PoshPrompt {
     param(
         [Parameter(Mandatory = $false)]
         [string]
-        $Theme
+        $Theme,
+        [Parameter(Mandatory = $false)]
+        [bool]
+        $ShowDebug = $false
     )
 
+    $global:PoshSettings.ShowDebug = $ShowDebug
+
     if (Test-Path ""$PSScriptRoot/themes/$Theme.json"") {
         $global:PoshSettings.Theme = ""$PSScriptRoot/themes/$Theme.json""
     }
@@ -68,8 +74,9 @@ function Set-PoshPrompt {
         $startInfo = New-Object System.Diagnostics.ProcessStartInfo
         $startInfo.FileName = Get-PoshCommand
         $config = $global:PoshSettings.Theme
+        $showDebug = $global:PoshSettings.ShowDebug
         $cleanPWD = $PWD.ProviderPath.TrimEnd(""\"")
-        $startInfo.Arguments = ""-config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
+        $startInfo.Arguments = ""-debug=""""$showDebug"""" -config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
         $startInfo.Environment[""TERM""] = ""xterm-256color""
         $startInfo.CreateNoWindow = $true
         $startInfo.StandardOutputEncoding = [System.Text.Encoding]::UTF8
diff --git a/segment.go b/segment.go
index 27dd416..4015dac 100644
--- a/segment.go
+++ b/segment.go
@@ -1,6 +1,9 @@
 package main
 
-import ""errors""
+import (
+	""errors""
+	""time""
+)
 
 // Segment represent a single segment and it's configuration
 type Segment struct {
@@ -17,6 +20,7 @@ type Segment struct {
 	writer          SegmentWriter
 	stringValue     string
 	active          bool
+	timing          time.Duration
 }
 
 // SegmentWriter is the interface used to define what and if to write to the prompt
@@ -149,3 +153,26 @@ func (segment *Segment) mapSegmentWithWriter(env environmentInfo) error {
 	}
 	return errors.New(""unable to map writer"")
 }
+
+func (segment *Segment) setStringValue(env environmentInfo, cwd string, debug bool) {
+	err := segment.mapSegmentWithWriter(env)
+	if err != nil || segment.hasValue(IgnoreFolders, cwd) {
+		return
+	}
+	// add timing only in debug
+	if debug {
+		start := time.Now()
+		defer (func() {
+			// force segment rendering to display the time it took
+			// to check if the segment is enabled or not
+			// depending on the segement, calling enabled()
+			// can be time consuming
+			segment.active = true
+			elapsed := time.Since(start)
+			segment.timing = elapsed
+		})()
+	}
+	if segment.enabled() {
+		segment.stringValue = segment.string()
+	}
+}

diff --git a/package.json b/package.json
index c8051d2..b0a97fb 100644
--- a/package.json
+++ b/package.json
@@ -60,6 +60,7 @@
     ""babel-cli"": ""^6.16.0"",
     ""babel-core"": ""^6.16.0"",
     ""babel-eslint"": ""^7.0.0"",
+    ""babel-loader"": ""^6.2.5"",
     ""babel-plugin-transform-class-properties"": ""^6.10.2"",
     ""babel-plugin-transform-flow-strip-types"": ""^6.14.0"",
     ""babel-preset-es2015-node6"": ""^0.3.0"",
@@ -82,6 +83,7 @@
     ""eslint-plugin-react"": ""^6.3.0"",
     ""flow-bin"": ""^0.33.0"",
     ""jsdom"": ""^9.4.2"",
+    ""json-loader"": ""^0.5.4"",
     ""jsx-chai"": ""^4.0.0"",
     ""mocha"": ""^3.0.2"",
     ""mock-require"": ""^1.3.0"",
@@ -91,6 +93,8 @@
     ""rimraf"": ""^2.5.2"",
     ""sinon"": ""^1.17.6"",
     ""sinon-chai"": ""^2.8.0"",
-    ""watch"": ""^1.0.0""
+    ""source-map-support"": ""^0.4.3"",
+    ""watch"": ""^1.0.0"",
+    ""webpack"": ""^1.13.2""
   }
 }
diff --git a/webpack.config.js b/webpack.config.js
new file mode 100644
index 0000000..0ca6da1
--- /dev/null
+++ b/webpack.config.js
@@ -0,0 +1,44 @@
+const webpack = require('webpack');
+const path = require('path');
+const fs = require('fs');
+
+const nodeModules = {
+  zmq: 'commonjs zmq',
+  jmp: 'commonjs jmp',
+  github: 'commonjs github',
+};
+
+module.exports = {
+  entry: './src/notebook/index.js',
+  target: 'electron-renderer',
+  output: {
+    path: path.join(__dirname, 'app', 'build'),
+    filename: 'webpacked-notebook.js'
+  },
+  module: {
+    loaders: [
+      { test: /\.js$/, exclude: /node_modules/, loaders: ['babel'] },
+      { test: /\.json$/, loader: 'json-loader' },
+    ]
+  },
+  resolve: {
+    extensions: ['', '.js', '.jsx'],
+    root: path.join(__dirname, 'app'),
+    // Webpack 1
+    modulesDirectories: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+      path.resolve(__dirname, 'node_modules'),
+    ],
+    // Webpack 2
+    modules: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+    ],
+  },
+  externals: nodeModules,
+  plugins: [
+    new webpack.IgnorePlugin(/\.(css|less)$/),
+    new webpack.BannerPlugin('require(""source-map-support"").install();',
+                             { raw: true, entryOnly: false })
+  ],
+  devtool: 'sourcemap'
+};
",3,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""bea32587586ca08f390c901a95e9b9c25263f4df"", ""4ab28fc2e63e975a0c77e18ae644f34fa5f8771a""]","[""fix"", ""feat"", ""build""]","1. The change in Configuration.ts fixes the logic for setting the default value of 'cache.enabled', resolving a bug where CLI cache commands would fail if not explicitly enabled.
2. Several Go files (engine.go, main.go, segment.go) and PowerShell scripts introduce a new debug parameter, segment timing, and debugging output, which are new features for segment debugging and visibility.
3. The addition of webpack.config.js and new devDependencies (webpack, babel-loader, json-loader, source-map-support) in package.json are dedicated to enabling bundling and tree-shaking with webpack, which is a build system enhancement.
4. The 'fix' label is justified for the Configuration.ts change as it resolves faulty behavior, not introducing new functionality or refactoring; the 'feat' label is appropriate for the new debugging features in Go and PowerShell as they add capabilities, not just restructuring or bug fixing; the 'build' label is correct for the webpack-related changes as these are solely build system modifications, not code logic, CI, or tests.
5. The assigned labels 'fix', 'feat', and 'build' are correct because the commit contains a bug fix, new feature additions, and build system changes, each aligned with the label definitions and classification rules."
"add system get version info Fiddle example (#20536)
update pr condition
add tests for ProfilePage methods","diff --git a/docs/fiddles/system/system-information/get-version-information/index.html b/docs/fiddles/system/system-information/get-version-information/index.html
new file mode 100644
index 0000000..0867bc3
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/index.html
@@ -0,0 +1,26 @@
+<!DOCTYPE html>
+<html>
+  <head>
+    <meta charset=""UTF-8"">
+  </head>
+  <body>
+    <div>
+      <div>
+        <h1>Get version information</h1>
+        <i>Supports: Win, macOS, Linux <span>|</span> Process: Both</i>
+        <div>
+          <div>
+            <button id=""version-info"">View Demo</button>
+            <span id=""got-version-info""></span>
+          </div>
+          <p>The <code>process</code> module is built into Node.js (therefore you can use this in both the main and renderer processes) and in Electron apps this object has a few more useful properties on it.</p>
+          <p>The example below gets the version of Electron in use by the app.</p>
+          <p>See the <a href=""http://electron.atom.io/docs/api/process"">process documentation <span>(opens in new window)</span></a> for more.</p>
+        </div>
+      </div>
+    </div>
+  </body>
+  <script>
+    require('./renderer.js')
+  </script>
+</html>
diff --git a/docs/fiddles/system/system-information/get-version-information/main.js b/docs/fiddles/system/system-information/get-version-information/main.js
new file mode 100644
index 0000000..1f9f917
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/main.js
@@ -0,0 +1,25 @@
+const { app, BrowserWindow } = require('electron')
+
+let mainWindow = null
+
+function createWindow () {
+  const windowOptions = {
+    width: 600,
+    height: 400,
+    title: 'Get version information',
+    webPreferences: {
+      nodeIntegration: true
+    }
+  }
+
+  mainWindow = new BrowserWindow(windowOptions)
+  mainWindow.loadFile('index.html')
+
+  mainWindow.on('closed', () => {
+    mainWindow = null
+  })
+}
+
+app.on('ready', () => {
+  createWindow()
+})
diff --git a/docs/fiddles/system/system-information/get-version-information/renderer.js b/docs/fiddles/system/system-information/get-version-information/renderer.js
new file mode 100644
index 0000000..40f7f2c
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/renderer.js
@@ -0,0 +1,8 @@
+const versionInfoBtn = document.getElementById('version-info')
+
+const electronVersion = process.versions.electron
+
+versionInfoBtn.addEventListener('click', () => {
+  const message = `This app is using Electron version: ${electronVersion}`
+  document.getElementById('got-version-info').innerHTML = message
+})

diff --git a/.github/workflows/release-pr.yml b/.github/workflows/release-pr.yml
index 697ca8e..23f4475 100644
--- a/.github/workflows/release-pr.yml
+++ b/.github/workflows/release-pr.yml
@@ -3,7 +3,6 @@ name: release
 on:
   issue_comment:
     types: [created]
-    contains: ""/trigger release""
 
 env:
   # 7 GiB by default on GitHub, setting to 6 GiB
@@ -11,6 +10,7 @@ env:
 
 jobs:
   release-pr:
+    if: ${{ github.event.issue.pull_request && github.event.comment.body == '/trigger release' }}
     permissions:
       id-token: write
     runs-on: ubuntu-latest

diff --git a/client/src/components/Profile/PreScreeningIviewCard.tsx b/client/src/components/Profile/PreScreeningIviewCard.tsx
index f84392a..2031203 100644
--- a/client/src/components/Profile/PreScreeningIviewCard.tsx
+++ b/client/src/components/Profile/PreScreeningIviewCard.tsx
@@ -27,7 +27,7 @@ type State = {
   isPreScreeningIviewModalVisible: boolean;
 };
 
-class CoreJSIviewsCard extends React.PureComponent<Props, State> {
+class PreScreeningIviewsCard extends React.PureComponent<Props, State> {
   state = {
     courseIndex: 0,
     isPreScreeningIviewModalVisible: false,
@@ -98,4 +98,4 @@ class CoreJSIviewsCard extends React.PureComponent<Props, State> {
   }
 }
 
-export default CoreJSIviewsCard;
+export default PreScreeningIviewsCard;
diff --git a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
index 7b73c3f..54b378c 100644
--- a/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
+++ b/client/src/components/Profile/__test__/__snapshots__/PreScreeningIviewCard.test.tsx.snap
@@ -1,7 +1,7 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
 exports[`PreScreeningIviewCard Should render correctly 1`] = `
-<CoreJSIviewsCard
+<PreScreeningIviewsCard
   data={
     Array [
       Object {
@@ -3015,5 +3015,5 @@ exports[`PreScreeningIviewCard Should render correctly 1`] = `
       </div>
     </Card>
   </CommonCard>
-</CoreJSIviewsCard>
+</PreScreeningIviewsCard>
 `;
diff --git a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
index 079d966..95f3e49 100644
--- a/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
+++ b/client/src/pages/profile/__tests__/ProfilePage.tests.tsx
@@ -4,7 +4,6 @@ import { shallowToJson } from 'enzyme-to-json';
 import { NextRouter } from 'next/router';
 import { Session } from 'components/withSession';
 import { ProfilePage } from '../index';
-// import { GeneralInfo } from '../../../../../common/models/profile';
 
 jest.mock('next/config', () => () => ({}));
 jest.mock('services/user', () => ({
@@ -12,80 +11,378 @@ jest.mock('services/user', () => ({
       getProfileInfo() {
         return jest.fn();
       }
+      saveProfileInfo() {
+        return jest.fn();
+      }
     },
   }),
 );
 
-describe('ProfilePage', () => {
-  const profile = {
-    generalInfo: {
-      name: 'Dzmitry Petrov',
-      githubId: 'petrov',
-      aboutMyself: 'Test',
+const profile = {
+  permissionsSettings: {
+    isProfileVisible: { all: true },
+    isAboutVisible: { mentor: true, student: false, all: false },
+    isEducationVisible: { mentor: true, student: false, all: false },
+    isEnglishVisible: { student: false, all: false },
+    isEmailVisible: { student: false, all: false },
+    isTelegramVisible: { student: false, all: false },
+    isSkypeVisible: { student: false, all: false },
+    isPhoneVisible: { student: false, all: false },
+    isContactsNotesVisible: { student: true, all: false },
+    isLinkedInVisible: { mentor: true, student: false, all: false },
+    isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+    isMentorStatsVisible: { mentor: true, student: true, all: false },
+    isStudentStatsVisible: { student: false, all: false },
+  },
+  generalInfo: {
+    aboutMyself: 'Test',
+    educationHistory: [{
+      graduationYear: '2019',
+      faculty: 'TT',
+      university: 'Test',
+    }],
+    englishLevel: 'a2+',
+    locationId: 456,
+    locationName: 'Brest',
+  },
+  contacts: {},
+  mentorStats: [
+    {},
+  ],
+  studentStats: [
+    {
+      courseFullName: 'test',
+      courseName: 'test',
       locationName: 'Minsk',
-      locationId: '1',
-      educationHistory: null,
-      englishLevel: 'a2+',
-    },
-    permissionsSettings: {
-      isProfileVisible: { all: true },
-      isAboutVisible: { mentor: true, student: false, all: false },
-      isEducationVisible: { mentor: true, student: false, all: false },
-      isEnglishVisible: { student: false, all: false },
-      isEmailVisible: { student: false, all: false },
-      isTelegramVisible: { student: false, all: false },
-      isSkypeVisible: { student: false, all: false },
-      isPhoneVisible: { student: false, all: false },
-      isContactsNotesVisible: { student: true, all: false },
-      isLinkedInVisible: { mentor: true, student: false, all: false },
-      isPublicFeedbackVisible: { mentor: true, student: true, all: false },
-      isMentorStatsVisible: { mentor: true, student: true, all: false },
-      isStudentStatsVisible: { student: false, all: false },
-    },
-    contacts: {
-      phone: '+375292123456',
-      email: 'petro@gmail.com',
-      skype: 'petro:live',
-      telegram: 'petro',
-      notes: 'discord: @petro, instagram: @petro12',
-    },
-    isPermissionsSettingsChanged: true,
-    isProfileSettingsChanged: true,
-  };
-  const session = {
-    id: 2020,
-    githubId: 'mikhama',
-    isAdmin: true,
-    isHirer: false,
-    isActivist: false,
-    roles: {
-      1: 'mentor',
-      2: 'student',
-      11: 'mentor',
-    },
-    coursesRoles: {
-      13: [
-        'manager',
+      tasks: [
+        {
+          interviewFormAnswers: {},
+        },
       ],
     },
-  } as Session;
-  const router = {
-    query: {
-      githubId: 'petrov',
-    },
-    asPath: '/#edit/',
-  } as unknown as NextRouter;
+  ],
+  publicFeedback: [
+    {},
+  ],
+  stageInterviewFeedback: [
+    {},
+  ],
+};
+const session = {
+  id: 2020,
+  githubId: 'mikhama',
+  isAdmin: true,
+  isHirer: false,
+  isActivist: false,
+  roles: {
+    1: 'mentor',
+    2: 'student',
+    11: 'mentor',
+  },
+  coursesRoles: {
+    13: [
+      'manager',
+    ],
+  },
+} as Session;
+const router = {
+  query: {
+    githubId: 'petrov',
+  },
+  asPath: '/#edit/',
+} as unknown as NextRouter;
+const state = {
+  profile,
+  isInitialPermissionsSettingsChanged: false,
+  isInitialProfileSettingsChanged: false,
+};
 
+describe('ProfilePage', () => {
   describe('Should render correctly', () => {
-    it('if full info about profile is in the state', () => {
+    it('if full profile info is in the state', () => {
       const wrapper = shallow(
         <ProfilePage
           session={session}
           router={router}
         />,
       );
-      wrapper.setState({ profile });
+      wrapper.setState(state);
       expect(shallowToJson(wrapper)).toMatchSnapshot();
     });
   });
+
+  const wrapper = shallow(
+    <ProfilePage
+      session={session}
+      router={router}
+    />,
+  );
+  const instance = wrapper.instance();
+  describe('onPermissionsSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if permissions for student role were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEmailVisible',
+          role: 'student',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEmailVisible).toEqual({
+          student: true, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for mentor role were changed', async () => {
+        const event = {
+          target: {
+            checked: false,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isLinkedInVisible',
+          role: 'mentor',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isLinkedInVisible).toEqual({
+          mentor: false, student: false, all: false,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+      it('if permissions for all roles were changed', async () => {
+        const event = {
+          target: {
+            checked: true,
+          },
+        }
+        const changedPermissionsSettings = {
+          permissionName: 'isEducationVisible',
+          role: 'all',
+        };
+        wrapper.setState(state);
+        await instance.onPermissionsSettingsChange(event, changedPermissionsSettings);
+        expect(wrapper.state().profile.permissionsSettings.isEducationVisible).toEqual({
+          mentor: true, student: true, all: true,
+        });
+        expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('onProfileSettingsChange', () => {
+    describe('Should set state correctly', () => {
+      it('if ""profile.generalInfo.location"" was changed', async () => {
+        const event = {
+          id: 123,
+          name: 'Minsk',
+        }
+        const path = 'generalInfo.location';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.locationId).toBe(123);
+        expect(wrapper.state().profile.generalInfo.locationName).toBe('Minsk');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if ""profile.generalInfo.englishLevel"" was changed', async () => {
+        const event = 'b2+';
+        const path = 'generalInfo.englishLevel';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.englishLevel).toBe('b2+');
+      });
+      it('if field added to ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'add',
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([
+          {
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          },
+          {
+            graduationYear: null,
+            faculty: null,
+            university: null,
+          },
+        ]);
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+      it('if field deleted from ""profile.generalInfo.educationHistory""', async () => {
+        const event = {
+          type: 'delete',
+          index: 0,
+        };
+        const path = 'generalInfo.educationHistory';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.educationHistory).toEqual([]);
+      });
+      it('if some other field was changed', async () => {
+        const event = {
+          target: {
+            value: 'Hello everyone, my name is Mike.',
+          }
+        };
+        const path = 'generalInfo.aboutMyself';
+        wrapper.setState(state);
+        await instance.onProfileSettingsChange(event, path);
+        expect(wrapper.state().profile.generalInfo.aboutMyself).toEqual('Hello everyone, my name is Mike.');
+        expect(wrapper.state().isInitialProfileSettingsChanged).toBe(true);
+      });
+    });
+  });
+  describe('changeProfilePageMode', () => {
+    describe('Should set state correctly', () => {
+      it('if mode = ""edit"" was passed', async () => {
+        const mode = 'edit';
+        wrapper.setState({ ...state, isEditingModeEnabled: false });
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+      });
+      it('if mode = ""view"" was passed', async () => {
+        const mode = 'view';
+        wrapper.setState({ ...state, isEditingModeEnabled: true });
+        expect(wrapper.state().isEditingModeEnabled).toBe(true);
+        await instance.changeProfilePageMode(mode);
+        expect(wrapper.state().isEditingModeEnabled).toBe(false);
+      });
+    });
+  });
+  describe('saveProfile', () => {
+    it('Should set state correctly', async () => {
+      const profile = {
+        generalInfo: {
+          aboutMyself: 'Hello',
+          educationHistory: [{
+            graduationYear: '2019',
+            faculty: 'TT',
+            university: 'Test',
+          }],
+          englishLevel: 'c1',
+          locationId: 778,
+          locationName: 'Hrodna',
+        },
+        contacts: {
+          telegram: 'test',
+        },
+        permissionsSettings: {
+          isProfileVisible: { all: true },
+          isAboutVisible: { mentor: true, student: false, all: false },
+          isEducationVisible: { mentor: true, student: false, all: false },
+          isEnglishVisible: { student: true, all: true },
+          isEmailVisible: { student: true, all: true },
+          isTelegramVisible: { student: true, all: true },
+          isSkypeVisible: { student: true, all: false },
+          isPhoneVisible: { student: true, all: false },
+          isContactsNotesVisible: { student: true, all: false },
+          isLinkedInVisible: { mentor: true, student: false, all: false },
+          isPublicFeedbackVisible: { mentor: true, student: true, all: false },
+          isMentorStatsVisible: { mentor: true, student: true, all: false },
+          isStudentStatsVisible: { student: false, all: false },
+        },
+      };
+      wrapper.setState({
+        ...state,
+        profile,
+        isInitialPermissionsSettingsChanged: true,
+        isInitialProfileSettingsChanged: true,
+      });
+      await instance.saveProfile();
+      expect(wrapper.state().isSaving).toBe(false);
+      expect(wrapper.state().isInitialPermissionsSettingsChanged).toBe(false);
+      expect(wrapper.state().isInitialProfileSettingsChanged).toBe(false);
+      expect(wrapper.state().initialPermissionsSettings).toEqual(profile.permissionsSettings);
+      expect(wrapper.state().initialProfileSettings).toEqual(profile);
+    });
+  });
+  describe('hadStudentCoreJSInterview', () => {
+    describe('Should return', () => {
+      it('""true"" if student has an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {
+                interviewFormAnswers: {},
+              },
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(true);
+      });
+      it('""false"" if student has not an ""interviewFormAnswers"" in one of the task', () => {
+        const studentStats = [
+          {
+            courseFullName: 'test',
+            courseName: 'test',
+            locationName: 'Minsk',
+            tasks: [
+              {},
+              {},
+              {},
+            ],
+          },
+        ];
+        const result = instance.hadStudentCoreJSInterview(studentStats);
+        expect(result).toBe(false);
+      });
+    });
+  });
+  describe('getStudentCoreJSInterviews', () => {
+    it('Should return info about CoreJS interviews', () => {
+      const studentStats = [
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          locationName: 'Minsk',
+          tasks: [
+            {},
+            {},
+            {
+              interviewer: {
+                name: 'Dima Petrov',
+                githubId: 'dip',
+              },
+              comment: 'Test',
+              score: 9,
+              interviewFormAnswers: {},
+            },
+            {},
+          ],
+        },
+      ];
+      const result = instance.getStudentCoreJSInterviews(studentStats);
+      expect(result).toEqual([
+        {
+          courseFullName: 'test',
+          courseName: 'test',
+          interview: {
+            answers: {},
+            interviewer: {
+              name: 'Dima Petrov',
+              githubId: 'dip',
+            },
+            comment: 'Test',
+            score: 9,
+          },
+          locationName: 'Minsk',
+        },
+      ]);
+    });
+  });
 });
diff --git a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
index fbd133c..729b2de 100644
--- a/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
+++ b/client/src/pages/profile/__tests__/__snapshots__/ProfilePage.tests.tsx.snap
@@ -1,6 +1,6 @@
 // Jest Snapshot v1, https://goo.gl/fbAQLP
 
-exports[`ProfilePage Should render correctly if  1`] = `
+exports[`ProfilePage Should render correctly if full profile info is in the state 1`] = `
 <Fragment>
   <LoadingScreen
     show={true}
@@ -50,12 +50,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -135,12 +139,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -220,12 +228,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -305,12 +317,16 @@ exports[`ProfilePage Should render correctly if  1`] = `
               data={
                 Object {
                   ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
+                  ""educationHistory"": Array [
+                    Object {
+                      ""faculty"": ""TT"",
+                      ""graduationYear"": ""2019"",
+                      ""university"": ""Test"",
+                    },
+                  ],
                   ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
+                  ""locationId"": 456,
+                  ""locationName"": ""Brest"",
                 }
               }
               isEditingModeEnabled={false}
@@ -387,15 +403,7 @@ exports[`ProfilePage Should render correctly if  1`] = `
             }
           >
             <ContactsCard
-              data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
+              data={Object {}}
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
               onProfileSettingsChange={[Function]}
@@ -461,84 +469,22 @@ exports[`ProfilePage Should render correctly if  1`] = `
               }
             />
           </div>
-        </Masonry>
-        <JSXStyle
-          id=""3803498300""
-        >
-          div.jsx-3803498300{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-left:-16px;width:auto;}
-        </JSXStyle>
-        <JSXStyle
-          id=""110195169""
-        >
-          div.jsx-110195169{padding-left:16px;background-clip:padding-box;}
-        </JSXStyle>
-      </div>
-    </Spin>
-  </LoadingScreen>
-</Fragment>
-`;
-
-exports[`ProfilePage Should render correctly if full info about profile is in the state 1`] = `
-<Fragment>
-  <LoadingScreen
-    show={true}
-  >
-    <Header
-      isProfileEditingModeEnabled={false}
-      isProfilePage={false}
-      isSaveButtonVisible={false}
-      onChangeProfilePageMode={[Function]}
-      onSaveClick={[Function]}
-      username=""mikhama""
-    />
-    <Spin
-      delay={200}
-      size=""default""
-      spinning={false}
-      wrapperClassName=""""
-    >
-      <div
-        style={
-          Object {
-            ""padding"": 10,
-          }
-        }
-      >
-        <Masonry
-          breakpointCols={
-            Object {
-              ""1100"": 3,
-              ""500"": 1,
-              ""700"": 2,
-              ""default"": 4,
-            }
-          }
-          className=""jsx-3803498300""
-          columnClassName=""jsx-110195169""
-        >
           <div
-            key=""card-0""
+            key=""card-5""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <MainCard
+            <PublicFeedbackCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -602,28 +548,30 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-1""
+            key=""card-6""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <AboutCard
+            <StudentStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""locationName"": ""Minsk"",
+                    ""tasks"": Array [
+                      Object {
+                        ""interviewFormAnswers"": Object {},
+                      },
+                    ],
+                  },
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -687,28 +635,21 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-2""
+            key=""card-7""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EnglishCard
+            <MentorStatsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
+                Array [
+                  Object {},
+                ]
               }
               isEditingModeEnabled={false}
               onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
               permissionsSettings={
                 Object {
                   ""isAboutVisible"": Object {
@@ -772,170 +713,44 @@ exports[`ProfilePage Should render correctly if full info about profile is in th
             />
           </div>
           <div
-            key=""card-3""
+            key=""card-8""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <EducationCard
+            <CoreJSIviewsCard
               data={
-                Object {
-                  ""aboutMyself"": ""Test"",
-                  ""educationHistory"": null,
-                  ""englishLevel"": ""a2+"",
-                  ""githubId"": ""petrov"",
-                  ""locationId"": ""1"",
-                  ""locationName"": ""Minsk"",
-                  ""name"": ""Dzmitry Petrov"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {
+                    ""courseFullName"": ""test"",
+                    ""courseName"": ""test"",
+                    ""interview"": Object {
+                      ""answers"": Object {},
+                      ""comment"": undefined,
+                      ""interviewer"": undefined,
+                      ""score"": undefined,
+                    },
+                    ""locationName"": ""Minsk"",
+                  },
+                ]
               }
             />
           </div>
           <div
-            key=""card-4""
+            key=""card-9""
             style={
               Object {
                 ""marginBottom"": 16,
               }
             }
           >
-            <ContactsCard
+            <PreScreeningIviewsCard
               data={
-                Object {
-                  ""email"": ""petro@gmail.com"",
-                  ""notes"": ""discord: @petro, instagram: @petro12"",
-                  ""phone"": ""+375292123456"",
-                  ""skype"": ""petro:live"",
-                  ""telegram"": ""petro"",
-                }
-              }
-              isEditingModeEnabled={false}
-              onPermissionsSettingsChange={[Function]}
-              onProfileSettingsChange={[Function]}
-              permissionsSettings={
-                Object {
-                  ""isAboutVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isContactsNotesVisible"": Object {
-                    ""all"": false,
-                    ""student"": true,
-                  },
-                  ""isEducationVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isEmailVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isEnglishVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isLinkedInVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": false,
-                  },
-                  ""isMentorStatsVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isPhoneVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isProfileVisible"": Object {
-                    ""all"": true,
-                  },
-                  ""isPublicFeedbackVisible"": Object {
-                    ""all"": false,
-                    ""mentor"": true,
-                    ""student"": true,
-                  },
-                  ""isSkypeVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isStudentStatsVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                  ""isTelegramVisible"": Object {
-                    ""all"": false,
-                    ""student"": false,
-                  },
-                }
+                Array [
+                  Object {},
+                ]
               }
             />
           </div>
",3,"[""16d4ace80096557fb3fd48396aa09107241c3131"", ""f8c7b34bdeedcf1a4628cd50b23920afeaf57cb6"", ""11ffd5174bd61a2939ae58d2b2d43284302ae490""]","[""docs"", ""cicd"", ""test""]","1. The commit introduces a new Fiddle example under docs/fiddles/system/system-information/get-version-information (HTML, JS) for version info, modifies the GitHub Actions workflow release-pr.yml, and adds/updates test logic and snapshots for ProfilePage and PreScreeningIviewCard.
2. The new Fiddle example is strictly documentation (usage/example), aligning with the 'docs' label; the workflow YAML change is a CI configuration update, matching 'cicd'; the changes to __tests__ and __snapshots__ directories are additions/updates of test logic and artifacts, which match the 'test' label.
3. 'docs' is appropriate because the Fiddle is a documentation/example artifact, not a code feature, fix, or refactor; 'cicd' is correct since the YAML file is for CI/CD, not build logic; 'test' is correct as the code units are dedicated to test logic, not to fixing or adding features in main code.
4. The assigned labels 'docs', 'cicd', and 'test' are correct because each code change is fully scoped to documentation, CI configuration, or test logic, with no overlap into feature, fix, refactor, or build domains."
"updates the readme to improve the readability and contributing sections
only restart if pages directory itself is changed

resolves #429","diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 

diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 
",2,"[""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6"", ""cbce777addb3dd118232a9f28db9d425d4c937b2""]","[""docs"", ""fix""]","1. The changes update the CONTRIBUTING.md and README.md files to improve instructions, readability, and add new sections, and also modify the dev.ts script to only trigger a restart if the 'pages' directory itself changes, providing a more precise restart condition.
2. The documentation changes align with the 'docs' label as they are solely focused on improving and updating documentation and instructions, while the change in dev.ts addresses a bug by refining the restart trigger logic, fitting the 'fix' label definition.
3. 'docs' is appropriate for the documentation file updates as no code logic is affected, and 'fix' is appropriate for the dev.ts change because it corrects unintended behavior (restarting on any file change in 'pages' instead of only when the directory itself changes); other labels like 'feat' or 'refactor' do not apply because no new features are added and the code structure is not merely improved without behavior change.
4. The assigned 'docs' and 'fix' labels accurately represent the documentation enhancements and the targeted bug fix in the code logic, matching the classification rules and label definitions."
"fixed tick interval
Add the select function for logicflow","diff --git a/backend/services/integrations/main.go b/backend/services/integrations/main.go
index 4a5e764..35c3ff2 100644
--- a/backend/services/integrations/main.go
+++ b/backend/services/integrations/main.go
@@ -54,7 +54,7 @@ func main() {
 	sigchan := make(chan os.Signal, 1)
 	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
 
-	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL)
+	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL * time.Millisecond)
 
 	log.Printf(""Integration service started\n"")
 	manager.RequestAll()
@@ -66,7 +66,7 @@ func main() {
 			pg.Close()
 			os.Exit(0)
 		case <-tick:
-			// log.Printf(""Requesting all...\n"")
+			log.Printf(""Requesting all...\n"")
 			manager.RequestAll()
 		case event := <-manager.Events:
 			// log.Printf(""New integration event: %v\n"", *event.RawErrorEvent)

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index 0d913b7..dcc59b3 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -276,6 +276,12 @@ export default class LogicFlow {
     this.translate(-TRANSLATE_X, -TRANSLATE_Y);
   }
   /**
+   * 将图形选中
+   */
+  select(id: string) {
+    this.graphModel.selectElementById(id);
+  }
+  /**
    * 将图形定位到画布中心
    * @param focusOnArgs 支持用户传入图形当前的坐标或id，可以通过type来区分是节点还是连线的id，也可以不传（兜底）
    */
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 94d0899..10280a9 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -481,6 +481,13 @@ class GraphModel {
     this.selectElement?.setSelected(true);
   }
 
+  @action
+  selectElementById(id: string) {
+    this.selectElement?.setSelected(false);
+    this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
+    this.selectElement?.setSelected(true);
+  }
+
   /* 修改连线类型 */
   @action
   changeEdgeType(type: string): void {
",2,"[""7dc3b70fe40fc7de255a28bb3098bcb8c0d35365"", ""6ae067153cd2608018fd3da76bd6d00a08da4b3a""]","[""fix"", ""feat""]","1. The code changes include correcting the tick interval unit in the Go service (from an unspecified unit to milliseconds), uncommenting a log statement, and adding a new 'select' method to LogicFlow and its underlying GraphModel class in TypeScript.
2. The tick interval correction addresses a likely bug in timing logic, fitting the 'fix' label, while the addition of the 'select' method enables new selection functionality, aligning with the 'feat' label.
3. 'fix' is appropriate for the Go code because it resolves incorrect interval behavior, not a new feature or refactor; 'feat' is appropriate for the TypeScript code because it introduces new capability, not merely a bug fix or restructuring. No object labels apply, as these are core logic changes rather than dedicated tests, docs, or CI/build scripts.
4. Both 'fix' and 'feat' are justified: 'fix' for correcting the tick interval logic, and 'feat' for introducing the select functionality in LogicFlow."
"simplyfy statement
initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/Object/Merge.ts b/src/Object/Merge.ts
index 1f48efb..06caad1 100644
--- a/src/Object/Merge.ts
+++ b/src/Object/Merge.ts
@@ -96,9 +96,11 @@ type ChooseMergeDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _MergeDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? MergeProp<O, O1, K, OOK, style>
-    : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? MergeProp<O, O1, K, OOK, style>
+      : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
diff --git a/src/Object/Patch.ts b/src/Object/Patch.ts
index 2d73784..2c8bd42 100644
--- a/src/Object/Patch.ts
+++ b/src/Object/Patch.ts
@@ -89,9 +89,11 @@ type ChoosePatchDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _PatchDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? PatchProp<O, O1, K, OOK>
-    : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? PatchProp<O, O1, K, OOK>
+      : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",2,"[""f86944ff00b970d7e2da48abbff43e58bdf29b99"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""refactor"", ""fix""]","1. The changes in Merge.ts and Patch.ts simplify type logic by replacing a compound conditional with nested conditionals, while the changes in canvas.tsx and types/index.d.ts initialize default values for several Three.js objects to avoid undefined errors and update type annotations accordingly.
2. The type logic changes in Merge.ts and Patch.ts improve code clarity and maintainability without changing behavior, aligning with the 'refactor' label, whereas the initialization of Three.js objects in canvas.tsx and types/index.d.ts addresses undefined errors, aligning with the 'fix' label as it resolves a runtime bug.
3. 'refactor' is appropriate for the type-level conditional simplification because it restructures code for clarity without altering external behavior, not introducing features or fixing bugs; 'fix' is appropriate for the Three.js object initialization because it directly resolves a bug (undefined errors), not simply restructuring or adding new features.
4. The 'refactor' label captures the code restructuring in type logic, while the 'fix' label captures the bug resolution in Three.js object initialization, both correctly reflecting the motivations and nature of their respective changes."
"fix typos (#90)
skip flaky test","diff --git a/README.md b/README.md
index de15ac5..5ad8b47 100755
--- a/README.md
+++ b/README.md
@@ -16,13 +16,13 @@ content that will be loaded, similar to Facebook cards loaders.
 
 ## Features
 
-* :gear: **Complety customizable:** you can change the colors, speed and sizes;
+* :gear: **Completely customizable:** you can change the colors, speed and sizes;
 * :pencil2: **Create your own loading:** use the
   [create-react-content-loader](https://danilowoz.github.io/create-react-content-loader/) to create
-  your customs loadings easily;
+  your custom loadings easily;
 * :ok_hand: **You can use right now:** there are a lot of presets to use the loader, see the
   [options](#options);
-* :rocket: **Perfomance:** react-content-loader uses pure SVG to work, so it's works without any extra scritpt,
+* :rocket: **Performance:** react-content-loader uses pure SVG to work, so it works without any extra scripts,
   canvas, etc;
 
 ## Usage

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",2,"[""88257ee720ed8ba136d49087c0d31373e8397dd5"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""docs"", ""test""]","1. The commit corrects several typos in the README.md file and skips a flaky test in a test file by marking it with test.skip and adding a comment.
2. The typo corrections in README.md are documentation-focused, aligning with the 'docs' label, while the modification in the test file is solely about test logic and test management, aligning with the 'test' label.
3. 'docs' is appropriate for the README.md changes as only documentation is affected (not code behavior), and 'test' is correct for skipping the test because the change is entirely within a test file and pertains to test execution—not bug fixing or refactoring code logic.
4. The assigned 'docs' and 'test' labels accurately reflect the exclusive focus on documentation and test artifacts in this commit, per the labeling rules."
"bundle and tree shake assets with webpack
adds test for exec with http proxy

Signed-off-by: Sam Alba <samalba@users.noreply.github.com>
replace tuple with record","diff --git a/package.json b/package.json
index c8051d2..b0a97fb 100644
--- a/package.json
+++ b/package.json
@@ -60,6 +60,7 @@
     ""babel-cli"": ""^6.16.0"",
     ""babel-core"": ""^6.16.0"",
     ""babel-eslint"": ""^7.0.0"",
+    ""babel-loader"": ""^6.2.5"",
     ""babel-plugin-transform-class-properties"": ""^6.10.2"",
     ""babel-plugin-transform-flow-strip-types"": ""^6.14.0"",
     ""babel-preset-es2015-node6"": ""^0.3.0"",
@@ -82,6 +83,7 @@
     ""eslint-plugin-react"": ""^6.3.0"",
     ""flow-bin"": ""^0.33.0"",
     ""jsdom"": ""^9.4.2"",
+    ""json-loader"": ""^0.5.4"",
     ""jsx-chai"": ""^4.0.0"",
     ""mocha"": ""^3.0.2"",
     ""mock-require"": ""^1.3.0"",
@@ -91,6 +93,8 @@
     ""rimraf"": ""^2.5.2"",
     ""sinon"": ""^1.17.6"",
     ""sinon-chai"": ""^2.8.0"",
-    ""watch"": ""^1.0.0""
+    ""source-map-support"": ""^0.4.3"",
+    ""watch"": ""^1.0.0"",
+    ""webpack"": ""^1.13.2""
   }
 }
diff --git a/webpack.config.js b/webpack.config.js
new file mode 100644
index 0000000..0ca6da1
--- /dev/null
+++ b/webpack.config.js
@@ -0,0 +1,44 @@
+const webpack = require('webpack');
+const path = require('path');
+const fs = require('fs');
+
+const nodeModules = {
+  zmq: 'commonjs zmq',
+  jmp: 'commonjs jmp',
+  github: 'commonjs github',
+};
+
+module.exports = {
+  entry: './src/notebook/index.js',
+  target: 'electron-renderer',
+  output: {
+    path: path.join(__dirname, 'app', 'build'),
+    filename: 'webpacked-notebook.js'
+  },
+  module: {
+    loaders: [
+      { test: /\.js$/, exclude: /node_modules/, loaders: ['babel'] },
+      { test: /\.json$/, loader: 'json-loader' },
+    ]
+  },
+  resolve: {
+    extensions: ['', '.js', '.jsx'],
+    root: path.join(__dirname, 'app'),
+    // Webpack 1
+    modulesDirectories: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+      path.resolve(__dirname, 'node_modules'),
+    ],
+    // Webpack 2
+    modules: [
+      path.resolve(__dirname, 'app', 'node_modules'),
+    ],
+  },
+  externals: nodeModules,
+  plugins: [
+    new webpack.IgnorePlugin(/\.(css|less)$/),
+    new webpack.BannerPlugin('require(""source-map-support"").install();',
+                             { raw: true, entryOnly: false })
+  ],
+  devtool: 'sourcemap'
+};

diff --git a/tests/tasks.bats b/tests/tasks.bats
index e3b95c4..4cfba15 100644
--- a/tests/tasks.bats
+++ b/tests/tasks.bats
@@ -101,6 +101,14 @@ setup() {
     assert_line --partial --index 9 'actions.basicTest.stop'
 }
 
+@test ""task: #Exec with HTTP proxy"" {
+    cd ./tasks/exec
+    export HTTPS_PROXY=""https://localhost:4242/""
+    run ""$DAGGER"" ""do"" -p ./http_proxy.cue curlProxy
+    assert_failure
+    unset HTTP_PROXY
+}
+
 @test ""task: #Start #Stop params"" {
     cd ./tasks/exec
     ""$DAGGER"" ""do"" -p ./start_stop_exec.cue execParamsTest
@@ -297,4 +305,4 @@ setup() {
 
 @test ""task: #Rm"" {
     ""$DAGGER"" ""do"" -p ./tasks/rm/rm.cue test
-}
\ No newline at end of file
+}
diff --git a/tests/tasks/exec/http_proxy.cue b/tests/tasks/exec/http_proxy.cue
new file mode 100644
index 0000000..05de4b9
--- /dev/null
+++ b/tests/tasks/exec/http_proxy.cue
@@ -0,0 +1,25 @@
+package main
+
+import (
+	""dagger.io/dagger""
+	""dagger.io/dagger/core""
+)
+
+dagger.#Plan & {
+	actions: {
+		image: core.#Pull & {
+			source: ""alpine:3.15.0@sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3""
+		}
+
+		curlProxy: core.#Exec & {
+			input: image.output
+			args: [
+				""sh"", ""-c"",
+				""""""
+					apk add --no-cache curl
+					curl -sfL -o /dev/null https://www.google.com/
+					"""""",
+			]
+		}
+	}
+}

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
index fa6f8d4..2185b1e 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/processinstance/CreateProcessInstanceProcessor.java
@@ -37,7 +37,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceCreationIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.protocol.record.value.BpmnElementType;
 import io.camunda.zeebe.util.Either;
-import io.camunda.zeebe.util.collection.Tuple;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
@@ -236,21 +235,22 @@ public final class CreateProcessInstanceProcessor
     return startInstructions.stream()
         .map(
             instruction ->
-                Tuple.of(
+                new ElementIdAndType(
                     instruction.getElementId(),
                     process.getElementById(instruction.getElementIdBuffer()).getElementType()))
-        .filter(elementTuple -> UNSUPPORTED_ELEMENT_TYPES.contains(elementTuple.getRight()))
+        .filter(
+            elementIdAndType -> UNSUPPORTED_ELEMENT_TYPES.contains(elementIdAndType.elementType))
         .findAny()
         .map(
-            elementTypeTuple ->
+            elementIdAndType ->
                 Either.left(
                     new Rejection(
                         RejectionType.INVALID_ARGUMENT,
                         (""Expected to create instance of process with start instructions but the element with id '%s' targets unsupported element type '%s'. ""
                                 + ""Supported element types are: %s"")
                             .formatted(
-                                elementTypeTuple.getLeft(),
-                                elementTypeTuple.getRight(),
+                                elementIdAndType.elementId,
+                                elementIdAndType.elementType,
                                 Arrays.stream(BpmnElementType.values())
                                     .filter(
                                         elementType ->
@@ -493,4 +493,6 @@ public final class CreateProcessInstanceProcessor
   }
 
   record Rejection(RejectionType type, String reason) {}
+
+  record ElementIdAndType(String elementId, BpmnElementType elementType) {}
 }
",3,"[""4ab28fc2e63e975a0c77e18ae644f34fa5f8771a"", ""6c7398993bc567ec84e4573b6ededbf50b1ef606"", ""bb2ccc1a778452aebf233cf78b20f1f4bab4354b""]","[""build"", ""test"", ""refactor""]","1. The commit adds new devDependencies (webpack, loaders) to package.json and introduces a webpack.config.js file, which configures asset bundling and tree shaking; these are build system changes. It also adds a new test case and supporting CUE file for HTTP proxy exec logic, which are test artifacts. Finally, it replaces usage of a Tuple class with a new record (ElementIdAndType) in a Java file, which is a refactor for improved code structure.
2. The build label aligns with changes to dependency management and addition of Webpack configuration, which affect the build process. The test label matches the exclusive addition of test cases and test-specific CUE files. The refactor label fits the replacement of Tuple with a record, as this restructures code without changing external behavior.
3. Alternative labels are ruled out: 'feat' is not appropriate since no new feature is exposed; 'fix' does not apply as no bugs are addressed; 'docs' is not relevant as no documentation is changed; 'cicd' is not suitable since no CI/CD scripts are modified. Each change is fully scoped to its respective artifact or purpose, justifying the selected labels.
4. The assigned labels build, test, and refactor accurately reflect the commit's build system updates, exclusive test additions, and internal code restructuring, according to the classification rules."
"better layout for block and segment
ensure checksum persist flushes to disk
only run JMH on develop and master

- reduces test duration of feature branches
- reduces bors merge duration
- show performance impact of PRs and Releases on the respective branches
- number parallel stages to enforce ordering in Blue Ocean view
- **note**: skipping a parallel stage in Blue Ocean triggers a bug where
  log will not be show until the stage finished https://issues.jenkins-ci.org/browse/JENKINS-48879","diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/Jenkinsfile b/Jenkinsfile
index 9fbd3a1..3e4f052 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -29,7 +29,7 @@ pipeline {
 
         stage('Verify') {
             parallel {
-                stage('Tests') {
+                stage('1 - Java Tests') {
                     steps {
                         withMaven(jdk: jdkVersion, maven: mavenVersion, mavenSettingsConfig: mavenSettingsConfig) {
                             sh 'mvn -B verify -P skip-unstable-ci'
@@ -42,7 +42,9 @@ pipeline {
                     }
                 }
 
-                stage('JMH') {
+                stage('2 - JMH') {
+                    // delete this line to also run JMH on feature branch
+                    when { anyOf { branch 'master'; branch 'develop' } }
                     agent { node { label 'ubuntu-large' } }
 
                     steps {
",3,"[""cb1f48b56ae0de93acb72e48726c7d610a1d538e"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""83934807f4061980e7f5bf46d36eca70e238835d""]","[""docs"", ""test"", ""cicd""]","1. The commit introduces new and reorganized documentation files (config-block.md, config-segment.md, config-example.md), updates navigation (sidebars.js), and revises/clarifies existing docs (config-overview.md, segment-environment.md), all of which are exclusively documentation changes; it also adds a new test (shouldFlushOnPersist) to SnapshotChecksumTest.java; and modifies Jenkinsfile to adjust CI behavior (branch-based JMH execution and stage naming).
2. The documentation changes align with the 'docs' label as they only affect documentation structure and content; the new test method is a pure addition to a test file, fitting the 'test' label; Jenkinsfile changes are dedicated to CI configuration, matching the 'cicd' label.
3. 'docs' is appropriate because no code logic or behavior is affected outside documentation; 'test' is correct as the change is solely about adding a test case, not fixing or refactoring test logic; 'cicd' is justified as the Jenkinsfile edits are limited to CI control and do not alter build scripts or application code.
4. The assigned labels 'docs', 'test', and 'cicd' are appropriate because each code unit exclusively modifies documentation, tests, or CI configuration files, matching the object label definitions."
update drone,"diff --git a/.drone.yml b/.drone.yml
index 53e3329..306516b 100644
--- a/.drone.yml
+++ b/.drone.yml
@@ -21,10 +21,10 @@ steps:
         from_secret: docker_username
       password:
         from_secret: docker_password
-      tags: pg
+      tags: latest
     when: 
       branch:
-        - pg
+        - master
       event: 
         - push
   - 
@@ -40,14 +40,14 @@ steps:
       port: 22
       script: 
         - ""sleep 10""
-        - ""docker pull rsschool/api:pg""
+        - ""docker pull rsschool/api:latest""
         - ""docker-compose stop api""
         - ""docker-compose rm -f api""
         - ""docker-compose up -d api""
         - ""docker system prune -f""
     when: 
       branch: 
-        - pg
+        - master
       event: 
         - push
 volumes:
",1,"[""88129ee45b1d49bc4ff887f3b488464cc7097e29""]","[""build""]","1. The code changes update the .drone.yml file, modifying Docker tags and deployment branches from 'pg' to 'latest' and from 'pg' branch to 'master'.
2. These changes affect the build and deployment process configuration, specifically targeting how images are tagged and which branch triggers deployments, which falls under the 'build' label as it pertains to build system configuration.
3. The 'build' label is appropriate because .drone.yml is a build pipeline configuration file; although it is also used for CI/CD, the changes here are related to build artifact tagging and deployment, not general CI logic ('cicd') or code/test logic.
4. The 'build' label correctly reflects that this commit modifies build and deployment configuration by updating tags and branch triggers in the build system."
"right side menus
fix error spacing","diff --git a/ionic/components/menu/menu-types.scss b/ionic/components/menu/menu-types.scss
index dbbfdda..5e4f990 100644
--- a/ionic/components/menu/menu-types.scss
+++ b/ionic/components/menu/menu-types.scss
@@ -35,3 +35,7 @@ ion-menu[type=overlay] {
     }
   }
 }
+
+ion-menu[type=overlay][side=right] {
+  left: 8px;
+}
diff --git a/ionic/components/menu/menu-types.ts b/ionic/components/menu/menu-types.ts
index 360aeb4..0666a38 100644
--- a/ionic/components/menu/menu-types.ts
+++ b/ionic/components/menu/menu-types.ts
@@ -10,7 +10,7 @@ import {Animation} from 'ionic/animations/animation';
  */
 export class MenuType {
 
-  constructor(menu: Menu) {
+  constructor() {
     this.open = new Animation();
     this.close = new Animation();
   }
@@ -88,16 +88,17 @@ class MenuRevealType extends MenuType {
     let duration = 250;
 
     let openedX = (menu.width() * (menu.side == 'right' ? -1 : 1)) + 'px';
+    let closedX = '0px'
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let contentOpen = new Animation(menu.getContentElement());
-    contentOpen.fromTo(TRANSLATE_X, CENTER, openedX);
+    contentOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(contentOpen);
 
     let contentClose = new Animation(menu.getContentElement());
-    contentClose.fromTo(TRANSLATE_X, openedX, CENTER);
+    contentClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(contentClose);
   }
 }
@@ -117,13 +118,23 @@ class MenuOverlayType extends MenuType {
     let duration = 250;
     let backdropOpacity = 0.5;
 
-    let closedX = (menu.width() * (menu.side == 'right' ? 1 : -1)) + 'px';
+    let closedX, openedX;
+    if (menu.side == 'right') {
+      // right side
+      closedX = menu.platform.width() + 'px';
+      openedX = (menu.platform.width() - menu.width() - 8) + 'px';
+
+    } else {
+      // left side
+      closedX = -menu.width() + 'px';
+      openedX = '8px';
+    }
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let menuOpen = new Animation(menu.getMenuElement());
-    menuOpen.fromTo(TRANSLATE_X, closedX, '8px');
+    menuOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(menuOpen);
 
     let backdropOpen = new Animation(menu.getBackdropElement());
@@ -131,7 +142,7 @@ class MenuOverlayType extends MenuType {
     this.open.add(backdropOpen);
 
     let menuClose = new Animation(menu.getMenuElement());
-    menuClose.fromTo(TRANSLATE_X, '8px', closedX);
+    menuClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(menuClose);
 
     let backdropClose = new Animation(menu.getBackdropElement());
@@ -144,4 +155,3 @@ Menu.register('overlay', MenuOverlayType);
 
 const OPACITY = 'opacity';
 const TRANSLATE_X = 'translateX';
-const CENTER = '0px';
diff --git a/ionic/components/menu/menu.ts b/ionic/components/menu/menu.ts
index d911b2e..e980069 100644
--- a/ionic/components/menu/menu.ts
+++ b/ionic/components/menu/menu.ts
@@ -4,6 +4,7 @@ import {Ion} from '../ion';
 import {IonicApp} from '../app/app';
 import {IonicConfig} from '../../config/config';
 import {IonicComponent} from '../../config/annotations';
+import {IonicPlatform} from '../../platform/platform';
 import * as gestures from  './menu-gestures';
 
 
@@ -35,10 +36,16 @@ import * as gestures from  './menu-gestures';
 })
 export class Menu extends Ion {
 
-  constructor(app: IonicApp, elementRef: ElementRef, config: IonicConfig) {
+  constructor(
+    app: IonicApp,
+    elementRef: ElementRef,
+    config: IonicConfig,
+    platform: IonicPlatform
+  ) {
     super(elementRef, config);
-
     this.app = app;
+    this.platform = platform;
+
     this.opening = new EventEmitter('opening');
     this.isOpen = false;
     this._disableTime = 0;
@@ -46,9 +53,9 @@ export class Menu extends Ion {
 
   onInit() {
     super.onInit();
-    this.contentElement = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
+    this._cntEle = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
 
-    if (!this.contentElement) {
+    if (!this._cntEle) {
       return console.error('Menu: must have a [content] element to listen for drag events on. Example:\n\n<ion-menu [content]=""content""></ion-menu>\n\n<ion-content #content></ion-content>');
     }
 
@@ -61,8 +68,8 @@ export class Menu extends Ion {
     this._initGesture();
     this._initType(this.type);
 
-    this.contentElement.classList.add('menu-content');
-    this.contentElement.classList.add('menu-content-' + this.type);
+    this._cntEle.classList.add('menu-content');
+    this._cntEle.classList.add('menu-content-' + this.type);
 
     let self = this;
     this.onContentClick = function(ev) {
@@ -161,11 +168,11 @@ export class Menu extends Ion {
 
     this.isOpen = isOpen;
 
-    this.contentElement.classList[isOpen ? 'add' : 'remove']('menu-content-open');
+    this._cntEle.classList[isOpen ? 'add' : 'remove']('menu-content-open');
 
-    this.contentElement.removeEventListener('click', this.onContentClick);
+    this._cntEle.removeEventListener('click', this.onContentClick);
     if (isOpen) {
-      this.contentElement.addEventListener('click', this.onContentClick);
+      this._cntEle.addEventListener('click', this.onContentClick);
 
     } else {
       this.getNativeElement().classList.remove('show-menu');
@@ -220,7 +227,7 @@ export class Menu extends Ion {
    * @return {Element} The Menu's associated content element.
    */
   getContentElement() {
-    return this.contentElement;
+    return this._cntEle;
   }
 
   /**
@@ -239,7 +246,7 @@ export class Menu extends Ion {
     this.app.unregister(this.id);
     this._gesture && this._gesture.destroy();
     this._type && this._type.onDestroy();
-    this.contentElement = null;
+    this._cntEle = null;
   }
 
 }
diff --git a/ionic/components/menu/test/basic/index.ts b/ionic/components/menu/test/basic/index.ts
index 698cec4..65952ff 100644
--- a/ionic/components/menu/test/basic/index.ts
+++ b/ionic/components/menu/test/basic/index.ts
@@ -36,9 +36,9 @@ class E2EApp {
     ];
   }
 
-  openPage(menu, page) {
+  openPage(page) {
     // close the menu when clicking a link from the menu
-    menu.close();
+    this.app.getComponent('leftMenu').close();
 
     // Reset the content nav to have just this page
     // we wouldn't want the back button to show in this scenario
diff --git a/ionic/components/menu/test/basic/main.html b/ionic/components/menu/test/basic/main.html
index 9bdeb5c..4905ae6 100644
--- a/ionic/components/menu/test/basic/main.html
+++ b/ionic/components/menu/test/basic/main.html
@@ -1,4 +1,4 @@
-<ion-menu #menu [content]=""content"">
+<ion-menu [content]=""content"" id=""leftMenu"">
 
   <ion-toolbar secondary>
     <ion-title>Left Menu</ion-title>
@@ -8,11 +8,35 @@
 
     <ion-list>
 
-      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(menu, p)"">
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
         {{p.title}}
       </button>
 
-      <button ion-item menu-toggle no-forward-icon class=""e2eCloseMenu"">
+      <button ion-item menu-toggle=""leftMenu"" no-forward-icon class=""e2eCloseMenu"">
+        Close Menu
+      </button>
+
+    </ion-list>
+  </ion-content>
+
+</ion-menu>
+
+
+<ion-menu side=""right"" [content]=""content"" id=""rightMenu"">
+
+  <ion-toolbar secondary>
+    <ion-title>Right Menu</ion-title>
+  </ion-toolbar>
+
+  <ion-content>
+
+    <ion-list>
+
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
+        {{p.title}}
+      </button>
+
+      <button ion-item menu-toggle=""rightMenu"" no-forward-icon class=""e2eCloseMenu"">
         Close Menu
       </button>
 
diff --git a/ionic/components/menu/test/basic/page1.html b/ionic/components/menu/test/basic/page1.html
index 1881d9e..2bc5c79 100644
--- a/ionic/components/menu/test/basic/page1.html
+++ b/ionic/components/menu/test/basic/page1.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -21,19 +21,23 @@
     </button>
   </ion-nav-items>
 
-  <a menu-toggle secondary>
+  <a menu-toggle=""rightMenu"" secondary>
     <icon menu></icon>
   </a>
 
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 1</h3>
 
   <p>
-    <button class=""e2eContentToggleMenu"" menu-toggle>Toggle Menu</button>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""leftMenu"">Toggle Left Menu</button>
+  </p>
+
+  <p>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""rightMenu"">Toggle Right Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/menu/test/basic/page2.html b/ionic/components/menu/test/basic/page2.html
index 9801c4f..098f3e1 100644
--- a/ionic/components/menu/test/basic/page2.html
+++ b/ionic/components/menu/test/basic/page2.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -11,12 +11,12 @@
 
 </ion-navbar>
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 2</h3>
 
   <p>
-    <button menu-toggle class=""e2eContentToggleMenu"">Toggle Menu</button>
+    <button menu-toggle=""leftMenu"" class=""e2eContentToggleMenu"">Toggle Left Menu</button>
   </p>
 
   <p>
diff --git a/ionic/components/menu/test/basic/page3.html b/ionic/components/menu/test/basic/page3.html
index a2d65e2..079a3e9 100644
--- a/ionic/components/menu/test/basic/page3.html
+++ b/ionic/components/menu/test/basic/page3.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -12,12 +12,12 @@
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 3</h3>
 
   <p>
-    <button menu-toggle>Toggle Menu</button>
+    <button menu-toggle=""leftMenu"">Toggle Left Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/toolbar/modes/md.scss b/ionic/components/toolbar/modes/md.scss
index 984e758..339169a 100644
--- a/ionic/components/toolbar/modes/md.scss
+++ b/ionic/components/toolbar/modes/md.scss
@@ -43,6 +43,12 @@ $toolbar-md-button-font-size:        1.4rem !default;
     }
   }
 
+  [menu-toggle][secondary],
+  [menu-toggle][secondary].activated {
+    margin: 0 2px;
+    min-width: 28px;
+  }
+
 }
 
 ion-title {

diff --git a/cmd/infracost/main.go b/cmd/infracost/main.go
index 425aef1..fcc9eb5 100644
--- a/cmd/infracost/main.go
+++ b/cmd/infracost/main.go
@@ -149,7 +149,7 @@ Example:
 			}
 
 			if appErr.Error() != """" {
-				fmt.Fprintf(os.Stderr, ""\n%s\n"", color.HiRedString(appErr.Error()))
+				fmt.Fprintf(os.Stderr, ""%s\n"", color.HiRedString(appErr.Error()))
 			}
 		}
 
",2,"[""1a60540f2bcda48d33f015e31f3728ac2c59a159"", ""c623b3622058b913290120b06ccdc779a4e4413d""]","[""feat"", ""fix""]","1. The commit introduces right-side menu support in the UI, updates menu animation logic for side-specific behavior, and modifies several HTML files to support left/right menu toggling; it also fixes a spacing error in a Go CLI error message and adjusts button spacing in SCSS.
2. The changes to the menu system (support for right-side menus, animation logic, new menu IDs, and HTML updates) add new capabilities, aligning with the 'feat' label; the Go CLI change and SCSS margin update correct minor errors, aligning with the 'fix' label.
3. 'feat' is appropriate for the new right-side menu functionality, as it adds user-facing features; 'fix' is correct for the error message formatting and spacing adjustments, as these resolve presentational bugs, not new features or code restructuring.
4. The 'feat' label captures the addition of right-side menu capability, while the 'fix' label covers error and spacing corrections, making both labels appropriate for this commit."
"remove writers from interface
missing transformation for T
also make dependents when running smoke tests","diff --git a/engine/src/main/java/io/camunda/zeebe/engine/Engine.java b/engine/src/main/java/io/camunda/zeebe/engine/Engine.java
index 91f1b41..eb4b9a8 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/Engine.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/Engine.java
@@ -81,8 +81,6 @@ public class Engine implements RecordProcessor<EngineContext> {
 
     engineContext.setLifecycleListeners(typedRecordProcessors.getLifecycleListeners());
     recordProcessorMap = typedRecordProcessors.getRecordProcessorMap();
-
-    engineContext.setWriters(writers);
   }
 
   @Override
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/EngineContext.java b/engine/src/main/java/io/camunda/zeebe/engine/EngineContext.java
index a8e5538..a27b6e6 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/EngineContext.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/EngineContext.java
@@ -15,7 +15,6 @@ import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessorListene
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecordProcessorFactory;
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.LegacyTypedResponseWriter;
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.LegacyTypedStreamWriter;
-import io.camunda.zeebe.engine.processing.streamprocessor.writers.Writers;
 import io.camunda.zeebe.engine.state.EventApplier;
 import io.camunda.zeebe.engine.state.mutable.MutableZeebeState;
 import java.util.Collections;
@@ -34,7 +33,6 @@ public final class EngineContext {
   private final TypedRecordProcessorFactory typedRecordProcessorFactory;
   private List<StreamProcessorLifecycleAware> lifecycleListeners = Collections.EMPTY_LIST;
   private StreamProcessorListener streamProcessorListener;
-  private Writers writers;
 
   public EngineContext(
       final int partitionId,
@@ -102,12 +100,4 @@ public final class EngineContext {
   public void setStreamProcessorListener(final StreamProcessorListener streamProcessorListener) {
     this.streamProcessorListener = streamProcessorListener;
   }
-
-  public Writers getWriters() {
-    return writers;
-  }
-
-  public void setWriters(final Writers writers) {
-    this.writers = writers;
-  }
 }
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/api/ReadonlyStreamProcessorContext.java b/engine/src/main/java/io/camunda/zeebe/engine/api/ReadonlyStreamProcessorContext.java
index f30c7cc..834b421 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/api/ReadonlyStreamProcessorContext.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/api/ReadonlyStreamProcessorContext.java
@@ -8,7 +8,6 @@
 package io.camunda.zeebe.engine.api;
 
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.LegacyTypedStreamWriter;
-import io.camunda.zeebe.engine.processing.streamprocessor.writers.Writers;
 import io.camunda.zeebe.engine.state.mutable.MutableZeebeState;
 import io.camunda.zeebe.logstreams.log.LogStream;
 
@@ -27,11 +26,6 @@ public interface ReadonlyStreamProcessorContext {
   LegacyTypedStreamWriter getLogStreamWriter();
 
   /**
-   * @return the specific writers, like command, response, etc
-   */
-  Writers getWriters();
-
-  /**
    * @return the state, where the data is stored during processing
    */
   MutableZeebeState getZeebeState();
diff --git a/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessor.java b/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessor.java
index 844e487..49fd8e2 100755
--- a/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessor.java
@@ -346,7 +346,6 @@ public class StreamProcessor extends Actor implements HealthMonitorable, LogReco
     if (listener != null) {
       streamProcessorContext.listener(engineContext.getStreamProcessorListener());
     }
-    streamProcessorContext.writers(engineContext.getWriters());
   }
 
   private long recoverFromSnapshot() {
diff --git a/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessorContext.java b/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessorContext.java
index d02b273..b527d3c 100644
--- a/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessorContext.java
+++ b/engine/src/main/java/io/camunda/zeebe/streamprocessor/StreamProcessorContext.java
@@ -17,7 +17,6 @@ import io.camunda.zeebe.engine.processing.streamprocessor.writers.CommandRespons
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.LegacyTypedResponseWriterImpl;
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.LegacyTypedStreamWriter;
 import io.camunda.zeebe.engine.processing.streamprocessor.writers.NoopLegacyTypedStreamWriter;
-import io.camunda.zeebe.engine.processing.streamprocessor.writers.Writers;
 import io.camunda.zeebe.engine.state.EventApplier;
 import io.camunda.zeebe.engine.state.KeyGeneratorControls;
 import io.camunda.zeebe.engine.state.ZeebeDbState;
@@ -55,7 +54,7 @@ public final class StreamProcessorContext implements ReadonlyStreamProcessorCont
   private StreamProcessorMode streamProcessorMode = StreamProcessorMode.PROCESSING;
   private ProcessingScheduleService processingScheduleService;
   private MutableLastProcessedPositionState lastProcessedPositionState;
-  private Writers writers;
+
   private LogStreamBatchWriter logStreamBatchWriter;
   private CommandResponseWriter commandResponseWriter;
 
@@ -85,11 +84,6 @@ public final class StreamProcessorContext implements ReadonlyStreamProcessorCont
   }
 
   @Override
-  public Writers getWriters() {
-    return writers;
-  }
-
-  @Override
   public MutableZeebeState getZeebeState() {
     return zeebeState;
   }
@@ -216,10 +210,6 @@ public final class StreamProcessorContext implements ReadonlyStreamProcessorCont
     return streamProcessorMode;
   }
 
-  public void writers(final Writers writers) {
-    this.writers = writers;
-  }
-
   public void logStreamBatchWriter(final LogStreamBatchWriter batchWriter) {
     logStreamBatchWriter = batchWriter;
   }

diff --git a/src/Tuple/Merge.ts b/src/Tuple/Merge.ts
index dfa7ce5..5ba44b7 100644
--- a/src/Tuple/Merge.ts
+++ b/src/Tuple/Merge.ts
@@ -30,7 +30,7 @@ type _MergeFlat<O extends object, O1P extends object> = {
 }
 
 type MergeDeep<T extends any[], T1 extends any[]> =
-    TupleOf<Compute<_MergeDeep<T, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
+    TupleOf<Compute<_MergeDeep<ObjectOf<T>, Omit<ObjectOf<T1>, keyof T>, ObjectOf<T1>>>>
     // same principle as above, but with a little tweak
     // we keep the original `O1` to know if we can merge
     // => if `O` and `O1` have `object` fields of same name

diff --git a/.github/workflows/os-smoke-test.yml b/.github/workflows/os-smoke-test.yml
index 194d108..7e41493 100644
--- a/.github/workflows/os-smoke-test.yml
+++ b/.github/workflows/os-smoke-test.yml
@@ -56,5 +56,7 @@ jobs:
         uses: JesseTG/rm@v1.0.2
         with:
           path: /Users/runner/.m2/repository/uk/co/real-logic/sbe-tool
+      - name: Build relevant modules
+        run: mvn -B -am -pl qa/integration-tests package -DskipTests -DskipChecks -T1C
       - name: Run smoke test
         run: mvn -B -pl qa/integration-tests verify -P smoke-test -DskipUTs -DskipChecks
",3,"[""d2709cab63295109dcd1a49f57da9418110e9044"", ""c4d9e5023fa0f88ba283b37da27677ceda1cbfbb"", ""2236b37bd671fdb71313cbc6ebd7633f0effba34""]","[""refactor"", ""fix"", ""build""]","1. The Java source files remove the 'writers' field and related methods from several engine and stream processor classes, which simplifies the code structure without changing external behavior; the TypeScript file corrects the MergeDeep type to properly transform T; the CI workflow adds a build step to ensure dependencies are built before smoke tests run.
2. The Java changes align with 'refactor' as they restructure code for maintainability, the TypeScript change is a 'fix' as it corrects a type transformation bug, and the CI workflow modification is 'build' since it adjusts the build process for test dependencies.
3. 'refactor' is appropriate for the Java changes because no new features or bug fixes are introduced, just code cleanup; 'fix' is correct for the TypeScript type correction as it resolves a functional bug; 'build' is justified for the CI change because it alters build commands rather than CI configuration itself or test logic.
4. The assigned labels 'refactor', 'fix', and 'build' accurately represent the motivations and artifacts modified in this commit, each corresponding directly to the nature of the respective code changes."
"don't delay rendering if initialLayout is not specified
remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file
skip flaky test","diff --git a/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js b/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
index fcc4708..397e6e6 100644
--- a/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
+++ b/packages/react-native-tab-view/example/src/BottomBarIconTextExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { Animated, View, Text, Dimensions, StyleSheet } from 'react-native';
+import { Animated, View, Text, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBar } from 'react-native-tab-view';
 import { Ionicons } from '@exponent/vector-icons';
 
@@ -13,7 +13,6 @@ const styles = StyleSheet.create({
     backgroundColor: '#222',
   },
   tab: {
-    opacity: 1,
     padding: 0,
   },
   icon: {
@@ -50,11 +49,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarIconExample extends Component {
 
   static title = 'Bottom bar with indicator';
@@ -80,14 +74,16 @@ export default class TopBarIconExample extends Component {
   };
 
   _renderIndicator = (props) => {
-    const { width, position } = props;
+    const { width, opacity, position } = props;
 
-    const translateX = Animated.multiply(position, new Animated.Value(width));
+    const translateX = Animated.multiply(position, width);
 
     return (
       <Animated.View
-        style={[ styles.indicator, { width: width - 8, transform: [ { translateX } ] } ]}
-      />
+        style={[ styles.container, { width, opacity, transform: [ { translateX } ] } ]}
+      >
+        <View style={styles.indicator} />
+      </Animated.View>
     );
   };
 
@@ -146,7 +142,6 @@ export default class TopBarIconExample extends Component {
         renderScene={this._renderScene}
         renderFooter={this._renderFooter}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/CoverflowExample.js b/packages/react-native-tab-view/example/src/CoverflowExample.js
index 8950c0e..2336591 100644
--- a/packages/react-native-tab-view/example/src/CoverflowExample.js
+++ b/packages/react-native-tab-view/example/src/CoverflowExample.js
@@ -2,7 +2,7 @@
 /* eslint-disable import/no-commonjs */
 
 import React, { Component } from 'react';
-import { Animated, View, Image, Text, Dimensions, StyleSheet } from 'react-native';
+import { Animated, View, Image, Text, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabViewPagerPan } from 'react-native-tab-view';
 
 const styles = StyleSheet.create({
@@ -48,11 +48,6 @@ const ALBUMS = {
   'Lost Horizons': require('../assets/album-art-8.jpg'),
 };
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class CoverflowExample extends Component {
 
   static title = 'Coverflow';
@@ -142,7 +137,6 @@ export default class CoverflowExample extends Component {
         renderPager={this._renderPager}
         renderScene={this._renderScene}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/ScrollViewsExample.js b/packages/react-native-tab-view/example/src/ScrollViewsExample.js
index 94fefbb..5be3b69 100644
--- a/packages/react-native-tab-view/example/src/ScrollViewsExample.js
+++ b/packages/react-native-tab-view/example/src/ScrollViewsExample.js
@@ -28,11 +28,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarTextExample extends Component {
 
   static title = 'Scroll views';
@@ -104,6 +99,7 @@ export default class TopBarTextExample extends Component {
         renderLabel={this._renderLabel(props)}
         indicatorStyle={styles.indicator}
         tabStyle={styles.tab}
+        tabWidth={80}
         style={styles.tabbar}
       />
     );
@@ -130,7 +126,6 @@ export default class TopBarTextExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/TopBarIconExample.js b/packages/react-native-tab-view/example/src/TopBarIconExample.js
index d13755f..5464981 100644
--- a/packages/react-native-tab-view/example/src/TopBarIconExample.js
+++ b/packages/react-native-tab-view/example/src/TopBarIconExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { View, Dimensions, StyleSheet } from 'react-native';
+import { View, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBarTop } from 'react-native-tab-view';
 import { Ionicons } from '@exponent/vector-icons';
 
@@ -22,11 +22,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarIconExample extends Component {
 
   static title = 'Icon only top bar';
@@ -93,7 +88,6 @@ export default class TopBarIconExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/example/src/TopBarTextExample.js b/packages/react-native-tab-view/example/src/TopBarTextExample.js
index 30307ad..454533d 100644
--- a/packages/react-native-tab-view/example/src/TopBarTextExample.js
+++ b/packages/react-native-tab-view/example/src/TopBarTextExample.js
@@ -1,7 +1,7 @@
 /* @flow */
 
 import React, { Component } from 'react';
-import { View, Dimensions, StyleSheet } from 'react-native';
+import { View, StyleSheet } from 'react-native';
 import { TabViewAnimated, TabBarTop } from 'react-native-tab-view';
 
 const styles = StyleSheet.create({
@@ -25,11 +25,6 @@ const styles = StyleSheet.create({
   },
 });
 
-const initialLayout = {
-  height: 0,
-  width: Dimensions.get('window').width,
-};
-
 export default class TopBarTextExample extends Component {
 
   static title = 'Scrollable top bar';
@@ -90,7 +85,6 @@ export default class TopBarTextExample extends Component {
         renderScene={this._renderScene}
         renderHeader={this._renderHeader}
         onRequestChangeTab={this._handleChangeTab}
-        initialLayout={initialLayout}
       />
     );
   }
diff --git a/packages/react-native-tab-view/src/TabBar.js b/packages/react-native-tab-view/src/TabBar.js
index 615e85a..a03d8e5 100644
--- a/packages/react-native-tab-view/src/TabBar.js
+++ b/packages/react-native-tab-view/src/TabBar.js
@@ -92,6 +92,7 @@ type Props = SceneRendererProps & {
 
 type State = {
   offset: Animated.Value;
+  visibility: Animated.Value;
 }
 
 export default class TabBar extends Component<DefaultProps, Props, State> {
@@ -115,8 +116,15 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
 
   state: State = {
     offset: new Animated.Value(0),
+    visibility: new Animated.Value(0),
   };
 
+  componentWillMount() {
+    if (this.props.layout.width || this.props.tabWidth) {
+      this.state.visibility.setValue(1);
+    }
+  }
+
   componentDidMount() {
     this._adjustScroll(this.props.navigationState.index);
     this._positionListener = this.props.subscribe('position', this._adjustScroll);
@@ -126,6 +134,16 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
     if (this.props.navigationState !== nextProps.navigationState) {
       this._resetScrollOffset(nextProps);
     }
+
+    if (
+        (this.props.tabWidth !== nextProps.tabWidth && nextProps.tabWidth) ||
+        (this.props.layout.width !== nextProps.layout.width && nextProps.layout.width)
+     ) {
+      Animated.timing(this.state.visibility, {
+        toValue: 1,
+        duration: 150,
+      }).start();
+    }
   }
 
   componentWillUnmount() {
@@ -282,7 +300,8 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
           {this.props.renderIndicator ?
             this.props.renderIndicator({
               ...this.props,
-              width: tabWidth,
+              width: new Animated.Value(tabWidth),
+              opacity: this.state.visibility,
             }) :
             null
           }
@@ -307,10 +326,10 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
             {routes.map((route, i) => {
               const focused = index === i;
               const outputRange = inputRange.map(inputIndex => inputIndex === i ? 1 : 0.7);
-              const opacity = position.interpolate({
+              const opacity = Animated.multiply(this.state.visibility, position.interpolate({
                 inputRange,
                 outputRange,
-              });
+              }));
               const scene = {
                 route,
                 focused,
@@ -348,14 +367,14 @@ export default class TabBar extends Component<DefaultProps, Props, State> {
                   }}
                 >
                   <View style={styles.container}>
-                    <Animated.View style={[ styles.tabitem, { opacity, width: tabWidth }, tabStyle, this.props.tabStyle ]}>
+                    <Animated.View style={[ styles.tabitem, { opacity }, tabWidth ? { width: tabWidth } : null, tabStyle, this.props.tabStyle ]}>
                       {icon}
                       {label}
                     </Animated.View>
                     {badge ?
-                      <View style={styles.badge}>
+                      <Animated.View style={[ styles.badge, { opacity: this.state.visibility } ]}>
                         {badge}
-                      </View> : null
+                      </Animated.View> : null
                     }
                   </View>
                 </TouchableItem>
diff --git a/packages/react-native-tab-view/src/TabBarTop.js b/packages/react-native-tab-view/src/TabBarTop.js
index 0960d4e..84dd6e2 100644
--- a/packages/react-native-tab-view/src/TabBarTop.js
+++ b/packages/react-native-tab-view/src/TabBarTop.js
@@ -28,7 +28,8 @@ const styles = StyleSheet.create({
 });
 
 type IndicatorProps = SceneRendererProps & {
-  width: number;
+  width: Animated.Valye;
+  opacity: Animated.Value;
 }
 
 type Props = SceneRendererProps & {
@@ -50,13 +51,13 @@ export default class TabBarTop extends Component<void, Props, void> {
   );
 
   _renderIndicator = (props: IndicatorProps) => {
-    const { width, position } = props;
+    const { width, opacity, position } = props;
 
-    const translateX = Animated.multiply(position, new Animated.Value(width));
+    const translateX = Animated.multiply(position, width);
 
     return (
       <Animated.View
-        style={[ styles.indicator, { width, transform: [ { translateX } ] }, this.props.indicatorStyle ]}
+        style={[ styles.indicator, { width, opacity, transform: [ { translateX } ] }, this.props.indicatorStyle ]}
       />
     );
   };
diff --git a/packages/react-native-tab-view/src/TabViewAnimated.js b/packages/react-native-tab-view/src/TabViewAnimated.js
index d484816..4499748 100644
--- a/packages/react-native-tab-view/src/TabViewAnimated.js
+++ b/packages/react-native-tab-view/src/TabViewAnimated.js
@@ -94,19 +94,17 @@ export default class TabViewAnimated extends Component<DefaultProps, Props, Stat
   };
 
   _renderItems = (props: SceneRendererProps) => {
-    if (props.layout.width === 0) {
-      return null;
-    }
-
     const { renderPager, renderHeader, renderFooter } = this.props;
+    const { navigationState, layout } = props;
+    const currentRoute = navigationState.routes[navigationState.index];
 
     return (
       <View style={styles.container}>
         {renderHeader && renderHeader(props)}
         {renderPager({
           ...props,
-          children: props.navigationState.routes.map((route, index) => (
-            <View key={route.key} style={{ width: props.layout.width }}>
+          children: layout.width ? navigationState.routes.map((route, index) => (
+            <View key={route.key} style={{ width: layout.width }}>
               {this._renderScene({
                 ...props,
                 route,
@@ -114,7 +112,16 @@ export default class TabViewAnimated extends Component<DefaultProps, Props, Stat
                 focused: index === props.navigationState.index,
               })}
             </View>
-          )),
+          )) : (
+            <View key={currentRoute.key} style={styles.container}>
+              {this._renderScene({
+                ...props,
+                route: currentRoute,
+                index: navigationState.index,
+                focused: true,
+              })}
+            </View>
+          ),
         })}
         {renderFooter && renderFooter(props)}
       </View>

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",3,"[""e9233ae3f7811707945fc2de60971595d83c578d"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""fix"", ""build"", ""test""]","1. The commit removes the deprecated ZEEBE_HOST environment variable and unnecessary log level variable from Docker-related files, updates startup scripts to use new environment variables, modifies example and source files in the react-native-tab-view package to avoid delayed rendering if initialLayout is not specified, and skips a flaky test in browser-pool.test.ts.
2. The removal of deprecated settings and environment variables in Dockerfile and startup.sh relates to the build process, updating build configuration; changes in the react-native-tab-view files address rendering behavior, which resolves a bug (fix); skipping a flaky test is a direct modification to test logic.
3. 'build' is appropriate for Dockerfile and startup.sh as these are build system artifacts, not CI or documentation; 'fix' is appropriate for the react-native-tab-view changes as they resolve a rendering issue rather than introducing a new feature or refactoring; 'test' is correct for skipping a flaky test, as it directly alters test logic, not production code.
4. The assigned labels 'fix', 'build', and 'test' are appropriate because the commit contains a bug fix in UI rendering, build system configuration cleanup, and a test modification, each matching the label definitions and selection rules."
"do not use scripts and binaries from the libcc repo
remove sync ts check","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/config/webpack.config.prod.js b/config/webpack.config.prod.js
index 8b23fba..58a4c17 100644
--- a/config/webpack.config.prod.js
+++ b/config/webpack.config.prod.js
@@ -251,7 +251,7 @@ module.exports = {
   plugins: [
     argv.notypecheck
     ? null
-    : new ForkTsCheckerWebpackPlugin({tslint: true, async: false}),
+    : new ForkTsCheckerWebpackPlugin({tslint: true}),
     // Makes some environment variables available in index.html.
     // The public URL is available as %PUBLIC_URL% in index.html, e.g.:
     // <link rel=""shortcut icon"" href=""%PUBLIC_URL%/favicon.ico"">
",2,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""411be831591b2ea15ca9138eaf8db81f51b5101e""]","[""cicd"", ""build""]","1. The code changes update CI configuration files (.circleci/config.yml, vsts-gn.yml) to use different sccache binaries and scripts, and remove a TypeScript sync check from the webpack production config.
2. Changes to .circleci/config.yml and vsts-gn.yml directly modify CI job scripts and environment variable settings, which are classic examples of the 'cicd' label; the change in webpack.config.prod.js alters the build pipeline behavior by removing an option from ForkTsCheckerWebpackPlugin, which is a build configuration artifact.
3. 'cicd' is appropriate for the CI config file changes because they are not general build scripts but are specific to CI orchestration; 'build' is correct for the webpack config change because it affects the build system and not the core app logic, documentation, or tests. No purpose label (feat, fix, refactor) is suitable as these are not user-facing features, bugfixes, or refactors of logic.
4. The 'cicd' and 'build' labels are appropriate because the changes are strictly to CI pipeline configuration and build system configuration, respectively, without affecting application code or artifacts outside those domains."
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909
skip flaky test
spring version, core version","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",3,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""docs"", ""test"", ""build""]","1. The commit updates a Java getting started guide to show handling payloads as maps, skips a flaky test in a test file, and bumps dependency versions in build configuration files.
2. The documentation change (get-started.md) is purely instructional, aligning with 'docs'; the test file modification (test.skip) is entirely about test logic, aligning with 'test'; the pom.xml and backend/pom.xml changes update versions, which are build configuration artifacts, aligning with 'build'.
3. 'docs' is correct for the guide as it only changes documentation, not code behavior; 'test' is appropriate for the test skip since it alters test execution, not production code; 'build' is right for dependency version bumps as these are build system concerns, not CI or app logic changes.
4. Each label accurately reflects the functional role of the modified artifacts: 'docs' for documentation, 'test' for test logic, and 'build' for build configuration updates."
"rename ELECTRON_CACHE env variable to electron_config_cache (#21313)
Publish crates
fetch git history","diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7b98b44..f17ad6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,9 @@
 
 - **(css/parser)** Fix parsing of at rules (#3328) ([506a310](https://github.com/swc-project/swc/commit/506a31078aaebf50129658f096bbd5929995205f))
 
+
+- **(es/compat)** Fix regression of `destructuring` (#3326) ([6d1ad36](https://github.com/swc-project/swc/commit/6d1ad368aca53ee64a63ae565cd015909f2f4458))
+
 ### Performance
 
 
diff --git a/Cargo.lock b/Cargo.lock
index 3c6598b..4baa252 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2652,7 +2652,7 @@ dependencies = [
 
 [[package]]
 name = ""swc""
-version = ""0.116.15""
+version = ""0.116.16""
 dependencies = [
  ""ahash"",
  ""anyhow"",
@@ -3097,7 +3097,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms""
-version = ""0.113.3""
+version = ""0.113.4""
 dependencies = [
  ""pretty_assertions 0.7.2"",
  ""sourcemap"",
@@ -3157,7 +3157,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms_compat""
-version = ""0.68.2""
+version = ""0.68.3""
 dependencies = [
  ""ahash"",
  ""arrayvec 0.7.2"",
@@ -3366,7 +3366,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecmascript""
-version = ""0.110.14""
+version = ""0.110.15""
 dependencies = [
  ""swc_ecma_ast"",
  ""swc_ecma_codegen"",
diff --git a/crates/swc/Cargo.toml b/crates/swc/Cargo.toml
index 756cfc8..2f02d22 100644
--- a/crates/swc/Cargo.toml
+++ b/crates/swc/Cargo.toml
@@ -9,7 +9,7 @@ include = [""Cargo.toml"", ""src/**/*.rs""]
 license = ""Apache-2.0""
 name = ""swc""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.116.15""
+version = ""0.116.16""
 
 [lib]
 name = ""swc""
@@ -55,7 +55,7 @@ swc_ecma_loader = {version = ""0.27.0"", path = ""../swc_ecma_loader"", features = [
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env""}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", features = [
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", features = [
   ""compat"",
   ""module"",
   ""optimization"",
@@ -64,11 +64,11 @@ swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", fea
   ""typescript"",
 ]}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat""}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat""}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization""}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils""}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit""}
-swc_ecmascript = {version = ""0.110.14"", path = ""../swc_ecmascript""}
+swc_ecmascript = {version = ""0.110.15"", path = ""../swc_ecmascript""}
 swc_node_comments = {version = ""0.4.0"", path = ""../swc_node_comments""}
 swc_plugin_runner = {version = ""0.30.0"", path = ""../swc_plugin_runner"", optional = true}
 swc_visit = {version = ""0.3.0"", path = ""../swc_visit""}
diff --git a/crates/swc_ecma_transforms/Cargo.toml b/crates/swc_ecma_transforms/Cargo.toml
index 1604f4e..a0aafae 100644
--- a/crates/swc_ecma_transforms/Cargo.toml
+++ b/crates/swc_ecma_transforms/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.113.3""
+version = ""0.113.4""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -28,7 +28,7 @@ swc_common = {version = ""0.17.0"", path = ""../swc_common""}
 swc_ecma_ast = {version = ""0.65.0"", path = ""../swc_ecma_ast""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat"", optional = true}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat"", optional = true}
 swc_ecma_transforms_module = {version = ""0.74.0"", path = ""../swc_ecma_transforms_module"", optional = true}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization"", optional = true}
 swc_ecma_transforms_proposal = {version = ""0.74.0"", path = ""../swc_ecma_transforms_proposal"", optional = true}
diff --git a/crates/swc_ecma_transforms_compat/Cargo.toml b/crates/swc_ecma_transforms_compat/Cargo.toml
index 0ea6609..58374e3 100644
--- a/crates/swc_ecma_transforms_compat/Cargo.toml
+++ b/crates/swc_ecma_transforms_compat/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms_compat""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.68.2""
+version = ""0.68.3""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
diff --git a/crates/swc_ecmascript/Cargo.toml b/crates/swc_ecmascript/Cargo.toml
index 63680a0..775208a 100644
--- a/crates/swc_ecmascript/Cargo.toml
+++ b/crates/swc_ecmascript/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecmascript""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.110.14""
+version = ""0.110.15""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -39,7 +39,7 @@ swc_ecma_dep_graph = {version = ""0.58.0"", path = ""../swc_ecma_dep_graph"", option
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier"", optional = true}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser"", optional = true, default-features = false}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env"", optional = true}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", optional = true}
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", optional = true}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils"", optional = true}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit"", optional = true}
 

diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 6726e35..9114eeb 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -172,6 +172,8 @@ jobs:
 
     steps:
       - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
       - run: corepack enable
       - uses: actions/setup-node@v3
         with:
diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index aa33d76..1d1cbc9 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -18,7 +18,7 @@ async function main () {
 
   const config = await loadChangelogConfig(process.cwd())
 
-  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0', 'main']).stdout
+  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0']).stdout
 
   const commits = await getGitDiff(latestTag)
   const bumpType = determineSemverChange(parseCommits(commits, config), config)
",3,"[""f2f52c23b513dd857350f3c163f676d37189d0d3"", ""af53b9487f74ff28438928903fb1f2db93fe4fa8"", ""e11d55a4922978b89a2c50bf577124b09449e89c""]","[""docs"", ""build"", ""cicd""]","1. The changes include renaming an environment variable reference in documentation, updating changelog text, bumping crate versions and dependency versions in several Cargo.toml and Cargo.lock files, adding a fetch-depth parameter to a GitHub Actions workflow (ci.yml), and modifying a script to change a git describe command.
2. The documentation change in installation.md directly aligns with the 'docs' label, the version bumps in Cargo.toml and Cargo.lock files are classic 'build' changes affecting the build system, and the update to the GitHub Actions workflow (ci.yml) is a 'cicd' change since it modifies CI configuration.
3. The 'docs' label is appropriate as the installation.md edit is purely documentation; 'build' is correct because the Cargo.toml and Cargo.lock changes are strictly about build/dependency management, not code logic; 'cicd' is correct since only the CI workflow file is modified in that part, and not the build or application code. No single purpose label (feat, fix, refactor) is appropriate because there is no new feature, bug fix, or code restructuring.
4. The assigned labels 'docs', 'build', and 'cicd' are correct because each major change is isolated to documentation, build system/dependencies, or CI configuration, matching the object label definitions and classification rules."
"adds test for exec with http proxy

Signed-off-by: Sam Alba <samalba@users.noreply.github.com>","diff --git a/tests/tasks.bats b/tests/tasks.bats
index e3b95c4..4cfba15 100644
--- a/tests/tasks.bats
+++ b/tests/tasks.bats
@@ -101,6 +101,14 @@ setup() {
     assert_line --partial --index 9 'actions.basicTest.stop'
 }
 
+@test ""task: #Exec with HTTP proxy"" {
+    cd ./tasks/exec
+    export HTTPS_PROXY=""https://localhost:4242/""
+    run ""$DAGGER"" ""do"" -p ./http_proxy.cue curlProxy
+    assert_failure
+    unset HTTP_PROXY
+}
+
 @test ""task: #Start #Stop params"" {
     cd ./tasks/exec
     ""$DAGGER"" ""do"" -p ./start_stop_exec.cue execParamsTest
@@ -297,4 +305,4 @@ setup() {
 
 @test ""task: #Rm"" {
     ""$DAGGER"" ""do"" -p ./tasks/rm/rm.cue test
-}
\ No newline at end of file
+}
diff --git a/tests/tasks/exec/http_proxy.cue b/tests/tasks/exec/http_proxy.cue
new file mode 100644
index 0000000..05de4b9
--- /dev/null
+++ b/tests/tasks/exec/http_proxy.cue
@@ -0,0 +1,25 @@
+package main
+
+import (
+	""dagger.io/dagger""
+	""dagger.io/dagger/core""
+)
+
+dagger.#Plan & {
+	actions: {
+		image: core.#Pull & {
+			source: ""alpine:3.15.0@sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3""
+		}
+
+		curlProxy: core.#Exec & {
+			input: image.output
+			args: [
+				""sh"", ""-c"",
+				""""""
+					apk add --no-cache curl
+					curl -sfL -o /dev/null https://www.google.com/
+					"""""",
+			]
+		}
+	}
+}
",1,"[""6c7398993bc567ec84e4573b6ededbf50b1ef606""]","[""test""]","1. The changes add a new test case in 'tests/tasks.bats' that verifies task execution with an HTTP proxy, and introduce a supporting test definition file 'http_proxy.cue'.
2. These modifications are entirely focused on expanding the test suite by adding a new test and its configuration, which aligns directly with the 'test' label as it signifies changes dedicated to tests.
3. The 'test' label is appropriate because all changes are additions to test files and logic; no production code, documentation, CI/CD, or build system files are affected, ruling out 'feat', 'fix', 'refactor', 'docs', 'cicd', or 'build'.
4. The 'test' label correctly captures that the commit is solely about introducing new test coverage for HTTP proxy execution behavior."
restructure ClusterTopology to track completed change,"diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",1,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""refactor""]","1. The code changes restructure how cluster topology changes and completed changes are tracked, refactoring the data model (e.g., moving from nested optional fields to explicit records), updating serialization logic, and cleaning up related methods and usages throughout several classes.
2. These changes align with the 'refactor' label as they modify the internal structure and design for clarity, maintainability, and separation of concerns, without introducing new features or fixing a specific bug.
3. 'refactor' is appropriate because the changes do not add new functionality (not 'feat'), do not address a bug (not 'fix'), and are not solely limited to documentation, tests, CI/CD, or build artifacts (so not 'docs', 'test', 'cicd', or 'build').
4. The 'refactor' label is justified as all modifications are aimed at improving code structure and maintainability, with no change to external behavior or addition of new capabilities."
"removing automatic page push on nav
fix pagination spacing
remove members that are left from ClusterTopology when last change is applied

When the change is applied, the member is marked as LEFT. It is removed from the
ClusterTopology when all changes in the ClusterChangePlan is completed.","diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage

diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 22d36a2..40f7130 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -399,7 +399,7 @@ export function Base({ children, headings }: BaseProps) {
                     >
                       <a className=""flex items-center space-x-4 group"">
                         <ArrowLeftIcon className=""h-4 transition-transform duration-100 ease-in-out transform group-hover:-translate-x-1"" />
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Previous
                           </span>
@@ -418,7 +418,7 @@ export function Base({ children, headings }: BaseProps) {
                       aria-label={`Go to ${next.resource?.label}`}
                     >
                       <a className=""flex items-center space-x-4 group"">
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Next
                           </span>

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index e5a111d..8ccd410 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -171,7 +171,31 @@ public record ClusterTopology(
   }
 
   private ClusterTopology advance() {
-    return new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    if (!result.hasPendingChanges()) {
+      // The last change has been applied. Clean up the members that are marked as LEFT in the
+      // topology. This operation will be executed in the member that executes the last operation.
+      // This is ok because it is guaranteed that no other concurrent modification will be applied
+      // to the topology. This is because all the operations are applied sequentially, and no
+      // topology update will be done without adding a ClusterChangePlan.
+      return result.gc();
+    }
+    return result;
+  }
+
+  private ClusterTopology gc() {
+    if (hasPendingChanges()) {
+      throw new IllegalStateException(
+          ""Expected to remove members that are left from the topology, but there are pending changes ""
+              + changes);
+    }
+    // remove members that are marked as LEFT
+    final var currentMembers =
+        members().entrySet().stream()
+            .filter(entry -> entry.getValue().state() != State.LEFT)
+            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
+    // Increment the version so that other members can merge by overwriting their local topology.
+    return new ClusterTopology(version + 1, currentMembers, changes);
   }
 
   public boolean hasMember(final MemberId memberId) {
",3,"[""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97"", ""1e05a24486f15889ddf6bf1c711ea2bbffc1a88e"", ""4bfbf60653068ef17df98c021134692bd6d02939""]","[""test"", ""fix"", ""refactor""]","1. The commit removes an automatic navigation push in a test file, fixes CSS spacing for pagination in a layout file, and updates cluster topology logic to remove 'LEFT' members after changes are applied.
2. Removing the navigation push in the test file is an update to test logic, which aligns with the 'test' object label; the CSS spacing fix in the layout directly addresses a UI bug, which fits the 'fix' purpose label; the cluster topology update restructures logic for member removal without altering external behavior, which matches the 'refactor' label.
3. 'test' is appropriate for the test file change as it only affects test logic, not production code; 'fix' is suitable for the pagination spacing adjustment since it resolves a UI issue, not introducing new features or merely restructuring; 'refactor' applies to the topology modification because it improves internal handling of member removal without changing observable functionality, and is not a bug fix or new feature.
4. The assigned labels 'test', 'fix', and 'refactor' accurately represent the distinct motivations and artifacts affected in this commit according to the classification rules."
"selenium java 4.8.1
add test for clickhouse-specific `create_table` parameters","diff --git a/pom.xml b/pom.xml
index f792f3c..477224a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -60,8 +60,8 @@
         <codehaus-groovy.version>3.0.11</codehaus-groovy.version>
         <jython.version>2.7.0</jython.version>
         <docker-java.version>3.2.14</docker-java.version>
-        <selenium.version>4.8.0</selenium.version>
-        <jmeter-plugins-webdriver.version>4.8.0</jmeter-plugins-webdriver.version>
+        <selenium.version>4.8.1</selenium.version>
+        <jmeter-plugins-webdriver.version>4.8.1</jmeter-plugins-webdriver.version>
         <opentelemetry.version>1.22.0</opentelemetry.version>
         <oracle-database.version>19.7.0.0</oracle-database.version>
         <zookeeper.version>3.8.0</zookeeper.version>

diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 678683d..c4e2aec 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -224,6 +224,21 @@ def test_create_table_data(con, data, engine, temp_table):
     assert len(t.execute()) == 3
 
 
+def test_create_table_with_properties(con, temp_table):
+    data = pd.DataFrame({""a"": list(""abcde"" * 20), ""b"": [1, 2, 3, 4, 5] * 20})
+    n = len(data)
+    t = con.create_table(
+        temp_table,
+        data,
+        schema=ibis.schema(dict(a=""string"", b=""!uint32"")),
+        order_by=[""a"", ""b""],
+        partition_by=[""a""],
+        sample_by=[""b""],
+        settings={""allow_nullable_key"": ""1""},
+    )
+    assert t.count().execute() == n
+
+
 @pytest.mark.parametrize(
     ""engine"",
     [
",2,"[""66f907f2d6ff0956bb5215518678bc79cab83c17"", ""7e1ece7d3fd41d1e3ee38e479c119494bb269966""]","[""build"", ""test""]","1. The commit updates the Selenium and JMeter WebDriver plugin versions in the Maven build configuration (pom.xml) and adds a new test function for ClickHouse-specific create_table parameters in a test file.
2. Updating dependency versions in pom.xml aligns with the 'build' label, as it affects the build system; adding a new test aligns with the 'test' label, as it is entirely scoped to test logic.
3. 'build' is more appropriate than 'cicd' or 'feat' because the change is strictly about dependency management, not CI config or feature development; 'test' is correct since the code unit is dedicated to a new test case, not a fix or refactor of existing test logic.
4. The 'build' and 'test' labels are appropriate because the commit is split between updating build dependencies and adding new test coverage, each mapping directly to their respective object label definitions."
"add unit test for query API
update dependencies
Template using kube api version

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
index 2d2d084..38261ad 100644
--- a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
@@ -25,6 +25,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 
 public final class StubbedBrokerClient implements BrokerClient {
@@ -67,7 +68,15 @@ public final class StubbedBrokerClient implements BrokerClient {
   @Override
   public <T> CompletableFuture<BrokerResponse<T>> sendRequestWithRetry(
       final BrokerRequest<T> request, final Duration requestTimeout) {
-    throw new UnsupportedOperationException(""not implemented"");
+    final CompletableFuture<BrokerResponse<T>> result = new CompletableFuture<>();
+
+    sendRequestWithRetry(
+        request,
+        (key, response) ->
+            result.complete(new BrokerResponse<>(response, Protocol.decodePartitionId(key), key)),
+        result::completeExceptionally);
+
+    return result.orTimeout(requestTimeout.toNanos(), TimeUnit.NANOSECONDS);
   }
 
   @Override
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
new file mode 100644
index 0000000..ec9ec80
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
@@ -0,0 +1,91 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+import io.camunda.zeebe.gateway.api.util.GatewayTest;
+import io.camunda.zeebe.gateway.cmd.BrokerErrorException;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerError;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerErrorResponse;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.QueryApiImpl;
+import io.camunda.zeebe.protocol.Protocol;
+import io.camunda.zeebe.protocol.record.ErrorCode;
+import java.time.Duration;
+import java.util.concurrent.CompletionStage;
+import java.util.concurrent.ExecutionException;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+import org.junit.runners.Parameterized.Parameter;
+import org.junit.runners.Parameterized.Parameters;
+
+@RunWith(Parameterized.class)
+public final class QueryApiTest extends GatewayTest {
+  @Parameter(0)
+  public String name;
+
+  @Parameter(1)
+  public Querier querier;
+
+  @Parameters(name = ""{index}: {0}"")
+  public static Object[][] queries() {
+    return new Object[][] {
+      new Object[] {""getBpmnProcessIdForProcess"", (Querier) QueryApi::getBpmnProcessIdFromProcess},
+      new Object[] {
+        ""getBpmnProcessIdForProcessInstance"",
+        (Querier) QueryApi::getBpmnProcessIdFromProcessInstance
+      },
+      new Object[] {""getBpmnProcessIdForProcessJob"", (Querier) QueryApi::getBpmnProcessIdFromJob},
+    };
+  }
+
+  @Test
+  public void shouldGetBpmnProcessId() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub = new QueryStub(new BrokerResponse<>(""myProcess"", 1, 1));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result).succeedsWithin(timeout).isEqualTo(""myProcess"");
+  }
+
+  @Test
+  public void shouldCompleteExceptionallyOnError() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub =
+        new QueryStub(
+            new BrokerErrorResponse<>(
+                new BrokerError(ErrorCode.PARTITION_LEADER_MISMATCH, ""Leader mismatch"")));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result)
+        .failsWithin(timeout)
+        .withThrowableOfType(ExecutionException.class)
+        .havingRootCause()
+        .isInstanceOf(BrokerErrorException.class);
+  }
+
+  private interface Querier {
+    CompletionStage<String> query(final QueryApi api, final long key, final Duration timeout);
+  }
+}
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
new file mode 100644
index 0000000..2f8334e
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient;
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient.RequestStub;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.BrokerExecuteQuery;
+
+final class QueryStub implements RequestStub<BrokerExecuteQuery, BrokerResponse<String>> {
+  private final BrokerResponse<String> response;
+
+  public QueryStub(final BrokerResponse<String> response) {
+    this.response = response;
+  }
+
+  @Override
+  public void registerWith(final StubbedBrokerClient gateway) {
+    gateway.registerHandler(BrokerExecuteQuery.class, this);
+  }
+
+  @Override
+  public BrokerResponse<String> handle(final BrokerExecuteQuery request) throws Exception {
+    return response;
+  }
+}

diff --git a/example/exp.json b/example/exp.json
index ea820f9..b838093 100644
--- a/example/exp.json
+++ b/example/exp.json
@@ -1,8 +1,8 @@
 {
-  ""name"": ""react-native-paper-example"",
+  ""name"": ""React Native Paper Example"",
   ""description"": ""Example for React Native Paper"",
   ""slug"": ""react-native-paper-example"",
-  ""sdkVersion"": ""10.0.0"",
+  ""sdkVersion"": ""11.0.0"",
   ""version"": ""1.0.0"",
   ""orientation"": ""portrait"",
   ""primaryColor"": ""#cccccc"",
diff --git a/example/package.json b/example/package.json
index c4d049a..7e2baeb 100644
--- a/example/package.json
+++ b/example/package.json
@@ -6,10 +6,10 @@
   ""private"": true,
   ""main"": ""main.js"",
   ""dependencies"": {
-    ""@exponent/ex-navigation"": ""^1.7.0"",
-    ""exponent"": ""^10.0.4"",
+    ""@exponent/ex-navigation"": ""^2.0.0"",
+    ""exponent"": ""^11.0.2"",
     ""react"": ""~15.3.2"",
-    ""react-native"": ""github:exponentjs/react-native#sdk-10.1.2"",
+    ""react-native"": ""github:exponentjs/react-native#sdk-11.0.3"",
     ""react-native-paper"": ""file:../"",
     ""react-native-vector-icons"": ""git+https://github.com/exponentjs/react-native-vector-icons.git""
   }
diff --git a/package.json b/package.json
index 65afbbc..326ab48 100644
--- a/package.json
+++ b/package.json
@@ -27,17 +27,17 @@
     ""react-native-vector-icons"": ""*""
   },
   ""devDependencies"": {
-    ""babel-eslint"": ""^7.0.0"",
-    ""eslint"": ""^3.8.1"",
+    ""babel-eslint"": ""^7.1.0"",
+    ""eslint"": ""^3.9.1"",
     ""eslint-plugin-babel"": ""^3.3.0"",
-    ""eslint-plugin-import"": ""^2.0.1"",
-    ""eslint-plugin-react"": ""^6.4.1"",
+    ""eslint-plugin-import"": ""^2.2.0"",
+    ""eslint-plugin-react"": ""^6.6.0"",
     ""eslint-plugin-react-native"": ""^2.0.0"",
     ""flow-bin"": ""^0.32.0"",
     ""react"": ""latest"",
     ""react-native"": ""latest""
   },
   ""dependencies"": {
-    ""color"": ""^0.11.3""
+    ""color"": ""^0.11.4""
   }
 }

diff --git a/.github/workflows/api-ee.yaml b/.github/workflows/api-ee.yaml
index c014f34..2a12e0d 100644
--- a/.github/workflows/api-ee.yaml
+++ b/.github/workflows/api-ee.yaml
@@ -8,7 +8,7 @@ on:
         default: 'false'
   push:
     branches:
-      - dev
+      - test_ci
     paths:
       - ee/api/**
       - api/**
@@ -112,7 +112,8 @@ jobs:
         # Deploy command
         kubectl config set-context --namespace=app --current
         kubectl config get-contexts
-        helm template openreplay -n app openreplay -f vars.yaml -f /tmp/image_override.yaml --set ingress-nginx.enabled=false --set skipMigration=true --no-hooks | kubectl apply -f -
+        k_version=$(kubectl version --short 2>/dev/null | awk '/Server/{print $NF}')
+        helm template openreplay -n app openreplay -f vars.yaml -f /tmp/image_override.yaml --set ingress-nginx.enabled=false --set skipMigration=true --no-hooks --kube-version=$k_version | kubectl apply -f -
       env:
         DOCKER_REPO: ${{ secrets.EE_REGISTRY_URL }}
         # We're not passing -ee flag, because helm will add that.
",3,"[""bed86aeae8dad2dd6371635cd24bf8ef3db80361"", ""ecc481f9f501aa34b41e06e7bbdde6e79f8ca1bb"", ""c3531347fe5a4cc82d426db195026a5bdad15e7a""]","[""test"", ""build"", ""cicd""]","1. The commit adds new unit test files (QueryApiTest.java, QueryStub.java) and test logic to the Java test directory, updates dependency versions in multiple package.json files, and modifies a GitHub Actions workflow script to use a dynamic Kubernetes API version.
2. The test files are dedicated entirely to testing logic, aligning with the 'test' object label; the package.json and exp.json changes update dependencies, matching the 'build' object label; the workflow YAML change is a CI script adjustment, which fits the 'cicd' object label.
3. 'test' is appropriate for the new test files because they are purely for testing, not fixing or refactoring code logic; 'build' is correct for dependency version bumps, as these affect the build system and not CI configuration or code logic; 'cicd' is right for the workflow file change, as it modifies CI/CD script logic, not affecting build or code/test files.
4. The assigned labels 'test', 'build', and 'cicd' are appropriate because each code unit is fully dedicated to its respective artifact category, with no overlap or misalignment with purpose-based labels."
"add unit test for query API
remove appear css animation","diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
index 2d2d084..38261ad 100644
--- a/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/api/util/StubbedBrokerClient.java
@@ -25,6 +25,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 
 public final class StubbedBrokerClient implements BrokerClient {
@@ -67,7 +68,15 @@ public final class StubbedBrokerClient implements BrokerClient {
   @Override
   public <T> CompletableFuture<BrokerResponse<T>> sendRequestWithRetry(
       final BrokerRequest<T> request, final Duration requestTimeout) {
-    throw new UnsupportedOperationException(""not implemented"");
+    final CompletableFuture<BrokerResponse<T>> result = new CompletableFuture<>();
+
+    sendRequestWithRetry(
+        request,
+        (key, response) ->
+            result.complete(new BrokerResponse<>(response, Protocol.decodePartitionId(key), key)),
+        result::completeExceptionally);
+
+    return result.orTimeout(requestTimeout.toNanos(), TimeUnit.NANOSECONDS);
   }
 
   @Override
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
new file mode 100644
index 0000000..ec9ec80
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryApiTest.java
@@ -0,0 +1,91 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+import io.camunda.zeebe.gateway.api.util.GatewayTest;
+import io.camunda.zeebe.gateway.cmd.BrokerErrorException;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerError;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerErrorResponse;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.QueryApiImpl;
+import io.camunda.zeebe.protocol.Protocol;
+import io.camunda.zeebe.protocol.record.ErrorCode;
+import java.time.Duration;
+import java.util.concurrent.CompletionStage;
+import java.util.concurrent.ExecutionException;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+import org.junit.runners.Parameterized.Parameter;
+import org.junit.runners.Parameterized.Parameters;
+
+@RunWith(Parameterized.class)
+public final class QueryApiTest extends GatewayTest {
+  @Parameter(0)
+  public String name;
+
+  @Parameter(1)
+  public Querier querier;
+
+  @Parameters(name = ""{index}: {0}"")
+  public static Object[][] queries() {
+    return new Object[][] {
+      new Object[] {""getBpmnProcessIdForProcess"", (Querier) QueryApi::getBpmnProcessIdFromProcess},
+      new Object[] {
+        ""getBpmnProcessIdForProcessInstance"",
+        (Querier) QueryApi::getBpmnProcessIdFromProcessInstance
+      },
+      new Object[] {""getBpmnProcessIdForProcessJob"", (Querier) QueryApi::getBpmnProcessIdFromJob},
+    };
+  }
+
+  @Test
+  public void shouldGetBpmnProcessId() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub = new QueryStub(new BrokerResponse<>(""myProcess"", 1, 1));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result).succeedsWithin(timeout).isEqualTo(""myProcess"");
+  }
+
+  @Test
+  public void shouldCompleteExceptionallyOnError() {
+    // given
+    final var key = Protocol.encodePartitionId(1, 1);
+    final var api = new QueryApiImpl(brokerClient);
+    final var timeout = Duration.ofSeconds(5);
+    final var stub =
+        new QueryStub(
+            new BrokerErrorResponse<>(
+                new BrokerError(ErrorCode.PARTITION_LEADER_MISMATCH, ""Leader mismatch"")));
+    stub.registerWith(brokerClient);
+
+    // when
+    final var result = querier.query(api, key, timeout);
+
+    // then
+    assertThat(result)
+        .failsWithin(timeout)
+        .withThrowableOfType(ExecutionException.class)
+        .havingRootCause()
+        .isInstanceOf(BrokerErrorException.class);
+  }
+
+  private interface Querier {
+    CompletionStage<String> query(final QueryApi api, final long key, final Duration timeout);
+  }
+}
diff --git a/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
new file mode 100644
index 0000000..2f8334e
--- /dev/null
+++ b/gateway/src/test/java/io/camunda/zeebe/gateway/query/QueryStub.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.gateway.query;
+
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient;
+import io.camunda.zeebe.gateway.api.util.StubbedBrokerClient.RequestStub;
+import io.camunda.zeebe.gateway.impl.broker.response.BrokerResponse;
+import io.camunda.zeebe.gateway.query.impl.BrokerExecuteQuery;
+
+final class QueryStub implements RequestStub<BrokerExecuteQuery, BrokerResponse<String>> {
+  private final BrokerResponse<String> response;
+
+  public QueryStub(final BrokerResponse<String> response) {
+    this.response = response;
+  }
+
+  @Override
+  public void registerWith(final StubbedBrokerClient gateway) {
+    gateway.registerHandler(BrokerExecuteQuery.class, this);
+  }
+
+  @Override
+  public BrokerResponse<String> handle(final BrokerExecuteQuery request) throws Exception {
+    return response;
+  }
+}

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter
",2,"[""bed86aeae8dad2dd6371635cd24bf8ef3db80361"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b""]","[""test"", ""refactor""]","1. The commit introduces two new test files (`QueryApiTest.java` and `QueryStub.java`) and updates a test utility (`StubbedBrokerClient.java`) to support testing, while also removing an 'appear' CSS animation prop in a React component (`Popup.tsx`).
2. The addition of new test files and supporting test logic directly aligns with the 'test' object label, as these files are dedicated to test logic; the removal of the animation prop in `Popup.tsx` is a structural change that does not affect behavior, fitting the 'refactor' purpose label.
3. 'test' is appropriate for the new and modified test-related files since their changes are entirely scoped to testing artifacts; 'refactor' is correct for the UI change, as it cleans up code without altering external behavior—neither 'fix' nor 'feat' are appropriate since no new feature is added and no bug is being fixed.
4. The assigned labels 'test' and 'refactor' accurately represent the addition of test logic and the non-behavioral code cleanup, respectively, matching the classification instructions."
"exception for non-executable processes

related to #36
restructure ClusterTopology to track completed change
fix cypress on windows","diff --git a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
index 3c68047..4668708 100644
--- a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
+++ b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
@@ -80,4 +80,22 @@ public class DeployBpmnResourceTest
             .execute();
     }
 
+    @Test
+    public void shouldNotDeployNonExecutableModel()
+    {
+        // given
+        final TngpClient client = clientRule.getClient();
+        final WorkflowsClient workflowService = client.workflows();
+
+        // then
+        exception.expect(BrokerRequestException.class);
+        exception.expectMessage(containsString(""ERROR 203""));
+        exception.expect(BrokerRequestExceptionMatcher.brokerException(1, 1));
+
+        // when
+        workflowService.deploy()
+            .bpmnModelInstance(Bpmn.createProcess().startEvent().endEvent().done())
+            .execute();
+    }
+
 }

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
index 22851fb..c9296fe 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
@@ -77,7 +77,7 @@ describe('Cypress builder', () => {
     await run.result;
     await run.stop();
     expect(fork).toHaveBeenCalledWith(
-      '/root/node_modules/.bin/tsc',
+      '/root/node_modules/typescript/bin/tsc',
       ['-p', '/root/apps/my-app-e2e/tsconfig.json'],
       { stdio: [0, 1, 2, 'ipc'] }
     );
diff --git a/packages/cypress/src/builders/cypress/cypress.impl.ts b/packages/cypress/src/builders/cypress/cypress.impl.ts
index 9d9ded3..d3917c2 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.ts
@@ -115,7 +115,7 @@ function compileTypescriptFiles(
       let args = ['-p', path.join(context.workspaceRoot, tsConfigPath)];
       const tscPath = path.join(
         context.workspaceRoot,
-        '/node_modules/.bin/tsc'
+        '/node_modules/typescript/bin/tsc'
       );
       if (isWatching) {
         args.push('--watch');
",3,"[""21c004b3c40bd3d68f0d32d173a29632765666c8"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""eebee9ab0bb6d4255ad0402d8422364e96bfef61""]","[""test"", ""refactor"", ""fix""]","1. The changes in 'DeployBpmnResourceTest.java' add a new test method to verify that non-executable BPMN models are not deployed, which is a test logic addition.
2. The modifications in the topology modules ('ClusterTopology', 'ClusterChangePlan', 'ProtoBufSerializer', etc.) restructure how cluster topology changes and completed changes are tracked, including new record types and method refactoring, which is a structural improvement without changing external behavior.
3. The updates in 'cypress.impl.spec.ts' and 'cypress.impl.ts' adjust the path for the TypeScript compiler to fix compatibility with Windows, resolving a specific bug.
4. The 'test' label is appropriate for the new test logic; 'refactor' is appropriate for the non-behavioral, structural improvements to topology tracking; 'fix' is appropriate for the Cypress builder path change that resolves a Windows-specific issue, and alternative labels do not fit as these changes are not new features, documentation, or build/CI-specific.
5. Therefore, the unique set of labels 'test', 'refactor', and 'fix' correctly captures the behavioral intent and artifact focus of each code unit in this commit."
"update CI images from docker buster to bullseye

This will break `perf_image` until the new CI image is built due to the
newly required `--all-tags` parameter to `docker push` that isn't
available for the docker version we run on buster.
stop playing audio on panel close

Closes #824","diff --git a/.circleci/config.yml b/.circleci/config.yml
index f8a53ba..c378c7e 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -336,7 +336,7 @@ jobs:
           # Disabling for now, and tracked further investigations
           # in https://github.com/influxdata/k8s-idpe/issues/3038
           docker_layer_caching: false
-          version: 19.03.14
+          version: 20.10.7
       - run: |
           sudo apt-get update
           sudo apt-get install -y docker.io
@@ -355,7 +355,7 @@ jobs:
           BRANCH=$(git rev-parse --abbrev-ref HEAD | tr '/' '.')
           COMMIT_SHA=$(git rev-parse --short HEAD)
           docker build -t quay.io/influxdb/iox:$COMMIT_SHA -t quay.io/influxdb/iox:main -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/iox
+          docker push --all-tags quay.io/influxdb/iox
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags
diff --git a/Dockerfile b/Dockerfile
index 8c23ea2..1df1fd2 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -17,7 +17,7 @@ RUN \
   cp /influxdb_iox/target/release/influxdb_iox /root/influxdb_iox && \
   du -cshx /usr/local/cargo/registry /usr/local/cargo/git /influxdb_iox/target
 
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
     && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates --no-install-recommends \
diff --git a/docker/Dockerfile.ci b/docker/Dockerfile.ci
index db0a8ca..cf9cd15 100644
--- a/docker/Dockerfile.ci
+++ b/docker/Dockerfile.ci
@@ -12,7 +12,7 @@
 
 ARG RUST_VERSION
 # Build actual image used for CI pipeline
-FROM rust:${RUST_VERSION}-slim-buster
+FROM rust:${RUST_VERSION}-slim-bullseye
 
 # When https://github.com/rust-lang/rustup/issues/2686 is fixed, run the command added that
 # will install everything in rust-toolchain.toml here so that components are in the container
@@ -42,7 +42,7 @@ COPY docker/redpanda.gpg /tmp/redpanda.gpg
 # Generated from https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/cfg/setup/bash.deb.sh
 RUN apt-key add /tmp/redpanda.gpg \
     && rm /tmp/redpanda.gpg \
-    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=buster&version=10&arch=x86_64"" \
+    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=bullseye&version=10&arch=x86_64"" \
       > /etc/apt/sources.list.d/vectorized-redpanda.list \
     && apt-get update \
     && apt-get install -y redpanda \
diff --git a/docker/Dockerfile.iox b/docker/Dockerfile.iox
index 42414db..ae1f38e 100644
--- a/docker/Dockerfile.iox
+++ b/docker/Dockerfile.iox
@@ -1,7 +1,7 @@
 ###
 # Dockerfile used for deploying IOx
 ##
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
   && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates gettext-base --no-install-recommends \

diff --git a/src/background/audio-manager.ts b/src/background/audio-manager.ts
index 84032f1..9e116fc 100644
--- a/src/background/audio-manager.ts
+++ b/src/background/audio-manager.ts
@@ -1,4 +1,4 @@
-import { timeout } from '@/_helpers/promise-more'
+import { timer } from '@/_helpers/promise-more'
 
 /**
  * To make sure only one audio plays at a time
@@ -16,6 +16,8 @@ export class AudioManager {
 
   private audio?: HTMLAudioElement
 
+  currentSrc?: string
+
   reset() {
     if (this.audio) {
       this.audio.pause()
@@ -23,28 +25,33 @@ export class AudioManager {
       this.audio.src = ''
       this.audio.onended = null
     }
+    this.currentSrc = ''
   }
 
   load(src: string): HTMLAudioElement {
     this.reset()
+    this.currentSrc = src
     return (this.audio = new Audio(src))
   }
 
   async play(src?: string): Promise<void> {
-    if (!src) {
+    if (!src || src === this.currentSrc) {
       this.reset()
       return
     }
 
     const audio = this.load(src)
 
-    const onEnd = new Promise(resolve => {
-      audio.onended = resolve
-    })
+    const onEnd = Promise.race([
+      new Promise(resolve => {
+        audio.onended = resolve
+      }),
+      timer(20000)
+    ])
+
+    await audio.play()
+    await onEnd
 
-    await audio
-      .play()
-      .then(() => timeout(onEnd, 4000))
-      .catch(() => {})
+    this.currentSrc = ''
   }
 }
diff --git a/src/background/server.ts b/src/background/server.ts
index 65f6f6c..4c70196 100644
--- a/src/background/server.ts
+++ b/src/background/server.ts
@@ -64,6 +64,9 @@ export class BackgroundServer {
           return openURL(msg.payload.url, msg.payload.self)
         case 'PLAY_AUDIO':
           return AudioManager.getInstance().play(msg.payload)
+        case 'STOP_AUDIO':
+          AudioManager.getInstance().reset()
+          return
         case 'FETCH_DICT_RESULT':
           return this.fetchDictResult(msg.payload)
         case 'DICT_ENGINE_METHOD':
@@ -79,6 +82,7 @@ export class BackgroundServer {
         case 'OPEN_QS_PANEL':
           return this.openQSPanel()
         case 'CLOSE_QS_PANEL':
+          AudioManager.getInstance().reset()
           return this.qsPanelManager.destroy()
         case 'QS_SWITCH_SIDEBAR':
           return this.qsPanelManager.toggleSidebar(msg.payload)
@@ -105,6 +109,16 @@ export class BackgroundServer {
           return this.youdaoTranslateAjax(msg.payload)
       }
     })
+
+    browser.runtime.onConnect.addListener(port => {
+      if (port.name === 'popup') {
+        // This is a workaround for browser action page
+        // which does not fire beforeunload event
+        port.onDisconnect.addListener(() => {
+          AudioManager.getInstance().reset()
+        })
+      }
+    })
   }
 
   async openQSPanel(): Promise<void> {
diff --git a/src/content/redux/epics/index.ts b/src/content/redux/epics/index.ts
index b941c07..587b54d 100644
--- a/src/content/redux/epics/index.ts
+++ b/src/content/redux/epics/index.ts
@@ -1,6 +1,6 @@
 import { combineEpics } from 'redux-observable'
 import { from, of, EMPTY } from 'rxjs'
-import { map, mapTo, mergeMap, filter } from 'rxjs/operators'
+import { map, mapTo, mergeMap, filter, pairwise } from 'rxjs/operators'
 
 import { isPopupPage, isStandalonePage } from '@/_helpers/saladict'
 import { saveWord } from '@/_helpers/record-manager'
@@ -11,6 +11,7 @@ import { ofType } from './utils'
 import searchStartEpic from './searchStart.epic'
 import newSelectionEpic from './newSelection.epic'
 import { translateCtxs, genCtxText } from '@/_helpers/translateCtx'
+import { message } from '@/_helpers/browser-api'
 
 export const epics = combineEpics<StoreAction, StoreAction, StoreState>(
   /** Start searching text. This will also send to Redux. */
@@ -28,6 +29,17 @@ export const epics = combineEpics<StoreAction, StoreAction, StoreState>(
       )
     ),
   (action$, state$) =>
+    state$.pipe(
+      map(state => state.isShowDictPanel),
+      pairwise(),
+      mergeMap(([oldShow, newShow]) => {
+        if (oldShow && !newShow) {
+          message.send({ type: 'STOP_AUDIO' })
+        }
+        return EMPTY
+      })
+    ),
+  (action$, state$) =>
     action$.pipe(
       ofType('ADD_TO_NOTEBOOK'),
       mergeMap(() => {
diff --git a/src/popup/index.tsx b/src/popup/index.tsx
index cbca1c0..a406bfd 100644
--- a/src/popup/index.tsx
+++ b/src/popup/index.tsx
@@ -21,6 +21,10 @@ import Popup from './Popup'
 import Notebook from './Notebook'
 import './_style.scss'
 
+// This is a workaround for browser action page
+// which does not fire beforeunload event
+browser.runtime.connect({ name: 'popup' } as any) // wrong typing
+
 const Title: FC = () => {
   const { t } = useTranslate('popup')
   return (
diff --git a/src/typings/message.ts b/src/typings/message.ts
index bdd6fad..63238cb 100644
--- a/src/typings/message.ts
+++ b/src/typings/message.ts
@@ -146,6 +146,8 @@ export type MessageConfig = MessageConfigType<{
     payload: string
   }
 
+  STOP_AUDIO: {}
+
   LAST_PLAY_AUDIO: {
     response?: null | { src: string; timestamp: number }
   }
",2,"[""640cd88df3069a97d8244398414338dd317c5470"", ""97cabf49e7aca7754edde247003fbcb4ea42dd59""]","[""cicd"", ""fix""]","1. The commit updates CI configuration files and Dockerfiles to use newer base images (buster to bullseye), updates the CI Docker version, and modifies the push command; it also changes application code to stop audio playback when panels close or popups disconnect, and adds a new STOP_AUDIO message type.
2. The CI and Dockerfile changes align with the 'cicd' label as they are entirely scoped to CI/CD infrastructure and image configuration; the application code changes address a bug where audio continues playing after panels close, which matches the 'fix' label for resolving faulty behavior.
3. 'cicd' is appropriate for the CI and Dockerfile changes because these files are dedicated CI/CD artifacts, not general build scripts; 'fix' is correct for the code changes as they directly resolve an undesired user-facing bug rather than adding new features ('feat') or just restructuring code ('refactor').
4. The 'cicd' label accurately reflects the CI/CD image and config updates, while 'fix' is appropriate for the bug fix ensuring audio stops as expected in the application."
"verify checkpoint listeners are notified
fix pagination spacing
post installers compatiblity with Windows #2520","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 22d36a2..40f7130 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -399,7 +399,7 @@ export function Base({ children, headings }: BaseProps) {
                     >
                       <a className=""flex items-center space-x-4 group"">
                         <ArrowLeftIcon className=""h-4 transition-transform duration-100 ease-in-out transform group-hover:-translate-x-1"" />
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Previous
                           </span>
@@ -418,7 +418,7 @@ export function Base({ children, headings }: BaseProps) {
                       aria-label={`Go to ${next.resource?.label}`}
                     >
                       <a className=""flex items-center space-x-4 group"">
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Next
                           </span>

diff --git a/packages/cubejs-databricks-jdbc-driver/package.json b/packages/cubejs-databricks-jdbc-driver/package.json
index cc164f0..fd7ad45 100644
--- a/packages/cubejs-databricks-jdbc-driver/package.json
+++ b/packages/cubejs-databricks-jdbc-driver/package.json
@@ -14,13 +14,16 @@
   },
   ""main"": ""dist/src/index.js"",
   ""typings"": ""dist/src/index.d.ts"",
+  ""bin"": {
+    ""databricks-jdbc-installer"": ""bin/post-install""
+  },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
     ""tsc"": ""tsc"",
     ""watch"": ""tsc -w"",
     ""lint"": ""eslint src/* --ext .ts"",
     ""lint:fix"": ""eslint --fix src/* --ext .ts"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""databricks-jdbc-installer""
   },
   ""files"": [
     ""README.md"",
diff --git a/rust/package.json b/rust/package.json
index b139279..5bf6446 100644
--- a/rust/package.json
+++ b/rust/package.json
@@ -8,7 +8,8 @@
     ""node"": "">=10.8.0""
   },
   ""bin"": {
-    ""cubestore-dev"": ""bin/cubestore-dev""
+    ""cubestore-dev"": ""bin/cubestore-dev"",
+    ""cubestore-installer"": ""bin/post-install""
   },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
@@ -18,7 +19,7 @@
     ""lint:fix"": ""eslint --fix js-wrapper/* --ext .ts,js"",
     ""unit"": ""jest"",
     ""unit:debug"": ""jest --runInBand"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""cubestore-installer""
   },
   ""files"": [
     ""dist"",
diff --git a/yarn.lock b/yarn.lock
index d2a4038..b59bb77 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -4036,9 +4036,9 @@
   integrity sha512-7btbphLrKvo5yl/5CC2OCxUSMx1wV1wvGT1qDXkSt7yi00/YW7E8k6qzXqJHsp+WU0eoG7r6MTQQXI9lIvd0qA==
 
 ""@types/fs-extra@^9.0.1"", ""@types/fs-extra@^9.0.2"", ""@types/fs-extra@^9.0.8"":
-  version ""9.0.10""
-  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.10.tgz#8023a72e3d06cf54929ea47ec7634e47f33f4046""
-  integrity sha512-O9T2LLkRDiTlalOBdjEkcnT0MRdT2+wglCl7pJUJ3mkWkR8hX4K+5bg2raQNJcLv4V8zGuTXe7Ud3wSqkTyuyQ==
+  version ""9.0.11""
+  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.11.tgz#8cc99e103499eab9f347dbc6ca4e99fb8d2c2b87""
+  integrity sha512-mZsifGG4QeQ7hlkhO56u7zt/ycBgGxSVsFI/6lGTU34VtwkiqrrSDgw0+ygs8kFGWcXnFQWMrzF2h7TtDFNixA==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5306,9 +5306,9 @@ acorn@^7.0.0, acorn@^7.1.0, acorn@^7.1.1, acorn@^7.4.0:
   integrity sha512-nQyp0o1/mNdbTO1PO6kHkwSrmgZ0MT/jCCpNiwbUjGoRN4dlBhqJtoQuCnEOKzgTVwg0ZWiCoQy6SxMebQVh8A==
 
 acorn@^8.1.0:
-  version ""8.1.0""
-  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.0.tgz#52311fd7037ae119cbb134309e901aa46295b3fe""
-  integrity sha512-LWCF/Wn0nfHOmJ9rzQApGnxnvgfROzGilS8936rqN/lfcYkY9MYZzdMqN+2NJ4SlTc+m5HiSa+kNfDtI64dwUA==
+  version ""8.1.1""
+  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.1.tgz#fb0026885b9ac9f48bac1e185e4af472971149ff""
+  integrity sha512-xYiIVjNuqtKXMxlRMDc6mZUhXehod4a3gbZ1qRlM7icK4EbxUFNLhWoPblCvFtB2Y9CIqHP3CF/rdxLItaQv8g==
 
 adal-node@^0.1.28:
   version ""0.1.28""
@@ -5441,9 +5441,9 @@ ajv@^6.1.0, ajv@^6.10.0, ajv@^6.10.2, ajv@^6.12.2, ajv@^6.12.3, ajv@^6.12.4, ajv
     uri-js ""^4.2.2""
 
 ajv@^8.0.1:
-  version ""8.0.5""
-  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.0.5.tgz#f07d6fdeffcdbb80485570ce3f1bc845fcc812b9""
-  integrity sha512-RkiLa/AeJx7+9OvniQ/qeWu0w74A8DiPPBclQ6ji3ZQkv5KamO+QGpqmi7O4JIw3rHGUXZ6CoP9tsAkn3gyazg==
+  version ""8.1.0""
+  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.1.0.tgz#45d5d3d36c7cdd808930cc3e603cf6200dbeb736""
+  integrity sha512-B/Sk2Ix7A36fs/ZkuGLIR86EdjbgR6fsAcbx9lOP/QBSXujDNbVmIS/U4Itz5k8fPFDeVZl/zQ/gJW4Jrq6XjQ==
   dependencies:
     fast-deep-equal ""^3.1.1""
     json-schema-traverse ""^1.0.0""
@@ -6828,15 +6828,15 @@ browserslist@4.14.2:
     node-releases ""^1.1.61""
 
 browserslist@^4.0.0, browserslist@^4.11.1, browserslist@^4.12.0, browserslist@^4.14.5, browserslist@^4.16.3, browserslist@^4.3.4, browserslist@^4.6.2, browserslist@^4.6.4, browserslist@^4.7.0, browserslist@^4.9.1:
-  version ""4.16.3""
-  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.3.tgz#340aa46940d7db878748567c5dea24a48ddf3717""
-  integrity sha512-vIyhWmIkULaq04Gt93txdh+j02yX/JzlyhLYbV3YQCn/zvES3JnY7TifHHvvr1w5hTDluNKMkV05cs4vy8Q7sw==
+  version ""4.16.4""
+  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.4.tgz#7ebf913487f40caf4637b892b268069951c35d58""
+  integrity sha512-d7rCxYV8I9kj41RH8UKYnvDYCRENUlHRgyXy/Rhr/1BaeLGfiCptEdFE8MIrvGfWbBFNjVYx76SQWvNX1j+/cQ==
   dependencies:
-    caniuse-lite ""^1.0.30001181""
-    colorette ""^1.2.1""
-    electron-to-chromium ""^1.3.649""
+    caniuse-lite ""^1.0.30001208""
+    colorette ""^1.2.2""
+    electron-to-chromium ""^1.3.712""
     escalade ""^3.1.1""
-    node-releases ""^1.1.70""
+    node-releases ""^1.1.71""
 
 bs-logger@0.x:
   version ""0.2.6""
@@ -7217,7 +7217,7 @@ caniuse-api@^3.0.0:
     lodash.memoize ""^4.1.2""
     lodash.uniq ""^4.5.0""
 
-caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001181:
+caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001208:
   version ""1.0.30001208""
   resolved ""https://registry.yarnpkg.com/caniuse-lite/-/caniuse-lite-1.0.30001208.tgz#a999014a35cebd4f98c405930a057a0d75352eb9""
   integrity sha512-OE5UE4+nBOro8Dyvv0lfx+SRtfVIOM9uhKqFmJeUbGriqhhStgp1A0OyBpgy3OUF8AhYCT+PVwPC1gMl2ZcQMA==
@@ -9549,10 +9549,10 @@ ejs@^2.6.1:
   resolved ""https://registry.yarnpkg.com/ejs/-/ejs-2.7.4.tgz#48661287573dcc53e366c7a1ae52c3a120eec9ba""
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
-electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.649:
-  version ""1.3.711""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.711.tgz#92c3caf7ffed5e18bf63f66b4b57b4db2409c450""
-  integrity sha512-XbklBVCDiUeho0PZQCjC25Ha6uBwqqJeyDhPLwLwfWRAo4x+FZFsmu1pPPkXT+B4MQMQoQULfyaMltDopfeiHQ==
+electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.712:
+  version ""1.3.712""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.712.tgz#ae467ffe5f95961c6d41ceefe858fc36eb53b38f""
+  integrity sha512-3kRVibBeCM4vsgoHHGKHmPocLqtFAGTrebXxxtgKs87hNUzXrX2NuS3jnBys7IozCnw7viQlozxKkmty2KNfrw==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -9945,9 +9945,9 @@ eslint-plugin-import@^2.16.0, eslint-plugin-import@^2.18.2, eslint-plugin-import
     tsconfig-paths ""^3.9.0""
 
 eslint-plugin-jest@^24.1.0:
-  version ""24.3.4""
-  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.4.tgz#6d90c3554de0302e879603dd6405474c98849f19""
-  integrity sha512-3n5oY1+fictanuFkTWPwSlehugBTAgwLnYLFsCllzE3Pl1BwywHl5fL0HFxmMjoQY8xhUDk8uAWc3S4JOHGh3A==
+  version ""24.3.5""
+  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.5.tgz#71f0b580f87915695c286c3f0eb88cf23664d044""
+  integrity sha512-XG4rtxYDuJykuqhsOqokYIR84/C8pRihRtEpVskYLbIIKGwPNW2ySxdctuVzETZE+MbF/e7wmsnbNVpzM0rDug==
   dependencies:
     ""@typescript-eslint/experimental-utils"" ""^4.0.1""
 
@@ -12140,12 +12140,11 @@ http-proxy-middleware@0.19.1:
     micromatch ""^3.1.10""
 
 http-proxy-middleware@^1.0.0:
-  version ""1.1.0""
-  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.0.tgz#b896b2cc6836019af4a4f2d5f7b21b99c77ea13f""
-  integrity sha512-OnjU5vyVgcZVe2AjLJyMrk8YLNOC2lspCHirB5ldM+B/dwEfZ5bgVTrFyzE9R7xRWAP/i/FXtvIqKjTNEZBhBg==
+  version ""1.1.1""
+  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.1.tgz#48900a68cd9d388c735d1dd97302c919b7e94a13""
+  integrity sha512-FIDg9zPvOwMhQ3XKB2+vdxK6WWbVAH7s5QpqQCif7a1TNL76GNAATWA1sy6q2gSfss8UJ/Nwza3N6QnFkKclpA==
   dependencies:
     ""@types/http-proxy"" ""^1.17.5""
-    camelcase ""^6.2.0""
     http-proxy ""^1.18.1""
     is-glob ""^4.0.1""
     is-plain-obj ""^3.0.0""
@@ -14341,9 +14340,9 @@ jsdom@^15.2.1:
     xml-name-validator ""^3.0.0""
 
 jsdom@^16.4.0:
-  version ""16.5.2""
-  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.2.tgz#583fac89a0aea31dbf6237e7e4bedccd9beab472""
-  integrity sha512-JxNtPt9C1ut85boCbJmffaQ06NBnzkQY/MWO3YxPW8IWS38A26z+B1oBvA9LwKrytewdfymnhi4UNH3/RAgZrg==
+  version ""16.5.3""
+  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.3.tgz#13a755b3950eb938b4482c407238ddf16f0d2136""
+  integrity sha512-Qj1H+PEvUsOtdPJ056ewXM4UJPCi4hhLA8wpiz9F2YvsRBhuFsXxtrIFAgGBDynQA9isAMGE91PfUYbdMPXuTA==
   dependencies:
     abab ""^2.0.5""
     acorn ""^8.1.0""
@@ -15590,12 +15589,12 @@ micromatch@^3.1.10, micromatch@^3.1.4:
     to-regex ""^3.0.2""
 
 micromatch@^4.0.2:
-  version ""4.0.3""
-  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.3.tgz#fdad8352bf0cbeb89b391b5d244bc22ff3dd4ec8""
-  integrity sha512-ueuSaP4i67F/FAUac9zzZ0Dz/5KeKDkITYIS/k4fps+9qeh1SkeH6gbljcqz97mNBOsaWZ+iv2UobMKK/yD+aw==
+  version ""4.0.4""
+  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.4.tgz#896d519dfe9db25fce94ceb7a500919bf881ebf9""
+  integrity sha512-pRmzw/XUcwXGpD9aI9q/0XOwLNygjETJ8y0ao0wdqprrzDa4YnxLcz7fQRZr8voh8V10kGhABbNcHVk5wHgWwg==
   dependencies:
     braces ""^3.0.1""
-    picomatch ""^2.2.1""
+    picomatch ""^2.2.3""
 
 miller-rabin@^4.0.0:
   version ""4.0.1""
@@ -16356,7 +16355,7 @@ node-pre-gyp@^0.11.0:
     semver ""^5.3.0""
     tar ""^4""
 
-node-releases@^1.1.61, node-releases@^1.1.70:
+node-releases@^1.1.61, node-releases@^1.1.71:
   version ""1.1.71""
   resolved ""https://registry.yarnpkg.com/node-releases/-/node-releases-1.1.71.tgz#cb1334b179896b1c89ecfdd4b725fb7bbdfc7dbb""
   integrity sha512-zR6HoT6LrLCRBwukmrVbHv0EpEQjksO6GmFcZQQuCAy139BEsoVKPYnf3jongYW83fAa1torLGYwxxky/p28sg==
@@ -17571,10 +17570,10 @@ pgpass@1.x:
   dependencies:
     split2 ""^3.1.1""
 
-picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2:
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.2.tgz#21f333e9b6b8eaff02468f5146ea406d345f4dad""
-  integrity sha512-q0M/9eZHzmr0AulXyPwNfZjtwZ/RBZlbN3K3CErVrk50T2ASYI7Bye0EvekFY3IP1Nt2DHu0re+V2ZHIpMkuWg==
+picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2, picomatch@^2.2.3:
+  version ""2.2.3""
+  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.3.tgz#465547f359ccc206d3c48e46a1bcb89bf7ee619d""
+  integrity sha512-KpELjfwcCDUb9PeigTs2mBJzXUPzAuP2oPcA989He8Rte0+YUAjw1JVedDhuTKPkHjSYzMN3npC9luThGYEKdg==
 
 pify@^2.0.0, pify@^2.2.0, pify@^2.3.0:
   version ""2.3.0""
@@ -18446,9 +18445,9 @@ postcss@^7, postcss@^7.0.0, postcss@^7.0.1, postcss@^7.0.14, postcss@^7.0.17, po
     supports-color ""^6.1.0""
 
 postcss@^8.1.0, postcss@^8.2.8:
-  version ""8.2.9""
-  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.9.tgz#fd95ff37b5cee55c409b3fdd237296ab4096fba3""
-  integrity sha512-b+TmuIL4jGtCHtoLi+G/PisuIl9avxs8IZMSmlABRwNz5RLUUACrC+ws81dcomz1nRezm5YPdXiMEzBEKgYn+Q==
+  version ""8.2.10""
+  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.10.tgz#ca7a042aa8aff494b334d0ff3e9e77079f6f702b""
+  integrity sha512-b/h7CPV7QEdrqIxtAf2j31U5ef05uBDuvoXv6L51Q4rcS1jdlXAVKJv+atCFdUXYl9dyTHGyoMzIepwowRJjFw==
   dependencies:
     colorette ""^1.2.2""
     nanoid ""^3.1.22""
@@ -19318,9 +19317,9 @@ rc-tree@^4.0.0, rc-tree@~4.1.0:
     rc-virtual-list ""^3.0.1""
 
 rc-trigger@^5.0.0, rc-trigger@^5.0.4, rc-trigger@^5.1.2, rc-trigger@^5.2.1:
-  version ""5.2.3""
-  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.3.tgz#8c55046ab432d7b52d51c69afb57ebb5bbe37e17""
-  integrity sha512-6Fokao07HUbqKIDkDRFEM0AGZvsvK0Fbp8A/KFgl1ngaqfO1nY037cISCG1Jm5fxImVsXp9awdkP7Vu5cxjjog==
+  version ""5.2.4""
+  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.4.tgz#f1cca4a6c1f378a5d6fadec010292250772069d3""
+  integrity sha512-nLZa4XYo3hOAVauQr7HsGrBtE8/pyoIWhHZnpr7x/H/dd6pPeRzH0//+1TzaBAXylbFgsY6hogKAMeJwaKeDFw==
   dependencies:
     ""@babel/runtime"" ""^7.11.2""
     classnames ""^2.2.6""
@@ -20516,9 +20515,9 @@ rollup@^1.31.1:
     acorn ""^7.1.0""
 
 rollup@^2.40.0, rollup@^2.8.0:
-  version ""2.45.0""
-  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.0.tgz#bfcce2347c96f15f5c78ac860bc38e3349ba27c9""
-  integrity sha512-JJznbtGIsHZfKH0Sa9RpCAy5JarH8SWvBzRAGuRkgzAafb8e8D7VSMJ0O1Bsix1nn91koN/Ecvl2+ZWhljcuTw==
+  version ""2.45.1""
+  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.1.tgz#eae2b94dc2088b4e0a3b7197a5a1ee0bdd589d5c""
+  integrity sha512-vPD+JoDj3CY8k6m1bLcAFttXMe78P4CMxoau0iLVS60+S9kLsv2379xaGy4NgYWu+h2WTlucpoLPAoUoixFBag==
   optionalDependencies:
     fsevents ""~2.3.1""
 
@@ -22971,9 +22970,9 @@ typescript@~4.1.5:
   integrity sha512-6OSu9PTIzmn9TCDiovULTnET6BgXtDYL4Gg4szY+cGsc3JP1dQL8qvE8kShTRx1NIw4Q9IBHlwODjkjWEtMUyA==
 
 ua-parser-js@^0.7.18:
-  version ""0.7.27""
-  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.27.tgz#b54f8ce9eb6c7abf3584edeaf9a3d8b3bd92edba""
-  integrity sha512-eXMaRYK2skomGocoX0x9sBXzx5A1ZVQgXfrW4mTc8dT0zS7olEcyfudAzRC5tIIRgLxQ69B6jut3DI+n5hslPA==
+  version ""0.7.28""
+  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.28.tgz#8ba04e653f35ce210239c64661685bf9121dec31""
+  integrity sha512-6Gurc1n//gjp9eQNXjD9O3M/sMwVtN5S8Lv9bvOYBfKfDNiIIhqiyi01vMBO45u4zkDE420w/e0se7Vs+sIg+g==
 
 uglify-js@3.4.x:
   version ""3.4.10""
@@ -22984,9 +22983,9 @@ uglify-js@3.4.x:
     source-map ""~0.6.1""
 
 uglify-js@^3.1.4, uglify-js@^3.4.9:
-  version ""3.13.3""
-  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.3.tgz#ce72a1ad154348ea2af61f50933c76cc8802276e""
-  integrity sha512-otIc7O9LyxpUcQoXzj2hL4LPWKklO6LJWoJUzNa8A17Xgi4fOeDC8FBDOLHnC/Slo1CQgsZMcM6as0M76BZaig==
+  version ""3.13.4""
+  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.4.tgz#592588bb9f47ae03b24916e2471218d914955574""
+  integrity sha512-kv7fCkIXyQIilD5/yQy8O+uagsYIOt5cZvs890W40/e/rvjMSzJw81o9Bg0tkURxzZBROtDQhW2LFjOGoK3RZw==
 
 uid-number@0.0.6:
   version ""0.0.6""
",3,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""1e05a24486f15889ddf6bf1c711ea2bbffc1a88e"", ""7e9bd7c86df1032d53e752654fe4a446951480bb""]","[""test"", ""fix"", ""build""]","1. The CheckpointRecordsProcessorTest.java file adds new test cases to verify that checkpoint listeners are correctly notified, which is solely test logic.
2. The Base.tsx file changes class spacing from 'space-x-1' to 'space-y-1', resolving a UI spacing bug, directly aligning with the 'fix' label definition.
3. The package.json files for cubejs-databricks-jdbc-driver and rust add new 'bin' entries and update the 'postinstall' script for installer compatibility with Windows, which relates to build configuration and post-install scripts, best captured by the 'build' label.
4. The yarn.lock file updates dependencies to newer versions, which is a typical build system maintenance task and fits the 'build' label.
5. The 'test' label is appropriate for the dedicated addition of test logic, 'fix' for correcting UI behavior, and 'build' for changes solely affecting build scripts, dependency versions, or install compatibility, ruling out other labels as these changes do not modify documentation, CI/CD, or general code structure without behavior change.
6. In summary, 'test' is for the new test logic, 'fix' for the UI bug fix, and 'build' for updates to build scripts and dependencies."
"add a branch name to Slack notifications (#14793)
fix height calc
add page balckwhitelist and pdf","diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/src/content/redux/modules/widget.ts b/src/content/redux/modules/widget.ts
index 96b54f1..bcfe3bb 100644
--- a/src/content/redux/modules/widget.ts
+++ b/src/content/redux/modules/widget.ts
@@ -93,7 +93,7 @@ export const initState: WidgetState = {
         : _initConfig.panelWidth,
       height: isSaladictPopupPage
         ? 400
-        : 30 + _initConfig.dicts.selected.length * 30,
+        : 30 + 30, // menubar + 1 dict hegiht
     },
     bowlRect: {
       x: 0,
@@ -565,7 +565,7 @@ function listenNewSelection (
           mouseX,
           mouseY,
           lastPanelRect.width,
-          30 + state.config.dicts.selected.length * 30,
+          30 + state.dictionaries.active.length * 30,
         )
       }
     }

diff --git a/src/_locales/common/messages.json b/src/_locales/common/messages.json
index e8524ac..3a596d6 100644
--- a/src/_locales/common/messages.json
+++ b/src/_locales/common/messages.json
@@ -4,11 +4,21 @@
     ""zh_CN"": ""添加"",
     ""zh_TW"": ""新增""
   },
+  ""blacklist"": {
+    ""en"": ""Blacklist"",
+    ""zh_CN"": ""黑名单"",
+    ""zh_TW"": ""黑名單""
+  },
   ""cancel"": {
     ""en"": ""Cancel"",
     ""zh_CN"": ""取消"",
     ""zh_TW"": ""取消""
   },
+  ""changes_confirm"": {
+    ""en"": ""Changes not saved. Close anyway?"",
+    ""zh_CN"": ""修改未保存。确认关闭？"",
+    ""zh_TW"": ""修改未保存。確定關閉？""
+  },
   ""confirm"": {
     ""en"": ""Confirm"",
     ""zh_CN"": ""确认"",
@@ -93,5 +103,10 @@
     ""en"": ""words"",
     ""zh_CN"": ""个"",
     ""zh_TW"": ""个""
+  },
+  ""whitelist"": {
+    ""en"": ""Whitelist"",
+    ""zh_CN"": ""白名单"",
+    ""zh_TW"": ""白名單""
   }
 }
diff --git a/src/_locales/options/messages.json b/src/_locales/options/messages.json
index ada2488..e7d699a 100644
--- a/src/_locales/options/messages.json
+++ b/src/_locales/options/messages.json
@@ -119,6 +119,11 @@
     ""zh_CN"": ""反馈问题"",
     ""zh_TW"": ""軟體使用疑問和建言""
   },
+  ""match_pattern_description"": {
+    ""en"": ""Specify URLs as match patterns. <a href=\""https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Match_patterns#Examples\"" target=\""_blank\"">Examples</a>. Empty fields will be removed."",
+    ""zh_CN"": ""网址支持匹配模式（<a href=\""https://developer.mozilla.org/zh-CN/Add-ons/WebExtensions/Match_patterns#范例\"" target=\""_blank\"">例子</a>）。留空保存即可清除。"",
+    ""zh_TW"": ""網址支援匹配模式（<a href=\""https://developer.mozilla.org/zh-CN/Add-ons/WebExtensions/Match_patterns#范例\"" target=\""_blank\"">例子</a>）。留空儲存即可清除。""
+  },
   ""msg_updated"": {
     ""en"": ""Successfully updated"",
     ""zh_CN"": ""设置已更新"",
@@ -319,6 +324,21 @@
     ""zh_CN"": ""开启后，本扩展会自动识别输入框以及常见编辑器，如 CodeMirror、ACE 和 Monaco。"",
     ""zh_TW"": ""開啟后，本程式會自動識別輸入框以及常見編輯器，如 CodeMirror、ACE 和 Monaco。""
   },
+  ""opt_pdf_blackwhitelist_help"": {
+    ""en"": ""Blacklisted PDF links will not jump to Saladict PDF Viewer."",
+    ""zh_CN"": ""黑名单匹配的 PDF 链接将不会跳转到 Saladict 打开。"",
+    ""zh_TW"": ""黑名單匹配的 PDF 連結將不會跳轉到 Saladict 開啟。""
+  },
+  ""opt_pdf_sniff"": {
+    ""en"": ""Enable PDF Sniffer"",
+    ""zh_CN"": ""默认用本扩展浏览 PDF"",
+    ""zh_TW"": ""使用本應用程式瀏覽 PDF""
+  },
+  ""opt_pdf_sniff_help"": {
+    ""en"": ""If turned on， PDF links will be automatically captured."",
+    ""zh_CN"": ""开启后所有 PDF 链接将自动跳转到本扩展打开（包括本地，如果在扩展管理页面勾选了允许）。"",
+    ""zh_TW"": ""開啟後所有 PDF 連結將自動跳轉到本擴充套件開啟（包括本地，如果在擴充套件管理頁面勾選了允許）。""
+  },
   ""opt_profile_change"": {
     ""en"": ""This option may change base on \""Profile\""."",
     ""zh_CN"": ""此选项会因「情景模式」而改变。"",
@@ -329,6 +349,16 @@
     ""zh_CN"": ""输入时显示候选"",
     ""zh_TW"": ""輸入時顯示候選""
   },
+  ""opt_sel_blackwhitelist"": {
+    ""en"": ""Selection Black/White List"",
+    ""zh_CN"": ""划词黑白名单"",
+    ""zh_TW"": ""選詞黑白名單""
+  },
+  ""opt_sel_blackwhitelist_help"": {
+    ""en"": ""Saladict will not react to selection in blacklisted pages."",
+    ""zh_CN"": ""黑名单匹配的页面 Saladict 将不会响应鼠标划词。"",
+    ""zh_TW"": ""黑名單匹配的頁面 Saladict 將不會響應滑鼠劃詞。""
+  },
   ""opt_sel_lang"": {
     ""en"": ""Selection Languages"",
     ""zh_CN"": ""划词语言"",
diff --git a/src/options/components/options/BlackWhiteList/index.tsx b/src/options/components/options/BlackWhiteList/index.tsx
new file mode 100644
index 0000000..52708dd
--- /dev/null
+++ b/src/options/components/options/BlackWhiteList/index.tsx
@@ -0,0 +1,69 @@
+import React from 'react'
+import { Props } from '../typings'
+import { formItemLayout } from '../helpers'
+import MatchPatternModal from '../../MatchPatternModal'
+
+import { FormComponentProps } from 'antd/lib/form'
+import { Form, Button } from 'antd'
+
+export type BlackWhiteListProps = Props & FormComponentProps
+
+interface BlackWhiteListState {
+  editingArea: '' | 'pdfWhitelist' | 'pdfBlacklist' | 'whitelist' | 'blacklist'
+}
+
+export class BlackWhiteList extends React.Component<BlackWhiteListProps, BlackWhiteListState> {
+  constructor (props: BlackWhiteListProps) {
+    super(props)
+    this.state = {
+      editingArea: ''
+    }
+  }
+
+  closeModal = () => {
+    this.setState({ editingArea: '' })
+  }
+
+  render () {
+    const { t, config } = this.props
+
+    return (
+      <Form>
+        <Form.Item
+          {...formItemLayout}
+          label={t('opt_sel_blackwhitelist')}
+          help={t('opt_sel_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'blacklist' })}
+          >{t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'whitelist' })}
+          >{t('common:whitelist')}</Button>
+        </Form.Item>
+        <Form.Item
+          {...formItemLayout}
+          label={`PDF ${t('nav_BlackWhiteList')}`}
+          help={t('opt_pdf_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'pdfBlacklist' })}
+          >PDF {t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'pdfWhitelist' })}
+          >PDF {t('common:whitelist')}</Button>
+        </Form.Item>
+        <MatchPatternModal
+          t={t}
+          config={config}
+          area={this.state.editingArea}
+          onClose={this.closeModal}
+        />
+      </Form>
+    )
+  }
+}
+
+export default BlackWhiteList
diff --git a/src/options/components/options/PDF/index.tsx b/src/options/components/options/PDF/index.tsx
new file mode 100644
index 0000000..3e7772d
--- /dev/null
+++ b/src/options/components/options/PDF/index.tsx
@@ -0,0 +1,72 @@
+import React from 'react'
+import { Props } from '../typings'
+import { updateConfigOrProfile, formItemLayout } from '../helpers'
+import MatchPatternModal from '../../MatchPatternModal'
+
+import { FormComponentProps } from 'antd/lib/form'
+import { Form, Switch, Button } from 'antd'
+
+export type PDFProps = Props & FormComponentProps
+
+interface PDFState {
+  editingArea: '' | 'pdfWhitelist' | 'pdfBlacklist'
+}
+
+export class PDF extends React.Component<PDFProps, PDFState> {
+  constructor (props: PDFProps) {
+    super(props)
+
+    this.state = {
+      editingArea: ''
+    }
+  }
+
+  closeModal = () => {
+    this.setState({ editingArea: '' })
+  }
+
+  render () {
+    const { t, config } = this.props
+    const { getFieldDecorator } = this.props.form
+
+    return (
+      <Form>
+        <Form.Item
+          {...formItemLayout}
+          label={t('opt_pdf_sniff')}
+          help={t('opt_pdf_sniff_help')}
+        >{
+          getFieldDecorator('config#pdfSniff', {
+            initialValue: config.pdfSniff,
+            valuePropName: 'checked',
+          })(
+            <Switch />
+          )
+        }</Form.Item>
+        <Form.Item
+          {...formItemLayout}
+          label={t('nav_BlackWhiteList')}
+          help={t('opt_pdf_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'pdfBlacklist' })}
+          >PDF {t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'pdfWhitelist' })}
+          >PDF {t('common:whitelist')}</Button>
+        </Form.Item>
+        <MatchPatternModal
+          t={t}
+          config={config}
+          area={this.state.editingArea}
+          onClose={this.closeModal}
+        />
+      </Form>
+    )
+  }
+}
+
+export default Form.create<PDFProps>({
+  onValuesChange: updateConfigOrProfile
+})(PDF)
",3,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""148cd56d096ba972e9706653c47052a07d5f9d08"", ""9b1c0fc20b614513384a1e562317dbf076eb8ef0""]","[""cicd"", ""fix"", ""feat""]","1. The commit modifies CI configuration files (.circleci/config.yml, vsts.yml) to include the branch name in Slack notifications, updates widget.ts to correct height calculation logic, and adds new options components and locale entries for page black/whitelist and PDF features.
2. The changes to CI scripts directly affect notification messages, aligning with the 'cicd' label; the widget.ts update addresses a calculation bug, which fits the 'fix' label; the addition of new components and configuration options for black/whitelist and PDF handling constitutes new functionality, matching the 'feat' label.
3. 'cicd' is appropriate for changes strictly within CI configuration, not 'build' or 'docs' as these are notification logic updates; 'fix' is justified for the bug correction in UI calculation, not 'refactor' as behavior changes; 'feat' is correct for the introduction of new user-facing features (black/whitelist, PDF options), not 'docs' or 'test' as these are functional enhancements.
4. The labels 'cicd', 'fix', and 'feat' accurately represent the commit's scope: CI notification improvement, bugfix in calculation logic, and addition of new feature capabilities."
"simplify aggregate_columns
add more tests for Utils.lookupPathFromDecorator","diff --git a/read_buffer/src/row_group.rs b/read_buffer/src/row_group.rs
index 19b0501..f2fbbe3 100644
--- a/read_buffer/src/row_group.rs
+++ b/read_buffer/src/row_group.rs
@@ -924,38 +924,30 @@ impl RowGroup {
             },
         };
 
-        // References to the columns to be used as input for producing the
-        // output aggregates. Also returns the required aggregate type.
-        let input_aggregate_columns = dst
-            .schema
-            .aggregate_columns
-            .iter()
-            .map(|(col_type, agg_type, _)| (self.column_by_name(col_type.as_str()), *agg_type))
-            .collect::<Vec<_>>();
-
-        let mut output_aggregate_columns = dst
+        dst.aggregate_cols = dst
             .schema
             .aggregate_columns
             .iter()
-            .map(|(_, agg_type, data_type)| AggregateVec::from((agg_type, data_type)))
-            .collect::<Vec<_>>();
+            .map(|(col_type, agg_type, data_type)| {
+                let col = self.column_by_name(col_type.as_str()); // input aggregate column
+                let mut agg_vec = AggregateVec::from((agg_type, data_type));
 
-        for (i, (col, agg_type)) in input_aggregate_columns.iter().enumerate() {
-            match agg_type {
-                AggregateType::Count => {
-                    let value = Value::Scalar(Scalar::U64(col.count(&row_ids) as u64));
-                    output_aggregate_columns[i].push(value);
-                }
-                AggregateType::First => unimplemented!(""First not yet implemented""),
-                AggregateType::Last => unimplemented!(""Last not yet implemented""),
-                AggregateType::Min => output_aggregate_columns[i].push(col.min(&row_ids)),
-                AggregateType::Max => output_aggregate_columns[i].push(col.max(&row_ids)),
-                AggregateType::Sum => {
-                    output_aggregate_columns[i].push(Value::Scalar(col.sum(&row_ids)))
+                // produce single aggregate for the input column subject to a
+                // predicate filter.
+                match agg_type {
+                    AggregateType::Count => {
+                        let value = Value::Scalar(Scalar::U64(col.count(&row_ids) as u64));
+                        agg_vec.push(value);
+                    }
+                    AggregateType::First => unimplemented!(""First not yet implemented""),
+                    AggregateType::Last => unimplemented!(""Last not yet implemented""),
+                    AggregateType::Min => agg_vec.push(col.min(&row_ids)),
+                    AggregateType::Max => agg_vec.push(col.max(&row_ids)),
+                    AggregateType::Sum => agg_vec.push(Value::Scalar(col.sum(&row_ids))),
                 }
-            }
-        }
-        dst.aggregate_cols = output_aggregate_columns;
+                agg_vec
+            })
+            .collect::<Vec<_>>();
     }
 
     /// Given the predicate (which may be empty), determine a set of rows

diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',
",2,"[""300ac2e411ef0ebfe1441d42cc88787116a9afa4"", ""c5e86dbc00a13a355bffadeb2db197e2fea5640f""]","[""refactor"", ""test""]","1. The changes in 'row_group.rs' simplify the implementation of aggregate column computation, restructuring the logic without altering external behavior, while the changes in 'Utils.ts' streamline a regular expression selection; the 'Utils.test.ts' file receives new and updated test cases for 'lookupPathFromDecorator'.
2. The modifications in 'row_group.rs' and 'Utils.ts' align with the 'refactor' label, as they improve internal code clarity and maintainability without changing the observable behavior, and the additions in 'Utils.test.ts' align with the 'test' label, as they expand and improve the test coverage.
3. 'refactor' is appropriate for the code restructuring because there is no change in features or bug fixes, and 'test' is correct for the test file changes as they are solely concerned with test logic; neither 'feat' nor 'fix' are relevant since no new functionality is added and no bugs are explicitly addressed.
4. The 'refactor' label correctly captures the intent to improve code structure, and the 'test' label is appropriate for the dedicated test additions and modifications."
export a modal transition preset,"diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",1,"[""535708ae50aecb452560a23356fd396f99ef13a2""]","[""refactor""]","1. The code introduces a new export 'ModalTransition' as a platform-selecting preset and updates its usage in another file, replacing direct reference to 'ModalSlideFromBottomIOS' with the new abstraction.
2. These changes improve the structure and maintainability of the code by encapsulating platform-specific logic within a reusable export, which aligns with the 'refactor' label definition.
3. The label 'refactor' is appropriate because the changes do not introduce new features ('feat') or fix bugs ('fix'), nor are they dedicated to documentation, tests, CI/CD, or build artifacts.
4. The 'refactor' label accurately captures the intent to improve code organization and abstraction without altering external behavior."
"e2e
create DashboardDetails
fix node test cases run into infinite loop","diff --git a/.github/workflows/kibbeh-e2e_tests.yaml b/.github/workflows/kibbeh-e2e_tests.yaml
index 52bf3ed..74fe785 100644
--- a/.github/workflows/kibbeh-e2e_tests.yaml
+++ b/.github/workflows/kibbeh-e2e_tests.yaml
@@ -4,7 +4,7 @@ on:
     branches:
       - staging
     paths:
-      - '.github/workflows/end-to-end-tests.yaml'
+      - '.github/workflows/kibbeh-e2e_tests.yaml'
       - 'kousa/lib/**'
       - 'kibbeh/src/**'
   pull_request:

diff --git a/client/src/components/MentorSearch.tsx b/client/src/components/MentorSearch.tsx
index 622560a..06f0114 100644
--- a/client/src/components/MentorSearch.tsx
+++ b/client/src/components/MentorSearch.tsx
@@ -7,8 +7,9 @@ type Props = UserProps & {
 };
 
 export function MentorSearch(props: Props) {
-  const courseService = useMemo(() => new CourseService(props.courseId), [props.courseId]);
+  const { courseId, ...otherProps } = props;
+  const courseService = useMemo(() => new CourseService(courseId), [courseId]);
   const handleSearch = useCallback(async (value: string) => courseService.searchMentors(value), [courseService]);
 
-  return <UserSearch {...props} searchFn={handleSearch} />;
+  return <UserSearch {...otherProps} searchFn={handleSearch} />;
 }
diff --git a/client/src/components/Student/DashboardDetails.tsx b/client/src/components/Student/DashboardDetails.tsx
new file mode 100644
index 0000000..30506ef
--- /dev/null
+++ b/client/src/components/Student/DashboardDetails.tsx
@@ -0,0 +1,89 @@
+import { BranchesOutlined, CloseCircleTwoTone, SolutionOutlined, UndoOutlined } from '@ant-design/icons';
+import { Button, Descriptions, Drawer } from 'antd';
+import { CommentModal, MentorSearch } from 'components';
+import { useState } from 'react';
+import { StudentDetails } from 'services/course';
+import { MentorBasic } from '../../../../common/models';
+import css from 'styled-jsx/css';
+
+type Props = {
+  details: StudentDetails | null;
+  courseId: number;
+  onClose: () => void;
+  onCreateRepository: () => void;
+  onRestoreStudent: () => void;
+  onExpelStudent: (comment: string) => void;
+  onIssueCertificate: () => void;
+  onUpdateMentor: (githubId: string) => void;
+};
+
+export function DashboardDetails(props: Props) {
+  const [expelMode, setExpelMode] = useState(false);
+  const { details } = props;
+  if (details == null) {
+    return null;
+  }
+  return (
+    <>
+      <Drawer
+        width={600}
+        title={`${details.name} , ${details.githubId}`}
+        placement=""right""
+        closable={false}
+        onClose={props.onClose}
+        visible={!!details}
+      >
+        <div className=""student-details-actions"">
+          <Button
+            disabled={!details.isActive || !!details.repository}
+            icon={<BranchesOutlined />}
+            onClick={props.onCreateRepository}
+          >
+            Create Repository
+          </Button>
+          <Button disabled={!details.isActive} icon={<SolutionOutlined />} onClick={props.onIssueCertificate}>
+            Issue Certificate
+          </Button>
+          <Button
+            hidden={!details.isActive}
+            icon={<CloseCircleTwoTone twoToneColor=""red"" />}
+            onClick={() => setExpelMode(true)}
+          >
+            Expel
+          </Button>
+          <Button hidden={details.isActive} icon={<UndoOutlined />} onClick={props.onRestoreStudent}>
+            Restore
+          </Button>
+          <Descriptions bordered layout=""vertical"" size=""small"" column={1}>
+            <Descriptions.Item label=""Mentor"">
+              <MentorSearch
+                style={{ width: '100%' }}
+                onChange={props.onUpdateMentor}
+                courseId={props.courseId}
+                keyField=""githubId""
+                value={(details.mentor as MentorBasic)?.githubId}
+                defaultValues={details.mentor ? [details.mentor as any] : []}
+              />
+            </Descriptions.Item>
+          </Descriptions>
+        </div>
+      </Drawer>
+      <CommentModal
+        title=""Expelling Reason""
+        visible={expelMode}
+        onCancel={() => setExpelMode(false)}
+        onOk={(text: string) => {
+          props.onExpelStudent(text);
+          setExpelMode(false);
+        }}
+      />
+      <style jsx>{styles}</style>
+    </>
+  );
+}
+
+const styles = css`
+  .student-details-actions :global(.ant-btn) {
+    margin: 0 8px 8px 0;
+  }
+`;
diff --git a/client/src/components/Student/index.ts b/client/src/components/Student/index.ts
index 71e28de..076f0e2 100644
--- a/client/src/components/Student/index.ts
+++ b/client/src/components/Student/index.ts
@@ -1 +1,2 @@
 export { default as AssignStudentModal } from './AssignStudentModal';
+export { DashboardDetails } from './DashboardDetails';
diff --git a/client/src/components/StudentSearch.tsx b/client/src/components/StudentSearch.tsx
index 5952aed..7c14263 100644
--- a/client/src/components/StudentSearch.tsx
+++ b/client/src/components/StudentSearch.tsx
@@ -7,8 +7,9 @@ type Props = UserProps & {
 };
 
 export function StudentSearch(props: Props) {
-  const courseService = useMemo(() => new CourseService(props.courseId), [props.courseId]);
+  const { courseId, ...otherProps } = props;
+  const courseService = useMemo(() => new CourseService(courseId), [courseId]);
   const handleSearch = useCallback(async (value: string) => courseService.searchStudents(value), [courseService]);
 
-  return <UserSearch {...props} searchFn={handleSearch} />;
+  return <UserSearch {...otherProps} searchFn={handleSearch} />;
 }
diff --git a/client/src/components/UserSearch.tsx b/client/src/components/UserSearch.tsx
index ff95941..4075827 100644
--- a/client/src/components/UserSearch.tsx
+++ b/client/src/components/UserSearch.tsx
@@ -14,7 +14,7 @@ export type UserProps = SelectProps<string> & {
 
 export function UserSearch(props: UserProps) {
   const [data, setData] = useState<Person[]>([]);
-  const { searchFn = defaultSearch, defaultValues } = props;
+  const { searchFn = defaultSearch, defaultValues, keyField, ...otherProps } = props;
 
   useEffect(() => {
     setData(defaultValues ?? []);
@@ -29,7 +29,6 @@ export function UserSearch(props: UserProps) {
     }
   };
 
-  const { keyField, ...otherProps } = props;
   return (
     <Select
       {...otherProps}
diff --git a/client/src/pages/course/admin/students.tsx b/client/src/pages/course/admin/students.tsx
index c15dee4..220ef54 100644
--- a/client/src/pages/course/admin/students.tsx
+++ b/client/src/pages/course/admin/students.tsx
@@ -2,15 +2,13 @@ import {
   BranchesOutlined,
   CheckCircleTwoTone,
   ClockCircleTwoTone,
-  CloseCircleTwoTone,
   FileExcelOutlined,
   MinusCircleOutlined,
-  SolutionOutlined,
-  UndoOutlined,
 } from '@ant-design/icons';
-import { Button, Drawer, message, Row, Statistic, Switch, Table, Typography, Descriptions } from 'antd';
+import { Button, message, Row, Statistic, Switch, Table, Typography } from 'antd';
 import { ColumnProps } from 'antd/lib/table/Column';
-import { CommentModal, PageLayout, withSession, MentorSearch } from 'components';
+import { PageLayout, withSession } from 'components';
+import { DashboardDetails } from 'components/Student';
 import {
   boolIconRenderer,
   boolSorter,
@@ -21,14 +19,12 @@ import {
 } from 'components/Table';
 import { useLoading } from 'components/useLoading';
 import withCourseData from 'components/withCourseData';
+import { isCourseManager } from 'domain/user';
 import _ from 'lodash';
 import { useMemo, useState } from 'react';
 import { useAsync } from 'react-use';
-import { isCourseManager } from 'domain/user';
 import { CourseService, StudentDetails } from 'services/course';
 import { CoursePageProps } from 'services/models';
-import css from 'styled-jsx/css';
-import { MentorBasic } from '../../../../../common/models';
 
 const { Text } = Typography;
 
@@ -39,7 +35,6 @@ function Page(props: Props) {
   const courseId = props.course.id;
 
   const [loading, withLoading] = useLoading(false);
-  const [expelMode, setExpelMode] = useState(false);
   const [isManager] = useState(isCourseManager(props.session, props.course.id));
   const courseService = useMemo(() => new CourseService(courseId), [courseId]);
   const [students, setStudents] = useState([] as StudentDetails[]);
@@ -77,7 +72,6 @@ function Page(props: Props) {
       await courseService.expelStudent(githubId, text);
       message.info('Student has been expelled');
     }
-    setExpelMode(false);
   });
 
   const restoreStudent = withLoading(async () => {
@@ -114,59 +108,20 @@ function Page(props: Props) {
           <div>{renderToolbar()}</div>
         </Row>
         <Table rowKey=""id"" pagination={{ pageSize: 100 }} size=""small"" dataSource={students} columns={getColumns()} />
-        <Drawer
-          width={400}
-          title={details ? `${details.name} , ${details.githubId}` : ''}
-          placement=""right""
-          closable={false}
+
+        <DashboardDetails
+          onUpdateMentor={updateMentor}
+          onRestoreStudent={restoreStudent}
+          onIssueCertificate={issueCertificate}
+          onExpelStudent={expelStudent}
+          onCreateRepository={createRepository}
           onClose={() => {
             setDetails(null);
             loadStudents();
           }}
-          visible={!!details}
-        >
-          <div className=""student-details-actions"">
-            <Button
-              disabled={!details?.isActive || !!details.repository}
-              icon={<BranchesOutlined />}
-              onClick={createRepository}
-            >
-              Create Repository
-            </Button>
-            <Button disabled={!details?.isActive} icon={<SolutionOutlined />} onClick={issueCertificate}>
-              Issue Certificate
-            </Button>
-            <Button
-              hidden={!details?.isActive}
-              icon={<CloseCircleTwoTone twoToneColor=""red"" />}
-              onClick={() => setExpelMode(true)}
-            >
-              Expel
-            </Button>
-            <Button hidden={details?.isActive} icon={<UndoOutlined />} onClick={restoreStudent}>
-              Restore
-            </Button>
-            <Descriptions bordered layout=""vertical"" size=""small"" column={1}>
-              <Descriptions.Item label=""Mentor"">
-                <MentorSearch
-                  style={{ width: '100%' }}
-                  onChange={updateMentor}
-                  courseId={props.course.id}
-                  keyField=""githubId""
-                  value={(details?.mentor as MentorBasic)?.githubId}
-                  defaultValues={details?.mentor ? [details?.mentor as any] : []}
-                />
-              </Descriptions.Item>
-            </Descriptions>
-          </div>
-        </Drawer>
-        <CommentModal
-          title=""Expelling Reason""
-          visible={expelMode}
-          onCancel={() => setExpelMode(false)}
-          onOk={expelStudent}
+          details={details}
+          courseId={props.course.id}
         />
-        <style jsx>{styles}</style>
       </PageLayout>
     );
   }
@@ -306,14 +261,4 @@ function calculateStats(students: StudentDetails[]) {
   };
 }
 
-const styles = css`
-  :global(.rs-table-row-disabled) {
-    opacity: 0.25;
-  }
-
-  .student-details-actions :global(.ant-btn) {
-    margin: 0 8px 8px 0;
-  }
-`;
-
 export default withCourseData(withSession(Page));
diff --git a/client/src/styles/main.css b/client/src/styles/main.css
index 2ccac3c..df3cc8c 100644
--- a/client/src/styles/main.css
+++ b/client/src/styles/main.css
@@ -21,6 +21,10 @@ body,
   display: none;
 }
 
+.ant-drawer-content-wrapper {
+  max-width: 85%;
+}
+
 .footer-dark.ant-layout-footer {
   background: #000;
   color: #fff;

diff --git a/packages/designer/tests/document/node/node.test.ts b/packages/designer/tests/document/node/node.test.ts
index dd20bd3..113360d 100644
--- a/packages/designer/tests/document/node/node.test.ts
+++ b/packages/designer/tests/document/node/node.test.ts
@@ -26,7 +26,7 @@ import rootHeaderMetadata from '../../fixtures/component-metadata/root-header';
 import rootContentMetadata from '../../fixtures/component-metadata/root-content';
 import rootFooterMetadata from '../../fixtures/component-metadata/root-footer';
 
-describe.skip('Node 方法测试', () => {
+describe('Node 方法测试', () => {
   let editor: Editor;
   let designer: Designer;
   let project: Project;
@@ -474,15 +474,16 @@ describe.skip('Node 方法测试', () => {
   it('didDropIn / didDropOut', () => {
     const form = doc.getNode('node_k1ow3cbo');
     designer.createComponentMeta(divMetadata);
+    designer.createComponentMeta(formMetadata);
     const callbacks = form.componentMeta.getMetadata().configure.advanced?.callbacks;
     const fn1 = callbacks.onNodeAdd = jest.fn();
     const fn2 = callbacks.onNodeRemove = jest.fn();
     const textField = doc.getNode('node_k1ow3cc9');
     form.didDropIn(textField);
-    expect(fn1).toHaveBeenCalledWith(textField, form);
+    expect(fn1).toHaveBeenCalledWith(textField.internalToShellNode(), form.internalToShellNode());
 
     form.didDropOut(textField);
-    expect(fn2).toHaveBeenCalledWith(textField, form);
+    expect(fn2).toHaveBeenCalledWith(textField.internalToShellNode(), form.internalToShellNode());
   });
 
   it('hover', () => {
",3,"[""02f9e79a755a1dd95e661c674d6966837f378442"", ""fd5f211916c989fddc2ee5afeeb7d46e6a2f51cb"", ""d2c3f0ba6f85b659b76636a91ea9ab2b5a95a720""]","[""cicd"", ""feat"", ""test""]","1. The commit introduces a new DashboardDetails component, updates references to it, refactors search component props handling, adjusts a workflow file path in CI, and fixes a node test to avoid an infinite loop and enable a previously skipped suite.
2. The new DashboardDetails and related integration is a clear new feature (feat), the workflow path update is a change to a CI configuration (cicd), and the test file modification both fixes a bug and directly updates test logic (test).
3. 'feat' is justified for the new UI component and integration, not 'fix' or 'refactor' since it adds functionality; 'cicd' is correct for workflow file changes, not 'build' since it is not a build system change; 'test' is appropriate for the node.test.ts file as the changes are scoped to test logic and resolve a bug in test execution, making 'fix' or 'refactor' less precise than 'test' per instructions.
4. The assigned labels 'feat', 'test', and 'cicd' accurately represent the distinct types of changes in this commit according to the classification instructions."
"better pin mode view
updated test to use rows for action items

references #279
better tested publishing flow","diff --git a/src/content/redux/modules/widget.ts b/src/content/redux/modules/widget.ts
index 5df38c2..b8a1080 100644
--- a/src/content/redux/modules/widget.ts
+++ b/src/content/redux/modules/widget.ts
@@ -627,7 +627,9 @@ function listenNewSelection (
         isSaladictOptionsPage
     ) {
       dispatch(searchText({ info: selectionInfo }))
-    } else {
+    } else if (!shouldPanelShow) {
+      // Everything stays the same if the panel is still visible (e.g. pin mode)
+      // Otherwise clean up all dicts
       dispatch(restoreDicts())
     }
   })

diff --git a/ionic/components/card/test/advanced/main.html b/ionic/components/card/test/advanced/main.html
index 7c56a7d..c19ea12 100644
--- a/ionic/components/card/test/advanced/main.html
+++ b/ionic/components/card/test/advanced/main.html
@@ -19,16 +19,20 @@
       </p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left>
-        <icon star></icon>
-        Star
-      </button>
-      <button clear item-right class=""activated"">
-        <icon share></icon>
-        Share.activated
-      </button>
-    </ion-item>
+    <ion-row no-padding>
+      <ion-col>
+        <button clear small>
+          <icon star></icon>
+          Star
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small class=""activated"">
+          <icon share></icon>
+          Share.activated
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
@@ -51,19 +55,24 @@
       <p>Hello. I am a paragraph.</p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left danger class=""activated"">
-        <icon star></icon>
-        Favorite.activated
-      </button>
-      <button clear item-left danger>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <ion-note item-right>
-        Right Note
-      </ion-note>
-    </ion-item>
+    <ion-row center no-padding>
+      <ion-col width-75>
+        <button clear small danger class=""activated"">
+          <icon star></icon>
+          Favorite.activated
+        </button>
+        <button clear small danger>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small>
+          <icon share></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
   </ion-card>
 
   <ion-card>
@@ -76,20 +85,27 @@
       This card was breaking the border radius.
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left dark>
-        <icon star></icon>
-        Favorite
-      </button>
-      <button clear item-right dark>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <button clear item-right dark>
-        <icon share-alt></icon>
-        Share
-      </button>
-    </ion-item>
+    <ion-row text-center no-padding>
+      <ion-col>
+        <button clear small dark>
+          <icon star></icon>
+          Favorite
+        </button>
+      </ion-col>
+
+      <ion-col>
+        <button clear small dark>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col>
+        <button clear small dark>
+          <icon share-alt></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 

diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-
",3,"[""9c0aae64774a6fd864622474cb645371fee114b5"", ""19feaea1885eb015759b5c7a5d785521f2b8a212"", ""65574eea5da54bf4722ecb551b42f8ff6088f33b""]","[""refactor"", ""test"", ""build""]","1. The commit modifies three areas: (a) a TypeScript logic file (widget.ts), (b) an HTML test fixture (main.html), and (c) a build configuration file (Makefile.toml).
2. The widget.ts change adds a conditional and clarifies comments, improving logic structure without altering external behavior—this aligns with 'refactor.' The main.html changes rework the HTML structure used in tests, focusing solely on test layout—this aligns with 'test.' The Makefile.toml changes update build and publish tasks, affecting how the project is built and released—this aligns with 'build.'
3. 'Refactor' is appropriate for widget.ts since the logic is clarified but no new features or bug fixes are introduced; 'test' is correct for main.html because only test scaffolding is changed; 'build' fits Makefile.toml because it exclusively updates build/release automation, not CI or documentation.
4. The labels 'refactor', 'test', and 'build' accurately and uniquely represent the intent and scope of the changes across the three modified code units."
"update renovate config
added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/.github/workflows/renovate.yml b/.github/workflows/renovate.yml
index 710d1f6..c83d681 100644
--- a/.github/workflows/renovate.yml
+++ b/.github/workflows/renovate.yml
@@ -1,7 +1,7 @@
 name: Renovate
 on:
   schedule:
-    - cron: '0/5 * * * *'
+    - cron: '0 */8 * * *'
 jobs:
   renovate:
     runs-on: ubuntu-latest

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",2,"[""6132632f7517195c7333308e9c667cdb756bf0af"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""cicd"", ""docs""]","1. The commit modifies the `.github/workflows/renovate.yml` file to change the cron schedule for Renovate and adds new documentation about the changelog pipe in `docs/115-release.md`.
2. The workflow file change is a CI configuration update, aligning with the 'cicd' label, and the documentation file update aligns with the 'docs' label as it solely adds and updates documentation content.
3. 'cicd' is appropriate for changes to CI workflow files rather than 'build', and 'docs' is correct for documentation changes rather than 'feat', 'fix', or 'refactor', since no code logic or behavior is altered.
4. The 'cicd' and 'docs' labels accurately reflect the commit's changes: one to CI configuration and one to documentation, with no overlap or ambiguity."
"explain `ChunkOrder` query test scenario
use a closure","diff --git a/query_tests/src/scenarios.rs b/query_tests/src/scenarios.rs
index f0e352b..86df0e9 100644
--- a/query_tests/src/scenarios.rs
+++ b/query_tests/src/scenarios.rs
@@ -1170,6 +1170,21 @@ impl DbSetup for ChunkOrder {
             .clear_lifecycle_action()
             .unwrap();
 
+        // Now we have the the following chunks (same partition and table):
+        //
+        // | ID | order | tag: region | field: user | time |
+        // | -- | ----- | ----------- | ----------- | ---- |
+        // |  1 |     1 | ""west""      |           2 | 100  |
+        // |  2 |     0 | ""west""      |           1 | 100  |
+        //
+        // The result after deduplication should be:
+        //
+        // | tag: region | field: user | time |
+        // | ----------- | ----------- | ---- |
+        // | ""west""      |           2 | 100  |
+        //
+        // So the query engine must use `order` as a primary key to sort chunks, NOT `id`.
+
         let scenario = DbScenario {
             scenario_name: ""chunks where chunk ID alone cannot be used for ordering"".into(),
             db,

diff --git a/ibis/expr/analysis.py b/ibis/expr/analysis.py
index bb17a7a..975c658 100644
--- a/ibis/expr/analysis.py
+++ b/ibis/expr/analysis.py
@@ -39,7 +39,9 @@ def sub_for(expr, substitutions):
         An Ibis expression
     """"""
 
-    def fn(node, mapping={k.op(): v for k, v in substitutions}):
+    mapping = {k.op(): v for k, v in substitutions}
+
+    def fn(node):
         try:
             return mapping[node]
         except KeyError:
",2,"[""9a60af7fa3b480e2e04bacd646112cad9aaab6d7"", ""ad52e1d67fd77f0b6a73fbf989b33f9abf395ecc""]","[""docs"", ""refactor""]","1. The first code unit adds a detailed comment block explaining the test scenario for 'ChunkOrder', while the second code unit refactors a function by moving the 'mapping' dictionary creation outside of the closure for clarity and efficiency.
2. The comment block aligns with the 'docs' label as it solely updates documentation within the code, and the refactoring of the closure aligns with the 'refactor' label as it restructures the code for improved readability and maintainability without changing its behavior.
3. 'docs' is appropriate for the first change because no logic or test structure is altered—only explanatory text is added; 'refactor' is appropriate for the second change as it does not introduce new features or fix bugs, but rather improves code structure. Other labels like 'feat', 'fix', 'test', 'cicd', or 'build' do not fit these changes.
4. The 'docs' and 'refactor' labels accurately represent the respective code units: documentation enhancement and code restructuring without behavior change."
"add documentation to use react-native-paper with CRA (#874)
lint source on ci","diff --git a/docs/pages/4.react-native-web.md b/docs/pages/4.react-native-web.md
index 69e4e52..8d6ae2a 100644
--- a/docs/pages/4.react-native-web.md
+++ b/docs/pages/4.react-native-web.md
@@ -16,6 +16,63 @@ To install `react-native-web`, run:
 yarn add react-native-web react-dom react-art
 ```
 
+### Using CRA ([Create React App](https://github.com/facebook/create-react-app))
+
+Install [`react-app-rewired`](https://github.com/timarney/react-app-rewired) to override `webpack` configuration:
+
+```sh
+yarn add --dev react-app-rewired
+```
+
+[Configure `babel-loader`](#2-configure-babel-loader) using a new file called `config-overrides.js`:
+
+```js
+module.exports = function override(config, env) {
+  config.module.rules.push({
+    test: /\.js$/,
+    exclude: /node_modules[/\\](?!react-native-paper|react-native-vector-icons|react-native-safe-area-view)/,
+    use: {
+      loader: ""babel-loader"",
+      options: {
+        // Disable reading babel configuration
+        babelrc: false,
+        configFile: false,
+
+        // The configration for compilation
+        presets: [
+          [""@babel/preset-env"", { useBuiltIns: ""usage"" }],
+          ""@babel/preset-react"",
+          ""@babel/preset-flow""
+        ],
+        plugins: [
+          ""@babel/plugin-proposal-class-properties"",
+          ""@babel/plugin-proposal-object-rest-spread""
+        ]
+      }
+    }
+  });
+
+  return config;
+};
+```
+
+Change your script in `package.json`:
+
+```diff
+/* package.json */
+
+  ""scripts"": {
+-   ""start"": ""react-scripts start"",
++   ""start"": ""react-app-rewired start"",
+-   ""build"": ""react-scripts build"",
++   ""build"": ""react-app-rewired build"",
+-   ""test"": ""react-scripts test --env=jsdom"",
++   ""test"": ""react-app-rewired test --env=jsdom""
+}
+```
+
+### Custom webpack setup
+
 To install `webpack`, run:
 
 ```sh

diff --git a/.travis.yml b/.travis.yml
index d56185e..96510cb 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -2,5 +2,6 @@ language: node_js
 node_js:
   - 'stable'
 script:
+  - yarn lint
   - yarn build
   - yarn test
",2,"[""ee7cc5d5a940fba774e715b1f029c6361110b108"", ""2ac99c0a66a1adc18ee4ef660608f814823dd198""]","[""docs"", ""cicd""]","1. The first code unit adds a section to the documentation describing how to use react-native-paper with Create React App, including installation steps and configuration examples; the second code unit modifies the CI configuration file (.travis.yml) to run 'yarn lint' as part of the CI process.
2. The documentation update aligns with the 'docs' label, as it is dedicated entirely to instructional content; the CI script change aligns with the 'cicd' label, as it affects only the continuous integration workflow.
3. 'docs' is appropriate for the markdown file update because it is solely documentation, not code logic, tests, or build configuration; 'cicd' is correct for the .travis.yml change because it is a CI configuration file, not a build script or application code, and the change is limited to CI behavior.
4. The 'docs' and 'cicd' labels accurately reflect the nature and scope of the respective changes, as each code unit is exclusively dedicated to documentation or CI configuration."
do not query all networks,"diff --git a/src/environment/windows_win32.go b/src/environment/windows_win32.go
index be0c7b5..b90e0ff 100644
--- a/src/environment/windows_win32.go
+++ b/src/environment/windows_win32.go
@@ -203,7 +203,6 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 	var pIFTable2 *MIN_IF_TABLE2
 	_, _, _ = hGetIfTable2.Call(uintptr(unsafe.Pointer(&pIFTable2)))
 
-	SSIDs, _ := env.getAllWifiSSID()
 	networks := make([]*Connection, 0)
 
 	for i := 0; i < int(pIFTable2.NumEntries); i++ {
@@ -220,11 +219,13 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 		}
 
 		var connectionType ConnectionType
+		var ssid string
 		switch networkInterface.Type {
 		case 6:
 			connectionType = ETHERNET
 		case 71:
 			connectionType = WIFI
+			ssid = env.getWiFiSSID(networkInterface.InterfaceGUID)
 		case 237, 234, 244:
 			connectionType = CELLULAR
 		}
@@ -243,10 +244,7 @@ func (env *ShellEnvironment) getConnections() []*Connection {
 			Name:         description, // we want a relatable name, alias isn't that
 			TransmitRate: networkInterface.TransmitLinkSpeed,
 			ReceiveRate:  networkInterface.ReceiveLinkSpeed,
-		}
-
-		if SSID, OK := SSIDs[network.Name]; OK {
-			network.SSID = SSID
+			SSID:         ssid,
 		}
 
 		networks = append(networks, network)
@@ -322,13 +320,21 @@ type MIB_IF_ROW2 struct { //nolint: revive
 	OutQLen            uint64
 }
 
-func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
+var (
+	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
+	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
+	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
+	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
+)
+
+func (env *ShellEnvironment) getWiFiSSID(guid windows.GUID) string {
+	// Query wifi connection state
 	var pdwNegotiatedVersion uint32
 	var phClientHandle uint32
 	e, _, err := hWlanOpenHandle.Call(uintptr(uint32(2)), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&pdwNegotiatedVersion)), uintptr(unsafe.Pointer(&phClientHandle)))
 	if e != 0 {
 		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
+		return """"
 	}
 
 	// defer closing handle
@@ -336,42 +342,11 @@ func (env *ShellEnvironment) getAllWifiSSID() (map[string]string, error) {
 		_, _, _ = hWlanCloseHandle.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)))
 	}()
 
-	ssid := make(map[string]string)
-	// list interfaces
-	var interfaceList *WLAN_INTERFACE_INFO_LIST
-	e, _, err = hWlanEnumInterfaces.Call(uintptr(phClientHandle), uintptr(unsafe.Pointer(nil)), uintptr(unsafe.Pointer(&interfaceList)))
-	if e != 0 {
-		env.Log(Error, ""getAllWifiSSID"", err.Error())
-		return nil, err
-	}
-
-	// use first interface that is connected
-	numberOfInterfaces := int(interfaceList.dwNumberOfItems)
-	infoSize := unsafe.Sizeof(interfaceList.InterfaceInfo[0])
-	for i := 0; i < numberOfInterfaces; i++ {
-		network := (*WLAN_INTERFACE_INFO)(unsafe.Pointer(uintptr(unsafe.Pointer(&interfaceList.InterfaceInfo[0])) + uintptr(i)*infoSize))
-		if network.isState == 1 {
-			wifiInterface := strings.TrimRight(string(utf16.Decode(network.strInterfaceDescription[:])), ""\x00"")
-			ssid[wifiInterface] = env.getWiFiSSID(network, phClientHandle)
-		}
-	}
-	return ssid, nil
-}
-
-var (
-	wlanapi             = syscall.NewLazyDLL(""wlanapi.dll"")
-	hWlanOpenHandle     = wlanapi.NewProc(""WlanOpenHandle"")
-	hWlanCloseHandle    = wlanapi.NewProc(""WlanCloseHandle"")
-	hWlanEnumInterfaces = wlanapi.NewProc(""WlanEnumInterfaces"")
-	hWlanQueryInterface = wlanapi.NewProc(""WlanQueryInterface"")
-)
-
-func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHandle uint32) string {
-	// Query wifi connection state
 	var dataSize uint16
 	var wlanAttr *WLAN_CONNECTION_ATTRIBUTES
-	e, _, _ := hWlanQueryInterface.Call(uintptr(clientHandle),
-		uintptr(unsafe.Pointer(&network.InterfaceGuid)),
+
+	e, _, _ = hWlanQueryInterface.Call(uintptr(phClientHandle),
+		uintptr(unsafe.Pointer(&guid)),
 		uintptr(7), // wlan_intf_opcode_current_connection
 		uintptr(unsafe.Pointer(nil)),
 		uintptr(unsafe.Pointer(&dataSize)),
@@ -389,18 +364,6 @@ func (env *ShellEnvironment) getWiFiSSID(network *WLAN_INTERFACE_INFO, clientHan
 	return string(ssid.ucSSID[0:ssid.uSSIDLength])
 }
 
-type WLAN_INTERFACE_INFO_LIST struct { //nolint: revive
-	dwNumberOfItems uint32
-	dwIndex         uint32 //nolint: unused
-	InterfaceInfo   [256]WLAN_INTERFACE_INFO
-}
-
-type WLAN_INTERFACE_INFO struct { //nolint: revive
-	InterfaceGuid           syscall.GUID //nolint: revive
-	strInterfaceDescription [256]uint16
-	isState                 uint32
-}
-
 type WLAN_CONNECTION_ATTRIBUTES struct { //nolint: revive
 	isState                   uint32      //nolint: unused
 	wlanConnectionMode        uint32      //nolint: unused
",1,"[""8a9a022baa15befc325f87892c6bdae25b35bc33""]","[""refactor""]","1. The code removes the getAllWifiSSID function and replaces it with a more targeted getWiFiSSID approach, updating logic to only query the SSID for relevant interfaces, and simplifies the overall network connection retrieval process.
2. These changes focus on restructuring and optimizing the code for efficiency and clarity, without introducing new features or fixing bugs, which aligns with the 'refactor' label definition.
3. The 'refactor' label is appropriate because the code's external behavior (retrieving connections and SSIDs) remains the same, but the internal implementation is improved; 'feat' is not suitable since no new capability is added, and 'fix' is not appropriate as no explicit bug is addressed.
4. The 'refactor' label is justified as the changes are strictly about improving code structure and efficiency without altering observable behavior or adding features."
verify checkpoint listeners are notified,"diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",1,"[""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""test""]","1. The code changes add three new test methods to CheckpointRecordsProcessorTest, each verifying that checkpoint listeners are properly notified during different processor operations.
2. These additions are fully contained within a test file and consist solely of new test logic and assertions, matching the 'test' label definition.
3. The 'test' label is appropriate because the changes are exclusive to testing code, not production logic (so not 'feat', 'fix', or 'refactor') and do not impact documentation, CI, or build artifacts.
4. Assigning the 'test' label is correct as the commit solely adds new tests to verify functionality, with no changes to non-test code."
"add react ecosystem
add props to get color and label from a route
fix unit tests","diff --git a/package.json b/package.json
index 1ba8c4f..d1de9a0 100644
--- a/package.json
+++ b/package.json
@@ -36,14 +36,19 @@
     ""@types/node"": ""^9.3.0"",
     ""@types/react"": ""^16.0.34"",
     ""@types/react-dom"": ""^16.0.3"",
+    ""@types/react-motion"": ""^0.0.25"",
     ""bootstrap-sass"": ""^3.3.7"",
     ""highcharts"": ""^6.0.4"",
     ""html2canvas"": ""^1.0.0-alpha.9"",
+    ""immer"": ""^1.2.1"",
     ""lodash"": ""^4.17.4"",
     ""moment"": ""^2.20.1"",
     ""normalize.css"": ""^8.0.0"",
-    ""react"": ""^16.2.0"",
-    ""react-dom"": ""^16.2.0"",
+    ""react"": ""^16.3.1"",
+    ""react-dom"": ""^16.3.1"",
+    ""react-motion"": ""^0.5.2"",
+    ""react-redux"": ""^5.0.7"",
+    ""redux"": ""^3.7.2"",
     ""rxjs"": ""^5.5.6"",
     ""vue"": ""^2.5.13"",
     ""vue-plugin-webextension-i18n"": ""^0.1.0"",
diff --git a/yarn.lock b/yarn.lock
index c8898d8..5d0fc9f 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -187,6 +187,12 @@
     ""@types/node"" ""*""
     ""@types/react"" ""*""
 
+""@types/react-motion@^0.0.25"":
+  version ""0.0.25""
+  resolved ""https://registry.npmjs.org/@types/react-motion/-/react-motion-0.0.25.tgz#2445745ee8e8e6149faa47a36ff6b0d4c21dbf94""
+  dependencies:
+    ""@types/react"" ""*""
+
 ""@types/react@*"", ""@types/react@^16.0.34"":
   version ""16.0.40""
   resolved ""https://registry.npmjs.org/@types/react/-/react-16.0.40.tgz#caabc2296886f40b67f6fc80f0f3464476461df9""
@@ -3837,6 +3843,10 @@ hoek@4.x.x:
   version ""4.2.1""
   resolved ""https://registry.npmjs.org/hoek/-/hoek-4.2.1.tgz#9634502aa12c445dd5a7c5734b572bb8738aacbb""
 
+hoist-non-react-statics@^2.5.0:
+  version ""2.5.0""
+  resolved ""https://registry.npmjs.org/hoist-non-react-statics/-/hoist-non-react-statics-2.5.0.tgz#d2ca2dfc19c5a91c5a6615ce8e564ef0347e2a40""
+
 home-or-tmp@^2.0.0:
   version ""2.0.0""
   resolved ""https://registry.npmjs.org/home-or-tmp/-/home-or-tmp-2.0.0.tgz#e36c3f2d2cae7d746a857e38d18d5f32a7882db8""
@@ -4004,6 +4014,10 @@ ignore@^3.3.5:
   version ""3.3.7""
   resolved ""https://registry.npmjs.org/ignore/-/ignore-3.3.7.tgz#612289bfb3c220e186a58118618d5be8c1bab021""
 
+immer@^1.2.1:
+  version ""1.2.1""
+  resolved ""https://registry.npmjs.org/immer/-/immer-1.2.1.tgz#96e2ae29cdfc428f28120b832701931b92fa597c""
+
 import-local@^1.0.0:
   version ""1.0.0""
   resolved ""https://registry.npmjs.org/import-local/-/import-local-1.0.0.tgz#5e4ffdc03f4fe6c009c6729beb29631c2f8227bc""
@@ -4104,7 +4118,7 @@ interpret@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/interpret/-/interpret-1.1.0.tgz#7ed1b1410c6a0e0f78cf95d3b8440c63f78b8614""
 
-invariant@^2.2.2:
+invariant@^2.0.0, invariant@^2.2.2:
   version ""2.2.4""
   resolved ""https://registry.npmjs.org/invariant/-/invariant-2.2.4.tgz#610f3c92c9359ce1db616e538008d23ff35158e6""
   dependencies:
@@ -5040,6 +5054,10 @@ locate-path@^2.0.0:
     p-locate ""^2.0.0""
     path-exists ""^3.0.0""
 
+lodash-es@^4.17.5, lodash-es@^4.2.1:
+  version ""4.17.8""
+  resolved ""https://registry.npmjs.org/lodash-es/-/lodash-es-4.17.8.tgz#6fa8c8c5d337481df0bdf1c0d899d42473121e45""
+
 lodash._reinterpolate@~3.0.0:
   version ""3.0.0""
   resolved ""https://registry.npmjs.org/lodash._reinterpolate/-/lodash._reinterpolate-3.0.0.tgz#0ccf2d89166af03b3663c796538b75ac6e114d9d""
@@ -5149,7 +5167,7 @@ lodash@4.17.2:
   version ""4.17.2""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.2.tgz#34a3055babe04ce42467b607d700072c7ff6bf42""
 
-lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
+lodash@4.x, lodash@^4.0.0, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.16.3, lodash@^4.17.2, lodash@^4.17.3, lodash@^4.17.4, lodash@^4.17.5, lodash@^4.2.0, lodash@^4.2.1, lodash@^4.3.0, lodash@~4.17.4:
   version ""4.17.5""
   resolved ""https://registry.npmjs.org/lodash/-/lodash-4.17.5.tgz#99a92d65c0272debe8c96b6057bc8fbfa3bed511""
 
@@ -6467,7 +6485,7 @@ promise@^7.1.1:
   dependencies:
     asap ""~2.0.3""
 
-prop-types@^15.6.0:
+prop-types@^15.5.8, prop-types@^15.6.0:
   version ""15.6.1""
   resolved ""https://registry.npmjs.org/prop-types/-/prop-types-15.6.1.tgz#36644453564255ddda391191fb3a125cbdf654ca""
   dependencies:
@@ -6574,7 +6592,7 @@ quick-lru@^1.0.0:
   version ""1.1.0""
   resolved ""https://registry.npmjs.org/quick-lru/-/quick-lru-1.1.0.tgz#4360b17c61136ad38078397ff11416e186dcfbb8""
 
-raf@3.4.0:
+raf@3.4.0, raf@^3.1.0:
   version ""3.4.0""
   resolved ""https://registry.npmjs.org/raf/-/raf-3.4.0.tgz#a28876881b4bc2ca9117d4138163ddb80f781575""
   dependencies:
@@ -6645,9 +6663,9 @@ react-dev-utils@^5.0.0:
     strip-ansi ""3.0.1""
     text-table ""0.2.0""
 
-react-dom@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.2.0.tgz#69003178601c0ca19b709b33a83369fe6124c044""
+react-dom@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react-dom/-/react-dom-16.3.1.tgz#6a3c90a4fb62f915bdbcf6204422d93a7d4ca573""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6658,9 +6676,28 @@ react-error-overlay@^4.0.0:
   version ""4.0.0""
   resolved ""https://registry.npmjs.org/react-error-overlay/-/react-error-overlay-4.0.0.tgz#d198408a85b4070937a98667f500c832f86bd5d4""
 
-react@^16.2.0:
-  version ""16.2.0""
-  resolved ""https://registry.npmjs.org/react/-/react-16.2.0.tgz#a31bd2dab89bff65d42134fa187f24d054c273ba""
+react-motion@^0.5.2:
+  version ""0.5.2""
+  resolved ""https://registry.npmjs.org/react-motion/-/react-motion-0.5.2.tgz#0dd3a69e411316567927917c6626551ba0607316""
+  dependencies:
+    performance-now ""^0.2.0""
+    prop-types ""^15.5.8""
+    raf ""^3.1.0""
+
+react-redux@^5.0.7:
+  version ""5.0.7""
+  resolved ""https://registry.npmjs.org/react-redux/-/react-redux-5.0.7.tgz#0dc1076d9afb4670f993ffaef44b8f8c1155a4c8""
+  dependencies:
+    hoist-non-react-statics ""^2.5.0""
+    invariant ""^2.0.0""
+    lodash ""^4.17.5""
+    lodash-es ""^4.17.5""
+    loose-envify ""^1.1.0""
+    prop-types ""^15.6.0""
+
+react@^16.3.1:
+  version ""16.3.1""
+  resolved ""https://registry.npmjs.org/react/-/react-16.3.1.tgz#4a2da433d471251c69b6033ada30e2ed1202cfd8""
   dependencies:
     fbjs ""^0.8.16""
     loose-envify ""^1.1.0""
@@ -6788,6 +6825,15 @@ reduce-function-call@^1.0.1:
   dependencies:
     balanced-match ""^0.4.2""
 
+redux@^3.7.2:
+  version ""3.7.2""
+  resolved ""https://registry.npmjs.org/redux/-/redux-3.7.2.tgz#06b73123215901d25d065be342eb026bc1c8537b""
+  dependencies:
+    lodash ""^4.2.1""
+    lodash-es ""^4.2.1""
+    loose-envify ""^1.1.0""
+    symbol-observable ""^1.0.3""
+
 regenerate@^1.2.1:
   version ""1.3.3""
   resolved ""https://registry.npmjs.org/regenerate/-/regenerate-1.3.3.tgz#0c336d3980553d755c39b586ae3b20aa49c82b7f""
@@ -7811,6 +7857,10 @@ symbol-observable@1.0.1:
   version ""1.0.1""
   resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.0.1.tgz#8340fc4702c3122df5d22288f88283f513d3fdd4""
 
+symbol-observable@^1.0.3:
+  version ""1.2.0""
+  resolved ""https://registry.npmjs.org/symbol-observable/-/symbol-observable-1.2.0.tgz#c22688aed4eab3cdc2dfeacbb561660560a00804""
+
 symbol-tree@^3.2.2:
   version ""3.2.2""
   resolved ""https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.2.tgz#ae27db38f660a7ae2e1c3b7d1bc290819b8519e6""

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
index 4d771d6..9f9683c 100644
--- a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
+++ b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
@@ -9,9 +9,6 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -132,6 +129,33 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -599,9 +623,6 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -783,12 +804,15 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -805,17 +829,20 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
@@ -1374,9 +1401,6 @@ exports[`renders non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -1497,6 +1521,33 @@ exports[`renders non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -2072,9 +2123,6 @@ exports[`renders shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -2256,12 +2304,15 @@ exports[`renders shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -2278,17 +2329,20 @@ exports[`renders shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
",3,"[""7e04a5e829d7416e312ac342a00a11787745753b"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""87427fe39d165bee2acedde8dbaa237cca3fb61e""]","[""build"", ""feat"", ""test""]","1. The changes to package.json and yarn.lock add new dependencies related to React and Redux, which are necessary for the React ecosystem setup and updating build tooling.
2. The modifications in src/components/BottomNavigation.js introduce new props (getColor, getLabelText) and extend the component's feature set, representing new functionality.
3. The updates to the snapshot files in __snapshots__/BottomNavigation.test.js.snap adjust the expected output of unit tests to match the new or changed component behavior, reflecting maintenance of test artifacts.
4. The 'build' label is appropriate for dependency and build system changes; 'feat' is correct for new component props and capabilities; 'test' is correct for snapshot/test updates, and alternative labels like 'fix' or 'refactor' are not as accurate since the main motivations are ecosystem setup, feature addition, and test maintenance."
"implement array flatten support
cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.
use connect instead of begin to avoid nesting transactions","diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/ibis/backends/duckdb/__init__.py b/ibis/backends/duckdb/__init__.py
index 2006f59..bb2028e 100644
--- a/ibis/backends/duckdb/__init__.py
+++ b/ibis/backends/duckdb/__init__.py
@@ -1180,7 +1180,7 @@ WHERE catalog_name = :database""""""
     def _register_udfs(self, expr: ir.Expr) -> None:
         import ibis.expr.operations as ops
 
-        with self.begin() as con:
+        with self.con.connect() as con:
             for udf_node in expr.op().find(ops.ScalarUDF):
                 compile_func = getattr(
                     self, f""_compile_{udf_node.__input_type__.name.lower()}_udf""
",3,"[""d3c754f09502be979e5dcc79f968b15052590bd0"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""6889543bec720e7e7da66535e1012cb66edfe081""]","[""feat"", ""refactor"", ""fix""]","1. The code adds support for ArrayFlatten in the Snowflake registry, cleans up boolean logic in Go code for clarity, and replaces 'begin' with 'connect' to avoid nested transactions in the DuckDB backend.
2. The addition of ArrayFlatten is a new feature (aligns with 'feat'), the boolean logic rewrite improves code clarity without changing behavior (aligns with 'refactor'), and using 'connect' instead of 'begin' prevents incorrect nested transactions (aligns with 'fix').
3. 'feat' is appropriate for the new array flatten capability, 'refactor' for the improved control flow readability, and 'fix' for correcting transaction handling; none of the changes are solely about tests, docs, CI/CD, or build system, so those labels are not applicable.
4. The assigned labels 'feat', 'refactor', and 'fix' are justified as each change directly matches these label definitions: new feature, code cleanup, and bug fix, respectively."
removing automatic page push on nav,"diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage
",1,"[""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97""]","[""test""]","1. The code change removes an automatic page navigation trigger from a test file, specifically deleting the 'onPageDidEnter' method that pushed a new page after a timeout.
2. This change is made entirely within a test file and modifies the test logic, aligning directly with the 'test' object label definition for changes scoped to test artifacts.
3. 'test' is appropriate because the modification is limited to test code; it is not a 'fix' (no bug resolution in production code), 'feat' (no new feature), or 'refactor' (not general code restructuring), nor does it affect documentation, build, or CI/CD files.
4. The 'test' label is correct because the change solely alters test behavior within a test file, matching the object label criteria."
"treeview width fix

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/tests/playwright/pages/Dashboard/TreeView.ts b/tests/playwright/pages/Dashboard/TreeView.ts
index 9cc622b..75c02c0 100644
--- a/tests/playwright/pages/Dashboard/TreeView.ts
+++ b/tests/playwright/pages/Dashboard/TreeView.ts
@@ -23,10 +23,24 @@ export class TreeViewPage extends BasePage {
   }
 
   async verifyVisibility({ isVisible }: { isVisible: boolean }) {
-    if (isVisible) {
-      await expect(this.get()).toBeVisible();
+    await this.rootPage.waitForTimeout(1000);
+
+    const domElement = await this.get();
+    // get width of treeview dom element
+    const width = (await domElement.boundingBox()).width;
+
+    // if (isVisible) {
+    //   await expect(this.get()).toBeVisible();
+    // } else {
+    //   await expect(this.get()).not.toBeVisible();
+    // }
+
+    // border for treeview is 1px
+    // if not-visible, width should be < 5;
+    if (!isVisible) {
+      expect(width).toBeLessThan(5);
     } else {
-      await expect(this.get()).not.toBeVisible();
+      expect(width).toBeGreaterThan(5);
     }
   }
 
",1,"[""efeb30f26252ef4791ef2a02d83827b7f0c45462""]","[""test""]","1. The code modifies a test file (`tests/playwright/pages/Dashboard/TreeView.ts`) by updating the `verifyVisibility` method to check the width of the treeview DOM element instead of relying solely on Playwright's visibility assertions.
2. These changes are entirely within a test artifact and adjust the logic used to verify UI state in automated tests, which aligns with the 'test' label definition.
3. 'test' is appropriate because the modifications are limited to test logic; 'fix' could be considered if it explicitly addressed a bug, but the scope and location indicate this is a test improvement, not a core code fix or refactor.
4. The 'test' label is correct because all changes are confined to test logic and artifacts, with no impact on production or build code."
Fix windows build,"diff --git a/src/fs/mounts/mod.rs b/src/fs/mounts/mod.rs
index a7f8188..662e2f5 100644
--- a/src/fs/mounts/mod.rs
+++ b/src/fs/mounts/mod.rs
@@ -29,11 +29,14 @@ impl std::error::Error for Error {}
 
 impl std::fmt::Display for Error {
     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        // Allow unreachable_patterns for windows build
+        #[allow(unreachable_patterns)]
         match self {
             #[cfg(target_os = ""macos"")]
             Error::GetFSStatError(err) => write!(f, ""getfsstat failed: {err}""),
             #[cfg(target_os = ""linux"")]
-            Error::IOError(err) => write!(f, ""failed to read /proc/mounts: {err}"")
+            Error::IOError(err) => write!(f, ""failed to read /proc/mounts: {err}""),
+            _ => write!(f, ""Unknown error""),
         }
     }
 }
\ No newline at end of file
diff --git a/src/main.rs b/src/main.rs
index 483e14d..ca28081 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -62,6 +62,8 @@ mod theme;
 // to `clap` is complete.
 lazy_static! {
     static ref ALL_MOUNTS: HashMap<PathBuf, mounts::MountedFs> = {
+        // Allow unused_mut for windows
+        #[allow(unused_mut)]
         let mut mount_map: HashMap<PathBuf, mounts::MountedFs> = HashMap::new();
 
         #[cfg(any(target_os = ""linux"", target_os = ""macos""))]
",1,"[""81ca000c6a7e7435809081c60be37dda23458ec8""]","[""build""]","1. The code changes add Rust attribute annotations to suppress specific compiler warnings (unreachable_patterns and unused_mut) to support successful builds on Windows, and introduce a fallback match arm to handle unknown error variants.
2. These changes are directly related to ensuring the code builds without errors or warnings on Windows, aligning with the 'build' label which covers modifications affecting the build process or build system compatibility.
3. The 'build' label is appropriate because the changes neither introduce new features ('feat'), fix runtime bugs ('fix'), restructure code for clarity ('refactor'), nor are they dedicated to documentation, tests, or CI/CD scripts; their sole intent is to address build issues across platforms.
4. The 'build' label accurately reflects that the commit is focused on enabling successful compilation and suppressing build-time issues for Windows targets."
"dashboard removed unused code
fix `get-deploy-tags.sh`
await job creation to ensure asserted event sequence","diff --git a/api/chalicelib/core/dashboard.py b/api/chalicelib/core/dashboard.py
index e5bc800..1afa105 100644
--- a/api/chalicelib/core/dashboard.py
+++ b/api/chalicelib/core/dashboard.py
@@ -126,13 +126,6 @@ SESSIONS_META_FIELDS = {""revId"": ""rev_id"",
                         ""browser"": ""user_browser""}
 
 
-def __get_domains_errors_neutral(rows):
-    neutral = {l: 0 for l in [i for k in [list(v.keys()) for v in rows] for i in k]}
-    if len(neutral.keys()) == 0:
-        neutral = {""All"": 0}
-    return neutral
-
-
 def get_processed_sessions(project_id, startTimestamp=TimeUTC.now(delta_days=-1),
                            endTimestamp=TimeUTC.now(),
                            density=7, **args):

diff --git a/.circleci/get-deploy-tags.sh b/.circleci/get-deploy-tags.sh
index f80c8cb..7ddfa62 100755
--- a/.circleci/get-deploy-tags.sh
+++ b/.circleci/get-deploy-tags.sh
@@ -20,7 +20,7 @@
 set -euo pipefail
 
 DOCKER_IMAGE_TAG=${1}
-DOCKER_IMAGE=""quay.io/influxdb/fusion""
+DOCKER_IMAGE=""quay.io/influxdb/iox""
 APP_NAME=""IOx""
 
 DOCKER_IMAGE_DIGEST=""$(docker image inspect ""${DOCKER_IMAGE}:${DOCKER_IMAGE_TAG}"" --format '{{ if eq (len .RepoDigests) 1 }}{{index .RepoDigests 0}}{{ end }}')""

diff --git a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
index 9ffa1fa..4333db0 100644
--- a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
+++ b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
@@ -114,12 +114,18 @@ public class BoundaryEventTest {
     ENGINE.deployment().withXmlResource(MULTIPLE_SEQUENCE_FLOWS).deploy();
     final long workflowInstanceKey = ENGINE.workflowInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    // when
     RecordingExporter.timerRecords()
         .withHandlerNodeId(""timer"")
         .withIntent(TimerIntent.CREATED)
         .withWorkflowInstanceKey(workflowInstanceKey)
         .getFirst();
+
+    RecordingExporter.jobRecords(JobIntent.CREATED)
+        .withType(""type"")
+        .withWorkflowInstanceKey(workflowInstanceKey)
+        .getFirst();
+
+    // when
     ENGINE.increaseTime(Duration.ofMinutes(1));
 
     // then
",3,"[""b7b1d2b315443e1854403c8fe8f871c4632b5d31"", ""6786fd5955b064021f5b6d6a630453351d683fae"", ""a8d1a60fd48d3fbd76d4271987a1b0f538d498f1""]","[""refactor"", ""cicd"", ""test""]","1. The commit removes an unused private function from a Python dashboard module, changes a Docker image name in a CI shell script, and updates a Java test to await job creation before advancing time.
2. Removing the unused function is a structural cleanup aligning with 'refactor'; changing the image name in a CI script is a configuration update for deployment, matching 'cicd'; updating test logic to ensure correct event sequencing is a modification of test code, fitting 'test'.
3. 'refactor' is appropriate for code removal that doesn't affect behavior, not 'fix' or 'feat'; 'cicd' is correct since the shell script is CI-specific, not 'build' (which would apply to build system changes); 'test' is correct as the changes are isolated to test logic rather than production code or bug fixes.
4. The assigned labels ('refactor', 'cicd', 'test') accurately reflect the commit's distinct changes: code cleanup, CI configuration update, and test logic improvement, each mapped to its respective category."
get ip from forwarded header,"diff --git a/kousa/lib/broth/socket_handler.ex b/kousa/lib/broth/socket_handler.ex
index d142135..5828f30 100644
--- a/kousa/lib/broth/socket_handler.ex
+++ b/kousa/lib/broth/socket_handler.ex
@@ -22,7 +22,7 @@ defmodule Broth.SocketHandler do
   ## initialization boilerplate
 
   @impl true
-  def init(request = %{peer: {ip, _reverse_port}}, _state) do
+  def init(request, _state) do
     props = :cowboy_req.parse_qs(request)
 
     compression =
@@ -37,10 +37,16 @@ defmodule Broth.SocketHandler do
         _ -> :json
       end
 
+    ip =
+      case request.headers do
+        %{""x-forwarded-for"" => v} -> v
+        _ -> nil
+      end
+
     state = %__MODULE__{
       awaiting_init: true,
       user_id: nil,
-      ip: IP.to_string(ip),
+      ip: ip,
       encoding: encoding,
       compression: compression,
       callers: get_callers(request)
diff --git a/kousa/test/_support/ws_client.ex b/kousa/test/_support/ws_client.ex
index aeca704..125da17 100644
--- a/kousa/test/_support/ws_client.ex
+++ b/kousa/test/_support/ws_client.ex
@@ -19,7 +19,9 @@ defmodule BrothTest.WsClient do
 
     @api_url
     |> Path.join(""socket"")
-    |> WebSockex.start_link(__MODULE__, nil, extra_headers: [{""user-agent"", ancestors}])
+    |> WebSockex.start_link(__MODULE__, nil,
+      extra_headers: [{""user-agent"", ancestors}, {""x-forwarded-for"", ""127.0.0.1""}]
+    )
   end
 
   ###########################################################################
",1,"[""2f5718743a830d40ddf272ad46f253dbb6d08cff""]","[""fix""]","1. The code modifies the socket handler to extract the IP address from the 'x-forwarded-for' header instead of the peer tuple, and updates test support code to include this header in test connections.
2. This change addresses an issue where the correct client IP was not being obtained in proxied environments, which is a bug fix aligning with the 'fix' label definition.
3. The 'fix' label is appropriate because the change corrects faulty behavior in IP extraction, rather than introducing a new feature ('feat') or simply restructuring code ('refactor'); the test file edit is a necessary adjustment to support the fix, not a new or updated test case itself, so 'test' is not applicable.
4. The 'fix' label accurately reflects the intent and scope of the changes, which resolve a specific behavioral bug in how client IPs are determined."
"await job creation to ensure asserted event sequence
reintroduce timeout for assertion

The timeout had been removed by a previous commit. Without the timeout the test might be flaky.
Also removed obsolete code","diff --git a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
index 9ffa1fa..4333db0 100644
--- a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
+++ b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
@@ -114,12 +114,18 @@ public class BoundaryEventTest {
     ENGINE.deployment().withXmlResource(MULTIPLE_SEQUENCE_FLOWS).deploy();
     final long workflowInstanceKey = ENGINE.workflowInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    // when
     RecordingExporter.timerRecords()
         .withHandlerNodeId(""timer"")
         .withIntent(TimerIntent.CREATED)
         .withWorkflowInstanceKey(workflowInstanceKey)
         .getFirst();
+
+    RecordingExporter.jobRecords(JobIntent.CREATED)
+        .withType(""type"")
+        .withWorkflowInstanceKey(workflowInstanceKey)
+        .getFirst();
+
+    // when
     ENGINE.increaseTime(Duration.ofMinutes(1));
 
     // then

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
index d0ee4f3..c2ab83c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -13,6 +13,7 @@ import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTI
 import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
 import static java.util.function.Predicate.isEqual;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.ArgumentMatchers.eq;
@@ -30,7 +31,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.streamprocessor.StreamProcessor.Phase;
 import io.camunda.zeebe.streamprocessor.StreamProcessorMode;
-import org.awaitility.Awaitility;
 import org.junit.Rule;
 import org.junit.Test;
 import org.mockito.InOrder;
@@ -71,7 +71,7 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayUntilEnd);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING));
 
@@ -163,7 +163,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
 
     // when
@@ -210,7 +210,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
     streamProcessor.pauseProcessing().join();
     replayContinuously.writeBatch(
@@ -244,7 +244,7 @@ public final class StreamProcessorReplayModeTest {
     // then
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> {
               final var lastProcessedPosition = getLastProcessedPosition(replayContinuously);
@@ -273,8 +273,7 @@ public final class StreamProcessorReplayModeTest {
 
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
-        .until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
+    await().until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
 
     // then
     assertThat(replayContinuously.getLastSuccessfulProcessedRecordPosition())
@@ -285,7 +284,6 @@ public final class StreamProcessorReplayModeTest {
   @Test
   public void shouldNotSetLastProcessedPositionIfLessThanSnapshotPosition() {
     // given
-    final var commandPositionBeforeSnapshot = 1L;
     final var snapshotPosition = 2L;
 
     startStreamProcessor(replayContinuously);
@@ -298,23 +296,20 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayContinuously);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPLAY));
 
-    final var eventPosition =
-        replayContinuously.writeEvent(
-            ELEMENT_ACTIVATING,
-            RECORD,
-            writer -> writer.sourceRecordPosition(commandPositionBeforeSnapshot));
-
     // then
     final var lastProcessedPositionState = replayContinuously.getLastProcessedPositionState();
 
-    assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
-        .describedAs(
-            ""Expected that the last processed position is not less than the snapshot position"")
-        .isEqualTo(snapshotPosition);
+    await()
+        .untilAsserted(
+            () ->
+                assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
+                    .describedAs(
+                        ""Expected that the last processed position is not less than the snapshot position"")
+                    .isEqualTo(snapshotPosition));
   }
 
   private StreamProcessor startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
",2,"[""a8d1a60fd48d3fbd76d4271987a1b0f538d498f1"", ""0d23f1b3ed22e615b9611bb4eae01d2241e64dff""]","[""test"", ""refactor""]","1. The changes are exclusively within test files, where one test adds a missing await for job creation to ensure correct event sequencing, and another test reintroduces a timeout and cleans up obsolete code to improve reliability and clarity.
2. These modifications directly update test logic and structure, aligning with the 'test' label, as all changes are scoped to test artifacts; the removal of obsolete code and improved assertions also enhance test maintainability, which could be considered 'refactor' but remains within test files.
3. The 'test' label is most appropriate because all changes are to test files and focus on test correctness and reliability; 'refactor' is not needed as a separate label since the refactoring occurs entirely within test logic, and per the rules, 'test' takes precedence for artifact-scoped changes.
4. The 'test' label correctly captures that all modifications are dedicated to improving and maintaining test logic, including reliability and code cleanliness."
"process CommandDistribution ACKNOWLEDGED event

Adds an EventApplier for the CommandDistribution ACKNOWLEDGED event. This applier will be responsible to remove a pending distribution from the state. This will be used to mark the distribution to a specific partition as completed.
reintroduce timeout for assertion

The timeout had been removed by a previous commit. Without the timeout the test might be flaky.
Also removed obsolete code
add Expr.equals benchmark","diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java
new file mode 100644
index 0000000..4abf2e3
--- /dev/null
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/CommandDistributionAcknowledgedApplier.java
@@ -0,0 +1,28 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.state.appliers;
+
+import io.camunda.zeebe.engine.state.TypedEventApplier;
+import io.camunda.zeebe.engine.state.mutable.MutableDistributionState;
+import io.camunda.zeebe.protocol.impl.record.value.distribution.CommandDistributionRecord;
+import io.camunda.zeebe.protocol.record.intent.CommandDistributionIntent;
+
+public final class CommandDistributionAcknowledgedApplier
+    implements TypedEventApplier<CommandDistributionIntent, CommandDistributionRecord> {
+
+  private final MutableDistributionState distributionState;
+
+  public CommandDistributionAcknowledgedApplier(final MutableDistributionState distributionState) {
+    this.distributionState = distributionState;
+  }
+
+  @Override
+  public void applyState(final long key, final CommandDistributionRecord value) {
+    distributionState.removePendingDistribution(key, value.getPartitionId());
+  }
+}
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
index a72309b..4793315 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
@@ -284,6 +284,9 @@ public final class EventAppliers implements EventApplier {
         CommandDistributionIntent.DISTRIBUTING,
         new CommandDistributionDistributingApplier(distributionState));
     register(
+        CommandDistributionIntent.ACKNOWLEDGED,
+        new CommandDistributionAcknowledgedApplier(distributionState));
+    register(
         CommandDistributionIntent.FINISHED,
         new CommandDistributionFinishedApplier(distributionState));
   }

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
index d0ee4f3..c2ab83c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -13,6 +13,7 @@ import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTI
 import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
 import static java.util.function.Predicate.isEqual;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.ArgumentMatchers.eq;
@@ -30,7 +31,6 @@ import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.streamprocessor.StreamProcessor.Phase;
 import io.camunda.zeebe.streamprocessor.StreamProcessorMode;
-import org.awaitility.Awaitility;
 import org.junit.Rule;
 import org.junit.Test;
 import org.mockito.InOrder;
@@ -71,7 +71,7 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayUntilEnd);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING));
 
@@ -163,7 +163,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
 
     // when
@@ -210,7 +210,7 @@ public final class StreamProcessorReplayModeTest {
         command().processInstance(ACTIVATE_ELEMENT, RECORD),
         event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
 
-    Awaitility.await(""should have replayed first events"")
+    await(""should have replayed first events"")
         .until(replayContinuously::getLastSuccessfulProcessedRecordPosition, (pos) -> pos > 0);
     streamProcessor.pauseProcessing().join();
     replayContinuously.writeBatch(
@@ -244,7 +244,7 @@ public final class StreamProcessorReplayModeTest {
     // then
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> {
               final var lastProcessedPosition = getLastProcessedPosition(replayContinuously);
@@ -273,8 +273,7 @@ public final class StreamProcessorReplayModeTest {
 
     verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
 
-    Awaitility.await()
-        .until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
+    await().until(() -> getLastProcessedPosition(replayContinuously), isEqual(commandPosition));
 
     // then
     assertThat(replayContinuously.getLastSuccessfulProcessedRecordPosition())
@@ -285,7 +284,6 @@ public final class StreamProcessorReplayModeTest {
   @Test
   public void shouldNotSetLastProcessedPositionIfLessThanSnapshotPosition() {
     // given
-    final var commandPositionBeforeSnapshot = 1L;
     final var snapshotPosition = 2L;
 
     startStreamProcessor(replayContinuously);
@@ -298,23 +296,20 @@ public final class StreamProcessorReplayModeTest {
     // when
     startStreamProcessor(replayContinuously);
 
-    Awaitility.await()
+    await()
         .untilAsserted(
             () -> assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPLAY));
 
-    final var eventPosition =
-        replayContinuously.writeEvent(
-            ELEMENT_ACTIVATING,
-            RECORD,
-            writer -> writer.sourceRecordPosition(commandPositionBeforeSnapshot));
-
     // then
     final var lastProcessedPositionState = replayContinuously.getLastProcessedPositionState();
 
-    assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
-        .describedAs(
-            ""Expected that the last processed position is not less than the snapshot position"")
-        .isEqualTo(snapshotPosition);
+    await()
+        .untilAsserted(
+            () ->
+                assertThat(lastProcessedPositionState.getLastSuccessfulProcessedRecordPosition())
+                    .describedAs(
+                        ""Expected that the last processed position is not less than the snapshot position"")
+                    .isEqualTo(snapshotPosition));
   }
 
   private StreamProcessor startStreamProcessor(final StreamProcessorRule streamProcessorRule) {

diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index 78305bb..9c7e6d7 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -1,3 +1,4 @@
+import copy
 import functools
 import itertools
 import string
@@ -340,8 +341,9 @@ def test_execute(benchmark, expression_fn, pt):
     benchmark(expr.execute)
 
 
-def test_repr_tpc_h02(benchmark):
-    part = ibis.table(
+@pytest.fixture
+def part():
+    return ibis.table(
         dict(
             p_partkey=""int64"",
             p_size=""int64"",
@@ -350,7 +352,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""part"",
     )
-    supplier = ibis.table(
+
+
+@pytest.fixture
+def supplier():
+    return ibis.table(
         dict(
             s_suppkey=""int64"",
             s_nationkey=""int64"",
@@ -362,7 +368,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""supplier"",
     )
-    partsupp = ibis.table(
+
+
+@pytest.fixture
+def partsupp():
+    return ibis.table(
         dict(
             ps_partkey=""int64"",
             ps_suppkey=""int64"",
@@ -370,14 +380,25 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""partsupp"",
     )
-    nation = ibis.table(
+
+
+@pytest.fixture
+def nation():
+    return ibis.table(
         dict(n_nationkey=""int64"", n_regionkey=""int64"", n_name=""string""),
         name=""nation"",
     )
-    region = ibis.table(
+
+
+@pytest.fixture
+def region():
+    return ibis.table(
         dict(r_regionkey=""int64"", r_name=""string""), name=""region""
     )
 
+
+@pytest.fixture
+def tpc_h02(part, supplier, partsupp, nation, region):
     REGION = ""EUROPE""
     SIZE = 25
     TYPE = ""BRASS""
@@ -420,7 +441,7 @@ def test_repr_tpc_h02(benchmark):
         ]
     )
 
-    expr = q.sort_by(
+    return q.sort_by(
         [
             ibis.desc(q.s_acctbal),
             q.n_name,
@@ -429,7 +450,9 @@ def test_repr_tpc_h02(benchmark):
         ]
     ).limit(100)
 
-    benchmark(repr, expr)
+
+def test_repr_tpc_h02(benchmark, tpc_h02):
+    benchmark(repr, tpc_h02)
 
 
 def test_repr_huge_union(benchmark):
@@ -478,3 +501,7 @@ def test_complex_datatype_builtins(benchmark, func):
         )
     )
     benchmark(func, datatype)
+
+
+def test_large_expr_equals(benchmark, tpc_h02):
+    benchmark(ir.Expr.equals, tpc_h02, copy.deepcopy(tpc_h02))
",3,"[""6f4c06076abff94f8bb5c634beaba55483a78b72"", ""0d23f1b3ed22e615b9611bb4eae01d2241e64dff"", ""b700285c1f27588922d9c56527cee721bb884682""]","[""feat"", ""refactor"", ""test""]","1. The commit introduces a new event applier class (`CommandDistributionAcknowledgedApplier`) and registers it, modifies a test to reintroduce a timeout for assertions and removes obsolete code, and adds a new benchmark test for `Expr.equals`.
2. Adding the event applier and its registration implements new behavior, matching the 'feat' label; reintroducing a timeout and removing obsolete code in tests are maintenance/cleanup, aligning with 'refactor'; the new benchmark test is a pure test addition, aligning with the 'test' label.
3. 'feat' is appropriate because the applier and registration are new features, not just bug fixes or refactoring; 'refactor' is justified because test maintenance and code cleanup do not add features or fix bugs; 'test' is correct for the benchmark addition since it is purely test logic, not production code or documentation.
4. The assigned labels 'feat', 'refactor', and 'test' are appropriate because the commit introduces new feature logic, improves test code structure, and adds new test coverage, each matching their label definitions."
"update README.md about the NPM package
add canonical `_name` to edge packages","diff --git a/README.md b/README.md
index 9faf168..bbb5b5c 100644
--- a/README.md
+++ b/README.md
@@ -126,23 +126,24 @@ pacman -S git-cliff
 
 ### From NPM
 
-[git-cliff](https://www.npmjs.com/package/git-cliff) can be installed from NPM:
+
+You can install and run [git-cliff](https://www.npmjs.com/package/git-cliff) with a single command:
 
 ```sh
-yarn add -D git-cliff
+npx git-cliff@latest
 ```
 
-or:
+Also, if you want to add `git-cliff` to your project:
 
 ```sh
+# with yarn
+yarn add -D git-cliff
+
+# with npm
 npm install git-cliff --save-dev
 ```
 
-You can also use `git-cliff` directly with `npx`:
-
-```sh
-npx git-cliff
-```
+Afterwards, you can run `git-cliff` via `npm exec git-cliff` or `npx git-cliff@latest`.
 
 ### From MacPorts
 

diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index e92e3c9..0b7a11a 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -53,6 +53,7 @@ async function loadWorkspace (dir: string) {
   }
 
   const rename = (from: string, to: string) => {
+    find(from).data._name = find(from).data.name
     find(from).data.name = to
     for (const pkg of packages) {
       pkg.updateDeps((dep) => {
",2,"[""e0177c25e13812306aab0b0991562d58b6d14767"", ""573f87edf9bdc19c9c4c3a978fad6ed3ce788f5f""]","[""docs"", ""build""]","1. The changes include updates to the README.md file to clarify NPM installation instructions and a code modification in scripts/bump-edge.ts to add a canonical _name property to edge packages during package renaming.
2. The README.md modifications are purely textual and instructional, aligning with the 'docs' label, while the script change alters the build/package metadata handling, which is a build system concern, aligning with the 'build' label.
3. 'docs' is appropriate for the README changes since they do not affect code logic, and 'build' is appropriate for the script change because it affects package naming and metadata, not runtime features or bug fixes; neither 'feat', 'fix', 'refactor', nor 'test' apply as no new features, bug fixes, structural refactors, or test changes are present.
4. The 'docs' and 'build' labels are correctly assigned as the changes are strictly limited to documentation and build/package configuration logic."
convert `run_tag_values_test_case` to a function,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
",1,"[""1db13ec43727aca872a0f3836e4023ed85db665e""]","[""refactor""]","1. The code replaces a macro (`run_tag_values_test_case!`) with an equivalent async function (`run_tag_values_test_case`) and updates all test invocations to use the new function form, without changing the external behavior or test logic.
2. This aligns with the 'refactor' label, which is defined as restructuring existing code to improve readability or maintainability without altering its behavior, as the change modernizes and clarifies the test helper usage.
3. The change is not a 'feat' (no new feature is introduced), not a 'fix' (no bug is resolved), and not a 'test' (no new tests or test logic is added—only the invocation style is updated), so 'refactor' is most appropriate.
4. The 'refactor' label is correct because the commit restructures test utility code and its usage for clarity and maintainability, without changing test coverage or behavior."
"updated test to use rows for action items

references #279
only restart if pages directory itself is changed

resolves #429","diff --git a/ionic/components/card/test/advanced/main.html b/ionic/components/card/test/advanced/main.html
index 7c56a7d..c19ea12 100644
--- a/ionic/components/card/test/advanced/main.html
+++ b/ionic/components/card/test/advanced/main.html
@@ -19,16 +19,20 @@
       </p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left>
-        <icon star></icon>
-        Star
-      </button>
-      <button clear item-right class=""activated"">
-        <icon share></icon>
-        Share.activated
-      </button>
-    </ion-item>
+    <ion-row no-padding>
+      <ion-col>
+        <button clear small>
+          <icon star></icon>
+          Star
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small class=""activated"">
+          <icon share></icon>
+          Share.activated
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
@@ -51,19 +55,24 @@
       <p>Hello. I am a paragraph.</p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left danger class=""activated"">
-        <icon star></icon>
-        Favorite.activated
-      </button>
-      <button clear item-left danger>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <ion-note item-right>
-        Right Note
-      </ion-note>
-    </ion-item>
+    <ion-row center no-padding>
+      <ion-col width-75>
+        <button clear small danger class=""activated"">
+          <icon star></icon>
+          Favorite.activated
+        </button>
+        <button clear small danger>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small>
+          <icon share></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
   </ion-card>
 
   <ion-card>
@@ -76,20 +85,27 @@
       This card was breaking the border radius.
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left dark>
-        <icon star></icon>
-        Favorite
-      </button>
-      <button clear item-right dark>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <button clear item-right dark>
-        <icon share-alt></icon>
-        Share
-      </button>
-    </ion-item>
+    <ion-row text-center no-padding>
+      <ion-col>
+        <button clear small dark>
+          <icon star></icon>
+          Favorite
+        </button>
+      </ion-col>
+
+      <ion-col>
+        <button clear small dark>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col>
+        <button clear small dark>
+          <icon share-alt></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 

diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 
",2,"[""19feaea1885eb015759b5c7a5d785521f2b8a212"", ""cbce777addb3dd118232a9f28db9d425d4c937b2""]","[""test"", ""fix""]","1. The first code unit updates the HTML structure in a test file (`main.html`) to use `<ion-row>` and `<ion-col>` for action items instead of `<ion-item>`, affecting only test markup.
2. This aligns with the 'test' label, as the changes are fully scoped to test artifacts without altering production code or logic.
3. The 'test' label is appropriate because the modification is strictly within a test file, not documentation ('docs'), build logic ('build'), CI/CD config ('cicd'), or application feature/bug logic ('feat'/'fix').
4. The 'test' label correctly represents updates to test markup structure in a dedicated test file.

1. The second code unit modifies the dev command logic in `dev.ts` to only restart the server if the pages directory itself is changed, refining the file watcher logic.
2. This change resolves an issue where unnecessary restarts would occur, directly aligning with the 'fix' label definition.
3. The 'fix' label is appropriate because the change addresses a bug in server restart logic, not introducing a new feature ('feat'), restructuring code without behavioral change ('refactor'), or modifying support artifacts ('test', 'docs', 'cicd', 'build').
4. The 'fix' label correctly captures the intent to resolve a behavioral bug in the dev server restart logic.

Final assigned labels: test, fix."
"repository creation
README","diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/README.md b/README.md
index 11a24b3..56e8d2a 100644
--- a/README.md
+++ b/README.md
@@ -16,7 +16,9 @@ oclif: create your own CLI
 
 # Description
 
-This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku). Most CLI tools in Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
+This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku).
+
+Most CLI tools for Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
 
 # Features
 
",2,"[""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""363f84c7da411468b4103da8e0b39ca48cfd8327""]","[""fix"", ""docs""]","1. The code changes add a call to createTeam in the repository service logic and adjust the placement of addTeamToRepository, as well as update the README to split a paragraph and clarify the description.
2. The repository.service.ts change addresses a missing step in repository creation (bug fix), which aligns with the 'fix' label, and the README.md change modifies documentation, aligning with the 'docs' label.
3. 'fix' is appropriate for the repository.service.ts change because it corrects functional behavior rather than adding new capability or refactoring, while 'docs' is correct for README.md as it solely affects documentation; no other labels apply since these changes do not add features, refactor code, or affect tests/build/CI.
4. The combination of 'fix' (for the service logic correction) and 'docs' (for the documentation update) accurately reflects the motivations and artifact types of the respective changes in this commit."
"Publish crates
replace api call which requires auth token in public page

re #4694

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 7b98b44..f17ad6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,9 @@
 
 - **(css/parser)** Fix parsing of at rules (#3328) ([506a310](https://github.com/swc-project/swc/commit/506a31078aaebf50129658f096bbd5929995205f))
 
+
+- **(es/compat)** Fix regression of `destructuring` (#3326) ([6d1ad36](https://github.com/swc-project/swc/commit/6d1ad368aca53ee64a63ae565cd015909f2f4458))
+
 ### Performance
 
 
diff --git a/Cargo.lock b/Cargo.lock
index 3c6598b..4baa252 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2652,7 +2652,7 @@ dependencies = [
 
 [[package]]
 name = ""swc""
-version = ""0.116.15""
+version = ""0.116.16""
 dependencies = [
  ""ahash"",
  ""anyhow"",
@@ -3097,7 +3097,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms""
-version = ""0.113.3""
+version = ""0.113.4""
 dependencies = [
  ""pretty_assertions 0.7.2"",
  ""sourcemap"",
@@ -3157,7 +3157,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecma_transforms_compat""
-version = ""0.68.2""
+version = ""0.68.3""
 dependencies = [
  ""ahash"",
  ""arrayvec 0.7.2"",
@@ -3366,7 +3366,7 @@ dependencies = [
 
 [[package]]
 name = ""swc_ecmascript""
-version = ""0.110.14""
+version = ""0.110.15""
 dependencies = [
  ""swc_ecma_ast"",
  ""swc_ecma_codegen"",
diff --git a/crates/swc/Cargo.toml b/crates/swc/Cargo.toml
index 756cfc8..2f02d22 100644
--- a/crates/swc/Cargo.toml
+++ b/crates/swc/Cargo.toml
@@ -9,7 +9,7 @@ include = [""Cargo.toml"", ""src/**/*.rs""]
 license = ""Apache-2.0""
 name = ""swc""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.116.15""
+version = ""0.116.16""
 
 [lib]
 name = ""swc""
@@ -55,7 +55,7 @@ swc_ecma_loader = {version = ""0.27.0"", path = ""../swc_ecma_loader"", features = [
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env""}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", features = [
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", features = [
   ""compat"",
   ""module"",
   ""optimization"",
@@ -64,11 +64,11 @@ swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", fea
   ""typescript"",
 ]}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat""}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat""}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization""}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils""}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit""}
-swc_ecmascript = {version = ""0.110.14"", path = ""../swc_ecmascript""}
+swc_ecmascript = {version = ""0.110.15"", path = ""../swc_ecmascript""}
 swc_node_comments = {version = ""0.4.0"", path = ""../swc_node_comments""}
 swc_plugin_runner = {version = ""0.30.0"", path = ""../swc_plugin_runner"", optional = true}
 swc_visit = {version = ""0.3.0"", path = ""../swc_visit""}
diff --git a/crates/swc_ecma_transforms/Cargo.toml b/crates/swc_ecma_transforms/Cargo.toml
index 1604f4e..a0aafae 100644
--- a/crates/swc_ecma_transforms/Cargo.toml
+++ b/crates/swc_ecma_transforms/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.113.3""
+version = ""0.113.4""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -28,7 +28,7 @@ swc_common = {version = ""0.17.0"", path = ""../swc_common""}
 swc_ecma_ast = {version = ""0.65.0"", path = ""../swc_ecma_ast""}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser""}
 swc_ecma_transforms_base = {version = ""0.57.1"", path = ""../swc_ecma_transforms_base""}
-swc_ecma_transforms_compat = {version = ""0.68.2"", path = ""../swc_ecma_transforms_compat"", optional = true}
+swc_ecma_transforms_compat = {version = ""0.68.3"", path = ""../swc_ecma_transforms_compat"", optional = true}
 swc_ecma_transforms_module = {version = ""0.74.0"", path = ""../swc_ecma_transforms_module"", optional = true}
 swc_ecma_transforms_optimization = {version = ""0.83.0"", path = ""../swc_ecma_transforms_optimization"", optional = true}
 swc_ecma_transforms_proposal = {version = ""0.74.0"", path = ""../swc_ecma_transforms_proposal"", optional = true}
diff --git a/crates/swc_ecma_transforms_compat/Cargo.toml b/crates/swc_ecma_transforms_compat/Cargo.toml
index 0ea6609..58374e3 100644
--- a/crates/swc_ecma_transforms_compat/Cargo.toml
+++ b/crates/swc_ecma_transforms_compat/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecma_transforms_compat""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.68.2""
+version = ""0.68.3""
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [features]
diff --git a/crates/swc_ecmascript/Cargo.toml b/crates/swc_ecmascript/Cargo.toml
index 63680a0..775208a 100644
--- a/crates/swc_ecmascript/Cargo.toml
+++ b/crates/swc_ecmascript/Cargo.toml
@@ -6,7 +6,7 @@ edition = ""2021""
 license = ""Apache-2.0""
 name = ""swc_ecmascript""
 repository = ""https://github.com/swc-project/swc.git""
-version = ""0.110.14""
+version = ""0.110.15""
 
 [package.metadata.docs.rs]
 all-features = true
@@ -39,7 +39,7 @@ swc_ecma_dep_graph = {version = ""0.58.0"", path = ""../swc_ecma_dep_graph"", option
 swc_ecma_minifier = {version = ""0.70.9"", path = ""../swc_ecma_minifier"", optional = true}
 swc_ecma_parser = {version = ""0.87.0"", path = ""../swc_ecma_parser"", optional = true, default-features = false}
 swc_ecma_preset_env = {version = ""0.86.1"", path = ""../swc_ecma_preset_env"", optional = true}
-swc_ecma_transforms = {version = ""0.113.3"", path = ""../swc_ecma_transforms"", optional = true}
+swc_ecma_transforms = {version = ""0.113.4"", path = ""../swc_ecma_transforms"", optional = true}
 swc_ecma_utils = {version = ""0.64.0"", path = ""../swc_ecma_utils"", optional = true}
 swc_ecma_visit = {version = ""0.51.1"", path = ""../swc_ecma_visit"", optional = true}
 

diff --git a/packages/nc-gui/composables/useSharedView.ts b/packages/nc-gui/composables/useSharedView.ts
index cb0c5ea..f67a6c9 100644
--- a/packages/nc-gui/composables/useSharedView.ts
+++ b/packages/nc-gui/composables/useSharedView.ts
@@ -17,7 +17,7 @@ export function useSharedView() {
 
   const { appInfo } = $(useGlobal())
 
-  const { loadProject } = useProject()
+  const { project } = useProject()
 
   const appInfoDefaultLimit = appInfo.defaultLimit || 25
 
@@ -76,7 +76,16 @@ export function useSharedView() {
 
     await setMeta(viewMeta.model)
 
-    await loadProject(true, viewMeta.project_id)
+    // if project is not defined then set it with an object containing base
+    if (!project.value?.bases)
+      project.value = {
+        bases: [
+          {
+            id: viewMeta.base_id,
+            type: viewMeta.client,
+          },
+        ],
+      }
 
     const relatedMetas = { ...viewMeta.relatedMetas }
     Object.keys(relatedMetas).forEach((key) => setMeta(relatedMetas[key]))
",2,"[""af53b9487f74ff28438928903fb1f2db93fe4fa8"", ""4986a5892fb00bd5a6b2065ad8cfefbc36052dd7""]","[""build"", ""fix""]","1. The commit updates multiple Cargo.toml and Cargo.lock files to increment the version numbers of various crates, modifies the changelog, and changes useSharedView.ts to replace an API call that required an auth token with logic that does not require authentication.
2. The Cargo.toml and Cargo.lock updates are related to dependency and version management, aligning with the 'build' label, while the TypeScript change addresses an authentication bug, aligning with the 'fix' label.
3. 'build' is appropriate for the manifest and lockfile changes because they are purely about build configuration and dependency versions, not feature, refactor, or CI; 'fix' is correct for the TypeScript logic change because it resolves a bug (auth token requirement), not a new feature or code cleanup.
4. The 'build' and 'fix' labels together accurately reflect the distinct changes: build system updates and a targeted bug fix in application logic."
"bump version

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>
repository creation","diff --git a/scripts/helmcharts/init.sh b/scripts/helmcharts/init.sh
index 5a2b4b0..69a6944 100644
--- a/scripts/helmcharts/init.sh
+++ b/scripts/helmcharts/init.sh
@@ -26,7 +26,7 @@ usr=$(whoami)
 
 # Installing k3s
 function install_k8s() {
-    curl -sL https://get.k3s.io | sudo K3S_KUBECONFIG_MODE=""644"" INSTALL_K3S_VERSION='v1.22.8+k3s1' INSTALL_K3S_EXEC=""--no-deploy=traefik"" sh -
+    curl -sL https://get.k3s.io | sudo K3S_KUBECONFIG_MODE=""644"" INSTALL_K3S_VERSION='v1.25.6+k3s1' INSTALL_K3S_EXEC=""--disable=traefik"" sh -
     [[ -d ~/.kube ]] || mkdir ~/.kube
     sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
     sudo chmod 0644 ~/.kube/config

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",2,"[""9a25fe59dfb63d32505afcea3a164ff0b8ea4c71"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""build"", ""fix""]","1. The commit updates a version string for k3s in a shell script (init.sh) and modifies logic in a TypeScript service (repository.service.ts) by adding a call to createTeam and moving addTeamToRepository outside an if block.
2. The shell script change updates the version of a build-time dependency (k3s), which aligns with the 'build' label, while the TypeScript change alters application logic to ensure teams are created and added regardless of mentor presence, which addresses a likely bug and aligns with 'fix.'
3. The 'build' label is appropriate for the script change because it exclusively affects build tooling, not CI/CD or documentation, and the 'fix' label is correct for the service change because it alters code behavior to resolve an error rather than refactoring or introducing a new feature.
4. Assigning 'build' and 'fix' accurately reflects the distinct motivations and functional areas of the two changes: one for dependency version management and one for correcting application logic."
"dedup redundant imports
rebuild when environment variables change (#11471)","diff --git a/ibis/backends/base/__init__.py b/ibis/backends/base/__init__.py
index effd44c..a59c0ec 100644
--- a/ibis/backends/base/__init__.py
+++ b/ibis/backends/base/__init__.py
@@ -31,7 +31,7 @@ import ibis.common.exceptions as exc
 import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 
 __all__ = ('BaseBackend', 'Database', 'connect')
 
diff --git a/ibis/backends/base/sql/__init__.py b/ibis/backends/base/sql/__init__.py
index e4f2129..7bbdaf9 100644
--- a/ibis/backends/base/sql/__init__.py
+++ b/ibis/backends/base/sql/__init__.py
@@ -12,7 +12,7 @@ import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import BaseBackend
 from ibis.backends.base.sql.compiler import Compiler
 
diff --git a/ibis/backends/base/sql/alchemy/__init__.py b/ibis/backends/base/sql/alchemy/__init__.py
index 71cc0e8..ab89d7d 100644
--- a/ibis/backends/base/sql/alchemy/__init__.py
+++ b/ibis/backends/base/sql/alchemy/__init__.py
@@ -11,7 +11,7 @@ import ibis
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.alchemy.database import AlchemyDatabase, AlchemyTable
 from ibis.backends.base.sql.alchemy.datatypes import (
diff --git a/ibis/backends/base/sql/alchemy/query_builder.py b/ibis/backends/base/sql/alchemy/query_builder.py
index 54c74ba..0ec432f 100644
--- a/ibis/backends/base/sql/alchemy/query_builder.py
+++ b/ibis/backends/base/sql/alchemy/query_builder.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import functools
 
 import sqlalchemy as sa
-import sqlalchemy.sql as sql
+from sqlalchemy import sql
 
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
diff --git a/ibis/backends/base/sql/compiler/base.py b/ibis/backends/base/sql/compiler/base.py
index 84102aa..fb44667 100644
--- a/ibis/backends/base/sql/compiler/base.py
+++ b/ibis/backends/base/sql/compiler/base.py
@@ -7,7 +7,7 @@ import toolz
 
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 class DML(abc.ABC):
diff --git a/ibis/backends/base/sql/compiler/query_builder.py b/ibis/backends/base/sql/compiler/query_builder.py
index a2d5214..95f5e8d 100644
--- a/ibis/backends/base/sql/compiler/query_builder.py
+++ b/ibis/backends/base/sql/compiler/query_builder.py
@@ -8,7 +8,7 @@ import toolz
 import ibis.common.exceptions as com
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.compiler.base import DML, QueryAST, SetOp
 from ibis.backends.base.sql.compiler.select_builder import SelectBuilder, _LimitSpec
 from ibis.backends.base.sql.compiler.translator import ExprTranslator, QueryContext
diff --git a/ibis/backends/base/sql/registry/main.py b/ibis/backends/base/sql/registry/main.py
index 77f70a5..586ace5 100644
--- a/ibis/backends/base/sql/registry/main.py
+++ b/ibis/backends/base/sql/registry/main.py
@@ -4,7 +4,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import (
     aggregate,
     binary_infix,
diff --git a/ibis/backends/base/sql/registry/timestamp.py b/ibis/backends/base/sql/registry/timestamp.py
index 412eab1..3c8571f 100644
--- a/ibis/backends/base/sql/registry/timestamp.py
+++ b/ibis/backends/base/sql/registry/timestamp.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
-import ibis.util as util
+from ibis import util
 
 
 def extract_field(sql_attr):
diff --git a/ibis/backends/clickhouse/tests/test_client.py b/ibis/backends/clickhouse/tests/test_client.py
index 8db6672..bb1b9ba 100644
--- a/ibis/backends/clickhouse/tests/test_client.py
+++ b/ibis/backends/clickhouse/tests/test_client.py
@@ -3,9 +3,9 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.backends.clickhouse.tests.conftest import (
     CLICKHOUSE_HOST,
     CLICKHOUSE_PASS,
diff --git a/ibis/backends/conftest.py b/ibis/backends/conftest.py
index 3a974da..ba7ad75 100644
--- a/ibis/backends/conftest.py
+++ b/ibis/backends/conftest.py
@@ -20,7 +20,7 @@ if TYPE_CHECKING:
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import _get_backend_names
 
 TEST_TABLES = {
diff --git a/ibis/backends/dask/execution/util.py b/ibis/backends/dask/execution/util.py
index 61bff7e..7ed0c10 100644
--- a/ibis/backends/dask/execution/util.py
+++ b/ibis/backends/dask/execution/util.py
@@ -9,13 +9,13 @@ import pandas as pd
 from dask.dataframe.groupby import SeriesGroupBy
 
 import ibis.backends.pandas.execution.util as pd_util
-import ibis.common.graph as graph
 import ibis.expr.analysis as an
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 import ibis.util
 from ibis.backends.dask.core import execute
 from ibis.backends.pandas.trace import TraceTwoLevelDispatcher
+from ibis.common import graph
 from ibis.expr.scope import Scope
 
 if TYPE_CHECKING:
diff --git a/ibis/backends/duckdb/datatypes.py b/ibis/backends/duckdb/datatypes.py
index fd6b8f5..52c0719 100644
--- a/ibis/backends/duckdb/datatypes.py
+++ b/ibis/backends/duckdb/datatypes.py
@@ -3,7 +3,7 @@ from __future__ import annotations
 import parsy as p
 import toolz
 
-import ibis.util as util
+from ibis import util
 from ibis.common.parsing import (
     COMMA,
     FIELD,
diff --git a/ibis/backends/impala/__init__.py b/ibis/backends/impala/__init__.py
index 4ad2057..8299a28 100644
--- a/ibis/backends/impala/__init__.py
+++ b/ibis/backends/impala/__init__.py
@@ -20,7 +20,7 @@ import ibis.config
 import ibis.expr.datatypes as dt
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.ddl import (
     CTAS,
diff --git a/ibis/backends/impala/client.py b/ibis/backends/impala/client.py
index 6655ce7..78d526f 100644
--- a/ibis/backends/impala/client.py
+++ b/ibis/backends/impala/client.py
@@ -10,7 +10,7 @@ import sqlalchemy as sa
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base import Database
 from ibis.backends.base.sql.compiler import DDL, DML
 from ibis.backends.base.sql.ddl import (
diff --git a/ibis/backends/impala/pandas_interop.py b/ibis/backends/impala/pandas_interop.py
index f410a8b..e687884 100644
--- a/ibis/backends/impala/pandas_interop.py
+++ b/ibis/backends/impala/pandas_interop.py
@@ -22,7 +22,7 @@ from posixpath import join as pjoin
 import ibis.backends.pandas.client  # noqa: F401
 import ibis.common.exceptions as com
 import ibis.expr.schema as sch
-import ibis.util as util
+from ibis import util
 from ibis.config import options
 
 
diff --git a/ibis/backends/impala/tests/conftest.py b/ibis/backends/impala/tests/conftest.py
index 1075ebe..a815be5 100644
--- a/ibis/backends/impala/tests/conftest.py
+++ b/ibis/backends/impala/tests/conftest.py
@@ -13,8 +13,7 @@ import pytest
 
 import ibis
 import ibis.expr.types as ir
-import ibis.util as util
-from ibis import options
+from ibis import options, util
 from ibis.backends.base import BaseBackend
 from ibis.backends.conftest import TEST_TABLES, _random_identifier
 from ibis.backends.impala.compiler import ImpalaCompiler, ImpalaExprTranslator
diff --git a/ibis/backends/impala/tests/test_client.py b/ibis/backends/impala/tests/test_client.py
index 0b56054..3fcca3a 100644
--- a/ibis/backends/impala/tests/test_client.py
+++ b/ibis/backends/impala/tests/test_client.py
@@ -7,9 +7,9 @@ import pytz
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_ddl.py b/ibis/backends/impala/tests/test_ddl.py
index 870c4dc..2346a3d 100644
--- a/ibis/backends/impala/tests/test_ddl.py
+++ b/ibis/backends/impala/tests/test_ddl.py
@@ -6,7 +6,7 @@ import ibis
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.ddl import fully_qualified_re
 from ibis.tests.util import assert_equal
 
diff --git a/ibis/backends/impala/tests/test_exprs.py b/ibis/backends/impala/tests/test_exprs.py
index cfc8552..1d6f44f 100644
--- a/ibis/backends/impala/tests/test_exprs.py
+++ b/ibis/backends/impala/tests/test_exprs.py
@@ -5,10 +5,10 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.types as ir
 from ibis import literal as L
 from ibis.backends.impala.compiler import ImpalaCompiler
+from ibis.expr import api
 from ibis.expr.datatypes import Category
 
 
diff --git a/ibis/backends/impala/tests/test_partition.py b/ibis/backends/impala/tests/test_partition.py
index 1f96e7d..44217a4 100644
--- a/ibis/backends/impala/tests/test_partition.py
+++ b/ibis/backends/impala/tests/test_partition.py
@@ -6,7 +6,7 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pytest.importorskip(""impala"")
diff --git a/ibis/backends/impala/tests/test_udf.py b/ibis/backends/impala/tests/test_udf.py
index 895918b..fd950d5 100644
--- a/ibis/backends/impala/tests/test_udf.py
+++ b/ibis/backends/impala/tests/test_udf.py
@@ -9,11 +9,11 @@ import ibis
 import ibis.backends.impala as api
 import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
-import ibis.expr.rules as rules
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.backends.impala import ddl
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import rules
 
 pytest.importorskip(""impala"")
 
diff --git a/ibis/backends/impala/udf.py b/ibis/backends/impala/udf.py
index c6f2ef6..8b8b552 100644
--- a/ibis/backends/impala/udf.py
+++ b/ibis/backends/impala/udf.py
@@ -21,7 +21,7 @@ import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.udf.validate as v
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql.registry import fixed_arity, sql_type_names
 from ibis.backends.impala.compiler import ImpalaExprTranslator
 
diff --git a/ibis/backends/mysql/__init__.py b/ibis/backends/mysql/__init__.py
index c0ddacb..50b331a 100644
--- a/ibis/backends/mysql/__init__.py
+++ b/ibis/backends/mysql/__init__.py
@@ -8,7 +8,7 @@ import warnings
 from typing import Literal
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
diff --git a/ibis/backends/mysql/compiler.py b/ibis/backends/mysql/compiler.py
index 13819cb..7456f71 100644
--- a/ibis/backends/mysql/compiler.py
+++ b/ibis/backends/mysql/compiler.py
@@ -1,7 +1,7 @@
 from __future__ import annotations
 
 import sqlalchemy as sa
-import sqlalchemy.dialects.mysql as mysql
+from sqlalchemy.dialects import mysql
 
 import ibis.expr.datatypes as dt
 from ibis.backends.base.sql.alchemy import AlchemyCompiler, AlchemyExprTranslator
diff --git a/ibis/backends/postgres/tests/test_functions.py b/ibis/backends/postgres/tests/test_functions.py
index 33c6d2e..0f377e3 100644
--- a/ibis/backends/postgres/tests/test_functions.py
+++ b/ibis/backends/postgres/tests/test_functions.py
@@ -11,9 +11,9 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.config as config
 import ibis.expr.datatypes as dt
 import ibis.expr.types as ir
+from ibis import config
 from ibis import literal as L
 from ibis.expr.window import rows_with_max_lookback
 
diff --git a/ibis/backends/pyspark/__init__.py b/ibis/backends/pyspark/__init__.py
index 1b42080..b994911 100644
--- a/ibis/backends/pyspark/__init__.py
+++ b/ibis/backends/pyspark/__init__.py
@@ -14,8 +14,7 @@ import ibis.config
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.expr.types as types
-import ibis.util as util
+from ibis import util
 from ibis.backends.base.sql import BaseSQLBackend
 from ibis.backends.base.sql.compiler import Compiler, TableSetFormatter
 from ibis.backends.base.sql.ddl import (
@@ -217,16 +216,16 @@ class Backend(BaseSQLBackend):
         **kwargs: Any,
     ) -> Any:
         """"""Execute an expression.""""""
-        if isinstance(expr, types.Table):
+        if isinstance(expr, ir.Table):
             return self.compile(expr, timecontext, params, **kwargs).toPandas()
-        elif isinstance(expr, types.Column):
+        elif isinstance(expr, ir.Column):
             # expression must be named for the projection
             if not expr.has_name():
                 expr = expr.name(""tmp"")
             return self.compile(
                 expr.to_projection(), timecontext, params, **kwargs
             ).toPandas()[expr.get_name()]
-        elif isinstance(expr, types.Scalar):
+        elif isinstance(expr, ir.Scalar):
             compiled = self.compile(expr, timecontext, params, **kwargs)
             if isinstance(compiled, Column):
                 # attach result column to a fake DataFrame and
diff --git a/ibis/backends/pyspark/tests/test_ddl.py b/ibis/backends/pyspark/tests/test_ddl.py
index 0288062..ccc8a97 100644
--- a/ibis/backends/pyspark/tests/test_ddl.py
+++ b/ibis/backends/pyspark/tests/test_ddl.py
@@ -5,7 +5,7 @@ import pytest
 
 import ibis
 import ibis.common.exceptions as com
-import ibis.util as util
+from ibis import util
 from ibis.tests.util import assert_equal
 
 pyspark = pytest.importorskip(""pyspark"")
diff --git a/ibis/backends/sqlite/tests/test_client.py b/ibis/backends/sqlite/tests/test_client.py
index 95aa24d..ad64700 100644
--- a/ibis/backends/sqlite/tests/test_client.py
+++ b/ibis/backends/sqlite/tests/test_client.py
@@ -5,8 +5,8 @@ import pandas.testing as tm
 import pytest
 
 import ibis
-import ibis.config as config
 import ibis.expr.types as ir
+from ibis import config
 
 pytest.importorskip(""sqlalchemy"")
 
diff --git a/ibis/expr/format.py b/ibis/expr/format.py
index e3d48cd..85fab3f 100644
--- a/ibis/expr/format.py
+++ b/ibis/expr/format.py
@@ -9,13 +9,13 @@ from typing import Any, Callable, Deque, Iterable, Mapping, Tuple
 import rich.pretty
 
 import ibis
-import ibis.common.graph as graph
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
 import ibis.expr.window as win
-import ibis.util as util
+from ibis import util
+from ibis.common import graph
 
 Aliases = Mapping[ops.TableNode, int]
 Deps = Deque[Tuple[int, ops.TableNode]]
diff --git a/ibis/expr/operations/relations.py b/ibis/expr/operations/relations.py
index 080ddcd..de44a15 100644
--- a/ibis/expr/operations/relations.py
+++ b/ibis/expr/operations/relations.py
@@ -11,7 +11,7 @@ import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute
 from ibis.expr.deferred import Deferred
 from ibis.expr.operations.core import Named, Node, Value
diff --git a/ibis/expr/rules.py b/ibis/expr/rules.py
index 9b1a3b7..d40700e 100644
--- a/ibis/expr/rules.py
+++ b/ibis/expr/rules.py
@@ -11,7 +11,7 @@ import ibis.common.exceptions as com
 import ibis.expr.datatypes as dt
 import ibis.expr.schema as sch
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.annotations import attribute, optional
 from ibis.common.validators import (
     bool_,
diff --git a/ibis/expr/timecontext.py b/ibis/expr/timecontext.py
index 7ecd8e7..9620d6c 100644
--- a/ibis/expr/timecontext.py
+++ b/ibis/expr/timecontext.py
@@ -38,8 +38,8 @@ from typing import TYPE_CHECKING, Any
 import numpy as np
 
 import ibis.common.exceptions as com
-import ibis.config as config
 import ibis.expr.operations as ops
+from ibis import config
 
 if TYPE_CHECKING:
     import pandas as pd
diff --git a/ibis/expr/types/groupby.py b/ibis/expr/types/groupby.py
index 138f92e..97aaaa2 100644
--- a/ibis/expr/types/groupby.py
+++ b/ibis/expr/types/groupby.py
@@ -22,7 +22,7 @@ from typing import Iterable, Sequence
 import ibis.expr.analysis as an
 import ibis.expr.types as ir
 import ibis.expr.window as _window
-import ibis.util as util
+from ibis import util
 from ibis.expr.deferred import Deferred
 
 _function_types = tuple(
diff --git a/ibis/expr/window.py b/ibis/expr/window.py
index 5ef3bb1..3e0efdc 100644
--- a/ibis/expr/window.py
+++ b/ibis/expr/window.py
@@ -11,7 +11,7 @@ import toolz
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
-import ibis.util as util
+from ibis import util
 from ibis.common.exceptions import IbisInputError
 from ibis.common.grounds import Comparable
 
diff --git a/ibis/tests/expr/test_decimal.py b/ibis/tests/expr/test_decimal.py
index 85d8eb2..12b809b 100644
--- a/ibis/tests/expr/test_decimal.py
+++ b/ibis/tests/expr/test_decimal.py
@@ -3,10 +3,10 @@ import operator
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_type_metadata(lineitem):
diff --git a/ibis/tests/expr/test_interactive.py b/ibis/tests/expr/test_interactive.py
index cea1945..0c5613b 100644
--- a/ibis/tests/expr/test_interactive.py
+++ b/ibis/tests/expr/test_interactive.py
@@ -14,7 +14,7 @@
 
 import pytest
 
-import ibis.config as config
+from ibis import config
 from ibis.tests.expr.mocks import MockBackend
 
 
diff --git a/ibis/tests/expr/test_table.py b/ibis/tests/expr/test_table.py
index 04f4a7d..3f77985 100644
--- a/ibis/tests/expr/test_table.py
+++ b/ibis/tests/expr/test_table.py
@@ -10,13 +10,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as an
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
 from ibis import _
 from ibis import literal as L
 from ibis.common.exceptions import RelationError
+from ibis.expr import api
 from ibis.expr.types import Column, Table
 from ibis.tests.expr.mocks import MockAlchemyBackend, MockBackend
 from ibis.tests.util import assert_equal, assert_pickle_roundtrip
diff --git a/ibis/tests/expr/test_temporal.py b/ibis/tests/expr/test_temporal.py
index e76e71c..9a0f43f 100644
--- a/ibis/tests/expr/test_temporal.py
+++ b/ibis/tests/expr/test_temporal.py
@@ -5,10 +5,10 @@ import pytest
 from pytest import param
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_temporal_literals():
diff --git a/ibis/tests/expr/test_timestamp.py b/ibis/tests/expr/test_timestamp.py
index 6601c8b..7782787 100644
--- a/ibis/tests/expr/test_timestamp.py
+++ b/ibis/tests/expr/test_timestamp.py
@@ -5,11 +5,11 @@ import pandas as pd
 import pytest
 
 import ibis
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
+from ibis.expr import api
 
 
 def test_field_select(alltypes):
diff --git a/ibis/tests/expr/test_value_exprs.py b/ibis/tests/expr/test_value_exprs.py
index 4c3d475..9eb247c 100644
--- a/ibis/tests/expr/test_value_exprs.py
+++ b/ibis/tests/expr/test_value_exprs.py
@@ -15,13 +15,13 @@ from pytest import param
 import ibis
 import ibis.common.exceptions as com
 import ibis.expr.analysis as L
-import ibis.expr.api as api
 import ibis.expr.datatypes as dt
 import ibis.expr.operations as ops
 import ibis.expr.rules as rlz
 import ibis.expr.types as ir
 from ibis import _, literal
 from ibis.common.exceptions import IbisTypeError
+from ibis.expr import api
 from ibis.tests.util import assert_equal
 
 
diff --git a/ibis/tests/expr/test_visualize.py b/ibis/tests/expr/test_visualize.py
index 5525944..253564f 100644
--- a/ibis/tests/expr/test_visualize.py
+++ b/ibis/tests/expr/test_visualize.py
@@ -9,8 +9,8 @@ import ibis.expr.types as ir
 
 pytest.importorskip('graphviz')
 
-import ibis.expr.api as api  # noqa: E402
 import ibis.expr.visualize as viz  # noqa: E402
+from ibis.expr import api  # noqa: E402
 
 pytestmark = pytest.mark.skipif(
     int(os.environ.get('CONDA_BUILD', 0)) == 1, reason='CONDA_BUILD defined'
diff --git a/ibis/tests/sql/test_sqlalchemy.py b/ibis/tests/sql/test_sqlalchemy.py
index 2ad5453..3aa8c3d 100644
--- a/ibis/tests/sql/test_sqlalchemy.py
+++ b/ibis/tests/sql/test_sqlalchemy.py
@@ -15,8 +15,8 @@
 import operator
 
 import pytest
-import sqlalchemy.sql as sql
 from sqlalchemy import func as F
+from sqlalchemy import sql
 from sqlalchemy import types as sat
 
 import ibis
diff --git a/ibis/tests/util.py b/ibis/tests/util.py
index f79d09a..025bfc7 100644
--- a/ibis/tests/util.py
+++ b/ibis/tests/util.py
@@ -5,7 +5,7 @@ from __future__ import annotations
 import pickle
 
 import ibis
-import ibis.util as util
+from ibis import util
 
 
 def assert_equal(left, right):
diff --git a/pyproject.toml b/pyproject.toml
index f2146d4..492ad9e 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -310,6 +310,7 @@ select = [
   ""PGH"", # pygrep-hooks
   ""PLC"", # pylint
   ""PLE"", # pylint
+  ""PLR"", # pylint import style
   ""PLW"", # pylint
   ""RET"", # flake8-return
   ""RUF"", # ruff-specific rules

diff --git a/cli/build.rs b/cli/build.rs
index 548fbb5..d7bed21 100644
--- a/cli/build.rs
+++ b/cli/build.rs
@@ -269,8 +269,17 @@ fn main() {
   // To debug snapshot issues uncomment:
   // op_fetch_asset::trace_serializer();
 
-  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  if let Ok(c) = env::var(""DENO_CANARY"") {
+    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
+  }
+  println!(""cargo:rerun-if-env-changed=DENO_CANARY"");
+
   println!(""cargo:rustc-env=GIT_COMMIT_HASH={}"", git_commit_hash());
+  println!(""cargo:rerun-if-env-changed=GIT_COMMIT_HASH"");
+
+  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  println!(""cargo:rerun-if-env-changed=TS_VERSION"");
+
   println!(
     ""cargo:rustc-env=DENO_CONSOLE_LIB_PATH={}"",
     deno_console::get_declaration().display()
@@ -322,9 +331,6 @@ fn main() {
 
   println!(""cargo:rustc-env=TARGET={}"", env::var(""TARGET"").unwrap());
   println!(""cargo:rustc-env=PROFILE={}"", env::var(""PROFILE"").unwrap());
-  if let Ok(c) = env::var(""DENO_CANARY"") {
-    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
-  }
 
   let c = PathBuf::from(env::var_os(""CARGO_MANIFEST_DIR"").unwrap());
   let o = PathBuf::from(env::var_os(""OUT_DIR"").unwrap());
",2,"[""8d53d724275ebe4b2a0bb0bd7e2c2dfc399e049b"", ""63546c15bfb1284ac6d956eee274e6d7cf263a8f""]","[""refactor"", ""build""]","1. The Python code changes replace redundant or non-idiomatic import statements with more concise or preferred forms, such as converting 'import ibis.util as util' to 'from ibis import util', across multiple files, and make similar adjustments for other modules (e.g., 'sqlalchemy.sql as sql' to 'from sqlalchemy import sql').
2. These modifications are strictly about cleaning up or deduplicating import statements and do not introduce new features, fix bugs, or alter external behavior, aligning with the 'refactor' label definition for restructuring code.
3. The changes do not qualify for 'feat' (no new capability), 'fix' (not addressing bugs), nor any object label (not dedicated to tests, docs, build, or CI artifacts), so 'refactor' is most appropriate for these Python changes.
4. The Rust 'build.rs' changes add 'rerun-if-env-changed' directives to ensure rebuilds when environment variables change, affecting the build system configuration and making the build process responsive to environment changes, which aligns with the 'build' label.
5. These Rust changes are not a refactor (they alter build behavior), not a bugfix (no explicit bug resolved), and not a feature addition (no new end-user capability), so 'build' is the correct label here.
6. In summary, the Python code changes are best described as 'refactor' for improving code structure, while the Rust build script changes are best described as 'build' for modifying build system logic, leading to the unique set: {'refactor', 'build'}."
fetch git history,"diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 6726e35..9114eeb 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -172,6 +172,8 @@ jobs:
 
     steps:
       - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
       - run: corepack enable
       - uses: actions/setup-node@v3
         with:
diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index aa33d76..1d1cbc9 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -18,7 +18,7 @@ async function main () {
 
   const config = await loadChangelogConfig(process.cwd())
 
-  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0', 'main']).stdout
+  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0']).stdout
 
   const commits = await getGitDiff(latestTag)
   const bumpType = determineSemverChange(parseCommits(commits, config), config)
",1,"[""e11d55a4922978b89a2c50bf577124b09449e89c""]","[""cicd""]","1. The code changes modify the GitHub Actions workflow file `.github/workflows/ci.yml` to set `fetch-depth: 0` for full git history, and update a script (`scripts/bump-edge.ts`) to change a git command argument.
2. The primary modification is to a CI configuration file, which aligns with the 'cicd' label as it directly affects continuous integration setup.
3. Although there is a script change, its context is related to CI workflow operation, and the main artifact modified is the CI configuration; 'cicd' is preferred over 'build' (not build logic), 'refactor' (not structural code change), or 'feat/fix' (not adding features or fixing bugs).
4. The 'cicd' label is appropriate because the commit's main focus is updating CI workflow configuration to ensure correct git history fetching during CI runs."
do not use scripts and binaries from the libcc repo,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |
",1,"[""45837af24a33308a70a3454f0f650f9fe728e272""]","[""cicd""]","1. The changes update paths and environment variables in CI configuration files (.circleci/config.yml and vsts-gn.yml) to stop using scripts and binaries from the libcc repo, switching to alternatives in the electron/external_binaries directory.
2. These modifications are exclusively to CI pipeline configuration files, affecting how builds are orchestrated in CI environments, and do not alter application code, tests, or documentation.
3. The 'cicd' label is appropriate because the commit solely changes CI configuration logic; it is not a 'build' label (not build scripts or dependency changes), nor 'fix', 'feat', or 'refactor' (no code behavior or structure change), nor 'test' or 'docs' (no test or documentation modification).
4. The 'cicd' label accurately captures that the commit is dedicated to updating CI pipeline configuration and related environment setup."
"updated riot to v6, fixed build
autostart feature fixed","diff --git a/components/riot/package.json b/components/riot/package.json
index c41743a..eb69756 100644
--- a/components/riot/package.json
+++ b/components/riot/package.json
@@ -61,7 +61,7 @@
   },
   ""devDependencies"": {
     ""@babel/preset-typescript"": ""^7.14.5"",
-    ""@riotjs/cli"": ""^6.0.4"",
+    ""@riotjs/cli"": ""^6.0.5"",
     ""@riotjs/compiler"": ""^6.0.0"",
     ""chai"": ""^4.3.4"",
     ""esm"": ""^3.2.25"",

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",2,"[""5d256f937f93e5a5ed003df86d38c44834095a11"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""build"", ""fix""]","1. The code changes include updating the @riotjs/cli version in package.json, removing unused imports in two TypeScript files, and changing the assignment of this.firstStart in Container.ts to fix autostart behavior.
2. Updating the @riotjs/cli version is a build system change, aligning with the 'build' label, while the change in Container.ts corrects autostart logic, which is a bug fix aligning with the 'fix' label; removing unused imports is a minor code cleanup but accompanies a bug fix and build update.
3. 'build' is appropriate for the dependency update since it affects the build process, not runtime code or features; 'fix' is appropriate for correcting autostart logic, as it resolves a behavioral bug rather than introducing a new feature or refactoring for clarity.
4. The 'build' and 'fix' labels are appropriate as the commit addresses a build dependency update and a runtime bug fix, directly matching the definitions and classification rules."
"post installers compatiblity with Windows #2520
added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/packages/cubejs-databricks-jdbc-driver/package.json b/packages/cubejs-databricks-jdbc-driver/package.json
index cc164f0..fd7ad45 100644
--- a/packages/cubejs-databricks-jdbc-driver/package.json
+++ b/packages/cubejs-databricks-jdbc-driver/package.json
@@ -14,13 +14,16 @@
   },
   ""main"": ""dist/src/index.js"",
   ""typings"": ""dist/src/index.d.ts"",
+  ""bin"": {
+    ""databricks-jdbc-installer"": ""bin/post-install""
+  },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
     ""tsc"": ""tsc"",
     ""watch"": ""tsc -w"",
     ""lint"": ""eslint src/* --ext .ts"",
     ""lint:fix"": ""eslint --fix src/* --ext .ts"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""databricks-jdbc-installer""
   },
   ""files"": [
     ""README.md"",
diff --git a/rust/package.json b/rust/package.json
index b139279..5bf6446 100644
--- a/rust/package.json
+++ b/rust/package.json
@@ -8,7 +8,8 @@
     ""node"": "">=10.8.0""
   },
   ""bin"": {
-    ""cubestore-dev"": ""bin/cubestore-dev""
+    ""cubestore-dev"": ""bin/cubestore-dev"",
+    ""cubestore-installer"": ""bin/post-install""
   },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
@@ -18,7 +19,7 @@
     ""lint:fix"": ""eslint --fix js-wrapper/* --ext .ts,js"",
     ""unit"": ""jest"",
     ""unit:debug"": ""jest --runInBand"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""cubestore-installer""
   },
   ""files"": [
     ""dist"",
diff --git a/yarn.lock b/yarn.lock
index d2a4038..b59bb77 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -4036,9 +4036,9 @@
   integrity sha512-7btbphLrKvo5yl/5CC2OCxUSMx1wV1wvGT1qDXkSt7yi00/YW7E8k6qzXqJHsp+WU0eoG7r6MTQQXI9lIvd0qA==
 
 ""@types/fs-extra@^9.0.1"", ""@types/fs-extra@^9.0.2"", ""@types/fs-extra@^9.0.8"":
-  version ""9.0.10""
-  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.10.tgz#8023a72e3d06cf54929ea47ec7634e47f33f4046""
-  integrity sha512-O9T2LLkRDiTlalOBdjEkcnT0MRdT2+wglCl7pJUJ3mkWkR8hX4K+5bg2raQNJcLv4V8zGuTXe7Ud3wSqkTyuyQ==
+  version ""9.0.11""
+  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.11.tgz#8cc99e103499eab9f347dbc6ca4e99fb8d2c2b87""
+  integrity sha512-mZsifGG4QeQ7hlkhO56u7zt/ycBgGxSVsFI/6lGTU34VtwkiqrrSDgw0+ygs8kFGWcXnFQWMrzF2h7TtDFNixA==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5306,9 +5306,9 @@ acorn@^7.0.0, acorn@^7.1.0, acorn@^7.1.1, acorn@^7.4.0:
   integrity sha512-nQyp0o1/mNdbTO1PO6kHkwSrmgZ0MT/jCCpNiwbUjGoRN4dlBhqJtoQuCnEOKzgTVwg0ZWiCoQy6SxMebQVh8A==
 
 acorn@^8.1.0:
-  version ""8.1.0""
-  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.0.tgz#52311fd7037ae119cbb134309e901aa46295b3fe""
-  integrity sha512-LWCF/Wn0nfHOmJ9rzQApGnxnvgfROzGilS8936rqN/lfcYkY9MYZzdMqN+2NJ4SlTc+m5HiSa+kNfDtI64dwUA==
+  version ""8.1.1""
+  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.1.tgz#fb0026885b9ac9f48bac1e185e4af472971149ff""
+  integrity sha512-xYiIVjNuqtKXMxlRMDc6mZUhXehod4a3gbZ1qRlM7icK4EbxUFNLhWoPblCvFtB2Y9CIqHP3CF/rdxLItaQv8g==
 
 adal-node@^0.1.28:
   version ""0.1.28""
@@ -5441,9 +5441,9 @@ ajv@^6.1.0, ajv@^6.10.0, ajv@^6.10.2, ajv@^6.12.2, ajv@^6.12.3, ajv@^6.12.4, ajv
     uri-js ""^4.2.2""
 
 ajv@^8.0.1:
-  version ""8.0.5""
-  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.0.5.tgz#f07d6fdeffcdbb80485570ce3f1bc845fcc812b9""
-  integrity sha512-RkiLa/AeJx7+9OvniQ/qeWu0w74A8DiPPBclQ6ji3ZQkv5KamO+QGpqmi7O4JIw3rHGUXZ6CoP9tsAkn3gyazg==
+  version ""8.1.0""
+  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.1.0.tgz#45d5d3d36c7cdd808930cc3e603cf6200dbeb736""
+  integrity sha512-B/Sk2Ix7A36fs/ZkuGLIR86EdjbgR6fsAcbx9lOP/QBSXujDNbVmIS/U4Itz5k8fPFDeVZl/zQ/gJW4Jrq6XjQ==
   dependencies:
     fast-deep-equal ""^3.1.1""
     json-schema-traverse ""^1.0.0""
@@ -6828,15 +6828,15 @@ browserslist@4.14.2:
     node-releases ""^1.1.61""
 
 browserslist@^4.0.0, browserslist@^4.11.1, browserslist@^4.12.0, browserslist@^4.14.5, browserslist@^4.16.3, browserslist@^4.3.4, browserslist@^4.6.2, browserslist@^4.6.4, browserslist@^4.7.0, browserslist@^4.9.1:
-  version ""4.16.3""
-  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.3.tgz#340aa46940d7db878748567c5dea24a48ddf3717""
-  integrity sha512-vIyhWmIkULaq04Gt93txdh+j02yX/JzlyhLYbV3YQCn/zvES3JnY7TifHHvvr1w5hTDluNKMkV05cs4vy8Q7sw==
+  version ""4.16.4""
+  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.4.tgz#7ebf913487f40caf4637b892b268069951c35d58""
+  integrity sha512-d7rCxYV8I9kj41RH8UKYnvDYCRENUlHRgyXy/Rhr/1BaeLGfiCptEdFE8MIrvGfWbBFNjVYx76SQWvNX1j+/cQ==
   dependencies:
-    caniuse-lite ""^1.0.30001181""
-    colorette ""^1.2.1""
-    electron-to-chromium ""^1.3.649""
+    caniuse-lite ""^1.0.30001208""
+    colorette ""^1.2.2""
+    electron-to-chromium ""^1.3.712""
     escalade ""^3.1.1""
-    node-releases ""^1.1.70""
+    node-releases ""^1.1.71""
 
 bs-logger@0.x:
   version ""0.2.6""
@@ -7217,7 +7217,7 @@ caniuse-api@^3.0.0:
     lodash.memoize ""^4.1.2""
     lodash.uniq ""^4.5.0""
 
-caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001181:
+caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001208:
   version ""1.0.30001208""
   resolved ""https://registry.yarnpkg.com/caniuse-lite/-/caniuse-lite-1.0.30001208.tgz#a999014a35cebd4f98c405930a057a0d75352eb9""
   integrity sha512-OE5UE4+nBOro8Dyvv0lfx+SRtfVIOM9uhKqFmJeUbGriqhhStgp1A0OyBpgy3OUF8AhYCT+PVwPC1gMl2ZcQMA==
@@ -9549,10 +9549,10 @@ ejs@^2.6.1:
   resolved ""https://registry.yarnpkg.com/ejs/-/ejs-2.7.4.tgz#48661287573dcc53e366c7a1ae52c3a120eec9ba""
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
-electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.649:
-  version ""1.3.711""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.711.tgz#92c3caf7ffed5e18bf63f66b4b57b4db2409c450""
-  integrity sha512-XbklBVCDiUeho0PZQCjC25Ha6uBwqqJeyDhPLwLwfWRAo4x+FZFsmu1pPPkXT+B4MQMQoQULfyaMltDopfeiHQ==
+electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.712:
+  version ""1.3.712""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.712.tgz#ae467ffe5f95961c6d41ceefe858fc36eb53b38f""
+  integrity sha512-3kRVibBeCM4vsgoHHGKHmPocLqtFAGTrebXxxtgKs87hNUzXrX2NuS3jnBys7IozCnw7viQlozxKkmty2KNfrw==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -9945,9 +9945,9 @@ eslint-plugin-import@^2.16.0, eslint-plugin-import@^2.18.2, eslint-plugin-import
     tsconfig-paths ""^3.9.0""
 
 eslint-plugin-jest@^24.1.0:
-  version ""24.3.4""
-  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.4.tgz#6d90c3554de0302e879603dd6405474c98849f19""
-  integrity sha512-3n5oY1+fictanuFkTWPwSlehugBTAgwLnYLFsCllzE3Pl1BwywHl5fL0HFxmMjoQY8xhUDk8uAWc3S4JOHGh3A==
+  version ""24.3.5""
+  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.5.tgz#71f0b580f87915695c286c3f0eb88cf23664d044""
+  integrity sha512-XG4rtxYDuJykuqhsOqokYIR84/C8pRihRtEpVskYLbIIKGwPNW2ySxdctuVzETZE+MbF/e7wmsnbNVpzM0rDug==
   dependencies:
     ""@typescript-eslint/experimental-utils"" ""^4.0.1""
 
@@ -12140,12 +12140,11 @@ http-proxy-middleware@0.19.1:
     micromatch ""^3.1.10""
 
 http-proxy-middleware@^1.0.0:
-  version ""1.1.0""
-  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.0.tgz#b896b2cc6836019af4a4f2d5f7b21b99c77ea13f""
-  integrity sha512-OnjU5vyVgcZVe2AjLJyMrk8YLNOC2lspCHirB5ldM+B/dwEfZ5bgVTrFyzE9R7xRWAP/i/FXtvIqKjTNEZBhBg==
+  version ""1.1.1""
+  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.1.tgz#48900a68cd9d388c735d1dd97302c919b7e94a13""
+  integrity sha512-FIDg9zPvOwMhQ3XKB2+vdxK6WWbVAH7s5QpqQCif7a1TNL76GNAATWA1sy6q2gSfss8UJ/Nwza3N6QnFkKclpA==
   dependencies:
     ""@types/http-proxy"" ""^1.17.5""
-    camelcase ""^6.2.0""
     http-proxy ""^1.18.1""
     is-glob ""^4.0.1""
     is-plain-obj ""^3.0.0""
@@ -14341,9 +14340,9 @@ jsdom@^15.2.1:
     xml-name-validator ""^3.0.0""
 
 jsdom@^16.4.0:
-  version ""16.5.2""
-  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.2.tgz#583fac89a0aea31dbf6237e7e4bedccd9beab472""
-  integrity sha512-JxNtPt9C1ut85boCbJmffaQ06NBnzkQY/MWO3YxPW8IWS38A26z+B1oBvA9LwKrytewdfymnhi4UNH3/RAgZrg==
+  version ""16.5.3""
+  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.3.tgz#13a755b3950eb938b4482c407238ddf16f0d2136""
+  integrity sha512-Qj1H+PEvUsOtdPJ056ewXM4UJPCi4hhLA8wpiz9F2YvsRBhuFsXxtrIFAgGBDynQA9isAMGE91PfUYbdMPXuTA==
   dependencies:
     abab ""^2.0.5""
     acorn ""^8.1.0""
@@ -15590,12 +15589,12 @@ micromatch@^3.1.10, micromatch@^3.1.4:
     to-regex ""^3.0.2""
 
 micromatch@^4.0.2:
-  version ""4.0.3""
-  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.3.tgz#fdad8352bf0cbeb89b391b5d244bc22ff3dd4ec8""
-  integrity sha512-ueuSaP4i67F/FAUac9zzZ0Dz/5KeKDkITYIS/k4fps+9qeh1SkeH6gbljcqz97mNBOsaWZ+iv2UobMKK/yD+aw==
+  version ""4.0.4""
+  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.4.tgz#896d519dfe9db25fce94ceb7a500919bf881ebf9""
+  integrity sha512-pRmzw/XUcwXGpD9aI9q/0XOwLNygjETJ8y0ao0wdqprrzDa4YnxLcz7fQRZr8voh8V10kGhABbNcHVk5wHgWwg==
   dependencies:
     braces ""^3.0.1""
-    picomatch ""^2.2.1""
+    picomatch ""^2.2.3""
 
 miller-rabin@^4.0.0:
   version ""4.0.1""
@@ -16356,7 +16355,7 @@ node-pre-gyp@^0.11.0:
     semver ""^5.3.0""
     tar ""^4""
 
-node-releases@^1.1.61, node-releases@^1.1.70:
+node-releases@^1.1.61, node-releases@^1.1.71:
   version ""1.1.71""
   resolved ""https://registry.yarnpkg.com/node-releases/-/node-releases-1.1.71.tgz#cb1334b179896b1c89ecfdd4b725fb7bbdfc7dbb""
   integrity sha512-zR6HoT6LrLCRBwukmrVbHv0EpEQjksO6GmFcZQQuCAy139BEsoVKPYnf3jongYW83fAa1torLGYwxxky/p28sg==
@@ -17571,10 +17570,10 @@ pgpass@1.x:
   dependencies:
     split2 ""^3.1.1""
 
-picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2:
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.2.tgz#21f333e9b6b8eaff02468f5146ea406d345f4dad""
-  integrity sha512-q0M/9eZHzmr0AulXyPwNfZjtwZ/RBZlbN3K3CErVrk50T2ASYI7Bye0EvekFY3IP1Nt2DHu0re+V2ZHIpMkuWg==
+picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2, picomatch@^2.2.3:
+  version ""2.2.3""
+  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.3.tgz#465547f359ccc206d3c48e46a1bcb89bf7ee619d""
+  integrity sha512-KpELjfwcCDUb9PeigTs2mBJzXUPzAuP2oPcA989He8Rte0+YUAjw1JVedDhuTKPkHjSYzMN3npC9luThGYEKdg==
 
 pify@^2.0.0, pify@^2.2.0, pify@^2.3.0:
   version ""2.3.0""
@@ -18446,9 +18445,9 @@ postcss@^7, postcss@^7.0.0, postcss@^7.0.1, postcss@^7.0.14, postcss@^7.0.17, po
     supports-color ""^6.1.0""
 
 postcss@^8.1.0, postcss@^8.2.8:
-  version ""8.2.9""
-  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.9.tgz#fd95ff37b5cee55c409b3fdd237296ab4096fba3""
-  integrity sha512-b+TmuIL4jGtCHtoLi+G/PisuIl9avxs8IZMSmlABRwNz5RLUUACrC+ws81dcomz1nRezm5YPdXiMEzBEKgYn+Q==
+  version ""8.2.10""
+  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.10.tgz#ca7a042aa8aff494b334d0ff3e9e77079f6f702b""
+  integrity sha512-b/h7CPV7QEdrqIxtAf2j31U5ef05uBDuvoXv6L51Q4rcS1jdlXAVKJv+atCFdUXYl9dyTHGyoMzIepwowRJjFw==
   dependencies:
     colorette ""^1.2.2""
     nanoid ""^3.1.22""
@@ -19318,9 +19317,9 @@ rc-tree@^4.0.0, rc-tree@~4.1.0:
     rc-virtual-list ""^3.0.1""
 
 rc-trigger@^5.0.0, rc-trigger@^5.0.4, rc-trigger@^5.1.2, rc-trigger@^5.2.1:
-  version ""5.2.3""
-  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.3.tgz#8c55046ab432d7b52d51c69afb57ebb5bbe37e17""
-  integrity sha512-6Fokao07HUbqKIDkDRFEM0AGZvsvK0Fbp8A/KFgl1ngaqfO1nY037cISCG1Jm5fxImVsXp9awdkP7Vu5cxjjog==
+  version ""5.2.4""
+  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.4.tgz#f1cca4a6c1f378a5d6fadec010292250772069d3""
+  integrity sha512-nLZa4XYo3hOAVauQr7HsGrBtE8/pyoIWhHZnpr7x/H/dd6pPeRzH0//+1TzaBAXylbFgsY6hogKAMeJwaKeDFw==
   dependencies:
     ""@babel/runtime"" ""^7.11.2""
     classnames ""^2.2.6""
@@ -20516,9 +20515,9 @@ rollup@^1.31.1:
     acorn ""^7.1.0""
 
 rollup@^2.40.0, rollup@^2.8.0:
-  version ""2.45.0""
-  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.0.tgz#bfcce2347c96f15f5c78ac860bc38e3349ba27c9""
-  integrity sha512-JJznbtGIsHZfKH0Sa9RpCAy5JarH8SWvBzRAGuRkgzAafb8e8D7VSMJ0O1Bsix1nn91koN/Ecvl2+ZWhljcuTw==
+  version ""2.45.1""
+  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.1.tgz#eae2b94dc2088b4e0a3b7197a5a1ee0bdd589d5c""
+  integrity sha512-vPD+JoDj3CY8k6m1bLcAFttXMe78P4CMxoau0iLVS60+S9kLsv2379xaGy4NgYWu+h2WTlucpoLPAoUoixFBag==
   optionalDependencies:
     fsevents ""~2.3.1""
 
@@ -22971,9 +22970,9 @@ typescript@~4.1.5:
   integrity sha512-6OSu9PTIzmn9TCDiovULTnET6BgXtDYL4Gg4szY+cGsc3JP1dQL8qvE8kShTRx1NIw4Q9IBHlwODjkjWEtMUyA==
 
 ua-parser-js@^0.7.18:
-  version ""0.7.27""
-  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.27.tgz#b54f8ce9eb6c7abf3584edeaf9a3d8b3bd92edba""
-  integrity sha512-eXMaRYK2skomGocoX0x9sBXzx5A1ZVQgXfrW4mTc8dT0zS7olEcyfudAzRC5tIIRgLxQ69B6jut3DI+n5hslPA==
+  version ""0.7.28""
+  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.28.tgz#8ba04e653f35ce210239c64661685bf9121dec31""
+  integrity sha512-6Gurc1n//gjp9eQNXjD9O3M/sMwVtN5S8Lv9bvOYBfKfDNiIIhqiyi01vMBO45u4zkDE420w/e0se7Vs+sIg+g==
 
 uglify-js@3.4.x:
   version ""3.4.10""
@@ -22984,9 +22983,9 @@ uglify-js@3.4.x:
     source-map ""~0.6.1""
 
 uglify-js@^3.1.4, uglify-js@^3.4.9:
-  version ""3.13.3""
-  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.3.tgz#ce72a1ad154348ea2af61f50933c76cc8802276e""
-  integrity sha512-otIc7O9LyxpUcQoXzj2hL4LPWKklO6LJWoJUzNa8A17Xgi4fOeDC8FBDOLHnC/Slo1CQgsZMcM6as0M76BZaig==
+  version ""3.13.4""
+  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.4.tgz#592588bb9f47ae03b24916e2471218d914955574""
+  integrity sha512-kv7fCkIXyQIilD5/yQy8O+uagsYIOt5cZvs890W40/e/rvjMSzJw81o9Bg0tkURxzZBROtDQhW2LFjOGoK3RZw==
 
 uid-number@0.0.6:
   version ""0.0.6""

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",2,"[""7e9bd7c86df1032d53e752654fe4a446951480bb"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""build"", ""docs""]","1. The code changes update two package.json files to modify binary and postinstall script configuration for Windows compatibility, update the yarn.lock file to new dependency versions, and add new documentation to docs/115-release.md for changelog customization.
2. The package.json and yarn.lock changes affect build configuration and dependency management, which aligns with the 'build' label; the changes to docs/115-release.md are solely documentation, aligning with the 'docs' label.
3. 'build' is appropriate because the changes are to build scripts and dependency versions, not CI scripts ('cicd'), test logic ('test'), or documentation ('docs'); 'docs' is appropriate as the documentation file change is fully scoped to documentation, not code or build artifacts.
4. The 'build' and 'docs' labels accurately reflect that this commit updates build/dependency configuration and adds documentation, each change fully scoped to its respective artifact category."
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",1,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""cicd""]","1. The change modifies the GitHub Actions workflow file (.github/workflows/snyk.yml) to schedule the Snyk job to run daily via cron instead of on every push.
2. This aligns with the 'cicd' label, as the modification is entirely within a CI configuration file and changes how the CI pipeline triggers.
3. The 'cicd' label is appropriate because the change does not affect build logic, application code, tests, or documentation—only the CI workflow trigger; alternative labels like 'build', 'test', or 'feat' are not applicable.
4. The 'cicd' label is correct since the commit solely updates the CI configuration for workflow scheduling."
"increase timeout of multiregion failover test

Due to the nature of the test, restarts and failovers can take long. If the recovery takes longer than 15m, then the test will fail unnecessarily. Since we are not really testing for how was it can recover, it is ok to increase the maxInstanceDuration.
use `regexp_instr != 0` instead of `REGEXP` keyword
add postgres-driver typings","diff --git a/.github/workflows/e2e-testbench.yaml b/.github/workflows/e2e-testbench.yaml
index 708f97f..fd0b918 100644
--- a/.github/workflows/e2e-testbench.yaml
+++ b/.github/workflows/e2e-testbench.yaml
@@ -31,6 +31,11 @@ on:
         default: null
         required: false
         type: string
+      maxInstanceDuration:
+        description: 'If an instance takes longer than the given duration to complete, test will fail.'
+        default: '15m'
+        required: false
+        type: string
 
   workflow_call:
     inputs:
@@ -59,6 +64,11 @@ on:
         default: null
         required: false
         type: string
+      maxInstanceDuration:
+        description: 'If an instance takes longer than the given duration to complete, test will fail.'
+        default: '15m'
+        required: false
+        type: string
 
 jobs:
   e2e:
@@ -81,7 +91,7 @@ jobs:
         {
         \""maxTestDuration\"": \""${{ inputs.maxTestDuration || 'P5D' }}\"",
         \""starter\"": [ {\""rate\"": 50, \""processId\"": \""one-task-one-timer\"" } ],
-        \""verifier\"" : { \""maxInstanceDuration\"" : \""15m\"" },
+        \""verifier\"" : { \""maxInstanceDuration\"" : \""${{ inputs.maxInstanceDuration }}\"" },
         \""fault\"": ${{ inputs.fault || 'null' }}
         }
         }
diff --git a/.github/workflows/weekly-e2e.yml b/.github/workflows/weekly-e2e.yml
index 93aaeb5..4bd0afd 100644
--- a/.github/workflows/weekly-e2e.yml
+++ b/.github/workflows/weekly-e2e.yml
@@ -31,4 +31,5 @@ jobs:
       maxTestDuration: P1D
       clusterPlan: Multiregion test simulation
       fault: \""2-region-dataloss-failover\""
+      maxInstanceDuration: 40m
     secrets: inherit

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/packages/cubejs-postgres-driver/driver/index.d.ts b/packages/cubejs-postgres-driver/driver/index.d.ts
new file mode 100644
index 0000000..47dcada
--- /dev/null
+++ b/packages/cubejs-postgres-driver/driver/index.d.ts
@@ -0,0 +1,8 @@
+import { PoolConfig } from ""pg"";
+
+declare module ""@cubejs-backend/postgres-driver"" {
+  class PostgresDriver {
+    constructor(options?: PoolConfig);
+  }
+  export = PostgresDriver;
+}
diff --git a/packages/cubejs-postgres-driver/package.json b/packages/cubejs-postgres-driver/package.json
index 9db5a20..1e9a236 100644
--- a/packages/cubejs-postgres-driver/package.json
+++ b/packages/cubejs-postgres-driver/package.json
@@ -12,6 +12,7 @@
     ""node"": "">=8.11.1""
   },
   ""main"": ""driver/PostgresDriver.js"",
+  ""typings"": ""driver/index.d.ts"",
   ""scripts"": {
     ""lint"": ""eslint **/*.js""
   },
",3,"[""ee824ddd71cbc4ccc26f7c6876d379c4927b79e6"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""364d9bf18b2ce73c04d5ec3a70aefa3e6b83cc12""]","[""cicd"", ""fix"", ""feat""]","1. The changes include increasing the timeout in CI workflow files, updating a regex operation implementation in the Snowflake backend, and adding TypeScript typings for the Postgres driver package.
2. Increasing the timeout in workflow YAML files is a CI/CD configuration change (cicd), updating the regex logic to use a different SQL function corrects behavior (fix), and adding typings introduces new developer-facing capability (feat).
3. 'cicd' is appropriate for workflow YAML changes as they are support scripts, not application code; 'fix' is justified for the regex implementation change as it corrects logic rather than adding new features or refactoring; 'feat' is correct for the addition of TypeScript typings, which is a new feature for type safety, not a documentation or test change.
4. The assigned labels accurately reflect the nature of each code unit: 'cicd' for workflow config, 'fix' for bug correction, and 'feat' for adding typings as a new capability."
"ensure checksum persist flushes to disk
fixed tick interval","diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/backend/services/integrations/main.go b/backend/services/integrations/main.go
index 4a5e764..35c3ff2 100644
--- a/backend/services/integrations/main.go
+++ b/backend/services/integrations/main.go
@@ -54,7 +54,7 @@ func main() {
 	sigchan := make(chan os.Signal, 1)
 	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
 
-	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL)
+	tick := time.Tick(intervals.INTEGRATIONS_REQUEST_INTERVAL * time.Millisecond)
 
 	log.Printf(""Integration service started\n"")
 	manager.RequestAll()
@@ -66,7 +66,7 @@ func main() {
 			pg.Close()
 			os.Exit(0)
 		case <-tick:
-			// log.Printf(""Requesting all...\n"")
+			log.Printf(""Requesting all...\n"")
 			manager.RequestAll()
 		case event := <-manager.Events:
 			// log.Printf(""New integration event: %v\n"", *event.RawErrorEvent)
",2,"[""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""7dc3b70fe40fc7de255a28bb3098bcb8c0d35365""]","[""test"", ""fix""]","1. The first code unit adds a new test ('shouldFlushOnPersist') to SnapshotChecksumTest, verifying that the persist operation flushes to disk, while the second code unit fixes the tick interval calculation in main.go and enables a previously commented log statement.
2. The new test logic aligns with the 'test' object label as it is solely dedicated to testing, and the tick interval correction addresses incorrect time unit usage, which is a classic 'fix' purpose label.
3. 'test' is appropriate for the Java test file because the change is entirely within a test artifact and is not fixing test logic, while 'fix' is correct for the Go file because it repairs a bug affecting runtime behavior, not adding new features or merely restructuring code.
4. The assigned labels 'test' and 'fix' are justified as each code unit is exclusively scoped to either test coverage or a runtime bug fix, with no overlap or ambiguity."
"use an action for issue assignment
update version (nightly.0)
update basic test with colors","diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}

diff --git a/Cargo.lock b/Cargo.lock
index e6f659c..cf93556 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.23""
+version = ""0.1.24-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index c58299b..6e51b6e 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.11"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.11"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.11"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.23"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.24-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index 5f005a1..e1a9964 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.23""
+version = ""0.1.24-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true

diff --git a/core/src/components/label/test/basic/index.html b/core/src/components/label/test/basic/index.html
index d0b566c..377e58c 100644
--- a/core/src/components/label/test/basic/index.html
+++ b/core/src/components/label/test/basic/index.html
@@ -19,12 +19,32 @@
     </ion-header>
 
     <ion-content>
+      <div padding>
+        <ion-label>Default</ion-label>
+
+        <ion-label color=""secondary"">Secondary</ion-label>
+
+        <ion-label color=""tertiary"">Tertiary</ion-label>
+
+        <ion-label color=""danger"">Danger</ion-label>
+
+        <ion-label class=""custom"">Custom</ion-label>
+      </div>
+
       <ion-list>
         <ion-item>
           <ion-label>Default</ion-label>
           <ion-input></ion-input>
         </ion-item>
         <ion-item>
+          <ion-label color=""tertiary"">Tertiary</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
+          <ion-label class=""custom"">Custom</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
           <ion-label text-wrap>Wrap label this label just goes on and on and on</ion-label>
           <ion-input></ion-input>
         </ion-item>
@@ -42,6 +62,12 @@
         </ion-item>
       </ion-list>
     </ion-content>
+
+    <style>
+      .custom {
+        color: lightblue;
+      }
+    </style>
   </ion-app>
 </body>
 
",3,"[""fb3a231b29bc8bff9270b99dd4aff9dad599f21f"", ""92e940efeee199b1e0bbbc3c9eea7f3dc8221619"", ""c3b5dc77ff3d89d389f6f3a868b17d0a8ca63074""]","[""cicd"", ""build"", ""test""]","1. The commit updates a GitHub Actions workflow to use an external action for issue assignment, bumps version numbers in Cargo.toml and Cargo.lock, and enhances a test HTML file by adding color variations and custom styles.
2. The workflow change in .github/workflows/assign.yml is a CI configuration update, matching the 'cicd' object label; the version updates in Cargo.toml and Cargo.lock are related to build metadata, aligning with the 'build' object label; the changes in core/src/components/label/test/basic/index.html introduce new test cases and styling for labels, which fits the 'test' object label as the file is a dedicated test artifact.
3. 'cicd' is appropriate because the workflow file is purely for CI and not build logic; 'build' is correct since only versioning and dependency metadata are updated, not code or features; 'test' is justified as the HTML file is a test file and the changes are test-related additions, not main code, documentation, or refactoring.
4. The assigned labels 'cicd', 'build', and 'test' accurately reflect the exclusive scope of the changes to CI configuration, build metadata, and test logic, respectively, with no overlap or misclassification."
"Support ISNULL
selenium java 4.8.1
rename step","diff --git a/rust/cubesql/src/compile/engine/udf.rs b/rust/cubesql/src/compile/engine/udf.rs
index f3991c0..549167a 100644
--- a/rust/cubesql/src/compile/engine/udf.rs
+++ b/rust/cubesql/src/compile/engine/udf.rs
@@ -3,13 +3,16 @@ use std::sync::Arc;
 
 use datafusion::{
     arrow::{
-        array::{ArrayRef, GenericStringArray, Int32Builder, StringBuilder, UInt32Builder},
+        array::{
+            ArrayRef, BooleanBuilder, GenericStringArray, Int32Builder, StringBuilder,
+            UInt32Builder,
+        },
         datatypes::DataType,
     },
     error::DataFusionError,
     logical_plan::create_udf,
     physical_plan::{
-        functions::{make_scalar_function, Volatility},
+        functions::{make_scalar_function, ReturnTypeFunction, Signature, Volatility},
         udf::ScalarUDF,
     },
 };
@@ -167,3 +170,24 @@ pub fn create_instr_udf() -> ScalarUDF {
         fun,
     )
 }
+
+pub fn create_isnull_udf() -> ScalarUDF {
+    let fun = make_scalar_function(move |args: &[ArrayRef]| {
+        assert!(args.len() == 1);
+
+        let mut builder = BooleanBuilder::new(1);
+        builder.append_value(args[0].is_null(0))?;
+
+        Ok(Arc::new(builder.finish()) as ArrayRef)
+    });
+
+    let return_type: ReturnTypeFunction =
+        Arc::new(move |_| Ok(Arc::new(DataType::Boolean).clone()));
+
+    ScalarUDF::new(
+        ""isnull"",
+        &Signature::any(1, Volatility::Immutable),
+        &return_type,
+        &fun,
+    )
+}
diff --git a/rust/cubesql/src/compile/mod.rs b/rust/cubesql/src/compile/mod.rs
index 891283b..9004ffe 100644
--- a/rust/cubesql/src/compile/mod.rs
+++ b/rust/cubesql/src/compile/mod.rs
@@ -36,7 +36,7 @@ use self::context::*;
 use self::engine::context::SystemVar;
 use self::engine::udf::{
     create_connection_id_udf, create_current_user_udf, create_db_udf, create_instr_udf,
-    create_user_udf, create_version_udf,
+    create_isnull_udf, create_user_udf, create_version_udf,
 };
 use self::parser::parse_sql_to_statement;
 
@@ -1415,6 +1415,7 @@ impl QueryPlanner {
         ctx.register_udf(create_user_udf(props));
         ctx.register_udf(create_current_user_udf(props));
         ctx.register_udf(create_instr_udf());
+        ctx.register_udf(create_isnull_udf());
 
         {
             let schema_provider = MemorySchemaProvider::new();

diff --git a/pom.xml b/pom.xml
index f792f3c..477224a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -60,8 +60,8 @@
         <codehaus-groovy.version>3.0.11</codehaus-groovy.version>
         <jython.version>2.7.0</jython.version>
         <docker-java.version>3.2.14</docker-java.version>
-        <selenium.version>4.8.0</selenium.version>
-        <jmeter-plugins-webdriver.version>4.8.0</jmeter-plugins-webdriver.version>
+        <selenium.version>4.8.1</selenium.version>
+        <jmeter-plugins-webdriver.version>4.8.1</jmeter-plugins-webdriver.version>
         <opentelemetry.version>1.22.0</opentelemetry.version>
         <oracle-database.version>19.7.0.0</oracle-database.version>
         <zookeeper.version>3.8.0</zookeeper.version>

diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index e81d897..5c3ee6b 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -45,7 +45,7 @@ jobs:
       - name: Install dependencies
         run: pnpm install
 
-      - name: Typecheck
+      - name: Build (stub)
         run: pnpm build:stub
 
       - name: Typecheck
",3,"[""f0a4b62f4bd2a1ba2caf37c764b117b352a2f2b3"", ""66f907f2d6ff0956bb5215518678bc79cab83c17"", ""34875bc0e59b43d9041903101c823d25ec194a21""]","[""feat"", ""build"", ""cicd""]","1. The code introduces a new 'isnull' UDF in Rust, registers it in the query planner, updates the Selenium and WebDriver versions in pom.xml, and renames a CI workflow step in .github/workflows/ci.yml.
2. Adding the 'isnull' UDF and registering it is a new feature, aligning with the 'feat' label; updating dependency versions in pom.xml affects the build system, matching the 'build' label; renaming a CI step is a change to CI configuration, which fits the 'cicd' label.
3. 'feat' is appropriate because the codebase gains new SQL function capability, not just a bug fix or refactor; 'build' is correct for dependency version changes, not 'cicd', as pom.xml is a build artifact; 'cicd' is correct for CI workflow changes, not 'build', as .github/workflows/ci.yml is a CI artifact.
4. The assigned labels ('feat', 'build', 'cicd') correctly represent the introduction of a new feature, build dependency updates, and CI configuration changes respectively in this commit."
"fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",1,"[""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""docs""]","1. The code change updates documentation in 'monorepo.md', replacing references from 'folder' to 'dir' and clarifying related descriptions.
2. These edits are strictly to documentation content, aligning directly with the 'docs' label, which is for changes to documentation or text.
3. 'docs' is appropriate because no code, test, CI, or build logic is modified—only documentation is corrected; 'fix' is not suitable as no code behavior is altered, and 'refactor' does not apply since structure or readability of code is not improved.
4. The 'docs' label is correct as the changes are solely documentation corrections reflecting property naming and clarifications."
"add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com>
removing automatic page push on nav
conditionals and iterators in rsx","diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number

diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage

diff --git a/packages/interpreter/src/interpreter.js b/packages/interpreter/src/interpreter.js
index 2f5c06f..58613ea 100644
--- a/packages/interpreter/src/interpreter.js
+++ b/packages/interpreter/src/interpreter.js
@@ -172,7 +172,7 @@ export class Interpreter {
         node.style = {};
       }
       node.style[name] = value;
-    } else if (ns != null || ns != undefined) {
+    } else if (ns != null && ns != undefined) {
       node.setAttributeNS(ns, name, value);
     } else {
       switch (name) {
@@ -266,7 +266,7 @@ export class Interpreter {
         this.AssignId(edit.path, edit.id);
         break;
       case ""CreateElement"":
-        if (edit.namespace !== null || edit.namespace !== undefined) {
+        if (edit.namespace !== null && edit.namespace !== undefined) {
           this.CreateElementNs(edit.name, edit.id, edit.namespace);
         } else {
           this.CreateElement(edit.name, edit.id);
diff --git a/packages/rsx/src/lib.rs b/packages/rsx/src/lib.rs
index 09c6bd6..d974a6c 100644
--- a/packages/rsx/src/lib.rs
+++ b/packages/rsx/src/lib.rs
@@ -245,7 +245,11 @@ impl<'a> DynamicContext<'a> {
                 quote! { ::dioxus::core::TemplateNode::Text(#text) }
             }
 
-            BodyNode::Text(_) | BodyNode::RawExpr(_) | BodyNode::Component(_) => {
+            BodyNode::RawExpr(_)
+            | BodyNode::Text(_)
+            | BodyNode::ForLoop(_)
+            | BodyNode::IfChain(_)
+            | BodyNode::Component(_) => {
                 let ct = self.dynamic_nodes.len();
                 self.dynamic_nodes.push(root);
                 self.node_paths.push(self.current_path.clone());
diff --git a/packages/rsx/src/node.rs b/packages/rsx/src/node.rs
index 4013c9c..7b4bd23 100644
--- a/packages/rsx/src/node.rs
+++ b/packages/rsx/src/node.rs
@@ -5,7 +5,7 @@ use quote::{quote, ToTokens, TokenStreamExt};
 use syn::{
     parse::{Parse, ParseStream},
     spanned::Spanned,
-    token, Expr, LitStr, Result,
+    token, Block, Expr, ExprIf, LitStr, Pat, Result,
 };
 
 /*
@@ -20,6 +20,8 @@ Parse
 pub enum BodyNode {
     Element(Element),
     Component(Component),
+    ForLoop(ForLoop),
+    IfChain(ExprIf),
     Text(IfmtInput),
     RawExpr(Expr),
 }
@@ -35,6 +37,8 @@ impl BodyNode {
             BodyNode::Component(component) => component.name.span(),
             BodyNode::Text(text) => text.source.span(),
             BodyNode::RawExpr(exp) => exp.span(),
+            BodyNode::ForLoop(fl) => fl.for_token.span(),
+            BodyNode::IfChain(f) => f.if_token.span(),
         }
     }
 }
@@ -89,6 +93,28 @@ impl Parse for BodyNode {
             }
         }
 
+        // Transform for loops into into_iter calls
+        if stream.peek(Token![for]) {
+            let _f = stream.parse::<Token![for]>()?;
+            let pat = stream.parse::<Pat>()?;
+            let _i = stream.parse::<Token![in]>()?;
+            let expr = stream.parse::<Box<Expr>>()?;
+            let body = stream.parse::<Block>()?;
+
+            return Ok(BodyNode::ForLoop(ForLoop {
+                for_token: _f,
+                pat,
+                in_token: _i,
+                expr,
+                body,
+            }));
+        }
+
+        // Transform unterminated if statements into terminated optional if statements
+        if stream.peek(Token![if]) {
+            return Ok(BodyNode::IfChain(stream.parse()?));
+        }
+
         Ok(BodyNode::RawExpr(stream.parse::<Expr>()?))
     }
 }
@@ -104,6 +130,104 @@ impl ToTokens for BodyNode {
             BodyNode::RawExpr(exp) => tokens.append_all(quote! {
                  __cx.fragment_from_iter(#exp)
             }),
+            BodyNode::ForLoop(exp) => {
+                let ForLoop {
+                    pat, expr, body, ..
+                } = exp;
+
+                tokens.append_all(quote! {
+                     __cx.fragment_from_iter(
+                        (#expr).into_iter().map(|#pat| {
+                            #body
+                        })
+                     )
+                })
+            }
+            BodyNode::IfChain(chain) => {
+                if is_if_chain_terminated(chain) {
+                    tokens.append_all(quote! {
+                         __cx.fragment_from_iter(#chain)
+                    });
+                } else {
+                    let ExprIf {
+                        cond,
+                        then_branch,
+                        else_branch,
+                        ..
+                    } = chain;
+
+                    let mut body = TokenStream2::new();
+
+                    body.append_all(quote! {
+                        if #cond {
+                            Some(#then_branch)
+                        }
+                    });
+
+                    let mut elif = else_branch;
+
+                    while let Some((_, ref branch)) = elif {
+                        match branch.as_ref() {
+                            Expr::If(ref eelif) => {
+                                let ExprIf {
+                                    cond,
+                                    then_branch,
+                                    else_branch,
+                                    ..
+                                } = eelif;
+
+                                body.append_all(quote! {
+                                    else if #cond {
+                                        Some(#then_branch)
+                                    }
+                                });
+
+                                elif = else_branch;
+                            }
+                            _ => {
+                                body.append_all(quote! {
+                                    else {
+                                        #branch
+                                    }
+                                });
+                                break;
+                            }
+                        }
+                    }
+
+                    body.append_all(quote! {
+                        else { None }
+                    });
+
+                    tokens.append_all(quote! {
+                        __cx.fragment_from_iter(#body)
+                    });
+                }
+            }
+        }
+    }
+}
+
+#[derive(PartialEq, Eq, Clone, Debug, Hash)]
+pub struct ForLoop {
+    pub for_token: Token![for],
+    pub pat: Pat,
+    pub in_token: Token![in],
+    pub expr: Box<Expr>,
+    pub body: Block,
+}
+
+fn is_if_chain_terminated(chain: &ExprIf) -> bool {
+    let mut current = chain;
+    loop {
+        if let Some((_, else_block)) = &current.else_branch {
+            if let Expr::If(else_if) = else_block.as_ref() {
+                current = else_if;
+            } else {
+                return true;
+            }
+        } else {
+            return false;
         }
     }
 }
",3,"[""e2821a56c7d867b8b591f1777019843a2ffca797"", ""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97"", ""6b473cbdc5997af47c56a2a74f5b64da6d4c2ad7""]","[""docs"", ""test"", ""feat""]","1. The commit updates documentation to reference `ibis.to_sql`, removes an automatic page push from a test file, and adds/extends code in `rsx` to support conditionals and iterators, including new parsing and code generation logic for `ForLoop` and `IfChain` constructs.
2. The documentation change in `docs/api/expressions/top_level.md` aligns with the 'docs' label, the test logic removal in `ionic/components/nav/test/basic/index.ts` fits the 'test' label, and the new feature additions in `packages/rsx/src/lib.rs` and `packages/rsx/src/node.rs` (support for conditionals and iterators in rsx) match the 'feat' label definition.
3. 'docs' is appropriate for the documentation update (not 'fix' or 'refactor' since it is a content update), 'test' is correct for changes scoped to test logic (not 'feat' as it does not add product features), and 'feat' is correct for the new language features in rsx (not 'fix' or 'refactor' since these are clear capability additions).
4. The assigned labels 'docs', 'test', and 'feat' are appropriate because each code unit is fully scoped to documentation, test, or feature addition, with no overlap or ambiguity regarding purpose or artifact role."
rename ELECTRON_CACHE env variable to electron_config_cache (#21313),"diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as
",1,"[""f2f52c23b513dd857350f3c163f676d37189d0d3""]","[""docs""]","1. The change updates a documentation file by renaming a referenced environment variable from 'ELECTRON_CACHE' to 'electron_config_cache' in the installation guide.
2. This aligns with the 'docs' label, as the change is entirely within documentation content and does not alter code, tests, or build configurations.
3. The 'docs' label is appropriate because the modification is confined to explanatory text; it does not introduce new features ('feat'), fix behavioral bugs ('fix'), refactor code ('refactor'), or affect tests, CI, or build systems.
4. The 'docs' label is correct because the commit solely updates documentation to reflect the new environment variable name."
pin version of actionlint used,"diff --git a/.github/workflows/introspect.yml b/.github/workflows/introspect.yml
index b6d9125..82d22a5 100644
--- a/.github/workflows/introspect.yml
+++ b/.github/workflows/introspect.yml
@@ -25,5 +25,5 @@ jobs:
       # From https://github.com/rhysd/actionlint/blob/main/docs/usage.md#use-actionlint-on-github-actions
       - name: Check workflow files
         run: |
-          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash)
+          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash) 1.6.25
           ./actionlint -color -shellcheck=""""
",1,"[""b702adc245f679ae20d84de39f0d63b14aabed5d""]","[""cicd""]","1. The change modifies a GitHub Actions workflow file to explicitly pin the version of 'actionlint' used in CI by specifying version '1.6.25' in the script invocation.
2. This update is scoped entirely to a CI configuration file and affects how CI checks are run, directly aligning with the 'cicd' object label definition.
3. The 'cicd' label is appropriate because the modification targets a workflow file and does not introduce new application features ('feat'), fix a code bug ('fix'), refactor code structure ('refactor'), or alter test or documentation artifacts ('test', 'docs').
4. The 'cicd' label accurately reflects a change dedicated to CI configuration, as required by the classification instructions."
add canonical `_name` to edge packages,"diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index e92e3c9..0b7a11a 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -53,6 +53,7 @@ async function loadWorkspace (dir: string) {
   }
 
   const rename = (from: string, to: string) => {
+    find(from).data._name = find(from).data.name
     find(from).data.name = to
     for (const pkg of packages) {
       pkg.updateDeps((dep) => {
",1,"[""573f87edf9bdc19c9c4c3a978fad6ed3ce788f5f""]","[""build""]","1. The code change adds a line to the bump-edge.ts script that sets a canonical _name property on package data before renaming the package.
2. This modification is entirely within a script that manages package metadata for build or release processes, aligning with the 'build' label which covers changes to build scripts or configuration.
3. The change does not introduce new features (not 'feat'), fix a bug (not 'fix'), or restructure code for maintainability (not 'refactor'); it also does not affect documentation, tests, or CI/CD configuration, ruling out 'docs', 'test', and 'cicd'.
4. The 'build' label is appropriate because the change modifies a build/release management script, directly affecting the build system."
"replace api call which requires auth token in public page

re #4694

Signed-off-by: Pranav C <pranavxc@gmail.com>
fix unit tests","diff --git a/packages/nc-gui/composables/useSharedView.ts b/packages/nc-gui/composables/useSharedView.ts
index cb0c5ea..f67a6c9 100644
--- a/packages/nc-gui/composables/useSharedView.ts
+++ b/packages/nc-gui/composables/useSharedView.ts
@@ -17,7 +17,7 @@ export function useSharedView() {
 
   const { appInfo } = $(useGlobal())
 
-  const { loadProject } = useProject()
+  const { project } = useProject()
 
   const appInfoDefaultLimit = appInfo.defaultLimit || 25
 
@@ -76,7 +76,16 @@ export function useSharedView() {
 
     await setMeta(viewMeta.model)
 
-    await loadProject(true, viewMeta.project_id)
+    // if project is not defined then set it with an object containing base
+    if (!project.value?.bases)
+      project.value = {
+        bases: [
+          {
+            id: viewMeta.base_id,
+            type: viewMeta.client,
+          },
+        ],
+      }
 
     const relatedMetas = { ...viewMeta.relatedMetas }
     Object.keys(relatedMetas).forEach((key) => setMeta(relatedMetas[key]))

diff --git a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
index 4d771d6..9f9683c 100644
--- a/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
+++ b/src/components/__tests__/__snapshots__/BottomNavigation.test.js.snap
@@ -9,9 +9,6 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -132,6 +129,33 @@ exports[`renders custom icon and label in non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -599,9 +623,6 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -783,12 +804,15 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -805,17 +829,20 @@ exports[`renders custom icon and label in shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
@@ -1374,9 +1401,6 @@ exports[`renders non-shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -1497,6 +1521,33 @@ exports[`renders non-shifting bottom navigation 1`] = `
         ]
       }
     >
+      <AnimatedComponent
+        pointerEvents=""none""
+        style={
+          Array [
+            Object {
+              ""position"": ""absolute"",
+            },
+            Object {
+              ""backgroundColor"": ""rgba(0, 0, 0, 0.12)"",
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -54.666666666666664,
+              ""opacity"": 0.002,
+              ""top"": -20,
+              ""transform"": Array [
+                Object {
+                  ""translateX"": 0,
+                },
+                Object {
+                  ""scale"": 0.001,
+                },
+              ],
+              ""width"": 96,
+            },
+          ]
+        }
+      />
       <TouchableWithoutFeedback
         key=""key-0""
         onPress={[Function]}
@@ -2072,9 +2123,6 @@ exports[`renders shifting bottom navigation 1`] = `
       Object {
         ""flex"": 1,
       },
-      Object {
-        ""backgroundColor"": ""#000000"",
-      },
       undefined,
     ]
   }
@@ -2256,12 +2304,15 @@ exports[`renders shifting bottom navigation 1`] = `
               ""backgroundColor"": undefined,
               ""borderRadius"": 0,
               ""height"": 0,
-              ""left"": 6,
+              ""left"": -4,
               ""opacity"": 0,
               ""top"": 28,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.008,
                 },
               ],
               ""width"": 0,
@@ -2278,17 +2329,20 @@ exports[`renders shifting bottom navigation 1`] = `
             },
             Object {
               ""backgroundColor"": ""rgba(255, 255, 255, 0.12)"",
-              ""borderRadius"": 36,
-              ""height"": 72,
-              ""left"": -30,
-              ""opacity"": 0,
-              ""top"": -8,
+              ""borderRadius"": 48,
+              ""height"": 96,
+              ""left"": -52,
+              ""opacity"": 0.002,
+              ""top"": -20,
               ""transform"": Array [
                 Object {
-                  ""scale"": 0.002,
+                  ""translateX"": 10,
+                },
+                Object {
+                  ""scale"": 0.001,
                 },
               ],
-              ""width"": 72,
+              ""width"": 96,
             },
           ]
         }
",2,"[""4986a5892fb00bd5a6b2065ad8cfefbc36052dd7"", ""87427fe39d165bee2acedde8dbaa237cca3fb61e""]","[""fix"", ""test""]","1. The code changes in 'useSharedView.ts' replace an API call that required authentication with logic that sets the project state directly, addressing a bug where unauthenticated users on a public page would encounter issues; the test snapshot updates in '__snapshots__/BottomNavigation.test.js.snap' reflect changes in the UI output, likely due to the fix.
2. The change in 'useSharedView.ts' aligns with the 'fix' label as it corrects faulty behavior related to authentication on public pages, while the snapshot file is a test artifact updated to match the corrected UI state, aligning with the 'test' label.
3. 'fix' is appropriate for the main code because it resolves a user-facing bug, not introducing new features ('feat') or only restructuring code ('refactor'); 'test' is correct for the snapshot file as it is solely concerned with maintaining accurate test outputs, not affecting runtime code or documentation.
4. The combination of 'fix' for the bug resolution in application logic and 'test' for the updated test snapshots precisely reflects the intent and scope of the changes in this commit."
"setup jest and add m.ts tests
use connect instead of begin to avoid nesting transactions","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/ibis/backends/duckdb/__init__.py b/ibis/backends/duckdb/__init__.py
index 2006f59..bb2028e 100644
--- a/ibis/backends/duckdb/__init__.py
+++ b/ibis/backends/duckdb/__init__.py
@@ -1180,7 +1180,7 @@ WHERE catalog_name = :database""""""
     def _register_udfs(self, expr: ir.Expr) -> None:
         import ibis.expr.operations as ops
 
-        with self.begin() as con:
+        with self.con.connect() as con:
             for udf_node in expr.op().find(ops.ScalarUDF):
                 compile_func = getattr(
                     self, f""_compile_{udf_node.__input_type__.name.lower()}_udf""
",2,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""6889543bec720e7e7da66535e1012cb66edfe081""]","[""test"", ""fix""]","1. The commit adds new and modifies existing test cases in 'm.spec.ts' and changes a method call from 'self.begin()' to 'self.con.connect()' in 'duckdb/__init__.py' to avoid transaction nesting.
2. The changes in 'm.spec.ts' are dedicated to adding and updating test logic, matching the definition of the 'test' label, while the change in 'duckdb/__init__.py' addresses a bug related to transaction management, aligning with the 'fix' label.
3. 'test' is appropriate for the test file changes because the code is solely focused on test cases, not on code behavior or documentation, and 'fix' is appropriate for the backend code change as it corrects faulty transactional logic, not introducing new features or refactoring for structure.
4. The 'test' and 'fix' labels are correctly assigned, as the commit both adds/modifies test cases and resolves a bug in transaction handling."
"spring version, core version","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",1,"[""c55591ba157298a9c5816693c102a89dfd058830""]","[""build""]","1. The changes update dependency versions in 'pom.xml' and 'backend/pom.xml', specifically upgrading 'ms-jmeter-core', 'ApacheJMeter_functions', and the Spring Boot parent version.
2. These modifications affect the build system's configuration by changing which versions of core libraries and frameworks are used, aligning directly with the 'build' label definition.
3. The 'build' label is appropriate because the changes are limited to dependency version management—no application logic, tests, documentation, or CI/CD scripts are altered, ruling out 'feat', 'fix', 'refactor', 'test', 'docs', or 'cicd'.
4. The 'build' label accurately reflects that the commit solely modifies build configuration by updating dependency versions."
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.
fetch git history
make it mode less","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
index 6726e35..9114eeb 100644
--- a/.github/workflows/ci.yml
+++ b/.github/workflows/ci.yml
@@ -172,6 +172,8 @@ jobs:
 
     steps:
       - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
       - run: corepack enable
       - uses: actions/setup-node@v3
         with:
diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index aa33d76..1d1cbc9 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -18,7 +18,7 @@ async function main () {
 
   const config = await loadChangelogConfig(process.cwd())
 
-  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0', 'main']).stdout
+  const latestTag = execaSync('git', ['describe', '--tags', '--abbrev=0']).stdout
 
   const commits = await getGitDiff(latestTag)
   const bumpType = determineSemverChange(parseCommits(commits, config), config)

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",3,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""e11d55a4922978b89a2c50bf577124b09449e89c"", ""771857b1df9470ebc15357e8879118a72c649d5b""]","[""fix"", ""cicd"", ""refactor""]","1. The commit modifies cache configuration logic to set a correct default (fixing a bug), updates a CI workflow to fetch full git history, changes a script to simplify git tag fetching, and refactors/removes themed thumbnail SCSS files and related code to consolidate styling.
2. The cache config logic change is a clear bug fix, aligning with the 'fix' label; the CI workflow change is dedicated CI configuration, aligning with 'cicd'; the refactoring of thumbnail component code and SCSS consolidation is a structural improvement without changing external behavior, aligning with 'refactor'.
3. 'fix' is appropriate for the cache default bug (not 'feat' or 'refactor' as it corrects faulty behavior); 'cicd' is correct for the workflow file change (not 'build', as it is a CI script); 'refactor' fits the style and code consolidation (not 'fix', since these changes do not resolve bugs or add features).
4. The labels 'fix', 'cicd', and 'refactor' accurately reflect the motivations and objects of the respective code units in this commit according to the instructions."
init environ cache,"diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {
",1,"[""dc50bd35462a49058c91a939fc8830ae7a9eb692""]","[""fix""]","1. The code change initializes the 'environCache' map before it is used, preventing possible nil map assignment errors.
2. This directly addresses a bug where the map could be nil, aligning with the 'fix' label definition of correcting faults in the codebase.
3. The 'fix' label is appropriate because the change resolves a potential runtime error, whereas 'feat' would be for new features and 'refactor' for non-behavioral improvements.
4. The 'fix' label accurately represents the correction of a bug by ensuring proper map initialization."
"move group logical op outside

Signed-off-by: Pranav C <pranavxc@gmail.com>
temporary do no run ""verify-ffmpeg.py"" on Mac CI (#14986)
update version (v0.6.18)","diff --git a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
index 5138589..f756981 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
@@ -2,40 +2,46 @@
   <div
     class=""backgroundColor pa-2 menu-filter-dropdown""
     :class=""{ nested }""
-    :style=""{ width: nested ? '100%' : '530px' }""
+    :style=""{ width: nested ? '100%' : '630px' }""
   >
     <div class=""grid"" @click.stop>
       <template v-for=""(filter, i) in filters"" dense>
         <template v-if=""filter.status !== 'delete'"">
-          <div v-if=""filter.is_group"" :key=""i"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
-            <div class=""d-flex"" style=""gap: 6px; padding: 0 6px"">
-              <v-icon
-                v-if=""!filter.readOnly""
-                small
-                class=""nc-filter-item-remove-btn""
-                @click.stop=""deleteFilter(filter, i)""
-              >
-                mdi-close-box
-              </v-icon>
-              <span v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
-              <v-select
-                v-else
-                v-model=""filter.logical_op""
-                class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
-                :items=""['and', 'or']""
-                solo
-                flat
-                dense
-                hide-details
-                placeholder=""Group op""
-                @click.stop
-                @change=""saveOrUpdate(filter, i)""
-              >
-                <template #item=""{ item }"">
-                  <span class=""caption font-weight-regular"">{{ item }}</span>
-                </template>
-              </v-select>
-            </div>
+          <template v-if=""filter.is_group"">
+            <v-icon
+              v-if=""!filter.readOnly""
+              small
+              class=""nc-filter-item-remove-btn""
+              @click.stop=""deleteFilter(filter, i)""
+              :key=""i + '_1'""
+            >
+              mdi-close-box
+            </v-icon>
+            <span v-else :key=""i + '_1'"" />
+
+            <span :key=""i + '_2'"" v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <v-select
+              v-else
+              :key=""i + '_2'""
+              v-model=""filter.logical_op""
+              class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
+              :items=""['and', 'or']""
+              solo
+              flat
+              dense
+              hide-details
+              placeholder=""Group op""
+              @click.stop
+              @change=""saveOrUpdate(filter, i)""
+            >
+              <template #item=""{ item }"">
+                <span class=""caption font-weight-regular"">{{ item }}</span>
+              </template>
+            </v-select>
+            <span :key=""i + '_3'"" style=""grid-column: span 3""></span>
+          </template>
+
+          <div v-if=""filter.is_group"" :key=""i + '_4'"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
             <column-filter
               v-if=""filter.id || shared""
               ref=""nestedFilter""
@@ -54,19 +60,19 @@
           <template v-else>
             <v-icon
               v-if=""!filter.readOnly""
-              :key=""i + '_1'""
+              :key=""i + '_5'""
               small
               class=""nc-filter-item-remove-btn""
               @click.stop=""deleteFilter(filter, i)""
             >
               mdi-close-box
             </v-icon>
-            <span v-else :key=""i + '_1'"" />
-            <span v-if=""!i"" :key=""i + '_2'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <span v-else :key=""i + '_5'"" />
+            <span v-if=""!i"" :key=""i + '_6'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
 
             <v-select
               v-else
-              :key=""i + '_2'""
+              :key=""i + '_6'""
               v-model=""filter.logical_op""
               class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
               :items=""['and', 'or']""
@@ -84,7 +90,7 @@
             </v-select>
 
             <field-list-auto-complete-dropdown
-              :key=""i + '_3'""
+              :key=""i + '_7'""
               v-model=""filter.fk_column_id""
               class=""caption nc-filter-field-select""
               :columns=""columns""
@@ -94,7 +100,7 @@
             />
 
             <v-select
-              :key=""i + '_4'""
+              :key=""i + '_8'""
               v-model=""filter.comparison_op""
               class=""flex-shrink-1 flex-grow-0 caption nc-filter-operation-select""
               :items=""filterComparisonOp(filter)""
@@ -114,11 +120,11 @@
                 <span class=""caption font-weight-regular"">{{ item.text }}</span>
               </template>
             </v-select>
-            <span v-else :key=""i + '_4'""></span>
+            <span v-else :key=""i + '_8'""></span>
             <span v-if=""['null', 'notnull', 'empty', 'notempty'].includes(filter.comparison_op)"" :key=""i + '_5'"" />
             <v-checkbox
               v-else-if=""types[filter.field] === 'boolean'""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               dense
               :disabled=""filter.readOnly""
@@ -126,7 +132,7 @@
             />
             <v-text-field
               v-else-if=""filter && filter.fk_column_id""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               solo
               flat
@@ -137,7 +143,7 @@
               @click.stop
               @input=""saveOrUpdate(filter, i)""
             />
-            <span v-else :key=""i + '_5'""></span>
+            <span v-else :key=""i + '_9'""></span>
           </template>
         </template>
       </template>
@@ -411,6 +417,7 @@ export default {
         parentId: this.parentId,
         is_group: true,
         status: 'update',
+        logical_op: 'and',
       });
       this.filters = this.filters.slice();
       const index = this.filters.length - 1;
@@ -478,4 +485,8 @@ export default {
   column-gap: 6px;
   row-gap: 6px;
 }
+
+.nc-filter-value-select {
+  min-width: 100px;
+}
 </style>

diff --git a/vsts.yml b/vsts.yml
index 6cb0eb3..a058238 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -86,13 +86,13 @@ jobs:
         killall Electron
       fi
     displayName: Make sure Electron isn't running from previous tests
-
-  - bash: |
-      cd src
-      python electron/script/verify-ffmpeg.py --source-root ""$PWD"" --build-dir out/Default --ffmpeg-path out/ffmpeg
-    displayName: Verify non proprietary ffmpeg
-    condition: and(succeeded(), eq(variables['RUN_TESTS'], '1'))
-    timeoutInMinutes: 5
+# FIXME(alexeykuzmin)
+#  - bash: |
+#      cd src
+#      python electron/script/verify-ffmpeg.py --source-root ""$PWD"" --build-dir out/Default --ffmpeg-path out/ffmpeg
+#    displayName: Verify non proprietary ffmpeg
+#    condition: and(succeeded(), eq(variables['RUN_TESTS'], '1'))
+#    timeoutInMinutes: 5
 
   - bash: |
       cd src

diff --git a/Cargo.lock b/Cargo.lock
index c32d8b4..599790e 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.30-nightly.2""
+version = ""0.1.30""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -125,7 +125,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -133,7 +133,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index baaa0ac..5082cd3 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.18-nightly.2""
+version = ""0.6.18""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 experimental = [""erg_common/experimental"", ""erg_parser/experimental"", ""erg_compiler/experimental""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.18-nightly.2"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.30-nightly.2"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.18"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.18"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.18"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.30"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index 3efbf4e..9f902fa 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.30-nightly.2""
+version = ""0.1.30""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true
",3,"[""4f86f2570b274c45605cc59d9adb38f7ed30cd17"", ""9187415f5ee35d2e88dd834e413fc16bf19c5db1"", ""bb3e3d9b96e435c3b92fc208bca93d1ad7e1ad50""]","[""refactor"", ""cicd"", ""build""]","1. The ColumnFilter.vue change restructures the logical operator handling in the filter UI, making the logic more explicit and moving it outside a nested block, without altering external behavior; this is a structural code improvement. The vsts.yml change comments out a CI step for Mac, affecting only the continuous integration pipeline. The Cargo.lock, Cargo.toml, and crates/els/Cargo.toml changes update package versions from nightly to release, affecting only build metadata and dependency resolution.
2. The ColumnFilter.vue change aligns with 'refactor' as it improves code organization without changing functionality. The vsts.yml change fits 'cicd' because it modifies CI configuration. The Cargo and lock file changes match 'build' since they solely update versioning/build configuration.
3. 'refactor' is correct for the Vue component because the logic is restructured for clarity, not to fix a bug or add a feature. 'cicd' is appropriate for the CI config change, as it does not affect code or tests directly. 'build' is suitable for the version bumps, as these are strictly build/dependency updates, not code or CI logic changes.
4. The assigned labels—refactor, cicd, and build—are appropriate because each code unit's changes are clearly scoped to code restructuring, CI pipeline modification, and build system updates, respectively."
"updated to lerna v6
fix scroll behavior in navigation
right side menus","diff --git a/lerna.json b/lerna.json
index 29cb6ed..4488fb6 100644
--- a/lerna.json
+++ b/lerna.json
@@ -25,7 +25,6 @@
   ""npmClient"": ""pnpm"",
   ""useWorkspaces"": true,
   ""conventionalCommits"": true,
-  ""useNx"": true,
   ""command"": {
     ""version"": {
       ""message"": ""chore(release): published new version""
diff --git a/nx.json b/nx.json
index 00997ba..b3f2627 100644
--- a/nx.json
+++ b/nx.json
@@ -33,32 +33,6 @@
       }
     }
   },
-  ""targetDependencies"": {
-    ""build"": [
-      {
-        ""target"": ""build"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""build:ci"": [
-      {
-        ""target"": ""build:ci"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""prepare"": [
-      {
-        ""target"": ""prepare"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""package"": [
-      {
-        ""target"": ""package"",
-        ""projects"": ""dependencies""
-      }
-    ]
-  },
   ""affected"": {
     ""defaultBase"": ""main""
   },
@@ -66,5 +40,28 @@
     ""@nrwl/js"": {
       ""analyzeSourceFiles"": false
     }
+  },
+  ""$schema"": ""./node_modules/nx/schemas/nx-schema.json"",
+  ""targetDefaults"": {
+    ""build"": {
+      ""dependsOn"": [
+        ""^build""
+      ]
+    },
+    ""build:ci"": {
+      ""dependsOn"": [
+        ""^build:ci""
+      ]
+    },
+    ""prepare"": {
+      ""dependsOn"": [
+        ""^prepare""
+      ]
+    },
+    ""package"": {
+      ""dependsOn"": [
+        ""^package""
+      ]
+    }
   }
 }

diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 5959fd2..08d5674 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -90,12 +90,21 @@ function SidebarItem({
 type SidebarNodeWrapper = {
   children: React.ReactNode,
   node: Sitemap,
-  elementRef: React.MutableRefObject<HTMLLIElement | null>;
+  isActive: boolean;
 };
 
-function SidebarNodeWrapper({ children, node, elementRef }: SidebarNodeWrapper) {
+function SidebarNodeWrapper({ children, node, isActive }: SidebarNodeWrapper) {
+  const { asPath } = useRouter();
+  const nodeRef = useRef<HTMLLIElement | null>(null);
+
+  useEffect(() => {
+    if (isActive) {
+      nodeRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
+    }
+  }, [asPath]);
+
   if (node.resource?.label) {
-    return <li ref={elementRef}>{children}</li>;
+    return <li ref={nodeRef}>{children}</li>;
   }
 
   return <>{children}</>;
@@ -109,14 +118,12 @@ type SidebarNodeProps = {
 
 function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   const { asPath } = useRouter();
-  const nodeWrapperRef = useRef<HTMLLIElement | null>(null);
   const isFirstLevel = level === 1;
   const initialIsExpanded = !isFirstLevel || hasActiveChild(node);
   const [isExpanded, setIsExpanded] = useState(initialIsExpanded);
 
   useEffect(() => {
     setIsExpanded(initialIsExpanded);
-    nodeWrapperRef.current?.scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });
   }, [asPath]);
 
   const id = node.resource?.label?.toLowerCase().replace(/\s/g, '-');
@@ -136,7 +143,7 @@ function SidebarNode({ node, level, isNodeActive }: SidebarNodeProps) {
   }
 
   return (
-    <SidebarNodeWrapper node={node} elementRef={nodeWrapperRef}>
+    <SidebarNodeWrapper node={node} isActive={isNodeActive(node)}>
       <>
         {node.resource?.label ? (
           <SidebarItem

diff --git a/ionic/components/menu/menu-types.scss b/ionic/components/menu/menu-types.scss
index dbbfdda..5e4f990 100644
--- a/ionic/components/menu/menu-types.scss
+++ b/ionic/components/menu/menu-types.scss
@@ -35,3 +35,7 @@ ion-menu[type=overlay] {
     }
   }
 }
+
+ion-menu[type=overlay][side=right] {
+  left: 8px;
+}
diff --git a/ionic/components/menu/menu-types.ts b/ionic/components/menu/menu-types.ts
index 360aeb4..0666a38 100644
--- a/ionic/components/menu/menu-types.ts
+++ b/ionic/components/menu/menu-types.ts
@@ -10,7 +10,7 @@ import {Animation} from 'ionic/animations/animation';
  */
 export class MenuType {
 
-  constructor(menu: Menu) {
+  constructor() {
     this.open = new Animation();
     this.close = new Animation();
   }
@@ -88,16 +88,17 @@ class MenuRevealType extends MenuType {
     let duration = 250;
 
     let openedX = (menu.width() * (menu.side == 'right' ? -1 : 1)) + 'px';
+    let closedX = '0px'
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let contentOpen = new Animation(menu.getContentElement());
-    contentOpen.fromTo(TRANSLATE_X, CENTER, openedX);
+    contentOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(contentOpen);
 
     let contentClose = new Animation(menu.getContentElement());
-    contentClose.fromTo(TRANSLATE_X, openedX, CENTER);
+    contentClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(contentClose);
   }
 }
@@ -117,13 +118,23 @@ class MenuOverlayType extends MenuType {
     let duration = 250;
     let backdropOpacity = 0.5;
 
-    let closedX = (menu.width() * (menu.side == 'right' ? 1 : -1)) + 'px';
+    let closedX, openedX;
+    if (menu.side == 'right') {
+      // right side
+      closedX = menu.platform.width() + 'px';
+      openedX = (menu.platform.width() - menu.width() - 8) + 'px';
+
+    } else {
+      // left side
+      closedX = -menu.width() + 'px';
+      openedX = '8px';
+    }
 
     this.open.easing(easing).duration(duration);
     this.close.easing(easing).duration(duration);
 
     let menuOpen = new Animation(menu.getMenuElement());
-    menuOpen.fromTo(TRANSLATE_X, closedX, '8px');
+    menuOpen.fromTo(TRANSLATE_X, closedX, openedX);
     this.open.add(menuOpen);
 
     let backdropOpen = new Animation(menu.getBackdropElement());
@@ -131,7 +142,7 @@ class MenuOverlayType extends MenuType {
     this.open.add(backdropOpen);
 
     let menuClose = new Animation(menu.getMenuElement());
-    menuClose.fromTo(TRANSLATE_X, '8px', closedX);
+    menuClose.fromTo(TRANSLATE_X, openedX, closedX);
     this.close.add(menuClose);
 
     let backdropClose = new Animation(menu.getBackdropElement());
@@ -144,4 +155,3 @@ Menu.register('overlay', MenuOverlayType);
 
 const OPACITY = 'opacity';
 const TRANSLATE_X = 'translateX';
-const CENTER = '0px';
diff --git a/ionic/components/menu/menu.ts b/ionic/components/menu/menu.ts
index d911b2e..e980069 100644
--- a/ionic/components/menu/menu.ts
+++ b/ionic/components/menu/menu.ts
@@ -4,6 +4,7 @@ import {Ion} from '../ion';
 import {IonicApp} from '../app/app';
 import {IonicConfig} from '../../config/config';
 import {IonicComponent} from '../../config/annotations';
+import {IonicPlatform} from '../../platform/platform';
 import * as gestures from  './menu-gestures';
 
 
@@ -35,10 +36,16 @@ import * as gestures from  './menu-gestures';
 })
 export class Menu extends Ion {
 
-  constructor(app: IonicApp, elementRef: ElementRef, config: IonicConfig) {
+  constructor(
+    app: IonicApp,
+    elementRef: ElementRef,
+    config: IonicConfig,
+    platform: IonicPlatform
+  ) {
     super(elementRef, config);
-
     this.app = app;
+    this.platform = platform;
+
     this.opening = new EventEmitter('opening');
     this.isOpen = false;
     this._disableTime = 0;
@@ -46,9 +53,9 @@ export class Menu extends Ion {
 
   onInit() {
     super.onInit();
-    this.contentElement = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
+    this._cntEle = (this.content instanceof Node) ? this.content : this.content.getNativeElement();
 
-    if (!this.contentElement) {
+    if (!this._cntEle) {
       return console.error('Menu: must have a [content] element to listen for drag events on. Example:\n\n<ion-menu [content]=""content""></ion-menu>\n\n<ion-content #content></ion-content>');
     }
 
@@ -61,8 +68,8 @@ export class Menu extends Ion {
     this._initGesture();
     this._initType(this.type);
 
-    this.contentElement.classList.add('menu-content');
-    this.contentElement.classList.add('menu-content-' + this.type);
+    this._cntEle.classList.add('menu-content');
+    this._cntEle.classList.add('menu-content-' + this.type);
 
     let self = this;
     this.onContentClick = function(ev) {
@@ -161,11 +168,11 @@ export class Menu extends Ion {
 
     this.isOpen = isOpen;
 
-    this.contentElement.classList[isOpen ? 'add' : 'remove']('menu-content-open');
+    this._cntEle.classList[isOpen ? 'add' : 'remove']('menu-content-open');
 
-    this.contentElement.removeEventListener('click', this.onContentClick);
+    this._cntEle.removeEventListener('click', this.onContentClick);
     if (isOpen) {
-      this.contentElement.addEventListener('click', this.onContentClick);
+      this._cntEle.addEventListener('click', this.onContentClick);
 
     } else {
       this.getNativeElement().classList.remove('show-menu');
@@ -220,7 +227,7 @@ export class Menu extends Ion {
    * @return {Element} The Menu's associated content element.
    */
   getContentElement() {
-    return this.contentElement;
+    return this._cntEle;
   }
 
   /**
@@ -239,7 +246,7 @@ export class Menu extends Ion {
     this.app.unregister(this.id);
     this._gesture && this._gesture.destroy();
     this._type && this._type.onDestroy();
-    this.contentElement = null;
+    this._cntEle = null;
   }
 
 }
diff --git a/ionic/components/menu/test/basic/index.ts b/ionic/components/menu/test/basic/index.ts
index 698cec4..65952ff 100644
--- a/ionic/components/menu/test/basic/index.ts
+++ b/ionic/components/menu/test/basic/index.ts
@@ -36,9 +36,9 @@ class E2EApp {
     ];
   }
 
-  openPage(menu, page) {
+  openPage(page) {
     // close the menu when clicking a link from the menu
-    menu.close();
+    this.app.getComponent('leftMenu').close();
 
     // Reset the content nav to have just this page
     // we wouldn't want the back button to show in this scenario
diff --git a/ionic/components/menu/test/basic/main.html b/ionic/components/menu/test/basic/main.html
index 9bdeb5c..4905ae6 100644
--- a/ionic/components/menu/test/basic/main.html
+++ b/ionic/components/menu/test/basic/main.html
@@ -1,4 +1,4 @@
-<ion-menu #menu [content]=""content"">
+<ion-menu [content]=""content"" id=""leftMenu"">
 
   <ion-toolbar secondary>
     <ion-title>Left Menu</ion-title>
@@ -8,11 +8,35 @@
 
     <ion-list>
 
-      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(menu, p)"">
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
         {{p.title}}
       </button>
 
-      <button ion-item menu-toggle no-forward-icon class=""e2eCloseMenu"">
+      <button ion-item menu-toggle=""leftMenu"" no-forward-icon class=""e2eCloseMenu"">
+        Close Menu
+      </button>
+
+    </ion-list>
+  </ion-content>
+
+</ion-menu>
+
+
+<ion-menu side=""right"" [content]=""content"" id=""rightMenu"">
+
+  <ion-toolbar secondary>
+    <ion-title>Right Menu</ion-title>
+  </ion-toolbar>
+
+  <ion-content>
+
+    <ion-list>
+
+      <button ion-item *ng-for=""#p of pages"" (click)=""openPage(p)"">
+        {{p.title}}
+      </button>
+
+      <button ion-item menu-toggle=""rightMenu"" no-forward-icon class=""e2eCloseMenu"">
         Close Menu
       </button>
 
diff --git a/ionic/components/menu/test/basic/page1.html b/ionic/components/menu/test/basic/page1.html
index 1881d9e..2bc5c79 100644
--- a/ionic/components/menu/test/basic/page1.html
+++ b/ionic/components/menu/test/basic/page1.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -21,19 +21,23 @@
     </button>
   </ion-nav-items>
 
-  <a menu-toggle secondary>
+  <a menu-toggle=""rightMenu"" secondary>
     <icon menu></icon>
   </a>
 
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 1</h3>
 
   <p>
-    <button class=""e2eContentToggleMenu"" menu-toggle>Toggle Menu</button>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""leftMenu"">Toggle Left Menu</button>
+  </p>
+
+  <p>
+    <button class=""e2eContentToggleMenu"" menu-toggle=""rightMenu"">Toggle Right Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/menu/test/basic/page2.html b/ionic/components/menu/test/basic/page2.html
index 9801c4f..098f3e1 100644
--- a/ionic/components/menu/test/basic/page2.html
+++ b/ionic/components/menu/test/basic/page2.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -11,12 +11,12 @@
 
 </ion-navbar>
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 2</h3>
 
   <p>
-    <button menu-toggle class=""e2eContentToggleMenu"">Toggle Menu</button>
+    <button menu-toggle=""leftMenu"" class=""e2eContentToggleMenu"">Toggle Left Menu</button>
   </p>
 
   <p>
diff --git a/ionic/components/menu/test/basic/page3.html b/ionic/components/menu/test/basic/page3.html
index a2d65e2..079a3e9 100644
--- a/ionic/components/menu/test/basic/page3.html
+++ b/ionic/components/menu/test/basic/page3.html
@@ -1,7 +1,7 @@
 
 <ion-navbar *navbar>
 
-  <a menu-toggle>
+  <a menu-toggle=""leftMenu"">
     <icon menu></icon>
   </a>
 
@@ -12,12 +12,12 @@
 </ion-navbar>
 
 
-<ion-content #content padding>
+<ion-content padding>
 
   <h3>Page 3</h3>
 
   <p>
-    <button menu-toggle>Toggle Menu</button>
+    <button menu-toggle=""leftMenu"">Toggle Left Menu</button>
   </p>
 
   <f></f><f></f><f></f><f></f><f></f><f></f><f></f><f></f>
diff --git a/ionic/components/toolbar/modes/md.scss b/ionic/components/toolbar/modes/md.scss
index 984e758..339169a 100644
--- a/ionic/components/toolbar/modes/md.scss
+++ b/ionic/components/toolbar/modes/md.scss
@@ -43,6 +43,12 @@ $toolbar-md-button-font-size:        1.4rem !default;
     }
   }
 
+  [menu-toggle][secondary],
+  [menu-toggle][secondary].activated {
+    margin: 0 2px;
+    min-width: 28px;
+  }
+
 }
 
 ion-title {
",3,"[""aa30370b796c1f46cc60aa56b2918c3d27c0cf88"", ""4b5604063fcb8ff457bcb61fdbea85c6b3a5c620"", ""1a60540f2bcda48d33f015e31f3728ac2c59a159""]","[""build"", ""fix"", ""feat""]","1. The changes include updating 'lerna.json' (removing 'useNx'), modifying 'nx.json' for build config, and updating menu logic, navigation scroll behavior, CSS for right side menus, and multiple HTML/TS files to support right side menus and improved toggling; test files are also updated to cover new menu behaviors.
2. The lerna and nx.json changes update the build system configuration, aligning with 'build'; the scroll behavior fix in the navigation component and related menu logic changes address bugs, aligning with 'fix'; the introduction of right side menus and related toggling in markup and logic is a new feature, aligning with 'feat'.
3. 'build' is appropriate for the build config changes rather than 'cicd' (not CI scripts) or 'refactor' (not just restructuring); 'fix' is correct for resolving scroll/navigation bugs, not 'feat' (not new capability) or 'refactor'; 'feat' is correct for adding right side menus, not 'fix' (not a bug) or 'refactor'.
4. The assigned labels 'build', 'fix', and 'feat' are appropriate because the commit contains distinct build config updates, bug fixes, and new feature additions, each matching their respective label definitions."
switch to callback ref,"diff --git a/src/notebook/components/transforms/html.js b/src/notebook/components/transforms/html.js
index 83fc1fb..021cc65 100644
--- a/src/notebook/components/transforms/html.js
+++ b/src/notebook/components/transforms/html.js
@@ -8,16 +8,16 @@ type Props = {
 
 export default class HTMLDisplay extends React.Component {
   props: Props;
+  el: HTMLElement;
 
   componentDidMount(): void {
-    if (this.refs.here) {
-      if (document.createRange && Range && Range.prototype.createContextualFragment) {
-        const range = document.createRange();
-        const fragment = range.createContextualFragment(this.props.data);
-        ReactDOM.findDOMNode(this.refs.here).appendChild(fragment);
-      } else {
-        ReactDOM.findDOMNode(this.refs.here).innerHTML = this.props.data;
-      }
+    // Create a range to ensure that scripts are invoked from within the HTML
+    if (document.createRange && Range && Range.prototype.createContextualFragment) {
+      const range = document.createRange();
+      const fragment = range.createContextualFragment(this.props.data);
+      this.el.appendChild(fragment);
+    } else {
+      this.el.innerHTML = this.props.data;
     }
   }
 
@@ -27,7 +27,7 @@ export default class HTMLDisplay extends React.Component {
 
   render(): ?React.Element<any> {
     return (
-      <div ref=""here"" />
+      <div ref={(el) => { this.el = el; }} />
     );
   }
 }
",1,"[""ee4bf61fb8836e249fb4ef3507dc938e70696b3f""]","[""refactor""]","1. The code changes replace a string ref (""ref=\""here\"""") with a callback ref (""ref={(el) => { this.el = el; }}"") and update all references from this.refs.here to this.el, without changing the component's external behavior.
2. This update aligns with the 'refactor' label because it restructures the way DOM nodes are referenced in the component, improving code quality and following modern React best practices, but does not add features or fix a bug.
3. The 'refactor' label is appropriate because the change is an internal code improvement; it neither introduces new functionality ('feat'), fixes a bug ('fix'), nor is it limited to documentation, tests, CI/CD, or build artifacts.
4. The 'refactor' label accurately represents this change as it is a structural code update that maintains existing behavior while improving implementation style."
"add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com>
pin version of actionlint used
only restart if pages directory itself is changed

resolves #429","diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 

diff --git a/.github/workflows/introspect.yml b/.github/workflows/introspect.yml
index b6d9125..82d22a5 100644
--- a/.github/workflows/introspect.yml
+++ b/.github/workflows/introspect.yml
@@ -25,5 +25,5 @@ jobs:
       # From https://github.com/rhysd/actionlint/blob/main/docs/usage.md#use-actionlint-on-github-actions
       - name: Check workflow files
         run: |
-          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash)
+          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash) 1.6.25
           ./actionlint -color -shellcheck=""""

diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 
",3,"[""12257ce53f94dc902df4ba087de90f52d2840ad4"", ""b702adc245f679ae20d84de39f0d63b14aabed5d"", ""cbce777addb3dd118232a9f28db9d425d4c937b2""]","[""docs"", ""cicd"", ""fix""]","1. The first change adds a GitLab CI configuration example to the documentation, the second pins a version for actionlint in a GitHub Actions workflow, and the third modifies the CLI command logic to only trigger a restart if the 'pages' directory itself (not just any file within) is changed, providing a more precise restart condition.
2. The documentation change directly aligns with the 'docs' label as it solely adds instructional content; the workflow change is a CI configuration update, matching the 'cicd' label; the CLI logic adjustment addresses an over-eager restart (potential bug), aligning with the 'fix' label.
3. 'docs' is appropriate for the markdown update as it does not alter code behavior; 'cicd' is correct for the workflow edit since it affects only CI tooling, not build or application logic; 'fix' is justified for the CLI change because it corrects restart behavior, not adding features or refactoring structure.
4. The assigned labels 'docs', 'cicd', and 'fix' are appropriate as each code unit is fully scoped to its respective artifact or purpose, with no overlap or ambiguity."
add jackson dependencies for zb-bpmn-model,"diff --git a/parent/pom.xml b/parent/pom.xml
index d475131..6290e66 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -35,6 +35,7 @@
     <version.mockito>1.8.5</version.mockito>
     <version.assertj>3.8.0</version.assertj>
     <version.msgpack>0.8.13</version.msgpack>
+    <version.jackson>2.9.0</version.jackson>
     <version.jmh>1.11.2</version.jmh>
     <version.sbe>1.5.6</version.sbe>
     <version.slf4j>1.7.23</version.slf4j>
@@ -64,6 +65,18 @@
       </dependency>
 
       <dependency>
+        <groupId>com.fasterxml.jackson.core</groupId>
+        <artifactId>jackson-databind</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
+        <groupId>com.fasterxml.jackson.dataformat</groupId>
+        <artifactId>jackson-dataformat-yaml</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
         <groupId>org.msgpack</groupId>
         <artifactId>msgpack-core</artifactId>
         <version>${version.msgpack}</version>
",1,"[""fab09655d5cc30727289cc3f26e5396fce235cd3""]","[""build""]","1. The code change adds a new version property for Jackson and introduces Jackson-related dependencies (jackson-databind and jackson-dataformat-yaml) to the Maven pom.xml file.
2. Adding or updating dependencies in build configuration files directly affects how the codebase is built and packaged, which fits the definition of the 'build' label.
3. The change does not modify source code logic (so not 'feat', 'fix', or 'refactor'), nor does it alter documentation, tests, or CI scripts, ruling out 'docs', 'test', and 'cicd' labels.
4. The 'build' label is appropriate because the commit exclusively modifies the build system by adding dependencies necessary for project compilation and packaging."
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.
fix typos (#90)
restructure ClusterTopology to track completed change","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/README.md b/README.md
index de15ac5..5ad8b47 100755
--- a/README.md
+++ b/README.md
@@ -16,13 +16,13 @@ content that will be loaded, similar to Facebook cards loaders.
 
 ## Features
 
-* :gear: **Complety customizable:** you can change the colors, speed and sizes;
+* :gear: **Completely customizable:** you can change the colors, speed and sizes;
 * :pencil2: **Create your own loading:** use the
   [create-react-content-loader](https://danilowoz.github.io/create-react-content-loader/) to create
-  your customs loadings easily;
+  your custom loadings easily;
 * :ok_hand: **You can use right now:** there are a lot of presets to use the loader, see the
   [options](#options);
-* :rocket: **Perfomance:** react-content-loader uses pure SVG to work, so it's works without any extra scritpt,
+* :rocket: **Performance:** react-content-loader uses pure SVG to work, so it works without any extra scripts,
   canvas, etc;
 
 ## Usage

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",3,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""88257ee720ed8ba136d49087c0d31373e8397dd5"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""fix"", ""docs"", ""refactor""]","1. The code changes include: (a) a bug fix in Configuration.ts to properly set the default for `cache.enabled`, (b) multiple typo corrections in README.md, and (c) a substantial restructuring and simplification of the ClusterTopology and ClusterChangePlan classes and related serialization logic in the Java topology module.
2. The fix label aligns with the Configuration.ts change, which resolves a behavioral bug where CLI cache commands would fail unless a config was explicitly set; the docs label aligns with the README.md typo corrections, which are purely documentation-related; the refactor label aligns with the Java topology changes, which restructure and simplify the topology change tracking logic without altering external behavior.
3. The Configuration.ts change is not a new feature nor a refactor, but a clear bug fix, so fix is correct; the README.md change is not a fix, feat, or refactor, but strictly documentation, so docs is correct; the Java topology changes, while extensive, do not introduce new features or fix bugs but improve code structure and maintainability, so refactor is correct.
4. The assigned labels fix, docs, and refactor accurately represent the motivations and artifacts modified in each code unit of this tangled commit, following the labeling instructions and resolving overlaps appropriately."
"add canonical `_name` to edge packages
implement array flatten support
await job creation to ensure asserted event sequence","diff --git a/scripts/bump-edge.ts b/scripts/bump-edge.ts
index e92e3c9..0b7a11a 100644
--- a/scripts/bump-edge.ts
+++ b/scripts/bump-edge.ts
@@ -53,6 +53,7 @@ async function loadWorkspace (dir: string) {
   }
 
   const rename = (from: string, to: string) => {
+    find(from).data._name = find(from).data.name
     find(from).data.name = to
     for (const pkg of packages) {
       pkg.updateDeps((dep) => {

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),

diff --git a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
index 9ffa1fa..4333db0 100644
--- a/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
+++ b/engine/src/test/java/io/zeebe/engine/processor/workflow/boundary/BoundaryEventTest.java
@@ -114,12 +114,18 @@ public class BoundaryEventTest {
     ENGINE.deployment().withXmlResource(MULTIPLE_SEQUENCE_FLOWS).deploy();
     final long workflowInstanceKey = ENGINE.workflowInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    // when
     RecordingExporter.timerRecords()
         .withHandlerNodeId(""timer"")
         .withIntent(TimerIntent.CREATED)
         .withWorkflowInstanceKey(workflowInstanceKey)
         .getFirst();
+
+    RecordingExporter.jobRecords(JobIntent.CREATED)
+        .withType(""type"")
+        .withWorkflowInstanceKey(workflowInstanceKey)
+        .getFirst();
+
+    // when
     ENGINE.increaseTime(Duration.ofMinutes(1));
 
     // then
",3,"[""573f87edf9bdc19c9c4c3a978fad6ed3ce788f5f"", ""d3c754f09502be979e5dcc79f968b15052590bd0"", ""a8d1a60fd48d3fbd76d4271987a1b0f538d498f1""]","[""build"", ""feat"", ""test""]","1. The first change in 'scripts/bump-edge.ts' adds a canonical '_name' property to package data, which is related to package metadata and build tooling; the second change in 'ibis/backends/snowflake/registry.py' registers array flatten support, introducing new backend capability; the third change in 'BoundaryEventTest.java' alters test logic to await job creation, ensuring correct event sequencing.
2. Adding '_name' to package data is a build system modification (build label); registering array flatten is a new feature (feat label); updating the test to await job creation is a test logic change (test label).
3. The 'build' label is appropriate for the package script change since it pertains to build-time metadata, not runtime behavior; 'feat' is correct for the registry update as it adds new functional support; 'test' fits the Java change as it is scoped to test code, not production logic.
4. The assigned labels 'build', 'feat', and 'test' are justified as each change is fully dedicated to its respective artifact or code purpose, with no overlap or ambiguity."
"skip flaky test
disable edit/delete if primary key missing

Signed-off-by: Pranav C <pranavxc@gmail.com>
remove members that are left from ClusterTopology when last change is applied

When the change is applied, the member is marked as LEFT. It is removed from the
ClusterTopology when all changes in the ClusterChangePlan is completed.","diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
index 5f9841f..c414c8c 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
@@ -413,6 +413,9 @@ export default {
 
           await this.reload()
         } else if (Object.keys(updatedObj).length) {
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
           await this.api.update(id, updatedObj, this.oldRow)
         } else {
           return this.$toast.info('No columns to update').goAway(3000)
diff --git a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
index c2b4b81..1b9d6a0 100644
--- a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
+++ b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
@@ -62,7 +62,15 @@
       <v-spacer class=""h-100"" @dblclick=""debug=true"" />
 
       <debug-metas v-if=""debug"" class=""mr-3"" />
-
+      <v-tooltip bottom>
+        <template #activator=""{on}"">
+          <v-icon v-if=""!isPkAvail"" color=""warning"" small class=""mr-3"" v-on=""on"">
+            mdi-information-outline
+          </v-icon>
+        </template>
+        <span class=""caption"">          Update & Delete not allowed since the table doesn't have any primary key
+        </span>
+      </v-tooltip>
       <lock-menu v-if=""_isUIAllowed('view-type')"" v-model=""viewStatus.type"" />
       <x-btn tooltip=""Reload view data"" outlined small text @click=""reload"">
         <v-icon small class=""mr-1"" color=""grey  darken-3"">
@@ -208,6 +216,7 @@
               :meta=""meta""
               :is-virtual=""selectedView.type === 'vtable'""
               :api=""api""
+              :is-pk-avail=""isPkAvail""
               @onNewColCreation=""onNewColCreation""
               @onCellValueChange=""onCellValueChange""
               @insertNewRow=""insertNewRow""
@@ -631,8 +640,8 @@ export default {
       if (
         !this.meta || (
           (this.meta.hasMany && this.meta.hasMany.length) ||
-        (this.meta.manyToMany && this.meta.manyToMany.length) ||
-        (this.meta.belongsTo && this.meta.belongsTo.length))
+          (this.meta.manyToMany && this.meta.manyToMany.length) ||
+          (this.meta.belongsTo && this.meta.belongsTo.length))
       ) {
         return this.$toast.info('Please delete relations before deleting table.').goAway(3000)
       }
@@ -817,6 +826,10 @@ export default {
 
           const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
 
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           const newData = await this.api.update(id, {
             [column._cn]: rowObj[column._cn]
           }, { [column._cn]: oldRow[column._cn] })
@@ -841,6 +854,11 @@ export default {
         const rowObj = this.rowContextMenu.row
         if (!this.rowContextMenu.rowMeta.new) {
           const id = this.meta && this.meta.columns && this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+          if (!id) {
+            return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           await this.api.delete(id)
         }
         this.data.splice(this.rowContextMenu.index, 1)
@@ -859,6 +877,11 @@ export default {
           }
           if (!rowMeta.new) {
             const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+            if (!id) {
+              return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             await this.api.delete(id)
           }
           this.data.splice(row, 1)
@@ -991,6 +1014,9 @@ export default {
     }
   },
   computed: {
+    isPkAvail() {
+      return this.meta && this.meta.columns.some(c => c.pk)
+    },
     isGallery() {
       return this.selectedView && this.selectedView.show_as === 'gallery'
     },
diff --git a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
index 5497d05..c198784 100644
--- a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
+++ b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
@@ -27,7 +27,7 @@
             @xcresized=""resizingCol = null""
           >
             <!--            :style=""columnsWidth[col._cn]  ? `min-width:${columnsWidth[col._cn]}; max-width:${columnsWidth[col._cn]}` : ''""
-    -->
+-->
 
             <virtual-header-cell
               v-if=""col.virtual""
@@ -136,13 +136,13 @@
             :key=""row + columnObj.alias""
             class=""cell pointer""
             :class=""{
-              'active' : !isPublicView && selected.col === col && selected.row === row && isEditable ,
+              'active' :!isPublicView && selected.col === col && selected.row === row && isEditable ,
               'primary-column' : primaryValueColumn === columnObj._cn,
               'text-center': isCentrallyAligned(columnObj),
               'required': isRequired(columnObj,rowObj)
             }""
             :data-col=""columnObj.alias""
-            @dblclick=""makeEditable(col,row,columnObj.ai)""
+            @dblclick=""makeEditable(col,row,columnObj.ai,rowMeta)""
             @click=""makeSelected(col,row);""
             @contextmenu=""showRowContextMenu($event,rowObj,rowMeta,row,col, columnObj)""
           >
@@ -162,7 +162,8 @@
 
             <editable-cell
               v-else-if=""
-                !isLocked
+                (isPkAvail ||rowMeta.new) &&
+                  !isLocked
                   && !isPublicView
                   && (editEnabled.col === col && editEnabled.row === row)
                   || enableEditable(columnObj)
@@ -190,11 +191,11 @@
               :db-alias=""nodes.dbAlias""
               :value=""rowObj[columnObj._cn]""
               :sql-ui=""sqlUi""
-              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai)""
+              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai, rowMeta)""
             />
           </td>
         </tr>
-        <tr v-if=""!isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
+        <tr v-if=""isPkAvail && !isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
           <td :colspan=""visibleColLength + 1"" class=""text-left pointer"" @click=""insertNewRow(true)"">
             <v-tooltip top>
               <template #activator=""{on}"">
@@ -214,7 +215,9 @@
     <!--    <div is=""style"" v-html=""resizeColStyle"" />-->
     <dynamic-style>
       <template v-if=""resizingCol"">
-        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{ resizingColWidth }};width:{{ resizingColWidth }};}
+        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{
+          resizingColWidth
+        }};width:{{ resizingColWidth }};}
       </template>
     </dynamic-style>
   </div>
@@ -261,7 +264,8 @@ export default {
     table: String,
     isVirtual: Boolean,
     isLocked: Boolean,
-    columnsWidth: { type: Object }
+    columnsWidth: { type: Object },
+    isPkAvail: Boolean
   },
   data: () => ({
     resizingCol: null,
@@ -426,6 +430,10 @@ export default {
             return
           }
           if (e.key && e.key.length === 1) {
+            if (!this.isPkAvail && !this.data[this.selected.row].rowMeta.new) {
+              return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             this.$set(this.data[this.selected.row].row, this.availableColumns[this.selected.col]._cn, '')
             this.editEnabled = { ...this.selected }
           }
@@ -466,10 +474,14 @@ export default {
         this.editEnabled = {}
       }
     },
-    makeEditable(col, row) {
+    makeEditable(col, row, _, rowMeta) {
       if (this.isPublicView || !this.isEditable) {
         return
       }
+
+      if (!this.isPkAvail && !rowMeta.new) {
+        return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+      }
       if (this.availableColumns[col].ai) {
         return this.$toast.info('Auto Increment field is not editable').goAway(3000)
       }

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index e5a111d..8ccd410 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -171,7 +171,31 @@ public record ClusterTopology(
   }
 
   private ClusterTopology advance() {
-    return new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    if (!result.hasPendingChanges()) {
+      // The last change has been applied. Clean up the members that are marked as LEFT in the
+      // topology. This operation will be executed in the member that executes the last operation.
+      // This is ok because it is guaranteed that no other concurrent modification will be applied
+      // to the topology. This is because all the operations are applied sequentially, and no
+      // topology update will be done without adding a ClusterChangePlan.
+      return result.gc();
+    }
+    return result;
+  }
+
+  private ClusterTopology gc() {
+    if (hasPendingChanges()) {
+      throw new IllegalStateException(
+          ""Expected to remove members that are left from the topology, but there are pending changes ""
+              + changes);
+    }
+    // remove members that are marked as LEFT
+    final var currentMembers =
+        members().entrySet().stream()
+            .filter(entry -> entry.getValue().state() != State.LEFT)
+            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
+    // Increment the version so that other members can merge by overwriting their local topology.
+    return new ClusterTopology(version + 1, currentMembers, changes);
   }
 
   public boolean hasMember(final MemberId memberId) {
",3,"[""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""4d92f352741b04c8709319dfe5c8419654f3682c"", ""4bfbf60653068ef17df98c021134692bd6d02939""]","[""test"", ""feat"", ""refactor""]","1. The commit disables a flaky test in a test file, adds UI logic to prevent editing/deleting when primary keys are missing in several Vue components, and refactors Java code to remove members marked as LEFT from ClusterTopology after the last change is applied.
2. Disabling the flaky test is a direct modification to test logic, aligning with the 'test' label; the UI changes add new restrictions and feedback, introducing new behavior (feature) for primary key handling, aligning with 'feat'; the Java change improves system state management without altering external behavior, aligning with 'refactor'.
3. 'test' is appropriate for the test modification as it is not fixing test logic but skipping it; 'feat' is correct for the UI changes as they add new user-facing checks and messages, not merely fixing or restructuring; 'refactor' fits the Java change as it reorganizes member cleanup logic without changing the observable behavior of the cluster topology for external consumers.
4. The assigned labels 'test', 'feat', and 'refactor' are appropriate as each code unit fits squarely within one label's definition based on its intent and artifact type."
add more tests for Utils.lookupPathFromDecorator,"diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',
",1,"[""c5e86dbc00a13a355bffadeb2db197e2fea5640f""]","[""test""]","1. The changes add new test cases to the 'Utils.test.ts' file, specifically increasing coverage for the 'Utils.lookupPathFromDecorator' method, and make minor adjustments to test data to match updated logic.
2. These modifications are restricted to test logic and assertions, directly aligning with the 'test' label, which is used for changes that add or update test files.
3. The 'test' label is appropriate because the code unit is fully dedicated to test logic; there are no changes to production code behavior that would warrant 'fix', 'feat', or 'refactor', nor are there documentation or build/CI changes.
4. The 'test' label is justified as the changes are solely focused on expanding and updating test coverage for a utility function."
"xfail on to_parquet and to_csv that use pyarrow write options
support react@17 in peer deps

resolves #1478
add comments for the Handler","diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/packages/animated/package.json b/packages/animated/package.json
index 2249a2f..e35a1fd 100644
--- a/packages/animated/package.json
+++ b/packages/animated/package.json
@@ -33,6 +33,6 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/core/package.json b/packages/core/package.json
index 584bbc2..c934253 100644
--- a/packages/core/package.json
+++ b/packages/core/package.json
@@ -36,7 +36,7 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   },
   ""devDependencies"": {
     ""rafz"": ""^0.1.13""
diff --git a/packages/parallax/package.json b/packages/parallax/package.json
index 49f8391..5a181fe 100644
--- a/packages/parallax/package.json
+++ b/packages/parallax/package.json
@@ -31,6 +31,6 @@
     ""@react-spring/web"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/shared/package.json b/packages/shared/package.json
index 67d286c..12f7db3 100644
--- a/packages/shared/package.json
+++ b/packages/shared/package.json
@@ -33,6 +33,6 @@
     ""rafz"": ""^0.1.13""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/targets/konva/package.json b/targets/konva/package.json
index 17675ac..271d58c 100644
--- a/targets/konva/package.json
+++ b/targets/konva/package.json
@@ -34,7 +34,7 @@
   },
   ""peerDependencies"": {
     ""konva"": "">=2.6"",
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-konva"": "">=16.8""
   },
   ""devDependencies"": {
diff --git a/targets/native/package.json b/targets/native/package.json
index e97aa97..802a66c 100644
--- a/targets/native/package.json
+++ b/targets/native/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-native"": "">=0.58""
   },
   ""devDependencies"": {
diff --git a/targets/web/package.json b/targets/web/package.json
index d74c25c..f7ac000 100644
--- a/targets/web/package.json
+++ b/targets/web/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8""
   }
 }
diff --git a/targets/zdog/package.json b/targets/zdog/package.json
index aa57890..f65945a 100644
--- a/targets/zdog/package.json
+++ b/targets/zdog/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8"",
     ""react-zdog"": "">=1.0"",
     ""zdog"": "">=1.0""

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",3,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""27169897c0e58bc4fbca724f290ad54fa39abec7"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""test"", ""build"", ""docs""]","1. The code changes include adding xfail markers and parameterization to test cases in 'test_export.py', updating 'peerDependencies' for React version support in multiple 'package.json' files, and adding documentation comments in 'nodes.rs'.
2. The test file modifications are fully scoped to test logic, matching the 'test' label; the 'package.json' changes alter dependency specifications, aligning with the 'build' label; the added comments in Rust source code are documentation-only, fitting the 'docs' label.
3. 'test' is chosen over purpose labels because the Python changes are strictly to test files, not to fix or add features in product code; 'build' is correct for dependency range changes, not 'cicd' since no CI config is touched; 'docs' is appropriate for pure comment additions, not 'refactor' as no logic is altered.
4. Thus, the unique set of labels 'test', 'build', and 'docs' accurately categorizes each code unit by its artifact type and intent per the classification rules."
added vue3 readme,"diff --git a/core/main/README.md b/core/main/README.md
index e5e4c93..e9cfda9 100644
--- a/core/main/README.md
+++ b/core/main/README.md
@@ -217,7 +217,7 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/svelte/README.md)
 
-### VueJS
+### VueJS 2.x
 
 #### `particles.vue`
 
@@ -225,6 +225,14 @@ You can find the instructions [here](https://github.com/matteobruni/tsparticles/
 
 You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue/README.md)
 
+### VueJS 3.x
+
+#### `particles.vue3`
+
+[![npm](https://img.shields.io/npm/v/particles.vue3)](https://www.npmjs.com/package/particles.vue3) [![npm](https://img.shields.io/npm/dm/particles.vue3)](https://www.npmjs.com/package/particles.vue3)
+
+You can find the instructions [here](https://github.com/matteobruni/tsparticles/blob/master/components/vue3/README.md)
+
 ---
 
 ## **_Demo / Generator_**
diff --git a/core/main/tsconfig.json b/core/main/tsconfig.json
index 7916bc5..72399c0 100644
--- a/core/main/tsconfig.json
+++ b/core/main/tsconfig.json
@@ -107,10 +107,14 @@
               ""source"": ""../../components/react/README.md""
             },
             {
-              ""title"": ""Vue"",
+              ""title"": ""Vue 2.x"",
               ""source"": ""../../components/vue/README.md""
             },
             {
+              ""title"": ""Vue 3.x"",
+              ""source"": ""../../components/vue3/README.md""
+            },
+            {
               ""title"": ""Svelte"",
               ""source"": ""../../components/svelte/README.md""
             },
",1,"[""e4c3e2cff769ce46d22d5c8f7dd527510443a8a7""]","[""docs""]","1. The changes add new documentation sections for Vue 3.x integration in the README and update the tsconfig.json to reference the corresponding Vue 3.x documentation file.
2. These modifications are strictly to documentation content and metadata, aligning directly with the 'docs' label definition for changes that modify documentation or text.
3. 'docs' is appropriate because no source or test code is altered, nor are there changes to build, CI, or testing artifacts—thus, 'feat', 'fix', 'refactor', 'test', 'cicd', and 'build' do not apply.
4. The 'docs' label is justified as all changes exclusively enhance or update documentation-related files and content."
"Fix Cube Store build on Windows
better tested publishing flow
verify checkpoint listeners are notified","diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml
index a986501..db33097 100644
--- a/.github/workflows/publish.yml
+++ b/.github/workflows/publish.yml
@@ -409,7 +409,7 @@ jobs:
         run: vcpkg integrate install; vcpkg install openssl:x64-windows
       - name: Instal LLVM for Windows
         if: ${{ startsWith(matrix.os, 'windows') }}
-        run: choco install -y llvm --version 9.0.1
+        run: choco install -y --force llvm --version 9.0.1
       - name: Set Env Variables for Windows
         uses: allenevans/set-env@v2.0.0
         if: ${{ startsWith(matrix.os, 'windows') }}
diff --git a/.github/workflows/rust.yml b/.github/workflows/rust.yml
index d45cdf9..8d87ed6 100644
--- a/.github/workflows/rust.yml
+++ b/.github/workflows/rust.yml
@@ -158,7 +158,7 @@ jobs:
         run: vcpkg integrate install; vcpkg install openssl:x64-windows
       - name: Instal LLVM for Windows
         if: ${{ startsWith(matrix.os, 'windows') }}
-        run: choco install -y llvm --version 9.0.1
+        run: choco install -y --force llvm --version 9.0.1
       - name: Set Env Variables for Windows
         uses: allenevans/set-env@v2.0.0
         if: ${{ startsWith(matrix.os, 'windows') }}

diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",3,"[""e34bb04baac7574e67bc566d13dea72092e0cfa3"", ""65574eea5da54bf4722ecb551b42f8ff6088f33b"", ""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""cicd"", ""build"", ""test""]","1. The changes modify two GitHub Actions workflow files (`.github/workflows/publish.yml` and `.github/workflows/rust.yml`) to add the `--force` flag to a Windows LLVM installation step, update the `Makefile.toml` to adjust build and publish task definitions, and add several new tests to `CheckpointRecordsProcessorTest.java` to verify checkpoint listener notifications.
2. The workflow file changes are dedicated to CI configuration, aligning with the `cicd` label; the `Makefile.toml` updates affect build and publishing processes, fitting the `build` label; the new and extended tests in the Java test class are solely focused on test logic, matching the `test` label.
3. `cicd` is appropriate for the workflow file edits since they are not code logic or build scripts but CI configuration; `build` is correct for `Makefile.toml` because it changes build/publish automation, not CI or tests; `test` is suitable for the Java file since the changes are exclusively new or modified tests, not production code behavior fixes or features.
4. The assigned labels (`cicd`, `build`, `test`) are justified as each code unit is entirely scoped to its respective artifact type, with no overlap or misclassification."
"Handle different events.
move group logical op outside

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/src/notebook/epics/kernel-launch.js b/src/notebook/epics/kernel-launch.js
index 9075d7c..9f16e67 100644
--- a/src/notebook/epics/kernel-launch.js
+++ b/src/notebook/epics/kernel-launch.js
@@ -113,6 +113,12 @@ export function newKernelObservable(kernelSpec: KernelInfo, cwd: string) {
           observer.error({ type: 'ERROR', payload: error, err: true });
           observer.complete();
         });
+        spawn.on('exit', () => {
+          observer.complete();
+        });
+        spawn.on('disconnect', () => {
+          observer.complete();
+        });
       });
   });
 }

diff --git a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
index 5138589..f756981 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
@@ -2,40 +2,46 @@
   <div
     class=""backgroundColor pa-2 menu-filter-dropdown""
     :class=""{ nested }""
-    :style=""{ width: nested ? '100%' : '530px' }""
+    :style=""{ width: nested ? '100%' : '630px' }""
   >
     <div class=""grid"" @click.stop>
       <template v-for=""(filter, i) in filters"" dense>
         <template v-if=""filter.status !== 'delete'"">
-          <div v-if=""filter.is_group"" :key=""i"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
-            <div class=""d-flex"" style=""gap: 6px; padding: 0 6px"">
-              <v-icon
-                v-if=""!filter.readOnly""
-                small
-                class=""nc-filter-item-remove-btn""
-                @click.stop=""deleteFilter(filter, i)""
-              >
-                mdi-close-box
-              </v-icon>
-              <span v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
-              <v-select
-                v-else
-                v-model=""filter.logical_op""
-                class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
-                :items=""['and', 'or']""
-                solo
-                flat
-                dense
-                hide-details
-                placeholder=""Group op""
-                @click.stop
-                @change=""saveOrUpdate(filter, i)""
-              >
-                <template #item=""{ item }"">
-                  <span class=""caption font-weight-regular"">{{ item }}</span>
-                </template>
-              </v-select>
-            </div>
+          <template v-if=""filter.is_group"">
+            <v-icon
+              v-if=""!filter.readOnly""
+              small
+              class=""nc-filter-item-remove-btn""
+              @click.stop=""deleteFilter(filter, i)""
+              :key=""i + '_1'""
+            >
+              mdi-close-box
+            </v-icon>
+            <span v-else :key=""i + '_1'"" />
+
+            <span :key=""i + '_2'"" v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <v-select
+              v-else
+              :key=""i + '_2'""
+              v-model=""filter.logical_op""
+              class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
+              :items=""['and', 'or']""
+              solo
+              flat
+              dense
+              hide-details
+              placeholder=""Group op""
+              @click.stop
+              @change=""saveOrUpdate(filter, i)""
+            >
+              <template #item=""{ item }"">
+                <span class=""caption font-weight-regular"">{{ item }}</span>
+              </template>
+            </v-select>
+            <span :key=""i + '_3'"" style=""grid-column: span 3""></span>
+          </template>
+
+          <div v-if=""filter.is_group"" :key=""i + '_4'"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
             <column-filter
               v-if=""filter.id || shared""
               ref=""nestedFilter""
@@ -54,19 +60,19 @@
           <template v-else>
             <v-icon
               v-if=""!filter.readOnly""
-              :key=""i + '_1'""
+              :key=""i + '_5'""
               small
               class=""nc-filter-item-remove-btn""
               @click.stop=""deleteFilter(filter, i)""
             >
               mdi-close-box
             </v-icon>
-            <span v-else :key=""i + '_1'"" />
-            <span v-if=""!i"" :key=""i + '_2'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <span v-else :key=""i + '_5'"" />
+            <span v-if=""!i"" :key=""i + '_6'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
 
             <v-select
               v-else
-              :key=""i + '_2'""
+              :key=""i + '_6'""
               v-model=""filter.logical_op""
               class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
               :items=""['and', 'or']""
@@ -84,7 +90,7 @@
             </v-select>
 
             <field-list-auto-complete-dropdown
-              :key=""i + '_3'""
+              :key=""i + '_7'""
               v-model=""filter.fk_column_id""
               class=""caption nc-filter-field-select""
               :columns=""columns""
@@ -94,7 +100,7 @@
             />
 
             <v-select
-              :key=""i + '_4'""
+              :key=""i + '_8'""
               v-model=""filter.comparison_op""
               class=""flex-shrink-1 flex-grow-0 caption nc-filter-operation-select""
               :items=""filterComparisonOp(filter)""
@@ -114,11 +120,11 @@
                 <span class=""caption font-weight-regular"">{{ item.text }}</span>
               </template>
             </v-select>
-            <span v-else :key=""i + '_4'""></span>
+            <span v-else :key=""i + '_8'""></span>
             <span v-if=""['null', 'notnull', 'empty', 'notempty'].includes(filter.comparison_op)"" :key=""i + '_5'"" />
             <v-checkbox
               v-else-if=""types[filter.field] === 'boolean'""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               dense
               :disabled=""filter.readOnly""
@@ -126,7 +132,7 @@
             />
             <v-text-field
               v-else-if=""filter && filter.fk_column_id""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               solo
               flat
@@ -137,7 +143,7 @@
               @click.stop
               @input=""saveOrUpdate(filter, i)""
             />
-            <span v-else :key=""i + '_5'""></span>
+            <span v-else :key=""i + '_9'""></span>
           </template>
         </template>
       </template>
@@ -411,6 +417,7 @@ export default {
         parentId: this.parentId,
         is_group: true,
         status: 'update',
+        logical_op: 'and',
       });
       this.filters = this.filters.slice();
       const index = this.filters.length - 1;
@@ -478,4 +485,8 @@ export default {
   column-gap: 6px;
   row-gap: 6px;
 }
+
+.nc-filter-value-select {
+  min-width: 100px;
+}
 </style>
",2,"[""a280a52c8309465276c3509848ddcddbe19732b6"", ""4f86f2570b274c45605cc59d9adb38f7ed30cd17""]","[""fix"", ""refactor""]","1. The changes in `kernel-launch.js` add event handlers for 'exit' and 'disconnect' to properly complete the observer, while the changes in `ColumnFilter.vue` restructure the logic for rendering group filters and adjust some styling and key assignments.
2. The event handler additions in `kernel-launch.js` address a potential bug where the observer might not complete correctly on process exit/disconnect, aligning with the 'fix' label, while the reorganization and cleanup of group logic in `ColumnFilter.vue` are structural improvements without changing behavior, aligning with 'refactor'.
3. 'fix' is appropriate for the kernel event handling because it resolves an incomplete observer lifecycle (a bug), not a new feature or mere restructuring; 'refactor' is correct for the Vue component changes because they move logic and adjust code structure for clarity without altering functionality, not fixing a bug or adding a feature.
4. The combined 'fix' and 'refactor' labels accurately represent the two distinct motivations in this commit: bug resolution in process handling and codebase structural improvement in the UI component."
"set cursor position in setHorizontalRule correctly, fix #2429
increment failing test retries","diff --git a/packages/extension-horizontal-rule/src/horizontal-rule.ts b/packages/extension-horizontal-rule/src/horizontal-rule.ts
index 6f583e1..c905b63 100644
--- a/packages/extension-horizontal-rule/src/horizontal-rule.ts
+++ b/packages/extension-horizontal-rule/src/horizontal-rule.ts
@@ -49,15 +49,14 @@ export const HorizontalRule = Node.create<HorizontalRuleOptions>({
           // set cursor after horizontal rule
           .command(({ tr, dispatch }) => {
             if (dispatch) {
-              const { parent, pos } = tr.selection.$from
-              const posAfter = pos + 1
-              const nodeAfter = tr.doc.nodeAt(posAfter)
+              const { $to } = tr.selection
+              const posAfter = $to.end()
 
-              if (nodeAfter) {
-                tr.setSelection(TextSelection.create(tr.doc, posAfter))
+              if ($to.nodeAfter) {
+                tr.setSelection(TextSelection.create(tr.doc, $to.pos))
               } else {
                 // add node after horizontal rule if it’s the end of the document
-                const node = parent.type.contentMatch.defaultType?.create()
+                const node = $to.parent.type.contentMatch.defaultType?.create()
 
                 if (node) {
                   tr.insert(posAfter, node)

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",2,"[""34d80114704679118e9bb6058e0d6c7aa03fd4b5"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""fix"", ""cicd""]","1. The code change in 'horizontal-rule.ts' modifies cursor placement logic after inserting a horizontal rule, ensuring correct selection behavior; the changes in '.ci/scripts/distribution/*.sh' increase the test retry count in CI scripts.
2. The 'horizontal-rule.ts' update addresses a bug with cursor positioning and directly aligns with the 'fix' label definition (resolving faulty behavior); the CI script changes solely adjust CI pipeline configuration, which matches the 'cicd' object label.
3. 'fix' is appropriate for the TypeScript change because it corrects a user-facing bug rather than restructuring code ('refactor') or adding new features ('feat'); 'cicd' is correct for the shell script modifications as they only affect CI process parameters, not build logic ('build') or test logic ('test').
4. The labels 'fix' and 'cicd' are justified because each code unit cleanly maps to its respective label based on the nature and motivation of the changes."
fixed start types for size and opacity,"diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },
",1,"[""06960183db42cba1b1f1a8077660ba8c801c9e18""]","[""fix""]","1. The code changes update how the initial values for particle size and opacity are set, correcting the logic for determining their start values and animation status, and also adjust the speed parameter in a configuration file.
2. These changes directly address incorrect or buggy behavior in the initialization logic for size and opacity animations, which aligns with the 'fix' label definition for resolving faults in the codebase.
3. The 'fix' label is appropriate because the changes clearly resolve logic errors and unintended behaviors, rather than introducing new features ('feat') or simply restructuring code without changing behavior ('refactor'); the configuration change is closely tied to correcting the animation behavior rather than being a general build or config update.
4. The 'fix' label correctly captures the intent and effect of these changes, which is to resolve bugs in the particle start value logic and related configuration."
"document the use of export buckets for large pre-aggregations

Co-authored-by: Ray Paik <ray@cube.dev>
Co-authored-by: Artyom Keydunov <artyom@cube.dev>
Co-authored-by: Dmitry Patsura <talk@dmtry.me>
add jackson dependencies for zb-bpmn-model
do not pin time in tests but only skip ahead

related to #573","diff --git a/docs/content/Caching/Using-Pre-Aggregations.md b/docs/content/Caching/Using-Pre-Aggregations.md
index 7882a25..a927241 100644
--- a/docs/content/Caching/Using-Pre-Aggregations.md
+++ b/docs/content/Caching/Using-Pre-Aggregations.md
@@ -65,8 +65,8 @@ In development mode, Cube.js enables background refresh by default and will
 refresh all pre-aggregations marked with the
 [`scheduledRefresh`](/pre-aggregations#scheduled-refresh) parameter.
 
-Please consult the [Production Checklist][ref-production-checklist-refresh] for
-best practices on running background refresh in production environments.
+Please consult the [Production Checklist][ref-prod-list-refresh] for best
+practices on running background refresh in production environments.
 
 ```js
 cube(`Orders`, {
@@ -193,10 +193,20 @@ CUBEJS_EXT_DB_TYPE=<SUPPORTED_DB_TYPE_HERE>
 
 <!-- prettier-ignore-start -->
 [[warning |]]
-| Please be aware of the limitations when using internal and external (outside of Cube Store) pre-aggregations.
+| Please be aware of the limitations when using internal and external (outside
+| of Cube Store) pre-aggregations.
 <!-- prettier-ignore-end -->
 
-![](https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/Caching/pre-aggregations.png)
+<div
+  style=""text-align: center""
+>
+  <img
+  alt=""Internal vs External vs External with Cube Store diagram""
+  src=""https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/Caching/pre-aggregations.png""
+  style=""border: none""
+  width=""100%""
+  />
+</div>
 
 #### Some known limitations when using Postgres/MySQL as a storage layer listed below.
 
@@ -245,15 +255,75 @@ slow to return results.
 (such as AWS Athena and BigQuery). Repeatedly querying for this data can easily
 rack up costs.
 
+## Optimizing Pre-Aggregation Build Times
+
+<!-- prettier-ignore-start -->
+[[info | ]]
+| For ideal performance, pre-aggregations should be built using a dedicated
+| Refresh Worker. [See here for more details][ref-prod-list-refresh].
+<!-- prettier-ignore-end -->
+
+By default, Cube.js will use the source database as a temporary staging area for
+writing pre-aggregations to determine column types. The data is loaded back into
+memory before writing them to Cube Store (or an external database).
+
+![](build-regular.png)
+
+If the dataset is large (more than 100k rows), then Cube.js can face issues when
+the Node runtime runs out of memory.
+
+### Batching
+
+Batching is a more performant strategy where Cube.js sends compressed CSVs for
+Cube Store to ingest.
+
+![](build-batching.png)
+
+The performance scales to the amount of memory available on the Cube.js
+instance. Support is currently available for:
+
+- [AWS Athena][ref-connect-db-athena] (coming soon)
+- [AWS Redshift][ref-connect-db-redshift]
+- [BigQuery][ref-connect-db-bigquery]
+- [MySQL][ref-connect-db-mysql]
+- [Postgres][ref-connect-db-postgres]
+
+### Export bucket
+
+When dealing with larger pre-aggregations (more than 100k rows), performance can
+be significantly improved by using an export bucket. This allows the source
+database to persist data directly into cloud storage, which is then loaded into
+Cube Store in parallel:
+
+![](build-export-bucket.png)
+
+Export buckets are currently supported for the following databases:
+
+- [AWS Athena][ref-connect-db-athena] (coming soon)
+- [AWS Redshift][ref-connect-db-redshift]
+- [BigQuery][ref-connect-db-bigquery]
+- [Snowflake][ref-connect-db-snowflake]
+
+When using cloud storage, it is important to correctly configure any data
+retention policies to clean up the data in the export bucket as Cube.js does not
+currently manage this. For most use-cases, 1 day is sufficient.
+
 [wiki-partitioning]: https://en.wikipedia.org/wiki/Partition_(database)
+[ref-config-connect-db]: /connecting-to-the-database
+[ref-config-env]: /reference/environment-variables#cube-store
+[ref-connect-db-athena]: /connecting-to-the-database#notes-aws-athena
+[ref-connect-db-redshift]: /connecting-to-the-database#notes-aws-redshift
+[ref-connect-db-bigquery]: /connecting-to-the-database#notes-google-big-query
+[ref-connect-db-mysql]: /connecting-to-the-database#notes-my-sql
+[ref-connect-db-postgres]: /connecting-to-the-database#notes-aws-rds-postgres
+[ref-connect-db-snowflake]: /connecting-to-the-database#notes-snowflake
 [ref-schema-timedimension]: /types-and-formats#dimensions-types-time
 [ref-preaggs]: /pre-aggregations
 [ref-preagg-sched-refresh]: /pre-aggregations#scheduled-refresh
 [ref-preagg-time-part]: /pre-aggregations#rollup-time-partitioning
 [ref-preagg-segment-part]: /pre-aggregations#rollup-segment-partitioning
 [ref-preaggs-refresh-key]: /pre-aggregations#refresh-key
+[ref-prod-list-refresh]: /deployment/production-checklist#set-up-refresh-worker
 [ref-config-extdbtype]: /config#options-reference-external-db-type
 [ref-config-driverfactory]: /config#options-reference-driver-factory
 [ref-config-extdriverfactory]: /config#options-reference-external-driver-factory
-[ref-production-checklist-refresh]:
-  /deployment/production-checklist#set-up-refresh-worker
diff --git a/docs/content/Caching/build-batching.png b/docs/content/Caching/build-batching.png
new file mode 100755
index 0000000..d1e28b3
Binary files /dev/null and b/docs/content/Caching/build-batching.png differ
diff --git a/docs/content/Caching/build-export-bucket.png b/docs/content/Caching/build-export-bucket.png
new file mode 100755
index 0000000..7da2425
Binary files /dev/null and b/docs/content/Caching/build-export-bucket.png differ
diff --git a/docs/content/Caching/build-regular.png b/docs/content/Caching/build-regular.png
new file mode 100644
index 0000000..af4c3a2
Binary files /dev/null and b/docs/content/Caching/build-regular.png differ
diff --git a/docs/content/Configuration/Connecting-to-the-Database.md b/docs/content/Configuration/Connecting-to-the-Database.md
index 321518f..a16ccc4 100644
--- a/docs/content/Configuration/Connecting-to-the-Database.md
+++ b/docs/content/Configuration/Connecting-to-the-Database.md
@@ -49,20 +49,21 @@ CUBEJS_API_SECRET=secret
 The table below shows which environment variables are used for different
 databases:
 
-| Database                                               | Credentials                                                                                                                                                                                                                                                                                                                                          |
-| ------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
-| PostgreSQL, MySQL, AWS Redshift, Hive/SparkSQL, Oracle | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                                             |
-| MS SQL                                                 | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_DOMAIN`                                                                                                                                                                                                                                         |
-| ClickHouse                                             | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_CLICKHOUSE_READONLY`                                                                                                                                                                                                           |
-| AWS Athena                                             | `CUBEJS_AWS_KEY`, `CUBEJS_AWS_SECRET`, `CUBEJS_AWS_REGION`, `CUBEJS_AWS_S3_OUTPUT_LOCATION`                                                                                                                                                                                                                                                          |
-| Google BigQuery                                        | `CUBEJS_DB_BQ_PROJECT_ID`, `CUBEJS_DB_BQ_KEY_FILE or CUBEJS_DB_BQ_CREDENTIALS`, `CUBEJS_DB_BQ_LOCATION`, `CUBEJS_DB_BQ_EXPORT_BUCKET`                                                                                                                                                                                                                |
-| MongoDB                                                | `CUBEJS_DB_HOST`, `CUBEJS_DB_NAME`, `CUBEJS_DB_PORT`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_SSL_CA`, `CUBEJS_DB_SSL_CERT`, `CUBEJS_DB_SSL_CIPHERS`, `CUBEJS_DB_SSL_PASSPHRASE`                                                                                                                                             |
-| Snowflake                                              | `CUBEJS_DB_SNOWFLAKE_ACCOUNT`, `CUBEJS_DB_SNOWFLAKE_REGION`, `CUBEJS_DB_SNOWFLAKE_WAREHOUSE`, `CUBEJS_DB_SNOWFLAKE_ROLE`, `CUBEJS_DB_SNOWFLAKE_CLIENT_SESSION_KEEP_ALIVE`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SNOWFLAKE_AUTHENTICATOR`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PATH`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS` |
-| Presto                                                 | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_CATALOG`, `CUBEJS_DB_SCHEMA`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                      |
-| Druid                                                  | `CUBEJS_DB_URL`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`                                                                                                                                                                                                                                                                                 |
-| SQLite                                                 | `CUBEJS_DB_NAME`                                                                                                                                                                                                                                                                                                                                     |
-| Databricks                                             | `CUBEJS_DB_NAME`, `CUBEJS_DB_DATABRICKS_URL`                                                                                                                                                                                                                                                                                                         |
-| Elasticsearch                                          | `CUBEJS_DB_URL`, `CUBEJS_DB_ELASTIC_QUERY_FORMAT`,`CUBEJS_DB_ELASTIC_OPENDISTRO` ,`CUBEJS_DB_ELASTIC_APIKEY_ID`,`CUBEJS_DB_ELASTIC_APIKEY_KEY`                                                                                                                                                                                                       |
+| Database                                 | Credentials                                                                                                                                                                                                                                                                                                                                          |
+| ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
+| PostgreSQL, MySQL, Hive/SparkSQL, Oracle | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                                             |
+| AWS Redshift                             | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`,                                                                                                                                                                                                                                                            |
+| MS SQL                                   | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_DOMAIN`                                                                                                                                                                                                                                         |
+| ClickHouse                               | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_CLICKHOUSE_READONLY`                                                                                                                                                                                                           |
+| AWS Athena                               | `CUBEJS_AWS_KEY`, `CUBEJS_AWS_SECRET`, `CUBEJS_AWS_REGION`, `CUBEJS_AWS_S3_OUTPUT_LOCATION`                                                                                                                                                                                                                                                          |
+| Google BigQuery                          | `CUBEJS_DB_BQ_PROJECT_ID`, `CUBEJS_DB_BQ_KEY_FILE or CUBEJS_DB_BQ_CREDENTIALS`, `CUBEJS_DB_BQ_LOCATION`,                                                                                                                                                                                                                                             |
+| MongoDB                                  | `CUBEJS_DB_HOST`, `CUBEJS_DB_NAME`, `CUBEJS_DB_PORT`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`, `CUBEJS_DB_SSL_CA`, `CUBEJS_DB_SSL_CERT`, `CUBEJS_DB_SSL_CIPHERS`, `CUBEJS_DB_SSL_PASSPHRASE`                                                                                                                                             |
+| Snowflake                                | `CUBEJS_DB_SNOWFLAKE_ACCOUNT`, `CUBEJS_DB_SNOWFLAKE_REGION`, `CUBEJS_DB_SNOWFLAKE_WAREHOUSE`, `CUBEJS_DB_SNOWFLAKE_ROLE`, `CUBEJS_DB_SNOWFLAKE_CLIENT_SESSION_KEEP_ALIVE`, `CUBEJS_DB_NAME`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SNOWFLAKE_AUTHENTICATOR`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PATH`, `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS` |
+| Presto                                   | `CUBEJS_DB_HOST`, `CUBEJS_DB_PORT`, `CUBEJS_DB_CATALOG`, `CUBEJS_DB_SCHEMA`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`                                                                                                                                                                                                                                      |
+| Druid                                    | `CUBEJS_DB_URL`, `CUBEJS_DB_USER`, `CUBEJS_DB_PASS`, `CUBEJS_DB_SSL`                                                                                                                                                                                                                                                                                 |
+| SQLite                                   | `CUBEJS_DB_NAME`                                                                                                                                                                                                                                                                                                                                     |
+| Databricks                               | `CUBEJS_DB_NAME`, `CUBEJS_DB_DATABRICKS_URL`                                                                                                                                                                                                                                                                                                         |
+| Elasticsearch                            | `CUBEJS_DB_URL`, `CUBEJS_DB_ELASTIC_QUERY_FORMAT`,`CUBEJS_DB_ELASTIC_OPENDISTRO` ,`CUBEJS_DB_ELASTIC_APIKEY_ID`,`CUBEJS_DB_ELASTIC_APIKEY_KEY`                                                                                                                                                                                                       |
 
 ## Multiple Databases
 
@@ -195,18 +196,25 @@ You can learn more about acquiring Google BigQuery credentials
 [here][link-bigquery-getting-started] and [here][link-bigquery-credentials].
 
 You can set the dataset location using the `CUBEJS_DB_BQ_LOCATION` environment
-variable.
+variable. All supported regions [can be found
+here][link-bigquery-regional-locations].
 
 ```dotenv
 CUBEJS_DB_BQ_LOCATION=us-central1
 ```
 
-You can find more supported regions [here][link-bigquery-regional-locations].
+#### Configuring an export bucket
 
-If your pre-aggregations dataset is too big to fit in memory, we **strongly**
-recommend configuring `CUBEJS_DB_BQ_EXPORT_BUCKET`. This will allow Cube.js to
-materialize results on an ""export"" bucket which are then loaded into BigQuery,
-providing better performance.
+<!-- prettier-ignore-start -->
+[[warning |]]
+| BigQuery only supports using Google Cloud Storage for export buckets.
+<!-- prettier-ignore-end -->
+
+##### Google Cloud Storage
+
+For [improved pre-aggregation performance with large
+datasets][ref-caching-large-preaggs], enable the export bucket functionality by
+configuring Cube.js with the following environment variables:
 
 <!-- prettier-ignore-start -->
 [[info |]]
@@ -216,7 +224,8 @@ providing better performance.
 <!-- prettier-ignore-end -->
 
 ```dotenv
-CUBEJS_DB_BQ_EXPORT_BUCKET=export_data_58148478376
+CUBEJS_DB_EXPORT_BUCKET=export_data_58148478376
+CUBEJS_DB_EXPORT_BUCKET_TYPE=gcp
 ```
 
 ### MSSQL
@@ -279,6 +288,73 @@ To connect to a Elasticsearch database, use `CUBEJS_DB_URL` with the username
 and password embedded in the URL, if required. If you're not using Elastic
 Cloud, you **must** specify `CUBEJS_DB_ELASTIC_QUERY_FORMAT`.
 
+### AWS Redshift
+
+#### Configuring an export bucket
+
+<!-- prettier-ignore-start -->
+[[warning |]]
+| AWS Redshift only supports using AWS S3 for export buckets.
+<!-- prettier-ignore-end -->
+
+##### AWS S3
+
+For [improved pre-aggregation performance with large
+datasets][ref-caching-large-preaggs], enable the export bucket functionality by
+configuring Cube.js with the following environment variables:
+
+<!-- prettier-ignore-start -->
+[[info |]]
+| Ensure the AWS credentials are correctly configured in IAM to allow reads and
+| writes to the export bucket.
+<!-- prettier-ignore-end -->
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET_TYPE=s3
+CUBEJS_DB_EXPORT_BUCKET=my.bucket.on.s3
+CUBEJS_DB_EXPORT_BUCKET_AWS_KEY=<AWS_KEY>
+CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET=<AWS_SECRET>
+CUBEJS_DB_EXPORT_BUCKET_AWS_REGION=<AWS_REGION>
+```
+
+### Snowflake
+
+#### Configuring an export bucket
+
+Snowflake supports using both AWS S3 and Google Cloud Storage for export bucket
+functionality.
+
+##### AWS S3
+
+<!-- prettier-ignore-start -->
+[[info |]]
+| Ensure the AWS credentials are correctly configured in IAM to allow reads and
+| writes to the export bucket.
+<!-- prettier-ignore-end -->
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET_TYPE=s3
+CUBEJS_DB_EXPORT_BUCKET=my.bucket.on.s3
+CUBEJS_DB_EXPORT_BUCKET_AWS_KEY=<AWS_KEY>
+CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET=<AWS_SECRET>
+CUBEJS_DB_EXPORT_BUCKET_AWS_REGION=<AWS_REGION>
+```
+
+##### Google Cloud Storage
+
+Before configuring Cube.js, an [integration must be created and configured in
+Snowflake][link-snowflake-gcs-integration]. Take note of the integration name
+(`gcs_int` from the example link) as you'll need it to configure Cube.js.
+
+Once the Snowflake integration is set up, configure Cube.js using the following:
+
+```dotenv
+CUBEJS_DB_EXPORT_BUCKET=snowflake-export-bucket
+CUBEJS_DB_EXPORT_BUCKET_TYPE=gcp
+CUBEJS_DB_EXPORT_GCS_CREDENTIALS=<BASE64_ENCODED_SERVICE_CREDENTIALS_JSON
+CUBEJS_DB_EXPORT_INTEGRATION=gcs_int
+```
+
 [link-java-guide]:
   https://github.com/cube-js/cube.js/blob/master/packages/cubejs-jdbc-driver/README.md#java-installation
 [link-cubejs-driver-guide]:
@@ -300,8 +376,11 @@ Cloud, you **must** specify `CUBEJS_DB_ELASTIC_QUERY_FORMAT`.
   https://console.cloud.google.com/apis/credentials/serviceaccountkey
 [link-heroku-postgres-issue]:
   https://help.heroku.com/3DELT3RK/why-can-t-my-third-party-utility-connect-to-heroku-postgres-with-ssl
+[link-snowflake-gcs-integration]:
+  https://docs.snowflake.com/en/user-guide/data-load-gcs-config.html
+[link-bigquery-regional-locations]:
+  https://cloud.google.com/bigquery/docs/locations#regional-locations
 [ref-cubejs-cli]: /using-the-cubejs-cli
 [ref-enabling-ssl]: #enabling-ssl
 [ref-env-var]: /reference/environment-variables#database-connection
-[link-bigquery-regional-locations]:
-  https://cloud.google.com/bigquery/docs/locations#regional-locations
+[ref-caching-large-preaggs]: /using-pre-aggregations#large-pre-aggregations
diff --git a/docs/content/Configuration/Environment-Variables-Reference.md b/docs/content/Configuration/Environment-Variables-Reference.md
index 692d2c7..6888697 100644
--- a/docs/content/Configuration/Environment-Variables-Reference.md
+++ b/docs/content/Configuration/Environment-Variables-Reference.md
@@ -124,6 +124,18 @@ databases [in this guide][link-connecting-to-db].
 | `CUBEJS_DB_SNOWFLAKE_PRIVATE_KEY_PASS`          | Snowflake            | The password for the private RSA key. Only required for encrypted keys                                                                                                                                      | A valid password for the encrypted private RSA key               |
 | `CUBEJS_DB_DATABRICKS_URL`                      | Databricks           | The URL for a JDBC connection                                                                                                                                                                               | A valid JDBC URL                                                 |
 
+## Export Bucket
+
+| Environment variable                 | Description                                                                                  | Possible Values                                                  |
+| ------------------------------------ | -------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- |
+| `CUBEJS_DB_EXPORT_BUCKET`            | The name of a bucket in cloud storage                                                        | `exports-20210505`                                               |
+| `CUBEJS_DB_EXPORT_BUCKET_TYPE`       | The cloud provider where the bucket is hosted                                                | `gcs`, `s3`                                                      |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_KEY`    | The AWS Access Key ID to use for the export bucket                                           | A valid AWS Access Key ID                                        |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_SECRET` | The AWS Secret Access Key to use for the export bucket                                       | A valid AWS Secret Access Key                                    |
+| `CUBEJS_DB_EXPORT_BUCKET_AWS_REGION` | The AWS region of the export bucket                                                          | [A valid AWS region][link-aws-regions]                           |
+| `CUBEJS_DB_EXPORT_GCS_CREDENTIALS`   | A Base64 encoded JSON key file for connecting to Google Cloud                                | A valid Google Cloud JSON key file encoded as a Base64 string    |
+| `CUBEJS_DB_EXPORT_INTEGRATION`       | The name of the integration used in the database. Only required when using Snowflake and GCS | A valid string matching the name of the integration in Snowflake |
+
 ## Cube Store
 
 | Environment variable            | Description                                                                                                                             | Possible Values                                             |

diff --git a/parent/pom.xml b/parent/pom.xml
index d475131..6290e66 100644
--- a/parent/pom.xml
+++ b/parent/pom.xml
@@ -35,6 +35,7 @@
     <version.mockito>1.8.5</version.mockito>
     <version.assertj>3.8.0</version.assertj>
     <version.msgpack>0.8.13</version.msgpack>
+    <version.jackson>2.9.0</version.jackson>
     <version.jmh>1.11.2</version.jmh>
     <version.sbe>1.5.6</version.sbe>
     <version.slf4j>1.7.23</version.slf4j>
@@ -64,6 +65,18 @@
       </dependency>
 
       <dependency>
+        <groupId>com.fasterxml.jackson.core</groupId>
+        <artifactId>jackson-databind</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
+        <groupId>com.fasterxml.jackson.dataformat</groupId>
+        <artifactId>jackson-dataformat-yaml</artifactId>
+        <version>${version.jackson}</version>
+      </dependency>
+
+      <dependency>
         <groupId>org.msgpack</groupId>
         <artifactId>msgpack-core</artifactId>
         <version>${version.msgpack}</version>

diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 636cd21..76afff7 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.doRepeatedly;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
@@ -24,11 +26,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.assertj.core.util.Files;
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -38,7 +47,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -48,9 +59,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.assertj.core.util.Files;
-import org.junit.*;
-import org.junit.rules.*;
 
 public class BrokerRecoveryTest
 {
@@ -360,17 +368,12 @@ public class BrokerRecoveryTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         // wait until stream processor and scheduler process the lock task event which is not re-processed on recovery
         doRepeatedly(() ->
         {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
+            ClockUtil.addTime(Duration.ofSeconds(60)); // retriggers lock expiration check in broker
             return null;
         }).until(t -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
 
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
index 5ff1301..0ffe98d 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRestartTest.java
@@ -15,7 +15,9 @@
  */
 package io.zeebe.broker.it.startup;
 
-import static io.zeebe.broker.it.util.TopicEventRecorder.*;
+import static io.zeebe.broker.it.util.TopicEventRecorder.incidentEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.taskEvent;
+import static io.zeebe.broker.it.util.TopicEventRecorder.wfInstanceEvent;
 import static io.zeebe.test.util.TestUtil.waitUntil;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -23,11 +25,18 @@ import java.io.File;
 import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.Collections;
 import java.util.List;
 import java.util.regex.Pattern;
 
+import org.junit.After;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.experimental.categories.Category;
+import org.junit.rules.ExpectedException;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TemporaryFolder;
+
 import io.zeebe.broker.clustering.ClusterServiceNames;
 import io.zeebe.broker.it.ClientRule;
 import io.zeebe.broker.it.EmbeddedBrokerRule;
@@ -37,7 +46,9 @@ import io.zeebe.client.ZeebeClient;
 import io.zeebe.client.clustering.impl.TopicLeader;
 import io.zeebe.client.clustering.impl.TopologyResponse;
 import io.zeebe.client.cmd.ClientCommandRejectedException;
-import io.zeebe.client.event.*;
+import io.zeebe.client.event.DeploymentEvent;
+import io.zeebe.client.event.TaskEvent;
+import io.zeebe.client.event.WorkflowInstanceEvent;
 import io.zeebe.model.bpmn.Bpmn;
 import io.zeebe.model.bpmn.instance.WorkflowDefinition;
 import io.zeebe.raft.Raft;
@@ -47,9 +58,6 @@ import io.zeebe.test.util.TestFileUtil;
 import io.zeebe.test.util.TestUtil;
 import io.zeebe.transport.SocketAddress;
 import io.zeebe.util.time.ClockUtil;
-import org.junit.*;
-import org.junit.experimental.categories.Category;
-import org.junit.rules.*;
 
 public class BrokerRestartTest
 {
@@ -360,11 +368,7 @@ public class BrokerRestartTest
         waitUntil(() -> !recordingTaskHandler.getHandledTasks().isEmpty());
 
         // when
-        restartBroker(() ->
-        {
-            final Instant now = ClockUtil.getCurrentTime();
-            ClockUtil.setCurrentTime(now.plusSeconds(60));
-        });
+        restartBroker(() -> ClockUtil.addTime(Duration.ofSeconds(60)));
 
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""LOCK_EXPIRED"")));
         recordingTaskHandler.clear();
diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
index 49b527d..a322fbe 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/task/TaskSubscriptionTest.java
@@ -353,7 +353,7 @@ public class TaskSubscriptionTest
         waitUntil(() -> taskHandler.getHandledTasks().size() == 1);
 
         // when
-        ClockUtil.setCurrentTime(Instant.now().plus(Duration.ofMinutes(5)));
+        ClockUtil.addTime(Duration.ofMinutes(5));
 
         // then
         waitUntil(() -> taskHandler.getHandledTasks().size() == 2);
",3,"[""81f37be838d5e3af738908b1bcbf59fea2b45989"", ""fab09655d5cc30727289cc3f26e5396fce235cd3"", ""7ece3a9a16780dc6c633bbd903d36ce0aefd6a8a""]","[""docs"", ""build"", ""test""]","1. The commit makes extensive changes to Markdown documentation files and adds new image assets, all focused on explaining and illustrating the use of export buckets for large pre-aggregations, as well as updating configuration and environment variable references.
2. These changes are wholly documentation-related, matching the 'docs' label, which is for modifications to documentation or text.
3. The commit also updates the Maven parent POM to add new Jackson dependencies and a version property, which directly affects the build configuration and dependency management, aligning with the 'build' label definition.
4. Additionally, the commit modifies several Java test files to change the way time is manipulated in tests (using ClockUtil.addTime instead of setting the time directly), which is strictly test logic and belongs under the 'test' label.
5. The 'docs', 'build', and 'test' labels are appropriate: 'docs' for all documentation and asset additions/changes, 'build' for dependency management updates, and 'test' for changes limited to test code; alternative labels (feat, fix, refactor, cicd) do not apply as there are no new features, bug fixes, code refactoring, or CI/CD script changes.
6. In summary, the assigned labels 'docs', 'build', and 'test' accurately reflect the nature and scope of the code units changed in this commit."
"svg helper
update pr condition
update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index 0f9cb63..ff5e5f0 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -1,4 +1,4 @@
-import { className, m, ns, style } from '../m';
+import { className, m, ns, svg, style } from '../m';
 import { VNode, VProps } from '../structs';
 
 const h = (tag: string, props?: VProps, ...children: VNode[]) =>
@@ -173,6 +173,28 @@ describe('.m', () => {
     });
   });
 
+  it('should attach ns to props using svg helper', () => {
+    const vnode = {
+      tag: 'svg',
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    expect(svg(vnode)).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
+
   it('should move key to distinct property', () => {
     expect(h('div', { key: 'foo' }, 'foo', h('div'))).toEqual({
       tag: 'div',

diff --git a/.github/workflows/release-pr.yml b/.github/workflows/release-pr.yml
index 697ca8e..23f4475 100644
--- a/.github/workflows/release-pr.yml
+++ b/.github/workflows/release-pr.yml
@@ -3,7 +3,6 @@ name: release
 on:
   issue_comment:
     types: [created]
-    contains: ""/trigger release""
 
 env:
   # 7 GiB by default on GitHub, setting to 6 GiB
@@ -11,6 +10,7 @@ env:
 
 jobs:
   release-pr:
+    if: ${{ github.event.issue.pull_request && github.event.comment.body == '/trigger release' }}
     permissions:
       id-token: write
     runs-on: ubuntu-latest

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",3,"[""4aa3e4c438742ef0fe694ffaf6a181874366d777"", ""f8c7b34bdeedcf1a4628cd50b23920afeaf57cb6"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""test"", ""cicd"", ""docs""]","1. The changes include adding a new test for the 'svg' helper in a test file, modifying a GitHub Actions workflow condition, and updating documentation in the Java get-started guide to handle payloads as maps instead of JSON strings.
2. The test file change is a pure addition of test logic, aligning with the 'test' object label; the workflow YAML modification updates CI/CD configuration, which fits the 'cicd' object label; the markdown documentation update in the Java guide is strictly documentation, matching the 'docs' object label.
3. These labels are appropriate because each change is fully scoped to its artifact: no behavioral code changes (so not 'feat', 'fix', or 'refactor'), and each artifact (test, CI config, documentation) is modified in isolation.
4. The assigned 'test', 'cicd', and 'docs' labels accurately and specifically reflect the essence of each code unit's modifications in this commit."
fix cypress on windows,"diff --git a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
index 22851fb..c9296fe 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.spec.ts
@@ -77,7 +77,7 @@ describe('Cypress builder', () => {
     await run.result;
     await run.stop();
     expect(fork).toHaveBeenCalledWith(
-      '/root/node_modules/.bin/tsc',
+      '/root/node_modules/typescript/bin/tsc',
       ['-p', '/root/apps/my-app-e2e/tsconfig.json'],
       { stdio: [0, 1, 2, 'ipc'] }
     );
diff --git a/packages/cypress/src/builders/cypress/cypress.impl.ts b/packages/cypress/src/builders/cypress/cypress.impl.ts
index 9d9ded3..d3917c2 100644
--- a/packages/cypress/src/builders/cypress/cypress.impl.ts
+++ b/packages/cypress/src/builders/cypress/cypress.impl.ts
@@ -115,7 +115,7 @@ function compileTypescriptFiles(
       let args = ['-p', path.join(context.workspaceRoot, tsConfigPath)];
       const tscPath = path.join(
         context.workspaceRoot,
-        '/node_modules/.bin/tsc'
+        '/node_modules/typescript/bin/tsc'
       );
       if (isWatching) {
         args.push('--watch');
",1,"[""eebee9ab0bb6d4255ad0402d8422364e96bfef61""]","[""fix""]","1. The code changes update the path used to invoke the TypeScript compiler in both the implementation and its test, replacing the '.bin/tsc' symlink with the direct path to 'typescript/bin/tsc'.
2. This change addresses a platform-specific issue (Cypress not working on Windows), which aligns with the 'fix' label definition for correcting faulty behavior.
3. The 'fix' label is appropriate because the modification resolves a bug affecting Windows compatibility, rather than adding features ('feat'), restructuring code for clarity ('refactor'), or solely updating tests ('test')—the changes are not limited to test logic but also affect core implementation.
4. The 'fix' label correctly captures that the commit resolves a bug in cross-platform compatibility by adjusting the TypeScript compiler path."
"fix ""types"" field in dist
apply element migrated events

This is a very straightforward event applier. All it needs to do is
update the persisted data for the element instance using the data in the
event.
remove unused branches and ignore envrc file","diff --git a/scripts/prepare.js b/scripts/prepare.js
index 4bab09b..55f459b 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -96,7 +96,6 @@ async function prepare() {
     delete json.private
     delete json.scripts
     delete json.devDependencies
-    delete json.types
 
     // Add ""postinstall"" script for donations.
     if (/(native|core)$/.test(name))
@@ -128,6 +127,7 @@ async function prepare() {
     else {
       json.main = json.main.replace(/^dist\//, '')
       if (json.main.endsWith('.cjs.js')) {
+        json.types = json.main.replace('.cjs.js', '.d.ts')
         json.module = json.main.replace('.cjs', '')
       }
     }

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
index da05e13..9231df3 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/EventAppliers.java
@@ -154,6 +154,9 @@ public final class EventAppliers implements EventApplier {
     register(
         ProcessInstanceIntent.SEQUENCE_FLOW_TAKEN,
         new ProcessInstanceSequenceFlowTakenApplier(elementInstanceState, processState));
+    register(
+        ProcessInstanceIntent.ELEMENT_MIGRATED,
+        new ProcessInstanceElementMigratedApplier(elementInstanceState));
   }
 
   private void registerProcessInstanceCreationAppliers(final MutableProcessingState state) {
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
index e5a0f3a..d38358f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/appliers/ProcessInstanceElementMigratedApplier.java
@@ -24,5 +24,16 @@ final class ProcessInstanceElementMigratedApplier
   }
 
   @Override
-  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {}
+  public void applyState(final long elementInstanceKey, final ProcessInstanceRecord value) {
+    elementInstanceState.updateInstance(
+        elementInstanceKey,
+        elementInstance ->
+            elementInstance
+                .getValue()
+                .setProcessDefinitionKey(value.getProcessDefinitionKey())
+                .setBpmnProcessId(value.getBpmnProcessId())
+                .setVersion(value.getVersion())
+                .setElementId(value.getElementId())
+                .setFlowScopeKey(value.getFlowScopeKey()));
+  }
 }

diff --git a/.github/workflows/ibis-backends-cloud.yml b/.github/workflows/ibis-backends-cloud.yml
index 2003e8e..7c7fd26 100644
--- a/.github/workflows/ibis-backends-cloud.yml
+++ b/.github/workflows/ibis-backends-cloud.yml
@@ -5,9 +5,12 @@ on:
     # Skip the backend suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
+      - ""**/*.md""
+      - ""**/*.qmd""
+      - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
-      - quarto
 
 permissions:
   # this allows extractions/setup-just to list releases for `just` at a higher
diff --git a/.github/workflows/ibis-backends-skip-helper.yml b/.github/workflows/ibis-backends-skip-helper.yml
index 5d5f3f7..0471994 100644
--- a/.github/workflows/ibis-backends-skip-helper.yml
+++ b/.github/workflows/ibis-backends-skip-helper.yml
@@ -9,20 +9,20 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_backends:
diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4a1cae9..30e6c1a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -8,10 +8,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the backend suite if all changes are docs
     paths-ignore:
@@ -19,10 +19,10 @@ on:
       - ""**/*.md""
       - ""**/*.qmd""
       - ""codecov.yml""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 1adda11..b528a30 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -5,12 +5,10 @@ on:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-main-skip-helper.yml b/.github/workflows/ibis-main-skip-helper.yml
index a5fdc6f..0fb5dea 100644
--- a/.github/workflows/ibis-main-skip-helper.yml
+++ b/.github/workflows/ibis-main-skip-helper.yml
@@ -8,19 +8,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 jobs:
   test_core:
diff --git a/.github/workflows/ibis-main.yml b/.github/workflows/ibis-main.yml
index aa31436..0b1536a 100644
--- a/.github/workflows/ibis-main.yml
+++ b/.github/workflows/ibis-main.yml
@@ -7,20 +7,20 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     # Skip the test suite if all changes are in the docs directory
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 permissions:
diff --git a/.github/workflows/ibis-tpch-queries-skip-helper.yml b/.github/workflows/ibis-tpch-queries-skip-helper.yml
index 1f1c0bc..f10fb8d 100644
--- a/.github/workflows/ibis-tpch-queries-skip-helper.yml
+++ b/.github/workflows/ibis-tpch-queries-skip-helper.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/ibis-tpch-queries.yml b/.github/workflows/ibis-tpch-queries.yml
index b4f8a48..9e65a61 100644
--- a/.github/workflows/ibis-tpch-queries.yml
+++ b/.github/workflows/ibis-tpch-queries.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
diff --git a/.github/workflows/nix-skip-helper.yml b/.github/workflows/nix-skip-helper.yml
index 677b4d7..e0ab8f7 100644
--- a/.github/workflows/nix-skip-helper.yml
+++ b/.github/workflows/nix-skip-helper.yml
@@ -9,19 +9,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 jobs:
diff --git a/.github/workflows/nix.yml b/.github/workflows/nix.yml
index f2dd3f0..7ea9e26 100644
--- a/.github/workflows/nix.yml
+++ b/.github/workflows/nix.yml
@@ -6,19 +6,19 @@ on:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   pull_request:
     paths-ignore:
       - ""docs/**""
       - ""**/*.md""
       - ""**/*.qmd""
+      - "".envrc""
     branches:
       - master
       - ""*.x.x""
-      - quarto
   merge_group:
 
 concurrency:
",3,"[""f14ef3809f456aadd73523e47cb16c5d15e9a9df"", ""39d5d1cfe8d2210305df2c8fab4a4ae430732cf7"", ""d0c6476df61b9c6ab07b87e1724ea7c5318595bb""]","[""build"", ""feat"", ""cicd""]","1. The change in 'scripts/prepare.js' corrects the handling of the 'types' field in the package output, ensuring it is properly set in the distribution build; this is a build system script. 
2. The Java changes add an event applier for ELEMENT_MIGRATED events, implementing logic to update persisted element instance data when such an event occurs, which is a clear new feature. 
3. The many '.github/workflows/*.yml' changes update CI workflow files to ignore '.envrc' and remove references to 'quarto', which are modifications strictly to CI configuration. 
4. 'build' is appropriate for the prepare.js change as it solely affects the build artifact generation, 'feat' is correct for the new event applier logic as it adds new functional capability, and 'cicd' is correct for the CI workflow YAML updates; alternative labels such as 'fix' or 'refactor' are not as suitable because none of these changes are strictly bug fixes or code restructuring. 
5. The assigned labels 'build', 'feat', and 'cicd' each precisely match the nature and scope of the respective code units modified in this commit."
`worktree::encode_to_worktree()` to turn UTf-8 into the worktree encoding.,"diff --git a/gix-filter/src/worktree.rs b/gix-filter/src/worktree.rs
deleted file mode 100644
index cda7640..0000000
--- a/gix-filter/src/worktree.rs
+++ /dev/null
@@ -1,132 +0,0 @@
-//! Worktree encodings are powered by the `encoding_rs` crate, which has a narrower focus than the `iconv` library. Thus this implementation
-//! is inherently more limited but will handle the common cases.
-//!  
-//! Note that for encoding to legacy formats, [additional normalization steps](https://docs.rs/encoding_rs/0.8.32/encoding_rs/#preparing-text-for-the-encoders)
-//! can be taken, which we do not yet take unless there is specific examples or problems to solve.
-
-use crate::clear_and_set_capacity;
-use crate::worktree::encode_to_git::RoundTrip;
-use encoding_rs::DecoderResult;
-
-///
-pub mod encoding {
-    use bstr::BStr;
-    use encoding_rs::Encoding;
-
-    ///
-    pub mod for_label {
-        use bstr::BString;
-
-        /// The error returned by [for_label()][super::for_label()].
-        #[derive(Debug, thiserror::Error)]
-        #[allow(missing_docs)]
-        pub enum Error {
-            #[error(""An encoding named '{name}' is not known"")]
-            Unknown { name: BString },
-        }
-    }
-    /// Try to produce a new `Encoding` for `label` or report an error if it is not known.
-    ///
-    /// ### Deviation
-    ///
-    /// * There is no special handling of UTF-16LE/BE with checks if data contains a BOM or not, like `git` as we don't expect to have
-    ///   data available here.
-    /// * Special `-BOM` suffixed versions of `UTF-16` encodings are not supported.
-    pub fn for_label<'a>(label: impl Into<&'a BStr>) -> Result<&'static Encoding, for_label::Error> {
-        let mut label = label.into();
-        if label == ""latin-1"" {
-            label = ""ISO-8859-1"".into();
-        }
-        let enc =
-            Encoding::for_label(label.as_ref()).ok_or_else(|| for_label::Error::Unknown { name: label.into() })?;
-        Ok(enc)
-    }
-}
-
-///
-pub mod encode_to_git {
-    /// Whether or not to perform round-trip checks.
-    #[derive(Debug, Copy, Clone)]
-    pub enum RoundTrip {
-        /// Assure that we can losslessly convert the UTF-8 result back to the original encoding.
-        Validate,
-        /// Do not check if the encoding is round-trippable.
-        Ignore,
-    }
-
-    /// The error returned by [`encode_to_git()][super::encode_to_git()].
-    #[derive(Debug, thiserror::Error)]
-    #[allow(missing_docs)]
-    pub enum Error {
-        #[error(""Cannot convert input of {input_len} bytes to UTF-8 without overflowing"")]
-        Overflow { input_len: usize },
-        #[error(""The input was malformed and could not be decoded as '{encoding}'"")]
-        Malformed { encoding: &'static str },
-        #[error(""Encoding from '{src_encoding}' to '{dest_encoding}' and back is not the same"")]
-        RoundTrip {
-            src_encoding: &'static str,
-            dest_encoding: &'static str,
-        },
-    }
-}
-
-/// Decode `src` according to `src_encoding` to `UTF-8` for storage in git.
-/// Note that the encoding is always applied, there is no conditional even if `src_encoding` already is `UTF-8`.
-pub fn encode_to_git(
-    src: &[u8],
-    src_encoding: &'static encoding_rs::Encoding,
-    buf: &mut Vec<u8>,
-    round_trip: encode_to_git::RoundTrip,
-) -> Result<(), encode_to_git::Error> {
-    let mut decoder = src_encoding.new_decoder_with_bom_removal();
-    let buf_len = decoder
-        .max_utf8_buffer_length_without_replacement(src.len())
-        .ok_or_else(|| encode_to_git::Error::Overflow { input_len: src.len() })?;
-    clear_and_set_capacity(buf, buf_len);
-    // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
-    //          what is allocated. Later we will truncate to the amount of actually written bytes.
-    #[allow(unsafe_code)]
-    unsafe {
-        buf.set_len(buf_len);
-    }
-    let (res, read, written) = decoder.decode_to_utf8_without_replacement(src, buf, true);
-    match res {
-        DecoderResult::InputEmpty => {
-            assert!(
-                buf_len >= written,
-                ""encoding_rs estimates the maximum amount of bytes written correctly""
-            );
-            assert_eq!(read, src.len(), ""input buffer should be fully consumed"");
-            // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
-            #[allow(unsafe_code)]
-            unsafe {
-                buf.set_len(written);
-            }
-        }
-        DecoderResult::OutputFull => {
-            unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
-        }
-        DecoderResult::Malformed(_, _) => {
-            return Err(encode_to_git::Error::Malformed {
-                encoding: src_encoding.name(),
-            })
-        }
-    }
-
-    match round_trip {
-        RoundTrip::Validate => {
-            // SAFETY: we trust `encoding_rs` to output valid UTF-8 only if we ask it to.
-            #[allow(unsafe_code)]
-            let str = unsafe { std::str::from_utf8_unchecked(&buf) };
-            let (should_equal_src, _actual_encoding, _had_errors) = src_encoding.encode(str);
-            if should_equal_src != src {
-                return Err(encode_to_git::Error::RoundTrip {
-                    src_encoding: src_encoding.name(),
-                    dest_encoding: ""UTF-8"",
-                });
-            }
-        }
-        RoundTrip::Ignore => {}
-    }
-    Ok(())
-}
diff --git a/gix-filter/src/worktree/encode_to_git.rs b/gix-filter/src/worktree/encode_to_git.rs
new file mode 100644
index 0000000..da1bbf7
--- /dev/null
+++ b/gix-filter/src/worktree/encode_to_git.rs
@@ -0,0 +1,90 @@
+/// Whether or not to perform round-trip checks.
+#[derive(Debug, Copy, Clone)]
+pub enum RoundTrip {
+    /// Assure that we can losslessly convert the UTF-8 result back to the original encoding.
+    Validate,
+    /// Do not check if the encoding is round-trippable.
+    Ignore,
+}
+
+/// The error returned by [`encode_to_git()][super::encode_to_git()].
+#[derive(Debug, thiserror::Error)]
+#[allow(missing_docs)]
+pub enum Error {
+    #[error(""Cannot convert input of {input_len} bytes to UTF-8 without overflowing"")]
+    Overflow { input_len: usize },
+    #[error(""The input was malformed and could not be decoded as '{encoding}'"")]
+    Malformed { encoding: &'static str },
+    #[error(""Encoding from '{src_encoding}' to '{dest_encoding}' and back is not the same"")]
+    RoundTrip {
+        src_encoding: &'static str,
+        dest_encoding: &'static str,
+    },
+}
+
+pub(crate) mod function {
+    use super::{Error, RoundTrip};
+    use crate::clear_and_set_capacity;
+    use encoding_rs::DecoderResult;
+
+    /// Decode `src` according to `src_encoding` to `UTF-8` for storage in git and place it in `buf`.
+    /// Note that the encoding is always applied, there is no conditional even if `src_encoding` already is `UTF-8`.
+    pub fn encode_to_git(
+        src: &[u8],
+        src_encoding: &'static encoding_rs::Encoding,
+        buf: &mut Vec<u8>,
+        round_trip: RoundTrip,
+    ) -> Result<(), Error> {
+        let mut decoder = src_encoding.new_decoder_with_bom_removal();
+        let buf_len = decoder
+            .max_utf8_buffer_length_without_replacement(src.len())
+            .ok_or(Error::Overflow { input_len: src.len() })?;
+        clear_and_set_capacity(buf, buf_len);
+        // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
+        //          what is allocated. Later we will truncate to the amount of actually written bytes.
+        #[allow(unsafe_code)]
+        unsafe {
+            buf.set_len(buf_len);
+        }
+        let (res, read, written) = decoder.decode_to_utf8_without_replacement(src, buf, true);
+        match res {
+            DecoderResult::InputEmpty => {
+                assert!(
+                    buf_len >= written,
+                    ""encoding_rs estimates the maximum amount of bytes written correctly""
+                );
+                assert_eq!(read, src.len(), ""input buffer should be fully consumed"");
+                // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
+                #[allow(unsafe_code)]
+                unsafe {
+                    buf.set_len(written);
+                }
+            }
+            DecoderResult::OutputFull => {
+                unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
+            }
+            DecoderResult::Malformed(_, _) => {
+                return Err(Error::Malformed {
+                    encoding: src_encoding.name(),
+                })
+            }
+        }
+
+        match round_trip {
+            RoundTrip::Validate => {
+                // SAFETY: we trust `encoding_rs` to output valid UTF-8 only if we ask it to.
+                #[allow(unsafe_code)]
+                let str = unsafe { std::str::from_utf8_unchecked(buf) };
+                let (should_equal_src, _actual_encoding, _had_errors) = src_encoding.encode(str);
+                if should_equal_src != src {
+                    return Err(Error::RoundTrip {
+                        src_encoding: src_encoding.name(),
+                        dest_encoding: ""UTF-8"",
+                    });
+                }
+            }
+            RoundTrip::Ignore => {}
+        }
+        Ok(())
+    }
+}
diff --git a/gix-filter/src/worktree/encode_to_worktree.rs b/gix-filter/src/worktree/encode_to_worktree.rs
new file mode 100644
index 0000000..0a53419
--- /dev/null
+++ b/gix-filter/src/worktree/encode_to_worktree.rs
@@ -0,0 +1,69 @@
+/// The error returned by [`encode_to_worktree()][super::encode_to_worktree()].
+#[derive(Debug, thiserror::Error)]
+#[allow(missing_docs)]
+pub enum Error {
+    #[error(""Cannot convert input of {input_len} UTF-8 bytes to target encoding without overflowing"")]
+    Overflow { input_len: usize },
+    #[error(""Input was not UTF-8 encoded"")]
+    InputAsUtf8(#[from] std::str::Utf8Error),
+    #[error(""The character '{character}' could not be mapped to the {worktree_encoding}"")]
+    Unmappable {
+        character: char,
+        worktree_encoding: &'static str,
+    },
+}
+
+pub(crate) mod function {
+    use super::Error;
+    use crate::clear_and_set_capacity;
+    use encoding_rs::EncoderResult;
+
+    /// Encode `src_utf8`, which is assumed to be UTF-8 encoded, according to `worktree_encoding` for placement in the working directory,
+    /// and write it to `buf`, possibly resizing it.
+    /// Note that the encoding is always applied, there is no conditional even if `worktree_encoding` and the `src` encoding are the same.
+    pub fn encode_to_worktree(
+        src_utf8: &[u8],
+        worktree_encoding: &'static encoding_rs::Encoding,
+        buf: &mut Vec<u8>,
+    ) -> Result<(), Error> {
+        let mut encoder = worktree_encoding.new_encoder();
+        let buf_len = encoder
+            .max_buffer_length_from_utf8_if_no_unmappables(src_utf8.len())
+            .ok_or(Error::Overflow {
+                input_len: src_utf8.len(),
+            })?;
+        clear_and_set_capacity(buf, buf_len);
+        // SAFETY: `clear_and_set_capacity` assure that we have the given `buf_len` allocated, so setting its length is only making available
+        //          what is allocated. Later we will truncate to the amount of actually written bytes.
+        #[allow(unsafe_code)]
+        unsafe {
+            buf.set_len(buf_len);
+        }
+        let src = std::str::from_utf8(src_utf8)?;
+        let (res, read, written) = encoder.encode_from_utf8_without_replacement(src, buf, true);
+        match res {
+            EncoderResult::InputEmpty => {
+                assert!(
+                    buf_len >= written,
+                    ""encoding_rs estimates the maximum amount of bytes written correctly""
+                );
+                assert_eq!(read, src_utf8.len(), ""input buffer should be fully consumed"");
+                // SAFETY: we trust that `encoding_rs` reports this number correctly, and truncate everything else.
+                #[allow(unsafe_code)]
+                unsafe {
+                    buf.set_len(written);
+                }
+            }
+            EncoderResult::OutputFull => {
+                unreachable!(""we assure that the output buffer is big enough as per the encoder's estimate"")
+            }
+            EncoderResult::Unmappable(c) => {
+                return Err(Error::Unmappable {
+                    worktree_encoding: worktree_encoding.name(),
+                    character: c,
+                })
+            }
+        }
+        Ok(())
+    }
+}
diff --git a/gix-filter/src/worktree/encoding.rs b/gix-filter/src/worktree/encoding.rs
new file mode 100644
index 0000000..0b75adc
--- /dev/null
+++ b/gix-filter/src/worktree/encoding.rs
@@ -0,0 +1,31 @@
+use bstr::BStr;
+use encoding_rs::Encoding;
+
+///
+pub mod for_label {
+    use bstr::BString;
+
+    /// The error returned by [for_label()][super::for_label()].
+    #[derive(Debug, thiserror::Error)]
+    #[allow(missing_docs)]
+    pub enum Error {
+        #[error(""An encoding named '{name}' is not known"")]
+        Unknown { name: BString },
+    }
+}
+
+/// Try to produce a new `Encoding` for `label` or report an error if it is not known.
+///
+/// ### Deviation
+///
+/// * There is no special handling of UTF-16LE/BE with checks if data contains a BOM or not, like `git` as we don't expect to have
+///   data available here.
+/// * Special `-BOM` suffixed versions of `UTF-16` encodings are not supported.
+pub fn for_label<'a>(label: impl Into<&'a BStr>) -> Result<&'static Encoding, for_label::Error> {
+    let mut label = label.into();
+    if label == ""latin-1"" {
+        label = ""ISO-8859-1"".into();
+    }
+    let enc = Encoding::for_label(label.as_ref()).ok_or_else(|| for_label::Error::Unknown { name: label.into() })?;
+    Ok(enc)
+}
diff --git a/gix-filter/src/worktree/mod.rs b/gix-filter/src/worktree/mod.rs
new file mode 100644
index 0000000..3b13ea4
--- /dev/null
+++ b/gix-filter/src/worktree/mod.rs
@@ -0,0 +1,16 @@
+//! Worktree encodings are powered by the `encoding_rs` crate, which has a narrower focus than the `iconv` library. Thus this implementation
+//! is inherently more limited but will handle the common cases.
+//!  
+//! Note that for encoding to legacy formats, [additional normalization steps](https://docs.rs/encoding_rs/0.8.32/encoding_rs/#preparing-text-for-the-encoders)
+//! can be taken, which we do not yet take unless there is specific examples or problems to solve.
+
+///
+pub mod encoding;
+
+///
+pub mod encode_to_git;
+pub use encode_to_git::function::encode_to_git;
+
+///
+pub mod encode_to_worktree;
+pub use encode_to_worktree::function::encode_to_worktree;
diff --git a/gix-filter/tests/worktree/mod.rs b/gix-filter/tests/worktree/mod.rs
index cc2c6f1..1eb1a8e 100644
--- a/gix-filter/tests/worktree/mod.rs
+++ b/gix-filter/tests/worktree/mod.rs
@@ -74,13 +74,28 @@ mod encode_to_git {
         let input = &b""hello""[..];
         for round_trip in [RoundTrip::Ignore, RoundTrip::Validate] {
             let mut buf = Vec::new();
-            worktree::encode_to_git(input, encoding(""UTF-8""), &mut buf, round_trip)?;
+            worktree::encode_to_git(input, encoding_rs::UTF_8, &mut buf, round_trip)?;
             assert_eq!(buf.as_bstr(), input)
         }
         Ok(())
     }
+}
+
+mod encode_to_worktree {
+    use bstr::ByteSlice;
+    use gix_filter::worktree;
+    use gix_filter::worktree::encode_to_git::RoundTrip;
 
-    fn encoding(label: &str) -> &'static encoding_rs::Encoding {
-        worktree::encoding::for_label(label).expect(""encoding is valid and known at compile time"")
+    #[test]
+    fn shift_jis() -> crate::Result {
+        let input = ""ハローワールド"";
+        let mut buf = Vec::new();
+        worktree::encode_to_worktree(input.as_bytes(), encoding_rs::SHIFT_JIS, &mut buf)?;
+
+        let mut re_encoded = Vec::new();
+        worktree::encode_to_git(&buf, encoding_rs::SHIFT_JIS, &mut re_encoded, RoundTrip::Validate)?;
+
+        assert_eq!(re_encoded.as_bstr(), input, ""this should be round-trippable too"");
+        Ok(())
     }
 }
",1,"[""d1fed3e9907d0a9e3fe45dbfe2ff27bd10b3e1f4""]","[""feat""]","1. The commit deletes the original 'worktree.rs' file and splits its contents into new modules: 'encoding.rs', 'encode_to_git.rs', and 'encode_to_worktree.rs', introducing a new public API 'encode_to_worktree', and updates the test suite to cover the new functionality and modular structure.
2. These changes introduce a new capability: encoding UTF-8 to a worktree encoding via the new 'encode_to_worktree' function, which did not exist before, aligning with the 'feat' label for new features.
3. The label is not 'refactor' because the main motivation is not just structural improvement—the new encode_to_worktree functionality is a feature addition; it is not 'fix' because it does not address a bug, nor is it 'test' or 'docs' since the main code logic is not solely about tests or documentation.
4. The 'feat' label is appropriate as the commit's primary motivation is to add new worktree encoding functionality and expand the API surface."
update flushed index before truncating,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {
",1,"[""933ab6bb86372913c992567cf9660009900911a7""]","[""fix""]","1. The code changes the order of operations by updating the flushed index before truncating the journal segment in the SegmentedJournalWriter class.
2. This change corrects the sequence of operations to ensure that the flushed index accurately reflects the truncated state, which aligns with the 'fix' label definition for resolving bugs or faulty behavior.
3. The 'fix' label is appropriate because the change addresses a potential bug relating to state consistency, not introducing new features ('feat') or merely improving structure ('refactor').
4. Therefore, the 'fix' label is correctly assigned as the change resolves a behavioral issue by ensuring correct state update sequencing."
"add `to_sql`

Co-authored-by: Gil Forsyth <gforsyth@users.noreply.github.com>
fixed start types for size and opacity","diff --git a/docs/api/expressions/top_level.md b/docs/api/expressions/top_level.md
index efaffbd..34b529e 100644
--- a/docs/api/expressions/top_level.md
+++ b/docs/api/expressions/top_level.md
@@ -28,7 +28,7 @@ These methods and objects are available directly in the `ibis` module.
 ::: ibis.or_
 ::: ibis.param
 ::: ibis.show_sql
-::: ibis.sql
+::: ibis.to_sql
 ::: ibis.random
 ::: ibis.range_window
 ::: ibis.row_number

diff --git a/core/main/src/Core/Particle.ts b/core/main/src/Core/Particle.ts
index 1aa6fba..6ea6ffc 100644
--- a/core/main/src/Core/Particle.ts
+++ b/core/main/src/Core/Particle.ts
@@ -271,7 +271,7 @@ export class Particle implements IParticle {
             }
         }
 
-        const sizeAnimation = this.options.size.animation;
+        const sizeAnimation = sizeOptions.animation;
 
         if (sizeAnimation.enable) {
             this.size.status = AnimationStatus.increasing;
@@ -279,7 +279,8 @@ export class Particle implements IParticle {
             if (!randomSize) {
                 switch (sizeAnimation.startValue) {
                     case StartValueType.min:
-                        this.size.value = sizeAnimation.minimumValue * pxRatio;
+                        this.size.value = NumberUtils.getRangeMin(sizeOptions.value) * pxRatio;
+                        this.size.status = AnimationStatus.increasing;
 
                         break;
 
@@ -287,11 +288,14 @@ export class Particle implements IParticle {
                         this.size.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(sizeAnimation.minimumValue * pxRatio, this.size.value)
                         );
+                        this.size.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.size.value = NumberUtils.getRangeMax(sizeOptions.value) * pxRatio;
                         this.size.status = AnimationStatus.decreasing;
 
                         break;
@@ -393,7 +397,8 @@ export class Particle implements IParticle {
             if (!randomOpacity) {
                 switch (opacityAnimation.startValue) {
                     case StartValueType.min:
-                        this.opacity.value = opacityAnimation.minimumValue;
+                        this.opacity.value = NumberUtils.getRangeMin(this.opacity.value);
+                        this.opacity.status = AnimationStatus.increasing;
 
                         break;
 
@@ -401,11 +406,14 @@ export class Particle implements IParticle {
                         this.opacity.value = NumberUtils.randomInRange(
                             NumberUtils.setRangeValue(opacityAnimation.minimumValue, this.opacity.value)
                         );
+                        this.opacity.status =
+                            Math.random() >= 0.5 ? AnimationStatus.increasing : AnimationStatus.decreasing;
 
                         break;
 
                     case StartValueType.max:
                     default:
+                        this.opacity.value = NumberUtils.getRangeMax(this.opacity.value);
                         this.opacity.status = AnimationStatus.decreasing;
 
                         break;
diff --git a/presets/confetti/src/options.ts b/presets/confetti/src/options.ts
index 7fc6225..a713425 100644
--- a/presets/confetti/src/options.ts
+++ b/presets/confetti/src/options.ts
@@ -28,7 +28,7 @@ export const loadOptions = (confettiOptions: RecursivePartial<IConfettiOptions>)
                 animation: {
                     enable: true,
                     minimumValue: 0,
-                    speed: 2,
+                    speed: 0.5,
                     startValue: ""max"",
                     destroy: ""min"",
                 },
",2,"[""e2821a56c7d867b8b591f1777019843a2ffca797"", ""06960183db42cba1b1f1a8077660ba8c801c9e18""]","[""docs"", ""fix""]","1. The commit modifies a documentation file to replace a reference from 'ibis.sql' to 'ibis.to_sql' and updates logic in 'Particle.ts' to correct how size and opacity animation starting values are set, along with a parameter change in a config file.
2. The documentation change aligns with the 'docs' label, as it updates a markdown file for accuracy, while the TypeScript changes address incorrect initialization logic, which aligns with the 'fix' label for correcting faulty behavior.
3. 'docs' is appropriate for the markdown edit because it is purely documentation, not code logic or tests; 'fix' is suitable for the TypeScript changes because they correct bugs in how particle size and opacity animations are initialized, rather than adding new features or restructuring code for clarity.
4. The assigned labels 'docs' and 'fix' are correct because the commit separately addresses documentation accuracy and code bug fixes, matching the definitions and scope of each label."
"brew tests/multiple darwin builds/gh enterprise
fix build ordering
add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com>","diff --git a/pipeline/brew/brew.go b/pipeline/brew/brew.go
index ec27182..15ed189 100644
--- a/pipeline/brew/brew.go
+++ b/pipeline/brew/brew.go
@@ -1,5 +1,3 @@
-// Package brew implements the Pipe, providing formula generation and
-// uploading it to a configured repo.
 package brew
 
 import (
@@ -10,13 +8,12 @@ import (
 	""strings""
 	""text/template""
 
-	""github.com/goreleaser/goreleaser/internal/artifact""
-
 	""github.com/apex/log""
 
 	""github.com/goreleaser/goreleaser/checksum""
 	""github.com/goreleaser/goreleaser/config""
 	""github.com/goreleaser/goreleaser/context""
+	""github.com/goreleaser/goreleaser/internal/artifact""
 	""github.com/goreleaser/goreleaser/internal/client""
 	""github.com/goreleaser/goreleaser/pipeline""
 )
@@ -106,14 +103,14 @@ func doRun(ctx *context.Context, client client.Client) error {
 		artifact.And(
 			artifact.ByGoos(""darwin""),
 			artifact.ByGoarch(""amd64""),
-			artifact.ByGoarch(""""),
+			artifact.ByGoarm(""""),
 			artifact.ByType(artifact.UploadableArchive),
 		),
 	).List()
 	if len(archives) == 0 {
 		return ErrNoDarwin64Build
 	}
-	if len(archives) > 0 {
+	if len(archives) > 1 {
 		return ErrTooManyDarwin64Builds
 	}
 	var path = filepath.Join(ctx.Config.Brew.Folder, ctx.Config.ProjectName+"".rb"")
@@ -145,8 +142,7 @@ func doBuildFormula(data templateData) (out bytes.Buffer, err error) {
 }
 
 func dataFor(ctx *context.Context, client client.Client, artifact artifact.Artifact) (result templateData, err error) {
-	var file = artifact.Path
-	sum, err := checksum.SHA256(file)
+	sum, err := checksum.SHA256(artifact.Path)
 	if err != nil {
 		return
 	}
@@ -163,7 +159,7 @@ func dataFor(ctx *context.Context, client client.Client, artifact artifact.Artif
 		Tag:          ctx.Git.CurrentTag,
 		Version:      ctx.Version,
 		Caveats:      ctx.Config.Brew.Caveats,
-		File:         file,
+		File:         artifact.Name,
 		SHA256:       sum,
 		Dependencies: ctx.Config.Brew.Dependencies,
 		Conflicts:    ctx.Config.Brew.Conflicts,
diff --git a/pipeline/brew/brew_test.go b/pipeline/brew/brew_test.go
index 7e513bf..9066935 100644
--- a/pipeline/brew/brew_test.go
+++ b/pipeline/brew/brew_test.go
@@ -9,6 +9,7 @@ import (
 
 	""github.com/goreleaser/goreleaser/config""
 	""github.com/goreleaser/goreleaser/context""
+	""github.com/goreleaser/goreleaser/internal/artifact""
 	""github.com/goreleaser/goreleaser/internal/testlib""
 	""github.com/stretchr/testify/assert""
 )
@@ -93,7 +94,8 @@ func TestRunPipe(t *testing.T) {
 		Git: context.GitInfo{
 			CurrentTag: ""v1.0.1"",
 		},
-		Version: ""1.0.1"",
+		Version:   ""1.0.1"",
+		Artifacts: artifact.New(),
 		Config: config.Project{
 			Dist:        folder,
 			ProjectName: ""run-pipe"",
@@ -124,31 +126,53 @@ func TestRunPipe(t *testing.T) {
 		Publish: true,
 	}
 	var path = filepath.Join(folder, ""bin.tar.gz"")
-	ctx.AddBinary(""darwinamd64"", ""bin"", ""bin"", path)
+	ctx.Artifacts.Add(artifact.Artifact{
+		Name:   ""bin.tar.gz"",
+		Path:   path,
+		Goos:   ""darwin"",
+		Goarch: ""amd64"",
+		Type:   artifact.UploadableArchive,
+	})
 	client := &DummyClient{}
 	assert.Error(t, doRun(ctx, client))
 	assert.False(t, client.CreatedFile)
 
 	_, err = os.Create(path)
 	assert.NoError(t, err)
-	assert.NoError(t, doRun(ctx, client))
-	assert.True(t, client.CreatedFile)
 
-	bts, err := ioutil.ReadFile(""testdata/run_pipe.rb"")
-	assert.NoError(t, err)
-	// ioutil.WriteFile(""testdata/run_pipe.rb"", []byte(client.Content), 0644)
+	t.Run(""default git url"", func(tt *testing.T) {
+		assert.NoError(tt, doRun(ctx, client))
+		assert.True(tt, client.CreatedFile)
+
+		bts, err := ioutil.ReadFile(""testdata/run_pipe.rb"")
+		assert.NoError(tt, err)
+		// TODO: make writing this file toggleable somehow?
+		// ioutil.WriteFile(""testdata/run_pipe.rb"", []byte(client.Content), 0644)
+		assert.Equal(tt, string(bts), client.Content)
+	})
 
-	assert.Equal(t, string(bts), client.Content)
+	t.Run(""github enterprise url"", func(tt *testing.T) {
+		ctx.Config.GitHubURLs.Download = ""http://github.example.org""
+		assert.NoError(tt, doRun(ctx, client))
+		assert.True(tt, client.CreatedFile)
+
+		bts, err := ioutil.ReadFile(""testdata/run_pipe_enterprise.rb"")
+		assert.NoError(tt, err)
+		// TODO: make writing this file toggleable somehow?
+		// ioutil.WriteFile(""testdata/run_pipe_enterprise.rb"", []byte(client.Content), 0644)
+		assert.Equal(tt, string(bts), client.Content)
+	})
 }
 
+// TODO: this test is irrelevant and can probavly be removed
 func TestRunPipeFormatOverride(t *testing.T) {
 	folder, err := ioutil.TempDir("""", ""goreleasertest"")
 	assert.NoError(t, err)
 	var path = filepath.Join(folder, ""bin.zip"")
 	_, err = os.Create(path)
 	assert.NoError(t, err)
-	var ctx = &context.Context{
-		Config: config.Project{
+	var ctx = context.New(
+		config.Project{
 			Dist: folder,
 			Archive: config.Archive{
 				Format: ""tar.gz"",
@@ -166,9 +190,15 @@ func TestRunPipeFormatOverride(t *testing.T) {
 				},
 			},
 		},
-		Publish: true,
-	}
-	ctx.AddBinary(""darwinamd64"", ""bin"", ""bin"", path)
+	)
+	ctx.Publish = true
+	ctx.Artifacts.Add(artifact.Artifact{
+		Name:   ""bin.zip"",
+		Path:   path,
+		Goos:   ""darwin"",
+		Goarch: ""amd64"",
+		Type:   artifact.UploadableArchive,
+	})
 	client := &DummyClient{}
 	assert.NoError(t, doRun(ctx, client))
 	assert.True(t, client.CreatedFile)
@@ -195,6 +225,40 @@ func TestRunPipeNoDarwin64Build(t *testing.T) {
 	assert.False(t, client.CreatedFile)
 }
 
+func TestRunPipeMultipleDarwin64Build(t *testing.T) {
+	var ctx = context.New(
+		config.Project{
+			Archive: config.Archive{
+				Format: ""tar.gz"",
+			},
+			Brew: config.Homebrew{
+				GitHub: config.Repo{
+					Owner: ""test"",
+					Name:  ""test"",
+				},
+			},
+		},
+	)
+	ctx.Publish = true
+	ctx.Artifacts.Add(artifact.Artifact{
+		Name:   ""bin1"",
+		Path:   ""doesnt mather"",
+		Goos:   ""darwin"",
+		Goarch: ""amd64"",
+		Type:   artifact.UploadableArchive,
+	})
+	ctx.Artifacts.Add(artifact.Artifact{
+		Name:   ""bin2"",
+		Path:   ""doesnt mather"",
+		Goos:   ""darwin"",
+		Goarch: ""amd64"",
+		Type:   artifact.UploadableArchive,
+	})
+	client := &DummyClient{}
+	assert.Equal(t, ErrTooManyDarwin64Builds, doRun(ctx, client))
+	assert.False(t, client.CreatedFile)
+}
+
 func TestRunPipeBrewNotSetup(t *testing.T) {
 	var ctx = &context.Context{
 		Config:  config.Project{},
@@ -206,9 +270,8 @@ func TestRunPipeBrewNotSetup(t *testing.T) {
 }
 
 func TestRunPipeBinaryRelease(t *testing.T) {
-	var ctx = &context.Context{
-		Publish: true,
-		Config: config.Project{
+	var ctx = context.New(
+		config.Project{
 			Archive: config.Archive{
 				Format: ""binary"",
 			},
@@ -219,8 +282,15 @@ func TestRunPipeBinaryRelease(t *testing.T) {
 				},
 			},
 		},
-	}
-	ctx.AddBinary(""darwinamd64"", ""foo"", ""bar"", ""baz"")
+	)
+	ctx.Publish = true
+	ctx.Artifacts.Add(artifact.Artifact{
+		Name:   ""bin"",
+		Path:   ""doesnt mather"",
+		Goos:   ""darwin"",
+		Goarch: ""amd64"",
+		Type:   artifact.Binary,
+	})
 	client := &DummyClient{}
 	testlib.AssertSkipped(t, doRun(ctx, client))
 	assert.False(t, client.CreatedFile)
diff --git a/pipeline/brew/doc.go b/pipeline/brew/doc.go
new file mode 100644
index 0000000..2cddc12
--- /dev/null
+++ b/pipeline/brew/doc.go
@@ -0,0 +1,3 @@
+// Package brew implements the Pipe, providing formula generation and
+// uploading it to a configured repo.
+package brew
diff --git a/pipeline/brew/testdata/run_pipe_enterprise.rb b/pipeline/brew/testdata/run_pipe_enterprise.rb
new file mode 100644
index 0000000..4b24ce0
--- /dev/null
+++ b/pipeline/brew/testdata/run_pipe_enterprise.rb
@@ -0,0 +1,33 @@
+class RunPipe < Formula
+  desc ""A run pipe test formula""
+  homepage ""https://github.com/goreleaser""
+  url ""http://github.example.org/test/test/releases/download/v1.0.1/bin.tar.gz""
+  version ""1.0.1""
+  sha256 ""e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855""
+  
+  depends_on ""zsh""
+  depends_on ""bash""
+  
+  conflicts_with ""gtk+""
+  conflicts_with ""qt""
+
+  def install
+    bin.install ""foo""
+  end
+
+  def caveats
+    ""don't do this""
+  end
+
+  plist_options :startup => false
+
+  def plist; <<-EOS.undent
+    <xml>whatever</xml>
+    EOS
+  end
+
+  test do
+    system ""true""
+    system ""#{bin}/foo -h""
+  end
+end

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 
",3,"[""f433bcb59c36571e22d4e86c612e0a6a52f73c09"", ""c323d59c607cabc91f17a78528d998f376f30b10"", ""12257ce53f94dc902df4ba087de90f52d2840ad4""]","[""feat"", ""build"", ""docs""]","1. The changes include: (a) updates to Go source and test files in 'pipeline/brew', (b) addition of a Go package documentation file, (c) addition of a testdata file for Homebrew formula, (d) a modification to the build script 'scripts/build.mjs', and (e) an update to documentation in 'docs/getting-started/1201-ci-environment.md' adding a GitLab CI example.
2. The Go source and test changes in 'brew.go' and 'brew_test.go' add new test coverage (e.g., multiple darwin builds, GitHub Enterprise URL handling), which is a new capability, aligning with 'feat'; the build script change in 'build.mjs' adjusts the build step order, which is a build system modification, aligning with 'build'; the addition of 'doc.go' and documentation update in '1201-ci-environment.md' are documentation changes, aligning with 'docs'.
3. 'feat' is appropriate for the Go code/test changes because they introduce new test scenarios and support for additional use cases, not just bug fixes or refactoring; 'build' is correct for the build script adjustment because it only affects build process order, not CI or feature logic; 'docs' is correct for the documentation file additions and changes, as they are strictly documentation without affecting code logic or behavior.
4. The assigned labels 'feat', 'build', and 'docs' accurately reflect the introduction of new features/tests, build process improvements, and documentation enhancements present in this commit."
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.
update build","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/bootstrap/scripts/publish-patch.sh b/bootstrap/scripts/publish-patch.sh
index a1b6f12..0d849a5 100755
--- a/bootstrap/scripts/publish-patch.sh
+++ b/bootstrap/scripts/publish-patch.sh
@@ -5,4 +5,4 @@ lerna version patch
 lerna publish from-package -y
 git push
 
-./pack_and_install.sh
\ No newline at end of file
+./bootstrap/scripts/pack_and_install.sh
\ No newline at end of file
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""3fcfb20b0feb371b357edc42fcb7c87085c9b82a""]","[""fix"", ""build""]","1. The first change modifies a conditional in Configuration.ts to set a default value for 'cache.enabled' if it is not present, fixing CLI cache command failures; the second change updates a script path in a build-related shell script.
2. The Configuration.ts change resolves a bug where cache commands fail without explicit configuration, matching the 'fix' label, while the shell script change is related to build tooling, aligning with the 'build' label.
3. 'fix' is appropriate for correcting the code logic that caused cache command failures (not 'feat' or 'refactor'), and 'build' is correct for modifying a build script (not 'cicd', as it's not a CI config, or 'test', as it's not test logic).
4. The assigned labels 'fix' and 'build' are justified because the commit both resolves a software bug and updates a build-related script, matching the definitions and classification rules."
"remove unnecessary lines from verify-wal test
deploy dmn using java client

This test is an acceptance test that verifies that the java client can
deploy a dmn decision model using the newDeployCommand client method.

It verifies that the model was resource was parsed and deployed,
resulting in a response that contains metadata of the deployed decision
requirements graph and the decisions it contains.
change notice from 'danger' > 'info'

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/storage/wal/verifier_test.go b/storage/wal/verifier_test.go
index 61e1536..a44755f 100644
--- a/storage/wal/verifier_test.go
+++ b/storage/wal/verifier_test.go
@@ -138,22 +138,13 @@ func writeCorruptEntries(file *os.File, t *testing.T, n int) {
 		}
 	}
 
-
 	// Write some random bytes to the file to simulate corruption.
 	if _, err := file.Write(corruption); err != nil {
 		fatal(t, ""corrupt WAL segment"", err)
 	}
-	corrupt := []byte{1, 255, 0, 3, 45, 26, 110}
-
-	wrote, err := file.Write(corrupt)
-	if err != nil {
-		t.Fatal(err)
-	} else if wrote != len(corrupt) {
-		t.Fatal(""Error writing corrupt data to file"")
-	}
 
 	if err := file.Close(); err != nil {
-		t.Fatalf(""Error: filed to close file: %v\n"", err)
+		t.Fatalf(""Error: failed to close file: %v\n"", err)
 	}
 }
 

diff --git a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
index f36465b..6b6ab48 100644
--- a/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
+++ b/qa/integration-tests/src/test/java/io/camunda/zeebe/it/client/command/CreateDeploymentTest.java
@@ -67,6 +67,49 @@ public final class CreateDeploymentTest {
   }
 
   @Test
+  public void shouldDeployDecisionModel() {
+    // given
+    final String resourceName = ""dmn/drg-force-user.dmn"";
+
+    // when
+    final DeploymentEvent result =
+        CLIENT_RULE
+            .getClient()
+            .newDeployCommand()
+            .addResourceFromClasspath(resourceName)
+            .send()
+            .join();
+
+    // then
+    assertThat(result.getKey()).isPositive();
+    assertThat(result.getDecisionRequirements()).hasSize(1);
+    assertThat(result.getDecisions()).hasSize(2);
+
+    final var decisionRequirements = result.getDecisionRequirements().get(0);
+    assertThat(decisionRequirements.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decisionRequirements.getDmnDecisionRequirementsName()).isEqualTo(""Force Users"");
+    assertThat(decisionRequirements.getVersion()).isEqualTo(1);
+    assertThat(decisionRequirements.getDecisionRequirementsKey()).isPositive();
+    assertThat(decisionRequirements.getResourceName()).isEqualTo(resourceName);
+
+    final var decision1 = result.getDecisions().get(0);
+    assertThat(decision1.getDmnDecisionId()).isEqualTo(""jedi_or_sith"");
+    assertThat(decision1.getDmnDecisionName()).isEqualTo(""Jedi or Sith"");
+    assertThat(decision1.getVersion()).isEqualTo(1);
+    assertThat(decision1.getDecisionKey()).isPositive();
+    assertThat(decision1.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision1.getDecisionRequirementsKey()).isPositive();
+
+    final var decision2 = result.getDecisions().get(1);
+    assertThat(decision2.getDmnDecisionId()).isEqualTo(""force_user"");
+    assertThat(decision2.getDmnDecisionName()).isEqualTo(""Which force user?"");
+    assertThat(decision2.getVersion()).isEqualTo(1);
+    assertThat(decision2.getDecisionKey()).isPositive();
+    assertThat(decision2.getDmnDecisionRequirementsId()).isEqualTo(""force_users"");
+    assertThat(decision2.getDecisionRequirementsKey()).isPositive();
+  }
+
+  @Test
   public void shouldRejectDeployIfProcessIsInvalid() {
     // given
     final BpmnModelInstance process =
diff --git a/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
new file mode 100644
index 0000000..8d55c55
--- /dev/null
+++ b/qa/integration-tests/src/test/resources/dmn/drg-force-user.dmn
@@ -0,0 +1,144 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<definitions xmlns=""https://www.omg.org/spec/DMN/20191111/MODEL/"" xmlns:dmndi=""https://www.omg.org/spec/DMN/20191111/DMNDI/"" xmlns:dc=""http://www.omg.org/spec/DMN/20180521/DC/"" xmlns:biodi=""http://bpmn.io/schema/dmn/biodi/2.0"" xmlns:di=""http://www.omg.org/spec/DMN/20180521/DI/"" id=""force_users"" name=""Force Users""  namespace=""http://camunda.org/schema/1.0/dmn"" exporter=""Camunda Modeler"" exporterVersion=""4.12.0"">
+  <decision id=""jedi_or_sith"" name=""Jedi or Sith"">
+    <decisionTable id=""DecisionTable_14n3bxx"">
+      <input id=""Input_1"" label=""Lightsaber color"" biodi:width=""192"">
+        <inputExpression id=""InputExpression_1"" typeRef=""string"">
+          <text>lightsaberColor</text>
+        </inputExpression>
+      </input>
+      <output id=""Output_1"" label=""Jedi or Sith"" name=""jedi_or_sith"" typeRef=""string"" biodi:width=""192"">
+        <outputValues id=""UnaryTests_0hj346a"">
+          <text>""Jedi"",""Sith""</text>
+        </outputValues>
+      </output>
+      <rule id=""DecisionRule_0zumznl"">
+        <inputEntry id=""UnaryTests_0leuxqi"">
+          <text>""blue""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0c9vpz8"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1utwb1e"">
+        <inputEntry id=""UnaryTests_1v3sd4m"">
+          <text>""green""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0tgh8k1"">
+          <text>""Jedi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1bwgcym"">
+        <inputEntry id=""UnaryTests_0n1ewm3"">
+          <text>""red""</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_19xnlkw"">
+          <text>""Sith""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <decision id=""force_user"" name=""Which force user?"">
+    <informationRequirement id=""InformationRequirement_1o8esai"">
+      <requiredDecision href=""#jedi_or_sith"" />
+    </informationRequirement>
+    <decisionTable id=""DecisionTable_07g94t1"" hitPolicy=""FIRST"">
+      <input id=""InputClause_0qnqj25"" label=""Jedi or Sith"">
+        <inputExpression id=""LiteralExpression_00lcyt5"" typeRef=""string"">
+          <text>jedi_or_sith</text>
+        </inputExpression>
+        <inputValues id=""UnaryTests_1xjidd8"">
+          <text>""Jedi"",""Sith""</text>
+        </inputValues>
+      </input>
+      <input id=""InputClause_0k64hys"" label=""Body height"">
+        <inputExpression id=""LiteralExpression_0ib6fnk"" typeRef=""number"">
+          <text>height</text>
+        </inputExpression>
+      </input>
+      <output id=""OutputClause_0hhe1yo"" label=""Force user"" name=""force_user"" typeRef=""string"" />
+      <rule id=""DecisionRule_13zidc5"">
+        <inputEntry id=""UnaryTests_056skcq"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0l4xksq"">
+          <text>&gt; 190</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0hclhw3"">
+          <text>""Mace Windu""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0uin2hk"">
+        <description></description>
+        <inputEntry id=""UnaryTests_16maepk"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0rv0nwf"">
+          <text>&gt; 180</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0t82c11"">
+          <text>""Obi-Wan Kenobi""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_0mpio0p"">
+        <inputEntry id=""UnaryTests_09eicyc"">
+          <text>""Jedi""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1bekl8k"">
+          <text>&lt; 70</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_0brx3vt"">
+          <text>""Yoda""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_06paffx"">
+        <inputEntry id=""UnaryTests_1baiid4"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_0fcdq0i"">
+          <text>&gt; 200</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_02oibi4"">
+          <text>""Darth Vader""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_1ua4pcl"">
+        <inputEntry id=""UnaryTests_1s1h3nm"">
+          <text>""Sith""</text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1pnvw8p"">
+          <text>&gt; 170</text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_1w1n2rc"">
+          <text>""Darth Sidius""</text>
+        </outputEntry>
+      </rule>
+      <rule id=""DecisionRule_00ew25e"">
+        <inputEntry id=""UnaryTests_07uxyug"">
+          <text></text>
+        </inputEntry>
+        <inputEntry id=""UnaryTests_1he6fym"">
+          <text></text>
+        </inputEntry>
+        <outputEntry id=""LiteralExpression_07i3sc8"">
+          <text>""unknown""</text>
+        </outputEntry>
+      </rule>
+    </decisionTable>
+  </decision>
+  <dmndi:DMNDI>
+    <dmndi:DMNDiagram>
+      <dmndi:DMNShape dmnElementRef=""jedi_or_sith"">
+        <dc:Bounds height=""80"" width=""180"" x=""160"" y=""280"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNShape id=""DMNShape_1sb3tre"" dmnElementRef=""force_user"">
+        <dc:Bounds height=""80"" width=""180"" x=""280"" y=""80"" />
+      </dmndi:DMNShape>
+      <dmndi:DMNEdge id=""DMNEdge_0gt1p1u"" dmnElementRef=""InformationRequirement_1o8esai"">
+        <di:waypoint x=""250"" y=""280"" />
+        <di:waypoint x=""370"" y=""180"" />
+        <di:waypoint x=""370"" y=""160"" />
+      </dmndi:DMNEdge>
+    </dmndi:DMNDiagram>
+  </dmndi:DMNDI>
+</definitions>

diff --git a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
index 17a1d85..b8c3f52 100644
--- a/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
+++ b/packages/noco-docs/docs/030.workspaces/040.actions-on-workspace.md
@@ -20,7 +20,7 @@ To update the workspace name:
 ## Delete workspace
 If you determine that a workspace is no longer necessary, you have the option to permanently remove it from your settings. Deleting a workspace will delete all the bases and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/040.bases/070.actions-on-base.md b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
index b8e5723..7207971 100644
--- a/packages/noco-docs/docs/040.bases/070.actions-on-base.md
+++ b/packages/noco-docs/docs/040.bases/070.actions-on-base.md
@@ -69,7 +69,7 @@ To duplicate a base, you can follow these straightforward steps:
 
 If you determine that a base is no longer necessary, you have the option to permanently remove it from your workspace. Deleting a base will delete all the tables and data associated with it.
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/050.tables/060.actions-on-table.md b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
index 3cf03d3..8ae9ade 100644
--- a/packages/noco-docs/docs/050.tables/060.actions-on-table.md
+++ b/packages/noco-docs/docs/050.tables/060.actions-on-table.md
@@ -46,7 +46,7 @@ A new table will be generated, mirroring the original table's schema and content
 
 ## Delete table
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/070.fields/060.actions-on-field.md b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
index 600c6fd..fe2cfa8 100644
--- a/packages/noco-docs/docs/070.fields/060.actions-on-field.md
+++ b/packages/noco-docs/docs/070.fields/060.actions-on-field.md
@@ -83,7 +83,7 @@ New field will be created to the right of the original field.
 New field will be created to the left of the original field.
 
 ### Delete field
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
diff --git a/packages/noco-docs/docs/080.records/070.actions-on-record.md b/packages/noco-docs/docs/080.records/070.actions-on-record.md
index a9245ff..6d4774a 100644
--- a/packages/noco-docs/docs/080.records/070.actions-on-record.md
+++ b/packages/noco-docs/docs/080.records/070.actions-on-record.md
@@ -54,8 +54,8 @@ On the bulk update modal,
 5. Click on the `Bulk Update all` button
 6. A confirmation dialog will be displayed. Click on `Confirm` to update the records.
 
-:::danger
-This operation cannot be undone.
+:::info
+**This action cannot be undone.**
 :::
 
 ![Bulk Update](/img/v2/records/bulk-update-1.png)
diff --git a/packages/noco-docs/docs/090.views/090.actions-on-view.md b/packages/noco-docs/docs/090.views/090.actions-on-view.md
index c6c6ab2..7d23959 100644
--- a/packages/noco-docs/docs/090.views/090.actions-on-view.md
+++ b/packages/noco-docs/docs/090.views/090.actions-on-view.md
@@ -41,7 +41,7 @@ The view context menu provides a set of tools to interact with the view. The vie
 
 ## Delete view
 
-:::danger
+:::info
 **This action cannot be undone.**
 :::
 
",3,"[""fba4326c72fc22d81aba6976a9fef1e4b6154fd9"", ""73eac947689e3fc6b53bf626a6b4604056166d6e"", ""2ba752d45350a676babe553dd68f019af81b512b""]","[""refactor"", ""test"", ""docs""]","1. The commit removes redundant lines and fixes a typo in a Go test file (`verifier_test.go`), adds a new Java integration test and its DMN resource, and updates Markdown documentation files to change the notice style from 'danger' to 'info'.
2. The Go test file changes remove unnecessary code and fix a typo, aligning with 'refactor' for structural improvement without behavioral change; the addition of a new Java test and DMN resource is fully dedicated to testing, aligning with 'test'; the Markdown changes update documentation formatting, aligning with 'docs'.
3. 'refactor' is appropriate for the Go test file because the changes improve code quality without altering test intent or behavior (not 'fix' as no bug is resolved, not 'test' as it's not adding new tests); 'test' is correct for the Java test and DMN file as they introduce new test logic and resources (not 'feat' or 'fix' since they're not production code); 'docs' fits the Markdown changes as they only affect documentation appearance (not 'refactor' or 'fix' as there's no code or bug involved).
4. The labels 'refactor', 'test', and 'docs' are appropriate as each code unit is dedicated to code structure improvement, test addition, or documentation modification, respectively."
"remove unnecessary import
add getting started gitlab ci configuration

Signed-off-by: Adrien Brault <adrien.brault@gmail.com>","diff --git a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
index 14c6f30..ebaef60 100644
--- a/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
+++ b/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/LogicalId.java
@@ -8,7 +8,6 @@
 package io.camunda.zeebe.transport.stream.impl;
 
 import io.camunda.zeebe.util.buffer.BufferUtil;
-import org.agrona.BitUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 
 /**

diff --git a/docs/getting-started/1201-ci-environment.md b/docs/getting-started/1201-ci-environment.md
index 6c72b15..2313e30 100644
--- a/docs/getting-started/1201-ci-environment.md
+++ b/docs/getting-started/1201-ci-environment.md
@@ -46,7 +46,60 @@ If you would like us to document CircleCI next, vote for it here: [dagger#1677](
 
 <TabItem value=""gitlab"">
 
-If you would like us to document GitLab next, vote for it here: [dagger#1677](https://github.com/dagger/dagger/discussions/1677)
+```yaml
+.docker:
+    image: docker:${DOCKER_VERSION}-git
+    services:
+        - docker:${DOCKER_VERSION}-dind
+    variables:
+        # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#docker-in-docker-with-tls-enabled-in-the-docker-executor
+        DOCKER_HOST: tcp://docker:2376
+
+        DOCKER_TLS_VERIFY: '1'
+        DOCKER_TLS_CERTDIR: '/certs'
+        DOCKER_CERT_PATH: '/certs/client'
+
+        # Faster than the default, apparently
+        DOCKER_DRIVER: overlay2
+
+        DOCKER_VERSION: '20.10'
+
+.dagger:
+    extends: [.docker]
+    variables:
+        DAGGER_VERSION: 0.2.4
+        DAGGER_LOG_FORMAT: plain
+        DAGGER_CACHE_PATH: .dagger-cache
+
+        ARGS: ''
+    cache:
+        key: dagger-${CI_JOB_NAME}
+        paths:
+            - ${DAGGER_CACHE_PATH}
+    before_script:
+        - apk add --no-cache curl
+        - |
+            # install dagger
+            cd /usr/local
+            curl -L https://dl.dagger.io/dagger/install.sh | sh
+            cd -
+
+            dagger version
+    script:
+        - dagger project update
+        - |
+            dagger \
+                do \
+                --cache-from type=local,src=${DAGGER_CACHE_PATH} \
+                --cache-to type=local,mode=max,dest=${DAGGER_CACHE_PATH} \
+                ${ARGS}
+
+build:
+    extends: [.dagger]
+    variables:
+        ARGS: build
+
+```
 
 </TabItem>
 
",2,"[""84529bcb10c6fe02e2c0079d069ab6c6ac7683d6"", ""12257ce53f94dc902df4ba087de90f52d2840ad4""]","[""refactor"", ""docs""]","1. The first change removes an unused import from a Java source file, and the second change adds a GitLab CI configuration example to a documentation markdown file.
2. Removing the import is a structural code improvement that does not affect behavior, aligning with the 'refactor' label; adding a CI configuration example to a markdown file is a documentation update, aligning with the 'docs' label.
3. 'refactor' is more appropriate than 'fix' or 'feat' for the code change because it only cleans up code without changing behavior; 'docs' is correct for the markdown update because it modifies documentation, not code, tests, or CI scripts themselves.
4. The assigned 'refactor' and 'docs' labels are appropriate because one change improves code structure without altering behavior, and the other enhances documentation by providing new instructional content."
"extract _value expr from predicate
create mock img server
remove unnecessary spotless definition

It receives this already from the parent pom.","diff --git a/predicate/src/delete_predicate.rs b/predicate/src/delete_predicate.rs
index 02e679a..6368df3 100644
--- a/predicate/src/delete_predicate.rs
+++ b/predicate/src/delete_predicate.rs
@@ -120,6 +120,7 @@ impl From<DeletePredicate> for crate::predicate::Predicate {
             partition_key: None,
             range: Some(pred.range),
             exprs: pred.exprs.into_iter().map(|expr| expr.into()).collect(),
+            value_expr: vec![],
         }
     }
 }
diff --git a/predicate/src/predicate.rs b/predicate/src/predicate.rs
index d7f3b62..2aa8fdf 100644
--- a/predicate/src/predicate.rs
+++ b/predicate/src/predicate.rs
@@ -11,7 +11,7 @@ use std::{
 use data_types::timestamp::TimestampRange;
 use datafusion::{
     error::DataFusionError,
-    logical_plan::{col, lit_timestamp_nano, Expr, Operator},
+    logical_plan::{col, lit_timestamp_nano, Column, Expr, Operator},
     optimizer::utils,
 };
 use datafusion_util::{make_range_expr, AndExprBuilder};
@@ -26,6 +26,7 @@ pub const EMPTY_PREDICATE: Predicate = Predicate {
     exprs: vec![],
     range: None,
     partition_key: None,
+    value_expr: vec![],
 };
 
 #[derive(Debug, Clone, Copy)]
@@ -72,6 +73,11 @@ pub struct Predicate {
     /// these expressions should be returned. Other rows are excluded
     /// from the results.
     pub exprs: Vec<Expr>,
+
+    /// Optional arbitrary predicates on the special `_value` column. These
+    /// expressions are applied to `field_columns` projections in the form of
+    /// `CASE` statement conditions.
+    pub value_expr: Vec<BinaryExpr>,
 }
 
 impl Predicate {
@@ -469,6 +475,14 @@ impl PredicateBuilder {
     }
 }
 
+// A representation of the `BinaryExpr` variant of a Datafusion expression.
+#[derive(Clone, Debug, PartialEq, PartialOrd)]
+pub struct BinaryExpr {
+    pub left: Column,
+    pub op: Operator,
+    pub right: Expr,
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
diff --git a/query/src/frontend/influxrpc.rs b/query/src/frontend/influxrpc.rs
index 5ac7a2e..70c43f2 100644
--- a/query/src/frontend/influxrpc.rs
+++ b/query/src/frontend/influxrpc.rs
@@ -9,8 +9,7 @@ use data_types::chunk_metadata::ChunkId;
 use datafusion::{
     error::{DataFusionError, Result as DatafusionResult},
     logical_plan::{
-        binary_expr, lit, Column, DFSchemaRef, Expr, ExprRewriter, LogicalPlan, LogicalPlanBuilder,
-        Operator,
+        lit, Column, DFSchemaRef, Expr, ExprRewriter, LogicalPlan, LogicalPlanBuilder, Operator,
     },
     optimizer::utils::expr_to_columns,
     prelude::col,
@@ -20,7 +19,7 @@ use datafusion_util::AsExpr;
 
 use hashbrown::{HashMap, HashSet};
 use observability_deps::tracing::{debug, trace};
-use predicate::predicate::{Predicate, PredicateMatch};
+use predicate::predicate::{BinaryExpr, Predicate, PredicateMatch};
 use schema::selection::Selection;
 use schema::{InfluxColumnType, Schema, TIME_COLUMN_NAME};
 use snafu::{ensure, OptionExt, ResultExt, Snafu};
@@ -243,7 +242,6 @@ impl InfluxRpcPlanner {
         // and which chunks needs full plan and group them into their table
         for chunk in database.chunks(normalizer.unnormalized()) {
             let table_name = chunk.table_name();
-            let schema = chunk.schema();
 
             // Table is already in the returned table list, no longer needs to discover it from other chunks
             if builder.contains_meta_data_table(table_name.to_string()) {
@@ -260,7 +258,7 @@ impl InfluxRpcPlanner {
             } else {
                 // See if we can have enough info from the chunk's meta data to answer
                 // that this table participates in the request
-                let predicate = normalizer.normalized(table_name, schema);
+                let predicate = normalizer.normalized(table_name);
                 //
                 // Try and apply the predicate using only metadata
                 let pred_result = chunk
@@ -346,7 +344,7 @@ impl InfluxRpcPlanner {
             let mut do_full_plan = chunk.has_delete_predicates();
 
             let table_name = chunk.table_name();
-            let predicate = normalizer.normalized(table_name, chunk.schema());
+            let predicate = normalizer.normalized(table_name);
 
             // Try and apply the predicate using only metadata
             let pred_result = chunk
@@ -474,7 +472,7 @@ impl InfluxRpcPlanner {
             let mut do_full_plan = chunk.has_delete_predicates();
 
             let table_name = chunk.table_name();
-            let predicate = normalizer.normalized(table_name, chunk.schema());
+            let predicate = normalizer.normalized(table_name);
 
             // Try and apply the predicate using only metadata
             let pred_result = chunk
@@ -821,7 +819,7 @@ impl InfluxRpcPlanner {
     {
         let mut table_chunks = BTreeMap::new();
         for chunk in chunks {
-            let predicate = normalizer.normalized(chunk.table_name(), chunk.schema());
+            let predicate = normalizer.normalized(chunk.table_name());
             // Try and apply the predicate using only metadata
             let pred_result = chunk
                 .apply_predicate_to_metadata(&predicate)
@@ -1040,9 +1038,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.as_ref();
-        let scan_and_filter =
-            self.scan_and_filter(table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(table_name, schema);
+        let scan_and_filter = self.scan_and_filter(table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1152,9 +1149,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.into();
-        let scan_and_filter =
-            self.scan_and_filter(&table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(&table_name, schema);
+        let scan_and_filter = self.scan_and_filter(&table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(&table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1263,9 +1259,8 @@ impl InfluxRpcPlanner {
         C: QueryChunk + 'static,
     {
         let table_name = table_name.into();
-        let scan_and_filter =
-            self.scan_and_filter(&table_name, Arc::clone(&schema), normalizer, chunks)?;
-        let predicate = normalizer.normalized(&table_name, schema);
+        let scan_and_filter = self.scan_and_filter(&table_name, schema, normalizer, chunks)?;
+        let predicate = normalizer.normalized(&table_name);
 
         let TableScanAndFilter {
             plan_builder,
@@ -1342,7 +1337,7 @@ impl InfluxRpcPlanner {
     where
         C: QueryChunk + 'static,
     {
-        let predicate = normalizer.normalized(table_name, Arc::clone(&schema));
+        let predicate = normalizer.normalized(table_name);
 
         // Scan all columns to begin with (DataFusion projection
         // push-down optimization will prune out unneeded columns later)
@@ -1701,13 +1696,13 @@ impl PredicateNormalizer {
 
     /// Return a reference to a predicate specialized for `table_name` based on
     /// its `schema`.
-    fn normalized(&mut self, table_name: &str, schema: Arc<Schema>) -> Arc<Predicate> {
+    fn normalized(&mut self, table_name: &str) -> Arc<Predicate> {
         if let Some(normalized_predicate) = self.normalized.get(table_name) {
             return normalized_predicate.inner();
         }
 
         let normalized_predicate =
-            TableNormalizedPredicate::new(table_name, schema, self.unnormalized.clone());
+            TableNormalizedPredicate::new(table_name, self.unnormalized.clone());
 
         self.normalized
             .entry(table_name.to_string())
@@ -1752,13 +1747,18 @@ struct TableNormalizedPredicate {
 }
 
 impl TableNormalizedPredicate {
-    fn new(table_name: &str, schema: Arc<Schema>, mut inner: Predicate) -> Self {
+    fn new(table_name: &str, mut inner: Predicate) -> Self {
         let mut field_projections = BTreeSet::new();
+        let mut field_value_exprs = vec![];
+
         inner.exprs = inner
             .exprs
             .into_iter()
             .map(|e| rewrite_measurement_references(table_name, e))
-            .map(|e| rewrite_field_value_references(Arc::clone(&schema), e))
+            // Rewrite any references to `_value = some_value` to literal true values.
+            // Keeps track of these expressions, which can then be used to
+            // augment field projections with conditions using `CASE` statements.
+            .map(|e| rewrite_field_value_references(&mut field_value_exprs, e))
             .map(|e| {
                 // Rewrite any references to `_field = a_field_name` with a literal true
                 // and keep track of referenced field names to add to the field
@@ -1766,6 +1766,8 @@ impl TableNormalizedPredicate {
                 rewrite_field_column_references(&mut field_projections, e)
             })
             .collect::<Vec<_>>();
+        // Store any field value (`_value`) expressions on the `Predicate`.
+        inner.value_expr = field_value_exprs;
 
         if !field_projections.is_empty() {
             match &mut inner.field_columns {
@@ -1811,23 +1813,19 @@ impl ExprRewriter for MeasurementRewriter<'_> {
     }
 }
 
-/// Rewrites a predicate on `_value` to a disjunctive set of expressions on each
-/// distinct field column in the table.
-///
-/// For example, the predicate `_value = 1.77` on a table with three field
-/// columns would be rewritten to:
-///
-/// `(field1 = 1.77 OR field2 = 1.77 OR field3 = 1.77)`.
-fn rewrite_field_value_references(schema: Arc<Schema>, expr: Expr) -> Expr {
-    let mut rewriter = FieldValueRewriter { schema };
+/// Rewrites an expression on `_value` as a boolean true literal, pushing any
+/// encountered expressions onto `value_exprs` so they can be moved onto column
+/// projections.
+fn rewrite_field_value_references(value_exprs: &mut Vec<BinaryExpr>, expr: Expr) -> Expr {
+    let mut rewriter = FieldValueRewriter { value_exprs };
     expr.rewrite(&mut rewriter).expect(""rewrite is infallible"")
 }
 
-struct FieldValueRewriter {
-    schema: Arc<Schema>,
+struct FieldValueRewriter<'a> {
+    value_exprs: &'a mut Vec<BinaryExpr>,
 }
 
-impl ExprRewriter for FieldValueRewriter {
+impl<'a> ExprRewriter for FieldValueRewriter<'a> {
     fn mutate(&mut self, expr: Expr) -> DatafusionResult<Expr> {
         Ok(match expr {
             Expr::BinaryExpr {
@@ -1836,21 +1834,16 @@ impl ExprRewriter for FieldValueRewriter {
                 ref right,
             } => {
                 if let Expr::Column(inner) = &**left {
-                    if inner.name != VALUE_COLUMN_NAME {
-                        return Ok(expr); // column name not `_value`.
+                    if inner.name == VALUE_COLUMN_NAME {
+                        self.value_exprs.push(BinaryExpr {
+                            left: inner.to_owned(),
+                            op,
+                            right: right.as_expr(),
+                        });
+                        return Ok(Expr::Literal(ScalarValue::Boolean(Some(true))));
                     }
-
-                    // build a disjunctive expression using binary expressions
-                    // for each field column and the original expression's
-                    // operator and rhs.
-                    self.schema
-                        .fields_iter()
-                        .map(|field| binary_expr(col(field.name()), op, *right.clone()))
-                        .reduce(|a, b| a.or(b))
-                        .expect(""at least one field column"")
-                } else {
-                    expr
                 }
+                expr
             }
             _ => expr,
         })
@@ -1918,7 +1911,7 @@ pub fn schema_has_all_expr_columns(schema: &Schema, expr: &Expr) -> bool {
 
 #[cfg(test)]
 mod tests {
-    use datafusion::logical_plan::Operator;
+    use datafusion::logical_plan::{binary_expr, Operator};
     use schema::builder::SchemaBuilder;
 
     use super::*;
@@ -1958,56 +1951,57 @@ mod tests {
 
     #[test]
     fn test_field_value_rewriter() {
-        let schema = SchemaBuilder::new()
-            .tag(""t1"")
-            .tag(""t2"")
-            .field(""f1"", DataType::Float64)
-            .field(""f2"", DataType::Float64)
-            .timestamp()
-            .build()
-            .unwrap();
-
         let mut rewriter = FieldValueRewriter {
-            schema: Arc::new(schema),
+            value_exprs: &mut vec![],
         };
 
         let cases = vec![
             (
                 binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
                 binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
+                vec![],
             ),
-            (col(""t2""), col(""t2"")),
+            (col(""t2""), col(""t2""), vec![]),
             (
                 binary_expr(col(VALUE_COLUMN_NAME), Operator::Eq, lit(1.82)),
-                //
-                // _value = 1.82 -> f1 = (1.82 OR f2 = 1.82)
-                //
-                binary_expr(
-                    binary_expr(col(""f1""), Operator::Eq, lit(1.82)),
-                    Operator::Or,
-                    binary_expr(col(""f2""), Operator::Eq, lit(1.82)),
-                ),
+                // _value = 1.82 -> true
+                lit(true),
+                vec![BinaryExpr {
+                    left: Column {
+                        relation: None,
+                        name: VALUE_COLUMN_NAME.into(),
+                    },
+                    op: Operator::Eq,
+                    right: lit(1.82),
+                }],
             ),
         ];
 
-        for (input, exp) in cases {
+        for (input, exp, mut value_exprs) in cases {
             let rewritten = input.rewrite(&mut rewriter).unwrap();
             assert_eq!(rewritten, exp);
+            assert_eq!(rewriter.value_exprs, &mut value_exprs);
         }
 
         // Test case with single field.
-        let schema = SchemaBuilder::new()
-            .field(""f1"", DataType::Float64)
-            .timestamp()
-            .build()
-            .unwrap();
         let mut rewriter = FieldValueRewriter {
-            schema: Arc::new(schema),
+            value_exprs: &mut vec![],
         };
 
         let input = binary_expr(col(VALUE_COLUMN_NAME), Operator::Gt, lit(1.88));
         let rewritten = input.rewrite(&mut rewriter).unwrap();
-        assert_eq!(rewritten, binary_expr(col(""f1""), Operator::Gt, lit(1.88)));
+        assert_eq!(rewritten, lit(true));
+        assert_eq!(
+            rewriter.value_exprs,
+            &mut vec![BinaryExpr {
+                left: Column {
+                    relation: None,
+                    name: VALUE_COLUMN_NAME.into(),
+                },
+                op: Operator::Gt,
+                right: lit(1.88),
+            }]
+        );
     }
 
     #[test]

diff --git a/scripts/gulp/tasks/test.ts b/scripts/gulp/tasks/test.ts
index 8014b12..d10c1aa 100644
--- a/scripts/gulp/tasks/test.ts
+++ b/scripts/gulp/tasks/test.ts
@@ -26,12 +26,18 @@ task('test.imageserver', () => {
   function handleRequest(req, res) {
     const urlParse = url.parse(req.url, true);
 
+    res.setHeader('Access-Control-Allow-Origin', '*');
+    res.setHeader('Access-Control-Allow-Methods', 'GET');
+    res.setHeader('Connection', 'keep-alive');
+    res.setHeader('Age', '0');
+    res.setHeader('cache-control', 'no-store');
+
     if (urlParse.pathname === '/reset') {
       console.log('Image Server Reset');
       console.log('---------------------------');
       requestedUrls.length = 0;
       start = Date.now();
-      res.setHeader('Access-Control-Allow-Origin', '*');
+      res.setHeader('Content-Type', 'text/plain');
       res.end('reset');
       return;
     }
@@ -48,9 +54,8 @@ task('test.imageserver', () => {
 
     setTimeout(() => {
       res.setHeader('Content-Type', 'image/svg+xml');
-      res.setHeader('Access-Control-Allow-Origin', '*');
       res.end(`<svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink""
-                   style=""background-color: ${color}; width: ${width}px; height: ${height}px;"">
+                   viewBox=""0 0 ${width} ${height}"" style=""background-color: ${color};"">
                  <text x=""5"" y=""22"" style=""font-family: Courier; font-size: 24px"">${id}</text>
                </svg>`);
     }, delay);

diff --git a/benchmarks/project/pom.xml b/benchmarks/project/pom.xml
index 62030b6..ab87dea 100644
--- a/benchmarks/project/pom.xml
+++ b/benchmarks/project/pom.xml
@@ -123,11 +123,6 @@
       </plugin>
 
       <plugin>
-        <groupId>com.diffplug.spotless</groupId>
-        <artifactId>spotless-maven-plugin</artifactId>
-      </plugin>
-
-      <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-shade-plugin</artifactId>
         <executions>
",3,"[""0cb9751b0a1bdd8d2c88b45d4366e760d6b1bbed"", ""32b76173a259ea1993298289b436cf10c1e800bf"", ""7f9721dc9bbf66a3712d59352f64ca089da139f0""]","[""refactor"", ""test"", ""build""]","1. The changes in Rust files (predicate and query modules) restructure how value expressions are handled in predicates, extracting logic into a new BinaryExpr structure and updating related code and tests accordingly; the TypeScript test script adds a mock image server for testing, and the Maven pom.xml removes a redundant spotless plugin definition. 
2. The Rust code changes do not alter external behavior but improve internal structure and clarity, aligning with 'refactor'; the new mock image server logic in the test script is dedicated to test infrastructure, aligning with 'test'; the pom.xml change is a build configuration cleanup, aligning with 'build'.
3. 'refactor' is appropriate for the Rust logic since the motivation is code structure improvement (not a bug fix or new feature); 'test' is correct for the dedicated test server logic, and not 'feat' or 'refactor' as it is not core behavior or structure change; 'build' fits the Maven config change, as it pertains only to build system configuration, not CI/CD or documentation.
4. The assigned labels 'refactor', 'test', and 'build' accurately reflect the motivations and artifacts of each code unit in the commit, following the classification instructions and label definitions."
"add LICENSE
remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file
repository creation","diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..005581d
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,21 @@
+MIT License
+
+Copyright (c) Hassan El Mghari
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the ""Software""), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",3,"[""096145f0d32a6b351b1db413b04a685952f04fb3"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""docs"", ""build"", ""fix""]","1. The commit adds a new LICENSE file, removes deprecated environment variables from Dockerfile and startup.sh, and modifies repository.service.ts to adjust the order and logic for repository and team creation.
2. Adding the LICENSE file is a documentation change (docs); removing deprecated settings from Dockerfile and startup.sh is a build system maintenance (build); updating repository.service.ts to fix repository creation logic aligns with bug fixing (fix).
3. 'docs' is appropriate for the LICENSE file, not 'build' or 'fix' since it only affects documentation; 'build' is correct for Dockerfile and shell script environment variable cleanup, not 'fix' since no bug is being directly resolved there; 'fix' is appropriate for repository.service.ts since it corrects the logic, not 'feat' (no new feature) or 'refactor' (behavior is changed).
4. The assigned labels 'docs', 'build', and 'fix' are correct because each code unit is fully dedicated to its respective artifact or purpose as defined by the instructions."
permission check,"diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));
",1,"[""33c25b2f59c931a7f4af994365522221a7821dca""]","[""fix""]","1. The change replaces a set of middleware validators with a different validator for a specific route in the course API, altering permission and input checking logic.
2. This aligns with the 'fix' label as it addresses a likely issue in permission or validation checks that could allow incorrect or unauthorized access.
3. The 'fix' label is appropriate because the change corrects a potential bug in route protection; it is not adding a new feature ('feat'), restructuring code without changing behavior ('refactor'), or solely updating documentation, tests, CI/CD, or build artifacts.
4. The 'fix' label is justified as the modification directly addresses and resolves a flaw in the route's permission or validation logic."
"temporary do no run ""verify-ffmpeg.py"" on Mac CI (#14986)
implement array flatten support","diff --git a/vsts.yml b/vsts.yml
index 6cb0eb3..a058238 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -86,13 +86,13 @@ jobs:
         killall Electron
       fi
     displayName: Make sure Electron isn't running from previous tests
-
-  - bash: |
-      cd src
-      python electron/script/verify-ffmpeg.py --source-root ""$PWD"" --build-dir out/Default --ffmpeg-path out/ffmpeg
-    displayName: Verify non proprietary ffmpeg
-    condition: and(succeeded(), eq(variables['RUN_TESTS'], '1'))
-    timeoutInMinutes: 5
+# FIXME(alexeykuzmin)
+#  - bash: |
+#      cd src
+#      python electron/script/verify-ffmpeg.py --source-root ""$PWD"" --build-dir out/Default --ffmpeg-path out/ffmpeg
+#    displayName: Verify non proprietary ffmpeg
+#    condition: and(succeeded(), eq(variables['RUN_TESTS'], '1'))
+#    timeoutInMinutes: 5
 
   - bash: |
       cd src

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),
",2,"[""9187415f5ee35d2e88dd834e413fc16bf19c5db1"", ""d3c754f09502be979e5dcc79f968b15052590bd0""]","[""cicd"", ""feat""]","1. The commit comments out a CI step in 'vsts.yml' to skip running 'verify-ffmpeg.py' on Mac, and adds support for array flatten operations in the Snowflake backend registry.
2. The CI step modification aligns with the 'cicd' label as it directly changes a CI configuration file, while the array flatten addition introduces new backend functionality, matching the 'feat' label.
3. 'cicd' is appropriate because the change is limited to a CI script, not build or test logic; 'feat' applies because the registry update adds a new operation, not a bug fix or refactor. No other labels fit as the changes are clearly scoped.
4. The 'cicd' label captures the CI script update, and the 'feat' label correctly marks the addition of new array flatten support in the backend."
"remove duplicated code
updates the readme to improve the readability and contributing sections","diff --git a/packages/core/src/components/action-sheet/action-sheet.tsx b/packages/core/src/components/action-sheet/action-sheet.tsx
index 7166508..dad7daf 100644
--- a/packages/core/src/components/action-sheet/action-sheet.tsx
+++ b/packages/core/src/components/action-sheet/action-sheet.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, isDef, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -23,15 +23,15 @@ import mdLeaveAnimation from './animations/md.leave';
 })
 export class ActionSheet implements OverlayInterface {
 
+  private presented = false;
+
   mode: string;
   color: string;
-
-  private presented = false;
-  private animation: Animation | null = null;
+  animation: Animation;
 
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -178,25 +178,8 @@ export class ActionSheet implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      // Check if prop animate is false or if the config for animate is defined/false
-      if (!this.willAnimate || (isDef(this.config.get('willAnimate')) && this.config.get('willAnimate') === false)) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        this.animation = animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   protected buttonClick(button: ActionSheetButton) {
diff --git a/packages/core/src/components/alert/alert.tsx b/packages/core/src/components/alert/alert.tsx
index 800b77b..bdf4fc5 100644
--- a/packages/core/src/components/alert/alert.tsx
+++ b/packages/core/src/components/alert/alert.tsx
@@ -1,8 +1,8 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync, autoFocus } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync, autoFocus } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,18 +21,19 @@ import mdLeaveAnimation from './animations/md.leave';
   }
 })
 export class Alert implements OverlayInterface {
-  mode: string;
-  color: string;
 
   private presented = false;
-  private animation: Animation | null = null;
   private activeId: string;
   private inputType: string | null = null;
   private hdrId: string;
 
+  animation: Animation;
+  mode: string;
+  color: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -264,25 +265,10 @@ export class Alert implements OverlayInterface {
     return values;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
-
   private renderCheckbox(inputs: AlertInput[]) {
     if (inputs.length === 0) return null;
 
diff --git a/packages/core/src/components/loading/loading.tsx b/packages/core/src/components/loading/loading.tsx
index f45eaf1..cc4f511 100644
--- a/packages/core/src/components/loading/loading.tsx
+++ b/packages/core/src/components/loading/loading.tsx
@@ -1,13 +1,13 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
 import mdEnterAnimation from './animations/md.enter';
 import mdLeaveAnimation from './animations/md.leave';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 @Component({
   tag: 'ion-loading',
@@ -21,16 +21,17 @@ import { OverlayInterface, BACKDROP } from '../../utils/overlays';
 })
 
 export class Loading implements OverlayInterface {
-  color: string;
-  mode: string;
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
 
+  animation: Animation;
+  color: string;
+  mode: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -199,24 +200,8 @@ export class Loading implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   hostData() {
diff --git a/packages/core/src/components/modal/modal.tsx b/packages/core/src/components/modal/modal.tsx
index af50d63..2b7510c 100644
--- a/packages/core/src/components/modal/modal.tsx
+++ b/packages/core/src/components/modal/modal.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -25,14 +25,16 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Modal implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
+
   @Prop() overlayId: number;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
 
@@ -208,22 +210,8 @@ export class Modal implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   @Method()
diff --git a/packages/core/src/components/picker/picker.tsx b/packages/core/src/components/picker/picker.tsx
index 13faa3e..d70381e 100644
--- a/packages/core/src/components/picker/picker.tsx
+++ b/packages/core/src/components/picker/picker.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop, State } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,16 +21,17 @@ import iosLeaveAnimation from './animations/ios.leave';
 export class Picker implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
   private mode: string;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
   @State() private showSpinner: boolean = null;
   @State() private spinner: string;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -231,22 +232,8 @@ export class Picker implements OverlayInterface {
     return this.columns;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   private buttonClick(button: PickerButton) {
diff --git a/packages/core/src/components/popover/popover.tsx b/packages/core/src/components/popover/popover.tsx
index 65031ff..6a47bf6 100644
--- a/packages/core/src/components/popover/popover.tsx
+++ b/packages/core/src/components/popover/popover.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,12 +24,13 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Popover implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
@@ -224,22 +225,8 @@ export class Popover implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.ev).then((animation) => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.ev);
   }
 
   hostData() {
diff --git a/packages/core/src/components/toast/toast.tsx b/packages/core/src/components/toast/toast.tsx
index 1afa318..372070a 100644
--- a/packages/core/src/components/toast/toast.tsx
+++ b/packages/core/src/components/toast/toast.tsx
@@ -1,9 +1,9 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,14 +24,14 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Toast implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation | null;
 
   @Element() private el: HTMLElement;
 
   mode: string;
   color: string;
+  animation: Animation | null;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -123,6 +123,22 @@ export class Toast implements OverlayInterface {
    */
   @Event() ionToastDidUnload: EventEmitter<ToastEventDetail>;
 
+  componentDidLoad() {
+    this.ionToastDidLoad.emit();
+  }
+
+  componentDidUnload() {
+    this.ionToastDidUnload.emit();
+  }
+
+  @Listen('ionDismiss')
+  protected onDismiss(ev: UIEvent) {
+    ev.stopPropagation();
+    ev.preventDefault();
+
+    this.dismiss();
+  }
+
   /**
    * Present the toast overlay after it has been created.
    */
@@ -169,38 +185,8 @@ export class Toast implements OverlayInterface {
     });
   }
 
-  playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.position).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
-  }
-
-  componentDidLoad() {
-    this.ionToastDidLoad.emit();
-  }
-
-  componentDidUnload() {
-    this.ionToastDidUnload.emit();
-  }
-
-  @Listen('ionDismiss')
-  protected onDismiss(ev: UIEvent) {
-    ev.stopPropagation();
-    ev.preventDefault();
-
-    this.dismiss();
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.position);
   }
 
   private wrapperClass(): CssClassMap {
diff --git a/packages/core/src/utils/overlays.ts b/packages/core/src/utils/overlays.ts
index 8926544..634df43 100644
--- a/packages/core/src/utils/overlays.ts
+++ b/packages/core/src/utils/overlays.ts
@@ -1,3 +1,5 @@
+import { AnimationBuilder, Animation } from "".."";
+import { playAnimationAsync } from ""./helpers"";
 
 let lastId = 1;
 
@@ -56,8 +58,33 @@ export function removeLastOverlay(overlays: OverlayMap) {
   return toRemove ? toRemove.dismiss() : Promise.resolve();
 }
 
+export function overlayAnimation(
+  overlay: OverlayInterface,
+  animationBuilder: AnimationBuilder,
+  animate: boolean,
+  baseEl: HTMLElement,
+  opts: any
+): Promise<void> {
+  if (overlay.animation) {
+    overlay.animation.destroy();
+    overlay.animation = null;
+  }
+  return overlay.animationCtrl.create(animationBuilder, baseEl, opts).then(animation => {
+    overlay.animation = animation;
+    if (!animate) {
+      animation.duration(0);
+    }
+    return playAnimationAsync(animation);
+  }).then((animation) => {
+    animation.destroy();
+    overlay.animation = null;
+  });
+}
+
 export interface OverlayInterface {
   overlayId: number;
+  animation: Animation;
+  animationCtrl: HTMLIonAnimationControllerElement;
 
   present(): Promise<void>;
   dismiss(data?: any, role?: string): Promise<void>;

diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 3c4dd8d..f8b8514 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -21,7 +21,8 @@ Contributions are always welcome! Please use the following guidelines when contr
     - `chore` - Catch all or things that have to do with the build system, etc
     - `examples` - Changes to existing example, or a new example
  * The `COMPONENT` is optional, and may be a single file, directory, or logical component. Can be omitted if commit applies globally
-5. Run the tests (`cargo test --no-std-features && cargo test --features yaml`)
+5. Run the tests (`cargo test --features ""yaml unstable""`)
+5. Run the lints (`cargo build --features lints`) (requires a nightly compiler)
 6. `git rebase` into concise commits and remove `--fixup`s (`git rebase -i HEAD~NUM` where `NUM` is number of commits back)
 7. Push your changes back to your fork (`git push origin $your-branch`)
 8. Create a pull request! (You can also create the pull request first, and we'll merge when ready. This a good way to discuss proposed changes.)
diff --git a/README.md b/README.md
index 9e6efce..b74405d 100644
--- a/README.md
+++ b/README.md
@@ -31,7 +31,9 @@ Table of Contents
   * [More Information](#more-information)
     * [Video Tutorials](#video-tutorials)
 * [How to Contribute](#how-to-contribute)
-  * [Running the tests](#running-the-tests)
+  * [Testing Code](#testing-code)
+  * [Linting Code](#linting-code)
+  * [Debugging Code](#debugging-code)
   * [Goals](#goals)
   * [Compatibility Policy](#compatibility-policy)
     * [Minimum Version of Rust](#minimum-version-of-rust)
@@ -43,288 +45,83 @@ Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)
 
 ## What's New
 
-Here's what's new in v2.18.0
+Here's the highlights from v2.0.0 to v2.18.0
 
 * **Completions:**  Adds completion support for Microsoft PowerShell! (Thanks to @Arnavion)
-
-Here's what's new in v2.17.1
-
-* Fixes a bug where using low index multiples was propagated to subcommands
-
-Here's what's new in v2.17.0
-
 * Allows specifying the second to last positional argument as `multiple(true)` (i.e. things such as `mv <files>... <target>`)
 * Adds an `App::get_name` and `App::get_bin_name`
-
-Here's what's new in v2.16.4
-
-* Fixes bug that caused panic on subcommands with aliases
 * Conflicting argument errors are now symetrical, meaning more consistent and better usage suggestions
-* Fixes typo in example `13a_enum_values_automatic`
-* Fixes failing yaml example (#715)
-* Fixes the `debug` feature (#716)
-
-Here's the highlights for v2.16.3
-
-* Fixes a bug where the derived display order isn't propagated
-* **yaml-example:**  fixes some inconsistent args in the example
-
-Here's the highlights for v2.16.2
-
-* Fixes a bug where single quotes are not escaped
-
-Here's the highlights for v2.16.1
-
-* **Help Message:**  fixes a regression bug where args with multiple(true) threw off alignment
-
-Here's the highlights for v2.16.0
-
 * **Completions:**  adds automatic ZSH completion script generation support! :tada: :tada:
-
-Here's a gif of them in action!
-
-![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
-
-Here's the highlights for v2.15.0
-
 * **AppSettings:**  adds new setting `AppSettings::AllowNegativeNumbers` which functions like `AllowLeadingHyphen` except only allows undefined negative numbers to pass parsing.
-* Improves some of the documentation of `AppSettings` by moving variants into roughly alphabetical order
-
-Here's the highlights for v2.14.1 (Huge thanks to all the contributors who put in a lot of work this cycle! Especially @tormol @nabijaczleweli and @wdv4758h)
-
 * Stabilize `clap_app!` macro (i.e. no longer need to use `unstable` feature)
-* Fixes a bug that made determining when to auto-wrap long help messages inconsistent
-* Fixes fish completions for nested subcommands
-* Improve documentation around features
-* Reword docs for `ErrorKind` and `App::settings`
-* Fix tests that fail when the `suggestions` feature is disabled
-* Fix the `OsString`-using doc-tests
-* Tag non-rust code blocks as such instead of ignoring them
-* Improve some errors about subcommands
-* Makes sure the doc-tests don't fail before ""missing file"" in YAML tests
 * Deprecate `App::with_defaults`
-* Make lints not enable other nightly-requiring features
-
-Here's the highlights for v2.14.0
-
-* One can now alias arguments either visibly (whichc appears in the help text) or invisibly just like subcommands!
+* One can now alias arguments either visibly (which appears in the help text) or invisibly just like subcommands!
 * The `from_usage` parser now correctly handles non-ascii names / options and help!
-* Fixes a bug in the `require_delimiter` code which caused some incorrect parses
-* Fixes various typos in the docs
-* Various other small performance improvements and enhancements
-
-Here's the highlights for v2.13.0
-
 * **Value Delimiters:**  fixes the confusion around implicitly setting value delimiters. (The default is to *not* use a delimiter unless explicitly set)
-* **Docs:** Updates README.md with new website information and updated video tutorials info
-* **Docs:** Updates the docs about removing implicit `value_delimiter(true)`
-* **Docs:** Adds better examples on using default values
-
-
-Here's the highlights for v2.12.1
-
-* Fixes a regression-bug where the old `{n}` newline char stopped being replaced a properly re-aligned newline
-
-Here's the highlights for v2.12.0
-
 * Changes the default value delimiter rules (i.e. the default is `use_delimiter(false)` *unless* a setting/method that implies multiple values was used) **[Bugfix that *may* ""break"" code]**
  * If code breaks, simply add `Arg::use_delimiter(true)` to the affected args
-* Updates the docs for the `Arg::multiple` method WRT value delimiters and default settings
 * Adds ability to hide the possible values from the help text on a per argument basis, instead of command wide
 * Allows for limiting detected terminal width (i.e. wrap at `x` length, unless the terminal width is *smaller*)
-* Removes some redundant `contains()` checks for minor performance improvements
-* Fixes a bug where valid args aren't recognized with the `AppSettings::AllowLeadingHyphen` setting
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Makes some minor changes to when next line help is automatically used
 * Adds support for the setting `Arg::require_delimiter` from YAML
-* Removes the verbage about using `'{n}'` to insert newlines in help text from the docs (the normal `\n` can now be used)
-* Documents `AppSetting::DisableVersion`
-
-Here's the highlights for v2.11.3
-
 * `clap` no longer requires one to use `{n}` inside help text to insert a newline that is properly aligned. One can now use the normal `\n`.
 * `clap` now ignores hard newlines in help messages and properly re-aligns text, but still wraps if the term width is too small
-* Supports setting `Arg::require_delimiter` from YAML
-
-Here's the highlights for v2.11.2
-
-* Makes some minor changes to when next line help is automatically used for improved wrapping
-
-Here's the highlights for v2.11.1
-
-* Fixes an issue where settings weren't propogated down through grand-child subcommands
 * Errors can now have custom description
 * Uses `term_size` instead of home-grown solution on Windows
-* Updates deps with some minor bug fixes
-
-
-Here's the highlights for v2.11.0
-
 * Adds the ability to wrap help text intelligently on Windows!
-* Moves docs to [docs.rs!](https://docs.rs/clap/)
-* Fixes some usage strings that contain both args in groups and ones that conflict with each other
-* Uses standard conventions for bash completion files, namely `{bin}.bash-completion`
+* Moves docs to [docs.rs!](https://docs.rs/clap/)!
 * Automatically moves help text to the next line and wraps when term width is determined to be too small, or help text is too long
 * Vastly improves *development* error messages when using YAML
-* Adds `App::with_defaults` to automatically use `crate_authors!` and `crate_version!` macros
-* Other minor improvements and bug fixes
-
-Here's the highlights for v2.10.4
-
-* Fixes a bug where help is wrapped incorrectly and causing a panic with some non-English characters
-
-Here's the highlights for v2.10.3
-
-* Fixes a bug with non-English characters in help text wrapping, where the character is stripped or causes a panic
-* Fixes an issue with `strsim` which caused a panic in some scenarios
 * Adds a shorthand way to ignore help text wrapping and use source formatting (i.e. `App::set_term_width(0)`)
-
-Here's the highlights for v2.10.2
-
-* Fixes a critical bug where the help message is printed twice
-
-Here's the highlights for v2.10.1
-
 * **Help Subcommand:**  fixes misleading usage string when using multi-level subcommmands such as `myprog help subcmd1 subcmd2`
 * **YAML:**  allows using lists or single values with certain arg declarations for increased ergonomics
-
-
-Here's the highlights for v2.10.0
-
-
 * **Fish Shell Completions:**  one can generate a basic fish completions script at compile time!
-* **External SubCommands:**  fixes a bug which now correctly preserves external subcommand name along with args to said command (Minor breaking change that breaks no known real world code)
-* **YAML Documentation:**  fixes example 17's incorrect reference to arg_groups instead of groups
-
-
-Here's the highlights for v2.9.3
-
 * Adds the ability to generate completions to an `io::Write` object
 * Adds an `App::unset_setting` and `App::unset_settings`
-* Fixes bug where only first arg in list of `required_unless_one` is recognized
-* Fixes a typo bug `SubcommandsRequired`->`SubcommandRequired`
-
-
-Here's the highlights for v2.9.2
-
-
-* fixes bug where --help and --version short weren't added to the completion list
-* improves completions allowing multiple bins to have seperate completion files
-
-Here's the highlights for v2.9.0
-
 * **Completions:**  one can now [generate a bash completions](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.gen_completions) script at compile time! These completions work with options using [possible values](https://docs.rs/clap/2.9.0/clap/struct.Arg.html#method.possible_values), [subcommand aliases](https://docs.rs/clap/2.9.0/clap/struct.App.html#method.aliases), and even multiple levels of subcommands
-* Minor bug fixes when using `AppSettings::TrailingVarArg` and `AppSettings::AllowLeadingHyphen`
-
-Here's the highlights for v2.8.0
-
 * **Arg:**  adds new optional setting [`Arg::require_delimiter`](https://docs.rs/clap/2.8.0/clap/struct.Arg.html#method.require_delimiter) which requires val delimiter to parse multiple values
 * The terminal sizing portion has been factored out into a separate crate, [term_size](https://crates.io/crates/term_size)
-* Minor bug fixes
-
-
-Here's the highlights for v2.7.1
-
-* **Options:**
-  *  options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
-  *  using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
-
-Here's the highlights for v2.7.0
-
+* Options using multiple values and delimiters no longer parse additional values after a trailing space (i.e. `prog -o 1,2 file.txt` parses as `1,2` for `-o` and `file.txt` for a positional arg)
+* Using options using multiple values and with an `=` no longer parse args after the trailing space as values (i.e. `prog -o=1 file.txt` parses as `1` for `-o` and `file.txt` for a positional arg)
 * **Usage Strings:**  `[FLAGS]` and `[ARGS]` are no longer blindly added to usage strings, instead only when applicable
 * `arg_enum!`:  allows using more than one meta item, or things like `#[repr(C)]` with `arg_enum!`s
 * `App::print_help`: now prints the same as would have been printed by `--help` or the like
-* **Help Messages:**
- *  prevents invoking `<cmd> help help` and displaying incorrect help message
- *  subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
-* **`ArgGroup`s:**
- *  one can now specify groups which require AT LEAST one of the args
- *  allows adding multiple ArgGroups per Arg
- * **Documentation:**  vastly improves `ArgGroup` docs by adding better examples
-* **Documentation:**  fixes a bunch of typos in the documentation
-
-Here's the highlights for v2.6.0
-
+* Prevents invoking `<cmd> help help` and displaying incorrect help message
+* Subcommand help messages requested via `<cmd> help <sub>` now correctly match `<cmd> <sub> --help`
+* One can now specify groups which require AT LEAST one of the args
+* Allows adding multiple ArgGroups per Arg
 * **Global Settings:** One can now set an `AppSetting` which is propogated down through child subcommands
 * **Terminal Wrapping:**  Allows wrapping at specified term width (Even on Windows!) (can now set an absolute width to ""smart"" wrap at)
 * **SubCommands/Aliases:**  adds support for visible aliases for subcommands (i.e. aliases that are dipslayed in the help message)
 * **Subcommands/Aliases:**  when viewing the help of an alias, it now display help of the aliased subcommand
-* Improves the default usage string when only a single positional arg is present
 * Adds new setting to stop delimiting values with `--` or `AppSettings::TrailingVarArg`
-* `App::before_help` and `App::after_help` now correctly wrap
-* Fixes bug where positional args are printed out of order when using templates
-* Fixes bug where one can't override the auto-generated version or help flags
-* Fixes issue where `App::before_help` wasn't printed
-* Fixes a failing windows build
-* Fixes bug where new color settings couldn't be converted from strings
-* Adds missing YAML methods for App and Arg
-* Allows printing version to any io::Write object
-* Removes extra newline from help and version output
-
-Here's what's new in v.2.5.2
-
-*   Removes trailing newlines from help and version output
-*   Allows printing version to any io::Write object
-*   Inter-links all types and pages
-*   Makes all publicly available types viewable in docs
-*   Fixes bug where one can't override version or help flags
-*   Fixes bug where args are printed out of order when using templates
-*   Fixes issue where `App::before_help` wasn't printed properly
-
-Here's what's new in v.2.5.0
-
 * Subcommands now support aliases - think of them as hidden subcommands that dispatch to said subcommand automatically
-
-Here's what's new in v2.4.3
-
-* Bug Fixes
- * Usage strings get de-deuplicated when there are args which are also part ``ArgGroup`s`
- * Fixed times when `ArgGroup`s are duplicated in usage strings
-* Improvements
- * Positional arguments which are part of a group are now formatted in a more readable way (fewer brackets)
- * Positional arguments use the standard `<>` brackets to reduce confusion
- * The default help string for the `help` subcommand has been shortened to fit in 80 columns
-
-Here's the highlights from v2.4.0
-
+* Fixed times when `ArgGroup`s are duplicated in usage strings
 * **Before Help:**  adds support for displaying info before help message
 * **Required Unless:**  adds support for allowing args that are required unless certain other args are present
-* Bug fixes
-
-Here's the highlights from v2.3.0
-
 * **New Help Template Engine!**: Now you have full control over the layout of your help message. Major thanks to @hgrecco
 * **Pull crate Authors from Cargo.toml**: One can now use the `crate_authors!` macro to automatically pull the crate authors from their Cargo.toml file
 * **Colored Help Messages**: Help messages can now be optionally colored (See the `AppSettings::ColoredHelp` setting). Screenshot below.
-* A bunch of bug fixes
-
-Here's the highlights from v2.2.1
-
 * **Help text auto wraps and aligns at for subcommands too!** - Long help strings of subcommands will now properly wrap and align to term width on Linux and OS X. This can be turned off as well.
-* Bug fixes
-
-An example of the optional colored help:
-
-![screenshot](http://i.imgur.com/7fs2h5j.png)
-
-Here's the highlights from v2.2.0
-
 * **Help text auto wraps and aligns at term width!** - Long help strings will now properly wrap and align to term width on Linux and OS X (and presumably Unix too). This can be turned off as well.
 * **Can customize the order of opts, flags, and subcommands in help messages**  - Instead of using the default alphabetical order, you can now re-arrange the order of your args and subcommands in help message. This helps to emphasize more popular or important options.
- * **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
+* **Can auto-derive the order from declaration order** - Have a bunch of args or subcommmands to re-order? You can now just derive the order from the declaration order!
 * **Help subcommand now accepts other subcommands as arguments!** - Similar to other CLI precedents, the `help` subcommand can now accept other subcommands as arguments to display their help message. i.e. `$ myprog help mysubcmd` (*Note* these can even be nested heavily such as `$ myprog help subcmd1 subcmd2 subcmd3` etc.)
+* **Default Values**: Args can now specify default values
+* **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
 
-* Other minor bug fixes
+Here's a gif of them in action!
+
+![zsh-comppletions](http://i.imgur.com/rwlMbAv.gif)
 
 An example of the help text wrapping at term width:
 
 ![screenshot](http://i.imgur.com/PAJzJJG.png)
 
-In v2.1.2
+An example of the optional colored help:
+
+![screenshot](http://i.imgur.com/7fs2h5j.png)
 
- * **Default Values**: Args can now specify default values
- * **Next Line Help**: Args can have help strings on the line following the argument (useful for long arguments, or those with many values). This can be set command-wide or for individual args
- * **Documentation Examples**: The examples in the documentation have been vastly improved
 
 For full details, see [CHANGELOG.md](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md)
 
@@ -697,6 +494,7 @@ features = [ ""suggestions"", ""color"" ]
 #### Opt-in features
 
 * **""yaml""**: Enables building CLIs from YAML documents. (builds dependency `yaml-rust`)
+* **""unstable""**: Enables unstable `clap` features that may change from release to release
 
 ### Dependencies Tree
 
@@ -707,6 +505,7 @@ The following graphic depicts `clap`s dependency graph (generated using [cargo-g
  * **Blue** Color: Dev dependency, only used while developing.
 
 ![clap dependencies](clap_dep_graph.png)
+
 ### More Information
 
 You can find complete documentation on the [docs.rs](https://docs.rs/clap/) for this project.
@@ -727,20 +526,65 @@ Another really great way to help is if you find an interesting, or helpful way i
 
 Please read [CONTRIBUTING.md](.github/CONTRIBUTING.md) before you start contributing.
 
+
+### Testing Code
+
 To test with all features both enabled and disabled, you can run theese commands:
 
 ```sh
 $ cargo test --no-default-features
-$ cargo test --features yaml
+$ cargo test --features ""yaml unstable""
 ```
 
-If you have a nightly compiler you can append `--features lints` to both commands
-to get style warnings and code smells; If you get one from code you think is fine,
-you can ignore it by prepending `#[cfg_attr(feature=""lints"", allow(lint_name))]`
-to the function or impl block.
+Alternatively, if you have [`just`](https://github.com/casey/just) installed you can run the prebuilt recipies. *Not* using `just` is prfeclty fine as well, it simply bundles commands automatically.
+
+For example, to test the code, as above simply run:
+
+```sh
+$ just run-tests`
+```
+
+From here on, I will lis the appropriate `cargo` command as well as the `just` command.
+
+Sometimes it's helpful to only run a subset of the tests, which can be done via:
+
+```sh
+$ cargo test --test <test_name>
+
+# Or
+
+$ just run-test <test_name>
+```
 
-If you are debugging (or just trying to understand the code) you can enable the
-""debug"" feature which will trace function calls and brances in some parts of the code.
+### Linting Code
+
+During the CI process `clap` runs against many different lints using [`clippy`](https://github.com/Manishearth/rust-clippy). In order to check if these lints pass on your own computer prior to submitting a PR you'll need a nightly compiler.
+
+In order to check the code for lints run either:
+
+```sh
+$ rustup override add nightly
+$ cargo build --features lints
+$ rustup override remove
+
+# Or
+
+$ just lint
+```
+
+### Debugging Code
+
+Another helpful technique is to see the `clap` debug output while developing features. In order to see the debug output while running the full test suite or individual tests, run:
+
+```sh
+$ cargo test --features debug
+
+# Or for individual tests
+$ cargo test --test <test_name> --features debug
+
+# The corresponding just command for individual debugging tests is:
+$ just debug <test_name>
+```
 
 ### Goals
 
",2,"[""9e3f295bbfd4098ffda1ae6656699f60b86c1f92"", ""eb51316cdfdc7258d287ba13b67ef2f42bd2b8f6""]","[""refactor"", ""docs""]","1. The code changes remove duplicated code by refactoring animation logic into a shared utility function across multiple overlay components, and also update various documentation files (README.md and CONTRIBUTING.md) to improve readability and instructions.
2. The removal of repeated animation code and consolidation into a utility aligns with the 'refactor' label, as it restructures code without changing external behavior, while the documentation edits are fully scoped to doc files and thus align with the 'docs' label.
3. 'refactor' is appropriate because the core code changes neither fix bugs nor add new features, but instead improve maintainability and reduce duplication; 'docs' is correct because the markdown file changes are solely documentation-focused, not affecting code, tests, or configuration. No other object or purpose labels fit these changes.
4. The 'refactor' and 'docs' labels together accurately represent the commit's restructuring of code and improvement of documentation, matching the classification rules."
"add hardware back button

Closes #5071","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 
",1,"[""68278b00450f2679761a2999500f6d87a579376b""]","[""feat""]","1. The code introduces a new hardware back button handler by subscribing to the platform's backButton event and implementing logic to pop navigation or exit the app, and modifies the getActiveNav method to support this feature.
2. This aligns with the 'feat' label as it adds new functionality (hardware back button support) to the application, directly matching the definition of introducing a new feature.
3. 'feat' is appropriate because the change delivers new user-facing capability, not a bug fix ('fix'), code cleanup ('refactor'), or modifications to docs, tests, CI/CD, or build artifacts.
4. The 'feat' label is justified as the code change implements a new feature (hardware back button support) in the app component."
"move toolbar to tab content level

Signed-off-by: Pranav C <pranavxc@gmail.com>
retry uploading pdb files on appveyor (#21561)
updated to lerna v6","diff --git a/packages/nc-gui-v2/components.d.ts b/packages/nc-gui-v2/components.d.ts
index f6be04b..cf555ef 100644
--- a/packages/nc-gui-v2/components.d.ts
+++ b/packages/nc-gui-v2/components.d.ts
@@ -201,6 +201,7 @@ declare module '@vue/runtime-core' {
     MdiThumbUp: typeof import('~icons/mdi/thumb-up')['default']
     MdiTrashCan: typeof import('~icons/mdi/trash-can')['default']
     MdiTwitter: typeof import('~icons/mdi/twitter')['default']
+    MdiUpload: typeof import('~icons/mdi/upload')['default']
     MdiUploadOutline: typeof import('~icons/mdi/upload-outline')['default']
     MdiViewListOutline: typeof import('~icons/mdi/view-list-outline')['default']
     MdiWhatsapp: typeof import('~icons/mdi/whatsapp')['default']
diff --git a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
index c2c87d3..27c0acc 100644
--- a/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
+++ b/packages/nc-gui-v2/components/smartsheet-toolbar/ViewActions.vue
@@ -132,7 +132,7 @@ async function changeLockType(type: LockType) {
   <div>
     <a-dropdown>
       <a-button v-t=""['c:actions']"" class=""nc-actions-menu-btn nc-toolbar-btn"">
-        <div class=""flex gap-2 align-center"">
+        <div class=""flex gap-2 items-center"">
           <component
             :is=""viewIcons[selectedView?.type].icon""
             class=""nc-view-icon group-hover:hidden""
@@ -311,6 +311,6 @@ async function changeLockType(type: LockType) {
 
 <style scoped>
 .nc-locked-menu-item > div {
-  @apply grid grid-cols-[30px,auto] gap-2  p-2 align-center;
+  @apply grid grid-cols-[30px,auto] gap-2  p-2 items-center;
 }
 </style>
diff --git a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
index 5fa555f..d498871 100644
--- a/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
+++ b/packages/nc-gui-v2/components/smartsheet/Toolbar.vue
@@ -36,7 +36,7 @@ const {isOpen} =useSidebar()
 
     <SmartsheetToolbarSearchData v-if=""(isGrid || isGallery) && !isPublic"" class=""shrink mr-2 ml-2"" />
 
-    <ToggleDrawer v-if=""!isOpen""/>
+    <ToggleDrawer class=""mr-2""/>
 
 
   </div>
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
index 896ad62..77aee05 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/index.vue
@@ -99,6 +99,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
     class=""relative shadow-md h-full""
     theme=""light""
   >
+    <!--
     <Toolbar
       v-if=""isOpen""
       class=""min-h-[var(--toolbar-height)] max-h-[var(--toolbar-height)]""
@@ -128,7 +129,7 @@ function onCreate(view: GridType | FormType | KanbanType | GalleryType) {
         <div v-if=""!isForm"" class=""dot"" />
       </template>
     </Toolbar>
-
+-->
     <div v-if=""isOpen"" class=""flex-1 flex flex-col"">
       <MenuTop @open-modal=""openModal"" @deleted=""loadViews"" @sorted=""loadViews"" />
 
diff --git a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
index 3e3d78a..8441450 100644
--- a/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
+++ b/packages/nc-gui-v2/components/smartsheet/sidebar/toolbar/ToggleDrawer.vue
@@ -4,7 +4,7 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
 </script>
 
 <template>
-  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
+<!--  <a-tooltip :placement=""isOpen ? 'bottomRight' : 'left'"" :mouse-enter-delay=""0.8"">
     <template #title> Toggle sidebar</template>
 
     <div class=""nc-sidebar-right-item hover:after:(bg-primary bg-opacity-75) group nc-sidebar-add-row"">
@@ -14,5 +14,11 @@ const { isOpen, toggle } = useSidebar({ storageKey: 'nc-right-sidebar' })
         @click=""toggle(!isOpen)""
       />
     </div>
-  </a-tooltip>
+  </a-tooltip>-->
+
+  <a-button @click=""toggle(!isOpen)"" size=""small"">
+  <div class=""flex items-center gap-2"">  <MdiMenu/> Views
+  </div>
+  </a-button>
+
 </template>
diff --git a/packages/nc-gui-v2/components/tabs/Smartsheet.vue b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
index 4181996..7b7ec36 100644
--- a/packages/nc-gui-v2/components/tabs/Smartsheet.vue
+++ b/packages/nc-gui-v2/components/tabs/Smartsheet.vue
@@ -83,11 +83,11 @@ watch(isLocked, (nextValue) => (treeViewIsLockedInj.value = nextValue), { immedi
 
             <SmartsheetForm v-else-if=""isForm"" />
           </div>
+          <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
         </div>
       </template>
     </div>
 
-    <SmartsheetSidebar class=""nc-right-sidebar"" v-if=""meta"" />
   </div>
 </template>
 

diff --git a/appveyor.yml b/appveyor.yml
index 9aca21e..8b54543 100644
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -146,12 +146,12 @@ build_script:
   - ps: >-
       if ($env:GN_CONFIG -eq 'release') {
         python electron\script\zip-symbols.py
-        appveyor PushArtifact out/Default/symbols.zip
+        appveyor-retry appveyor PushArtifact out/Default/symbols.zip
       } else {
         # It's useful to have pdb files when debugging testing builds that are
         # built on CI.
         7z a pdb.zip out\Default\*.pdb
-        appveyor PushArtifact pdb.zip
+        appveyor-retry appveyor PushArtifact pdb.zip
       }
   - python electron/script/zip_manifests/check-zip-manifest.py out/Default/dist.zip electron/script/zip_manifests/dist_zip.win.%TARGET_ARCH%.manifest
 test_script:

diff --git a/lerna.json b/lerna.json
index 29cb6ed..4488fb6 100644
--- a/lerna.json
+++ b/lerna.json
@@ -25,7 +25,6 @@
   ""npmClient"": ""pnpm"",
   ""useWorkspaces"": true,
   ""conventionalCommits"": true,
-  ""useNx"": true,
   ""command"": {
     ""version"": {
       ""message"": ""chore(release): published new version""
diff --git a/nx.json b/nx.json
index 00997ba..b3f2627 100644
--- a/nx.json
+++ b/nx.json
@@ -33,32 +33,6 @@
       }
     }
   },
-  ""targetDependencies"": {
-    ""build"": [
-      {
-        ""target"": ""build"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""build:ci"": [
-      {
-        ""target"": ""build:ci"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""prepare"": [
-      {
-        ""target"": ""prepare"",
-        ""projects"": ""dependencies""
-      }
-    ],
-    ""package"": [
-      {
-        ""target"": ""package"",
-        ""projects"": ""dependencies""
-      }
-    ]
-  },
   ""affected"": {
     ""defaultBase"": ""main""
   },
@@ -66,5 +40,28 @@
     ""@nrwl/js"": {
       ""analyzeSourceFiles"": false
     }
+  },
+  ""$schema"": ""./node_modules/nx/schemas/nx-schema.json"",
+  ""targetDefaults"": {
+    ""build"": {
+      ""dependsOn"": [
+        ""^build""
+      ]
+    },
+    ""build:ci"": {
+      ""dependsOn"": [
+        ""^build:ci""
+      ]
+    },
+    ""prepare"": {
+      ""dependsOn"": [
+        ""^prepare""
+      ]
+    },
+    ""package"": {
+      ""dependsOn"": [
+        ""^package""
+      ]
+    }
   }
 }
",3,"[""bf95d5d0b34d32ef2684488feb3de01cb824b2b4"", ""7152173d26293f4638920b17ce2dfa8ae995193b"", ""aa30370b796c1f46cc60aa56b2918c3d27c0cf88""]","[""refactor"", ""cicd"", ""build""]","1. The code changes include UI restructuring (moving toolbar logic and components), minor class and layout updates, updating AppVeyor CI scripts for retry logic, upgrading Lerna to v6, and modifying Nx build configuration files.
2. The UI and layout changes (Vue component files) are focused on reorganizing structure and presentation without adding features or fixing bugs, aligning with the 'refactor' label; changes to appveyor.yml are CI-specific and match the 'cicd' label; updates to lerna.json and nx.json relate to build tooling and configuration, fitting the 'build' label.
3. 'refactor' is appropriate for the UI code because there is no new functionality or bug fix; 'cicd' is used for CI pipeline script changes, not 'build', since the script is for CI; 'build' is correct for dependency and build tool configuration changes, not 'refactor', because the focus is on the build process and tooling, not code logic.
4. The labels 'refactor', 'cicd', and 'build' are correctly assigned, as each major segment of the commit aligns with the respective label's definition and scope according to the classification instructions."
"reorder startup steps
adds test for exec with http proxy

Signed-off-by: Sam Alba <samalba@users.noreply.github.com>
update pr condition","diff --git a/broker/src/main/java/io/camunda/zeebe/broker/bootstrap/BrokerStartupProcess.java b/broker/src/main/java/io/camunda/zeebe/broker/bootstrap/BrokerStartupProcess.java
index 52fa3a9..d81c27a 100644
--- a/broker/src/main/java/io/camunda/zeebe/broker/bootstrap/BrokerStartupProcess.java
+++ b/broker/src/main/java/io/camunda/zeebe/broker/bootstrap/BrokerStartupProcess.java
@@ -50,21 +50,20 @@ public final class BrokerStartupProcess {
       // must be executed before any disk space usage listeners are registered
       result.add(new DiskSpaceUsageMonitorStep());
     }
-
     result.add(new MonitoringServerStep());
     result.add(new BrokerAdminServiceStep());
+
     result.add(new ClusterServicesCreationStep());
+    result.add(new ClusterServicesStep());
 
     result.add(new CommandApiServiceStep());
     result.add(new SubscriptionApiStep());
-
-    result.add(new ClusterServicesStep());
+    result.add(new LeaderManagementRequestHandlerStep());
 
     if (config.getGateway().isEnable()) {
       result.add(new EmbeddedGatewayServiceStep());
     }
 
-    result.add(new LeaderManagementRequestHandlerStep());
     result.add(new PartitionManagerStep());
 
     return result;

diff --git a/tests/tasks.bats b/tests/tasks.bats
index e3b95c4..4cfba15 100644
--- a/tests/tasks.bats
+++ b/tests/tasks.bats
@@ -101,6 +101,14 @@ setup() {
     assert_line --partial --index 9 'actions.basicTest.stop'
 }
 
+@test ""task: #Exec with HTTP proxy"" {
+    cd ./tasks/exec
+    export HTTPS_PROXY=""https://localhost:4242/""
+    run ""$DAGGER"" ""do"" -p ./http_proxy.cue curlProxy
+    assert_failure
+    unset HTTP_PROXY
+}
+
 @test ""task: #Start #Stop params"" {
     cd ./tasks/exec
     ""$DAGGER"" ""do"" -p ./start_stop_exec.cue execParamsTest
@@ -297,4 +305,4 @@ setup() {
 
 @test ""task: #Rm"" {
     ""$DAGGER"" ""do"" -p ./tasks/rm/rm.cue test
-}
\ No newline at end of file
+}
diff --git a/tests/tasks/exec/http_proxy.cue b/tests/tasks/exec/http_proxy.cue
new file mode 100644
index 0000000..05de4b9
--- /dev/null
+++ b/tests/tasks/exec/http_proxy.cue
@@ -0,0 +1,25 @@
+package main
+
+import (
+	""dagger.io/dagger""
+	""dagger.io/dagger/core""
+)
+
+dagger.#Plan & {
+	actions: {
+		image: core.#Pull & {
+			source: ""alpine:3.15.0@sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3""
+		}
+
+		curlProxy: core.#Exec & {
+			input: image.output
+			args: [
+				""sh"", ""-c"",
+				""""""
+					apk add --no-cache curl
+					curl -sfL -o /dev/null https://www.google.com/
+					"""""",
+			]
+		}
+	}
+}

diff --git a/.github/workflows/release-pr.yml b/.github/workflows/release-pr.yml
index 697ca8e..23f4475 100644
--- a/.github/workflows/release-pr.yml
+++ b/.github/workflows/release-pr.yml
@@ -3,7 +3,6 @@ name: release
 on:
   issue_comment:
     types: [created]
-    contains: ""/trigger release""
 
 env:
   # 7 GiB by default on GitHub, setting to 6 GiB
@@ -11,6 +10,7 @@ env:
 
 jobs:
   release-pr:
+    if: ${{ github.event.issue.pull_request && github.event.comment.body == '/trigger release' }}
     permissions:
       id-token: write
     runs-on: ubuntu-latest
",3,"[""3e0c4cbf91fe5efc9b93baba93e4df93ef4ab5cd"", ""6c7398993bc567ec84e4573b6ededbf50b1ef606"", ""f8c7b34bdeedcf1a4628cd50b23920afeaf57cb6""]","[""refactor"", ""test"", ""cicd""]","1. The commit reorders steps in the BrokerStartupProcess Java class, adds a new test for HTTP proxy execution in the BATS test suite and a corresponding CUE file, and modifies a GitHub Actions workflow to update the PR trigger condition.
2. The Java class change restructures startup logic without altering external behavior (refactor), the new test and CUE file are dedicated to testing (test), and the workflow change directly modifies CI configuration (cicd).
3. 'refactor' is correct for the Java code because it reorganizes execution order without feature or bug implications, not 'feat' or 'fix'; 'test' is appropriate for the new test and CUE file as they only add test logic, not production code; 'cicd' is the right label for the workflow YAML change as it solely affects CI configuration, not build or code logic.
4. The assigned labels 'refactor', 'test', and 'cicd' are appropriate as each change is fully scoped to their respective categories according to the definitions and resolution rules."
"add instruction for finding version
retry uploading pdb files on appveyor (#21561)","diff --git a/.github/ISSUE_TEMPLATE/_bug_report_chs.md b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
index 42a2e0f..44a33db 100644
--- a/.github/ISSUE_TEMPLATE/_bug_report_chs.md
+++ b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
@@ -36,7 +36,7 @@ assignees: ''
 ## 设备信息
 - 操作系统: [] <!-- 如 [Window10] -->
 - 浏览器版本: [] <!-- 如 [Chrome77] -->
-- 沙拉查词版本: [] <!-- 如 [v7.0.0] -->
+- 沙拉查词版本: [] <!-- 如 [v7.0.0] （在扩展管理页面查看） -->
 
 <!-- 请在下方 ## 开头行之间的空白处填写 -->
 

diff --git a/appveyor.yml b/appveyor.yml
index 9aca21e..8b54543 100644
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -146,12 +146,12 @@ build_script:
   - ps: >-
       if ($env:GN_CONFIG -eq 'release') {
         python electron\script\zip-symbols.py
-        appveyor PushArtifact out/Default/symbols.zip
+        appveyor-retry appveyor PushArtifact out/Default/symbols.zip
       } else {
         # It's useful to have pdb files when debugging testing builds that are
         # built on CI.
         7z a pdb.zip out\Default\*.pdb
-        appveyor PushArtifact pdb.zip
+        appveyor-retry appveyor PushArtifact pdb.zip
       }
   - python electron/script/zip_manifests/check-zip-manifest.py out/Default/dist.zip electron/script/zip_manifests/dist_zip.win.%TARGET_ARCH%.manifest
 test_script:
",2,"[""af0a5f7ab9d71fe20aa0888f682368f32b26fe18"", ""7152173d26293f4638920b17ce2dfa8ae995193b""]","[""docs"", ""cicd""]","1. The first change updates a comment in a GitHub issue template to add instructions for locating the version number, and the second change modifies the AppVeyor CI configuration to use a retry helper when uploading artifacts.
2. The issue template edit is a documentation-only change, matching the 'docs' label, while the AppVeyor config change concerns CI/CD scripting, matching the 'cicd' label.
3. 'docs' is appropriate for the template update since it is purely instructional text, not code or logic, and 'cicd' is correct for the AppVeyor change, as it is scoped entirely to a CI configuration file rather than general build logic or application code.
4. The labels 'docs' and 'cicd' are correct because each change is fully contained within its respective artifact type—documentation and CI configuration—without overlap with code logic or other artifact types."
"treeview width fix

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>
add workflow to release branches
init environ cache","diff --git a/tests/playwright/pages/Dashboard/TreeView.ts b/tests/playwright/pages/Dashboard/TreeView.ts
index 9cc622b..75c02c0 100644
--- a/tests/playwright/pages/Dashboard/TreeView.ts
+++ b/tests/playwright/pages/Dashboard/TreeView.ts
@@ -23,10 +23,24 @@ export class TreeViewPage extends BasePage {
   }
 
   async verifyVisibility({ isVisible }: { isVisible: boolean }) {
-    if (isVisible) {
-      await expect(this.get()).toBeVisible();
+    await this.rootPage.waitForTimeout(1000);
+
+    const domElement = await this.get();
+    // get width of treeview dom element
+    const width = (await domElement.boundingBox()).width;
+
+    // if (isVisible) {
+    //   await expect(this.get()).toBeVisible();
+    // } else {
+    //   await expect(this.get()).not.toBeVisible();
+    // }
+
+    // border for treeview is 1px
+    // if not-visible, width should be < 5;
+    if (!isVisible) {
+      expect(width).toBeLessThan(5);
     } else {
-      await expect(this.get()).not.toBeVisible();
+      expect(width).toBeGreaterThan(5);
     }
   }
 

diff --git a/.github/workflows/release-pr.yml b/.github/workflows/release-pr.yml
new file mode 100644
index 0000000..697ca8e
--- /dev/null
+++ b/.github/workflows/release-pr.yml
@@ -0,0 +1,48 @@
+name: release
+
+on:
+  issue_comment:
+    types: [created]
+    contains: ""/trigger release""
+
+env:
+  # 7 GiB by default on GitHub, setting to 6 GiB
+  NODE_OPTIONS: --max-old-space-size=6144
+
+jobs:
+  release-pr:
+    permissions:
+      id-token: write
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+
+    steps:
+      - name: Ensure action is by maintainer
+        uses: octokit/request-action@v2.x
+        id: check_role
+        with:
+          route: GET /repos/danielroe/roe.dev/collaborators/${{ github.event.comment.user.login }}
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+
+      - uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+
+      - run: corepack enable
+      - uses: actions/setup-node@v3
+        with:
+          node-version: 20
+          cache: ""pnpm""
+
+      - name: Install dependencies
+        run: pnpm install
+
+      - name: Build
+        run: pnpm build
+
+      - name: Release Edge
+        run: ./scripts/release-edge.sh
+        env:
+          NODE_AUTH_TOKEN: ${{ secrets.NODE_AUTH_TOKEN }}
+          NPM_CONFIG_PROVENANCE: true
diff --git a/package.json b/package.json
index 1074dcd..48bb566 100644
--- a/package.json
+++ b/package.json
@@ -5,7 +5,7 @@
   ""license"": ""MIT"",
   ""type"": ""module"",
   ""scripts"": {
-    ""build"": ""FORCE_COLOR=1 pnpm --filter './packages/**' prepack"",
+    ""build"": ""pnpm --filter './packages/**' prepack"",
     ""build:stub"": ""pnpm --filter './packages/**' prepack --stub"",
     ""cleanup"": ""rimraf 'packages/**/node_modules' 'examples/**/node_modules' 'docs/node_modules' 'playground/node_modules' 'node_modules'"",
     ""dev"": ""pnpm play"",

diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {
",3,"[""efeb30f26252ef4791ef2a02d83827b7f0c45462"", ""bc28d536c0dd1061ac96cea0241857c1d4e4e0f2"", ""dc50bd35462a49058c91a939fc8830ae7a9eb692""]","[""test"", ""cicd"", ""fix""]","1. The commit modifies a test file to check the DOM width for TreeView visibility, adds a new GitHub Actions workflow for release branches, and initializes an environment cache in Go source code.
2. The test file change is entirely focused on test logic, aligning with the 'test' label; the new workflow YAML is a CI/CD configuration, aligning with the 'cicd' label; the Go code change initializes a cache to prevent nil access, which fixes a potential bug, aligning with the 'fix' label.
3. 'test' is appropriate for the test file as it only affects testing, not runtime code; 'cicd' fits for the workflow addition as it is CI config, not build logic; 'fix' is correct for the Go code because it prevents a runtime error, not introducing a new feature ('feat') or just restructuring ('refactor').
4. The assigned labels 'test', 'cicd', and 'fix' are correct because each code unit aligns directly and exclusively with its respective label according to the classification rules."
post installers compatiblity with Windows #2520,"diff --git a/packages/cubejs-databricks-jdbc-driver/package.json b/packages/cubejs-databricks-jdbc-driver/package.json
index cc164f0..fd7ad45 100644
--- a/packages/cubejs-databricks-jdbc-driver/package.json
+++ b/packages/cubejs-databricks-jdbc-driver/package.json
@@ -14,13 +14,16 @@
   },
   ""main"": ""dist/src/index.js"",
   ""typings"": ""dist/src/index.d.ts"",
+  ""bin"": {
+    ""databricks-jdbc-installer"": ""bin/post-install""
+  },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
     ""tsc"": ""tsc"",
     ""watch"": ""tsc -w"",
     ""lint"": ""eslint src/* --ext .ts"",
     ""lint:fix"": ""eslint --fix src/* --ext .ts"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""databricks-jdbc-installer""
   },
   ""files"": [
     ""README.md"",
diff --git a/rust/package.json b/rust/package.json
index b139279..5bf6446 100644
--- a/rust/package.json
+++ b/rust/package.json
@@ -8,7 +8,8 @@
     ""node"": "">=10.8.0""
   },
   ""bin"": {
-    ""cubestore-dev"": ""bin/cubestore-dev""
+    ""cubestore-dev"": ""bin/cubestore-dev"",
+    ""cubestore-installer"": ""bin/post-install""
   },
   ""scripts"": {
     ""build"": ""rm -rf dist && npm run tsc"",
@@ -18,7 +19,7 @@
     ""lint:fix"": ""eslint --fix js-wrapper/* --ext .ts,js"",
     ""unit"": ""jest"",
     ""unit:debug"": ""jest --runInBand"",
-    ""postinstall"": ""bin/post-install""
+    ""postinstall"": ""cubestore-installer""
   },
   ""files"": [
     ""dist"",
diff --git a/yarn.lock b/yarn.lock
index d2a4038..b59bb77 100644
--- a/yarn.lock
+++ b/yarn.lock
@@ -4036,9 +4036,9 @@
   integrity sha512-7btbphLrKvo5yl/5CC2OCxUSMx1wV1wvGT1qDXkSt7yi00/YW7E8k6qzXqJHsp+WU0eoG7r6MTQQXI9lIvd0qA==
 
 ""@types/fs-extra@^9.0.1"", ""@types/fs-extra@^9.0.2"", ""@types/fs-extra@^9.0.8"":
-  version ""9.0.10""
-  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.10.tgz#8023a72e3d06cf54929ea47ec7634e47f33f4046""
-  integrity sha512-O9T2LLkRDiTlalOBdjEkcnT0MRdT2+wglCl7pJUJ3mkWkR8hX4K+5bg2raQNJcLv4V8zGuTXe7Ud3wSqkTyuyQ==
+  version ""9.0.11""
+  resolved ""https://registry.yarnpkg.com/@types/fs-extra/-/fs-extra-9.0.11.tgz#8cc99e103499eab9f347dbc6ca4e99fb8d2c2b87""
+  integrity sha512-mZsifGG4QeQ7hlkhO56u7zt/ycBgGxSVsFI/6lGTU34VtwkiqrrSDgw0+ygs8kFGWcXnFQWMrzF2h7TtDFNixA==
   dependencies:
     ""@types/node"" ""*""
 
@@ -5306,9 +5306,9 @@ acorn@^7.0.0, acorn@^7.1.0, acorn@^7.1.1, acorn@^7.4.0:
   integrity sha512-nQyp0o1/mNdbTO1PO6kHkwSrmgZ0MT/jCCpNiwbUjGoRN4dlBhqJtoQuCnEOKzgTVwg0ZWiCoQy6SxMebQVh8A==
 
 acorn@^8.1.0:
-  version ""8.1.0""
-  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.0.tgz#52311fd7037ae119cbb134309e901aa46295b3fe""
-  integrity sha512-LWCF/Wn0nfHOmJ9rzQApGnxnvgfROzGilS8936rqN/lfcYkY9MYZzdMqN+2NJ4SlTc+m5HiSa+kNfDtI64dwUA==
+  version ""8.1.1""
+  resolved ""https://registry.yarnpkg.com/acorn/-/acorn-8.1.1.tgz#fb0026885b9ac9f48bac1e185e4af472971149ff""
+  integrity sha512-xYiIVjNuqtKXMxlRMDc6mZUhXehod4a3gbZ1qRlM7icK4EbxUFNLhWoPblCvFtB2Y9CIqHP3CF/rdxLItaQv8g==
 
 adal-node@^0.1.28:
   version ""0.1.28""
@@ -5441,9 +5441,9 @@ ajv@^6.1.0, ajv@^6.10.0, ajv@^6.10.2, ajv@^6.12.2, ajv@^6.12.3, ajv@^6.12.4, ajv
     uri-js ""^4.2.2""
 
 ajv@^8.0.1:
-  version ""8.0.5""
-  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.0.5.tgz#f07d6fdeffcdbb80485570ce3f1bc845fcc812b9""
-  integrity sha512-RkiLa/AeJx7+9OvniQ/qeWu0w74A8DiPPBclQ6ji3ZQkv5KamO+QGpqmi7O4JIw3rHGUXZ6CoP9tsAkn3gyazg==
+  version ""8.1.0""
+  resolved ""https://registry.yarnpkg.com/ajv/-/ajv-8.1.0.tgz#45d5d3d36c7cdd808930cc3e603cf6200dbeb736""
+  integrity sha512-B/Sk2Ix7A36fs/ZkuGLIR86EdjbgR6fsAcbx9lOP/QBSXujDNbVmIS/U4Itz5k8fPFDeVZl/zQ/gJW4Jrq6XjQ==
   dependencies:
     fast-deep-equal ""^3.1.1""
     json-schema-traverse ""^1.0.0""
@@ -6828,15 +6828,15 @@ browserslist@4.14.2:
     node-releases ""^1.1.61""
 
 browserslist@^4.0.0, browserslist@^4.11.1, browserslist@^4.12.0, browserslist@^4.14.5, browserslist@^4.16.3, browserslist@^4.3.4, browserslist@^4.6.2, browserslist@^4.6.4, browserslist@^4.7.0, browserslist@^4.9.1:
-  version ""4.16.3""
-  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.3.tgz#340aa46940d7db878748567c5dea24a48ddf3717""
-  integrity sha512-vIyhWmIkULaq04Gt93txdh+j02yX/JzlyhLYbV3YQCn/zvES3JnY7TifHHvvr1w5hTDluNKMkV05cs4vy8Q7sw==
+  version ""4.16.4""
+  resolved ""https://registry.yarnpkg.com/browserslist/-/browserslist-4.16.4.tgz#7ebf913487f40caf4637b892b268069951c35d58""
+  integrity sha512-d7rCxYV8I9kj41RH8UKYnvDYCRENUlHRgyXy/Rhr/1BaeLGfiCptEdFE8MIrvGfWbBFNjVYx76SQWvNX1j+/cQ==
   dependencies:
-    caniuse-lite ""^1.0.30001181""
-    colorette ""^1.2.1""
-    electron-to-chromium ""^1.3.649""
+    caniuse-lite ""^1.0.30001208""
+    colorette ""^1.2.2""
+    electron-to-chromium ""^1.3.712""
     escalade ""^3.1.1""
-    node-releases ""^1.1.70""
+    node-releases ""^1.1.71""
 
 bs-logger@0.x:
   version ""0.2.6""
@@ -7217,7 +7217,7 @@ caniuse-api@^3.0.0:
     lodash.memoize ""^4.1.2""
     lodash.uniq ""^4.5.0""
 
-caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001181:
+caniuse-lite@^1.0.0, caniuse-lite@^1.0.30000981, caniuse-lite@^1.0.30001032, caniuse-lite@^1.0.30001061, caniuse-lite@^1.0.30001109, caniuse-lite@^1.0.30001125, caniuse-lite@^1.0.30001208:
   version ""1.0.30001208""
   resolved ""https://registry.yarnpkg.com/caniuse-lite/-/caniuse-lite-1.0.30001208.tgz#a999014a35cebd4f98c405930a057a0d75352eb9""
   integrity sha512-OE5UE4+nBOro8Dyvv0lfx+SRtfVIOM9uhKqFmJeUbGriqhhStgp1A0OyBpgy3OUF8AhYCT+PVwPC1gMl2ZcQMA==
@@ -9549,10 +9549,10 @@ ejs@^2.6.1:
   resolved ""https://registry.yarnpkg.com/ejs/-/ejs-2.7.4.tgz#48661287573dcc53e366c7a1ae52c3a120eec9ba""
   integrity sha512-7vmuyh5+kuUyJKePhQfRQBhXV5Ce+RnaeeQArKu1EAMpL3WbgMt5WG6uQZpEVvYSSsxMXRKOewtDk9RaTKXRlA==
 
-electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.649:
-  version ""1.3.711""
-  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.711.tgz#92c3caf7ffed5e18bf63f66b4b57b4db2409c450""
-  integrity sha512-XbklBVCDiUeho0PZQCjC25Ha6uBwqqJeyDhPLwLwfWRAo4x+FZFsmu1pPPkXT+B4MQMQoQULfyaMltDopfeiHQ==
+electron-to-chromium@^1.3.564, electron-to-chromium@^1.3.712:
+  version ""1.3.712""
+  resolved ""https://registry.yarnpkg.com/electron-to-chromium/-/electron-to-chromium-1.3.712.tgz#ae467ffe5f95961c6d41ceefe858fc36eb53b38f""
+  integrity sha512-3kRVibBeCM4vsgoHHGKHmPocLqtFAGTrebXxxtgKs87hNUzXrX2NuS3jnBys7IozCnw7viQlozxKkmty2KNfrw==
 
 elegant-spinner@^1.0.1:
   version ""1.0.1""
@@ -9945,9 +9945,9 @@ eslint-plugin-import@^2.16.0, eslint-plugin-import@^2.18.2, eslint-plugin-import
     tsconfig-paths ""^3.9.0""
 
 eslint-plugin-jest@^24.1.0:
-  version ""24.3.4""
-  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.4.tgz#6d90c3554de0302e879603dd6405474c98849f19""
-  integrity sha512-3n5oY1+fictanuFkTWPwSlehugBTAgwLnYLFsCllzE3Pl1BwywHl5fL0HFxmMjoQY8xhUDk8uAWc3S4JOHGh3A==
+  version ""24.3.5""
+  resolved ""https://registry.yarnpkg.com/eslint-plugin-jest/-/eslint-plugin-jest-24.3.5.tgz#71f0b580f87915695c286c3f0eb88cf23664d044""
+  integrity sha512-XG4rtxYDuJykuqhsOqokYIR84/C8pRihRtEpVskYLbIIKGwPNW2ySxdctuVzETZE+MbF/e7wmsnbNVpzM0rDug==
   dependencies:
     ""@typescript-eslint/experimental-utils"" ""^4.0.1""
 
@@ -12140,12 +12140,11 @@ http-proxy-middleware@0.19.1:
     micromatch ""^3.1.10""
 
 http-proxy-middleware@^1.0.0:
-  version ""1.1.0""
-  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.0.tgz#b896b2cc6836019af4a4f2d5f7b21b99c77ea13f""
-  integrity sha512-OnjU5vyVgcZVe2AjLJyMrk8YLNOC2lspCHirB5ldM+B/dwEfZ5bgVTrFyzE9R7xRWAP/i/FXtvIqKjTNEZBhBg==
+  version ""1.1.1""
+  resolved ""https://registry.yarnpkg.com/http-proxy-middleware/-/http-proxy-middleware-1.1.1.tgz#48900a68cd9d388c735d1dd97302c919b7e94a13""
+  integrity sha512-FIDg9zPvOwMhQ3XKB2+vdxK6WWbVAH7s5QpqQCif7a1TNL76GNAATWA1sy6q2gSfss8UJ/Nwza3N6QnFkKclpA==
   dependencies:
     ""@types/http-proxy"" ""^1.17.5""
-    camelcase ""^6.2.0""
     http-proxy ""^1.18.1""
     is-glob ""^4.0.1""
     is-plain-obj ""^3.0.0""
@@ -14341,9 +14340,9 @@ jsdom@^15.2.1:
     xml-name-validator ""^3.0.0""
 
 jsdom@^16.4.0:
-  version ""16.5.2""
-  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.2.tgz#583fac89a0aea31dbf6237e7e4bedccd9beab472""
-  integrity sha512-JxNtPt9C1ut85boCbJmffaQ06NBnzkQY/MWO3YxPW8IWS38A26z+B1oBvA9LwKrytewdfymnhi4UNH3/RAgZrg==
+  version ""16.5.3""
+  resolved ""https://registry.yarnpkg.com/jsdom/-/jsdom-16.5.3.tgz#13a755b3950eb938b4482c407238ddf16f0d2136""
+  integrity sha512-Qj1H+PEvUsOtdPJ056ewXM4UJPCi4hhLA8wpiz9F2YvsRBhuFsXxtrIFAgGBDynQA9isAMGE91PfUYbdMPXuTA==
   dependencies:
     abab ""^2.0.5""
     acorn ""^8.1.0""
@@ -15590,12 +15589,12 @@ micromatch@^3.1.10, micromatch@^3.1.4:
     to-regex ""^3.0.2""
 
 micromatch@^4.0.2:
-  version ""4.0.3""
-  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.3.tgz#fdad8352bf0cbeb89b391b5d244bc22ff3dd4ec8""
-  integrity sha512-ueuSaP4i67F/FAUac9zzZ0Dz/5KeKDkITYIS/k4fps+9qeh1SkeH6gbljcqz97mNBOsaWZ+iv2UobMKK/yD+aw==
+  version ""4.0.4""
+  resolved ""https://registry.yarnpkg.com/micromatch/-/micromatch-4.0.4.tgz#896d519dfe9db25fce94ceb7a500919bf881ebf9""
+  integrity sha512-pRmzw/XUcwXGpD9aI9q/0XOwLNygjETJ8y0ao0wdqprrzDa4YnxLcz7fQRZr8voh8V10kGhABbNcHVk5wHgWwg==
   dependencies:
     braces ""^3.0.1""
-    picomatch ""^2.2.1""
+    picomatch ""^2.2.3""
 
 miller-rabin@^4.0.0:
   version ""4.0.1""
@@ -16356,7 +16355,7 @@ node-pre-gyp@^0.11.0:
     semver ""^5.3.0""
     tar ""^4""
 
-node-releases@^1.1.61, node-releases@^1.1.70:
+node-releases@^1.1.61, node-releases@^1.1.71:
   version ""1.1.71""
   resolved ""https://registry.yarnpkg.com/node-releases/-/node-releases-1.1.71.tgz#cb1334b179896b1c89ecfdd4b725fb7bbdfc7dbb""
   integrity sha512-zR6HoT6LrLCRBwukmrVbHv0EpEQjksO6GmFcZQQuCAy139BEsoVKPYnf3jongYW83fAa1torLGYwxxky/p28sg==
@@ -17571,10 +17570,10 @@ pgpass@1.x:
   dependencies:
     split2 ""^3.1.1""
 
-picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2:
-  version ""2.2.2""
-  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.2.tgz#21f333e9b6b8eaff02468f5146ea406d345f4dad""
-  integrity sha512-q0M/9eZHzmr0AulXyPwNfZjtwZ/RBZlbN3K3CErVrk50T2ASYI7Bye0EvekFY3IP1Nt2DHu0re+V2ZHIpMkuWg==
+picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.2.2, picomatch@^2.2.3:
+  version ""2.2.3""
+  resolved ""https://registry.yarnpkg.com/picomatch/-/picomatch-2.2.3.tgz#465547f359ccc206d3c48e46a1bcb89bf7ee619d""
+  integrity sha512-KpELjfwcCDUb9PeigTs2mBJzXUPzAuP2oPcA989He8Rte0+YUAjw1JVedDhuTKPkHjSYzMN3npC9luThGYEKdg==
 
 pify@^2.0.0, pify@^2.2.0, pify@^2.3.0:
   version ""2.3.0""
@@ -18446,9 +18445,9 @@ postcss@^7, postcss@^7.0.0, postcss@^7.0.1, postcss@^7.0.14, postcss@^7.0.17, po
     supports-color ""^6.1.0""
 
 postcss@^8.1.0, postcss@^8.2.8:
-  version ""8.2.9""
-  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.9.tgz#fd95ff37b5cee55c409b3fdd237296ab4096fba3""
-  integrity sha512-b+TmuIL4jGtCHtoLi+G/PisuIl9avxs8IZMSmlABRwNz5RLUUACrC+ws81dcomz1nRezm5YPdXiMEzBEKgYn+Q==
+  version ""8.2.10""
+  resolved ""https://registry.yarnpkg.com/postcss/-/postcss-8.2.10.tgz#ca7a042aa8aff494b334d0ff3e9e77079f6f702b""
+  integrity sha512-b/h7CPV7QEdrqIxtAf2j31U5ef05uBDuvoXv6L51Q4rcS1jdlXAVKJv+atCFdUXYl9dyTHGyoMzIepwowRJjFw==
   dependencies:
     colorette ""^1.2.2""
     nanoid ""^3.1.22""
@@ -19318,9 +19317,9 @@ rc-tree@^4.0.0, rc-tree@~4.1.0:
     rc-virtual-list ""^3.0.1""
 
 rc-trigger@^5.0.0, rc-trigger@^5.0.4, rc-trigger@^5.1.2, rc-trigger@^5.2.1:
-  version ""5.2.3""
-  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.3.tgz#8c55046ab432d7b52d51c69afb57ebb5bbe37e17""
-  integrity sha512-6Fokao07HUbqKIDkDRFEM0AGZvsvK0Fbp8A/KFgl1ngaqfO1nY037cISCG1Jm5fxImVsXp9awdkP7Vu5cxjjog==
+  version ""5.2.4""
+  resolved ""https://registry.yarnpkg.com/rc-trigger/-/rc-trigger-5.2.4.tgz#f1cca4a6c1f378a5d6fadec010292250772069d3""
+  integrity sha512-nLZa4XYo3hOAVauQr7HsGrBtE8/pyoIWhHZnpr7x/H/dd6pPeRzH0//+1TzaBAXylbFgsY6hogKAMeJwaKeDFw==
   dependencies:
     ""@babel/runtime"" ""^7.11.2""
     classnames ""^2.2.6""
@@ -20516,9 +20515,9 @@ rollup@^1.31.1:
     acorn ""^7.1.0""
 
 rollup@^2.40.0, rollup@^2.8.0:
-  version ""2.45.0""
-  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.0.tgz#bfcce2347c96f15f5c78ac860bc38e3349ba27c9""
-  integrity sha512-JJznbtGIsHZfKH0Sa9RpCAy5JarH8SWvBzRAGuRkgzAafb8e8D7VSMJ0O1Bsix1nn91koN/Ecvl2+ZWhljcuTw==
+  version ""2.45.1""
+  resolved ""https://registry.yarnpkg.com/rollup/-/rollup-2.45.1.tgz#eae2b94dc2088b4e0a3b7197a5a1ee0bdd589d5c""
+  integrity sha512-vPD+JoDj3CY8k6m1bLcAFttXMe78P4CMxoau0iLVS60+S9kLsv2379xaGy4NgYWu+h2WTlucpoLPAoUoixFBag==
   optionalDependencies:
     fsevents ""~2.3.1""
 
@@ -22971,9 +22970,9 @@ typescript@~4.1.5:
   integrity sha512-6OSu9PTIzmn9TCDiovULTnET6BgXtDYL4Gg4szY+cGsc3JP1dQL8qvE8kShTRx1NIw4Q9IBHlwODjkjWEtMUyA==
 
 ua-parser-js@^0.7.18:
-  version ""0.7.27""
-  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.27.tgz#b54f8ce9eb6c7abf3584edeaf9a3d8b3bd92edba""
-  integrity sha512-eXMaRYK2skomGocoX0x9sBXzx5A1ZVQgXfrW4mTc8dT0zS7olEcyfudAzRC5tIIRgLxQ69B6jut3DI+n5hslPA==
+  version ""0.7.28""
+  resolved ""https://registry.yarnpkg.com/ua-parser-js/-/ua-parser-js-0.7.28.tgz#8ba04e653f35ce210239c64661685bf9121dec31""
+  integrity sha512-6Gurc1n//gjp9eQNXjD9O3M/sMwVtN5S8Lv9bvOYBfKfDNiIIhqiyi01vMBO45u4zkDE420w/e0se7Vs+sIg+g==
 
 uglify-js@3.4.x:
   version ""3.4.10""
@@ -22984,9 +22983,9 @@ uglify-js@3.4.x:
     source-map ""~0.6.1""
 
 uglify-js@^3.1.4, uglify-js@^3.4.9:
-  version ""3.13.3""
-  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.3.tgz#ce72a1ad154348ea2af61f50933c76cc8802276e""
-  integrity sha512-otIc7O9LyxpUcQoXzj2hL4LPWKklO6LJWoJUzNa8A17Xgi4fOeDC8FBDOLHnC/Slo1CQgsZMcM6as0M76BZaig==
+  version ""3.13.4""
+  resolved ""https://registry.yarnpkg.com/uglify-js/-/uglify-js-3.13.4.tgz#592588bb9f47ae03b24916e2471218d914955574""
+  integrity sha512-kv7fCkIXyQIilD5/yQy8O+uagsYIOt5cZvs890W40/e/rvjMSzJw81o9Bg0tkURxzZBROtDQhW2LFjOGoK3RZw==
 
 uid-number@0.0.6:
   version ""0.0.6""
",1,"[""7e9bd7c86df1032d53e752654fe4a446951480bb""]","[""build""]","1. The changes update the 'bin' and 'scripts' fields in two package.json files to improve installer compatibility and update various dependencies in yarn.lock.
2. Modifications to package.json scripts and bin fields, as well as dependency updates in yarn.lock, relate directly to project build configuration and dependency management, aligning with the 'build' label.
3. 'build' is the appropriate label because the changes do not introduce new features (not 'feat'), fix bugs in code logic (not 'fix'), restructure code for readability (not 'refactor'), nor are they limited to documentation, tests, or CI/CD configuration.
4. The 'build' label accurately reflects that these changes are dedicated to build configuration and dependency updates, matching the intended classification."
add a branch name to Slack notifications (#14793),"diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",1,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""cicd""]","1. The changes update Slack notification messages in CI configuration files (.circleci/config.yml and vsts.yml) to include the branch name for both success and failure cases.
2. These modifications are limited to CI workflow scripts, specifically altering the content of notifications sent during CI runs, which aligns with the 'cicd' label definition.
3. The 'cicd' label is appropriate because only CI/CD pipeline configuration files are changed—no build logic, test code, documentation, or application features are affected, ruling out 'build', 'test', 'docs', 'feat', 'fix', or 'refactor'.
4. The 'cicd' label correctly captures that the commit is fully scoped to updating CI pipeline notification logic without impacting other aspects of the codebase."
"move group logical op outside

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
index 5138589..f756981 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/ColumnFilter.vue
@@ -2,40 +2,46 @@
   <div
     class=""backgroundColor pa-2 menu-filter-dropdown""
     :class=""{ nested }""
-    :style=""{ width: nested ? '100%' : '530px' }""
+    :style=""{ width: nested ? '100%' : '630px' }""
   >
     <div class=""grid"" @click.stop>
       <template v-for=""(filter, i) in filters"" dense>
         <template v-if=""filter.status !== 'delete'"">
-          <div v-if=""filter.is_group"" :key=""i"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
-            <div class=""d-flex"" style=""gap: 6px; padding: 0 6px"">
-              <v-icon
-                v-if=""!filter.readOnly""
-                small
-                class=""nc-filter-item-remove-btn""
-                @click.stop=""deleteFilter(filter, i)""
-              >
-                mdi-close-box
-              </v-icon>
-              <span v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
-              <v-select
-                v-else
-                v-model=""filter.logical_op""
-                class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
-                :items=""['and', 'or']""
-                solo
-                flat
-                dense
-                hide-details
-                placeholder=""Group op""
-                @click.stop
-                @change=""saveOrUpdate(filter, i)""
-              >
-                <template #item=""{ item }"">
-                  <span class=""caption font-weight-regular"">{{ item }}</span>
-                </template>
-              </v-select>
-            </div>
+          <template v-if=""filter.is_group"">
+            <v-icon
+              v-if=""!filter.readOnly""
+              small
+              class=""nc-filter-item-remove-btn""
+              @click.stop=""deleteFilter(filter, i)""
+              :key=""i + '_1'""
+            >
+              mdi-close-box
+            </v-icon>
+            <span v-else :key=""i + '_1'"" />
+
+            <span :key=""i + '_2'"" v-if=""!i"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <v-select
+              v-else
+              :key=""i + '_2'""
+              v-model=""filter.logical_op""
+              class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
+              :items=""['and', 'or']""
+              solo
+              flat
+              dense
+              hide-details
+              placeholder=""Group op""
+              @click.stop
+              @change=""saveOrUpdate(filter, i)""
+            >
+              <template #item=""{ item }"">
+                <span class=""caption font-weight-regular"">{{ item }}</span>
+              </template>
+            </v-select>
+            <span :key=""i + '_3'"" style=""grid-column: span 3""></span>
+          </template>
+
+          <div v-if=""filter.is_group"" :key=""i + '_4'"" style=""grid-column: span 5; padding: 6px"" class=""elevation-4"">
             <column-filter
               v-if=""filter.id || shared""
               ref=""nestedFilter""
@@ -54,19 +60,19 @@
           <template v-else>
             <v-icon
               v-if=""!filter.readOnly""
-              :key=""i + '_1'""
+              :key=""i + '_5'""
               small
               class=""nc-filter-item-remove-btn""
               @click.stop=""deleteFilter(filter, i)""
             >
               mdi-close-box
             </v-icon>
-            <span v-else :key=""i + '_1'"" />
-            <span v-if=""!i"" :key=""i + '_2'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
+            <span v-else :key=""i + '_5'"" />
+            <span v-if=""!i"" :key=""i + '_6'"" class=""caption d-flex align-center"">{{ $t('labels.where') }}</span>
 
             <v-select
               v-else
-              :key=""i + '_2'""
+              :key=""i + '_6'""
               v-model=""filter.logical_op""
               class=""flex-shrink-1 flex-grow-0 elevation-0 caption""
               :items=""['and', 'or']""
@@ -84,7 +90,7 @@
             </v-select>
 
             <field-list-auto-complete-dropdown
-              :key=""i + '_3'""
+              :key=""i + '_7'""
               v-model=""filter.fk_column_id""
               class=""caption nc-filter-field-select""
               :columns=""columns""
@@ -94,7 +100,7 @@
             />
 
             <v-select
-              :key=""i + '_4'""
+              :key=""i + '_8'""
               v-model=""filter.comparison_op""
               class=""flex-shrink-1 flex-grow-0 caption nc-filter-operation-select""
               :items=""filterComparisonOp(filter)""
@@ -114,11 +120,11 @@
                 <span class=""caption font-weight-regular"">{{ item.text }}</span>
               </template>
             </v-select>
-            <span v-else :key=""i + '_4'""></span>
+            <span v-else :key=""i + '_8'""></span>
             <span v-if=""['null', 'notnull', 'empty', 'notempty'].includes(filter.comparison_op)"" :key=""i + '_5'"" />
             <v-checkbox
               v-else-if=""types[filter.field] === 'boolean'""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               dense
               :disabled=""filter.readOnly""
@@ -126,7 +132,7 @@
             />
             <v-text-field
               v-else-if=""filter && filter.fk_column_id""
-              :key=""i + '_5'""
+              :key=""i + '_9'""
               v-model=""filter.value""
               solo
               flat
@@ -137,7 +143,7 @@
               @click.stop
               @input=""saveOrUpdate(filter, i)""
             />
-            <span v-else :key=""i + '_5'""></span>
+            <span v-else :key=""i + '_9'""></span>
           </template>
         </template>
       </template>
@@ -411,6 +417,7 @@ export default {
         parentId: this.parentId,
         is_group: true,
         status: 'update',
+        logical_op: 'and',
       });
       this.filters = this.filters.slice();
       const index = this.filters.length - 1;
@@ -478,4 +485,8 @@ export default {
   column-gap: 6px;
   row-gap: 6px;
 }
+
+.nc-filter-value-select {
+  min-width: 100px;
+}
 </style>
",1,"[""4f86f2570b274c45605cc59d9adb38f7ed30cd17""]","[""refactor""]","1. The code reorganizes the structure of logical operators in a Vue component, moving the group logical operator selection outside of a nested block, updates some UI layout, and adds a default value for 'logical_op' in the filter group creation.
2. These changes improve code structure and UI clarity without altering external behavior or adding new features, which aligns with the 'refactor' label definition.
3. The 'refactor' label is appropriate because the modifications are focused on code organization and maintainability; 'feat' is ruled out since no new capability is introduced, and 'fix' does not apply as there is no explicit bug resolution.
4. The 'refactor' label accurately reflects that the commit restructures code for clarity and maintainability without changing its outward behavior."
"use lambda to define backend operations
remove unnecessary spotless definition

It receives this already from the parent pom.
add more tests for Utils.lookupPathFromDecorator","diff --git a/ibis/backends/duckdb/registry.py b/ibis/backends/duckdb/registry.py
index 20ffd6f..3f56f2a 100644
--- a/ibis/backends/duckdb/registry.py
+++ b/ibis/backends/duckdb/registry.py
@@ -107,28 +107,13 @@ def _literal(_, op):
     return sa.cast(sa.literal(value), sqla_type)
 
 
-def _array_column(t, op):
-    (arg,) = op.args
-    sqla_type = to_sqla_type(op.output_dtype)
-    return sa.cast(sa.func.list_value(*map(t.translate, arg)), sqla_type)
-
-
 def _neg_idx_to_pos(array, idx):
     if_ = getattr(sa.func, ""if"")
     arg_length = sa.func.array_length(array)
     return if_(idx < 0, arg_length + sa.func.greatest(idx, -arg_length), idx)
 
 
-def _struct_field(t, op):
-    return sa.func.struct_extract(
-        t.translate(op.arg),
-        sa.text(repr(op.field)),
-        type_=to_sqla_type(op.output_dtype),
-    )
-
-
-def _regex_extract(t, op):
-    string, pattern, index = map(t.translate, op.args)
+def _regex_extract(string, pattern, index):
     result = sa.case(
         [
             (
@@ -149,8 +134,7 @@ def _regex_extract(t, op):
     return result
 
 
-def _json_get_item(t, op):
-    left, path = map(t.translate, op.args)
+def _json_get_item(left, path):
     # Workaround for https://github.com/duckdb/duckdb/issues/5063
     # In some situations duckdb silently does the wrong thing if
     # the path is parametrized.
@@ -197,7 +181,12 @@ def _struct_column(t, op):
 
 operation_registry.update(
     {
-        ops.ArrayColumn: _array_column,
+        ops.ArrayColumn: (
+            lambda t, op: sa.cast(
+                sa.func.list_value(*map(t.translate, op.cols)),
+                to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.ArrayConcat: fixed_arity(sa.func.array_concat, 2),
         ops.ArrayRepeat: fixed_arity(
             lambda arg, times: sa.func.flatten(
@@ -222,7 +211,13 @@ operation_registry.update(
         # TODO: map operations, but DuckDB's maps are multimaps
         ops.Modulus: fixed_arity(operator.mod, 2),
         ops.Round: _round,
-        ops.StructField: _struct_field,
+        ops.StructField: (
+            lambda t, op: sa.func.struct_extract(
+                t.translate(op.arg),
+                sa.text(repr(op.field)),
+                type_=to_sqla_type(op.output_dtype),
+            )
+        ),
         ops.TableColumn: _table_column,
         ops.TimestampDiff: fixed_arity(sa.func.age, 2),
         ops.TimestampFromUNIX: _timestamp_from_unix,
@@ -232,7 +227,7 @@ operation_registry.update(
             lambda *_: sa.cast(sa.func.now(), sa.TIMESTAMP),
             0,
         ),
-        ops.RegexExtract: _regex_extract,
+        ops.RegexExtract: fixed_arity(_regex_extract, 3),
         ops.RegexReplace: fixed_arity(
             lambda *args: sa.func.regexp_replace(*args, ""g""), 3
         ),
@@ -255,7 +250,7 @@ operation_registry.update(
         ops.ArgMin: reduction(sa.func.min_by),
         ops.ArgMax: reduction(sa.func.max_by),
         ops.BitwiseXor: fixed_arity(sa.func.xor, 2),
-        ops.JSONGetItem: _json_get_item,
+        ops.JSONGetItem: fixed_arity(_json_get_item, 2),
         ops.RowID: lambda *_: sa.literal_column('rowid'),
         ops.StringToTimestamp: fixed_arity(sa.func.strptime, 2),
     }

diff --git a/benchmarks/project/pom.xml b/benchmarks/project/pom.xml
index 62030b6..ab87dea 100644
--- a/benchmarks/project/pom.xml
+++ b/benchmarks/project/pom.xml
@@ -123,11 +123,6 @@
       </plugin>
 
       <plugin>
-        <groupId>com.diffplug.spotless</groupId>
-        <artifactId>spotless-maven-plugin</artifactId>
-      </plugin>
-
-      <plugin>
         <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-shade-plugin</artifactId>
         <executions>

diff --git a/lib/utils/Utils.ts b/lib/utils/Utils.ts
index 6de6e05..b03b3e9 100644
--- a/lib/utils/Utils.ts
+++ b/lib/utils/Utils.ts
@@ -338,15 +338,8 @@ export class Utils {
       line++;
     }
 
-    if (stack[line].match(/\(.+\)/i)) {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/\((.*):\d+:\d+\)/)![1],
-      );
-    } else {
-      meta.path = Utils.normalizePath(
-        stack[line].match(/at\s*(.*):\d+:\d+$/)![1],
-      );
-    }
+    const re = stack[line].match(/\(.+\)/i) ? /\((.*):\d+:\d+\)/ : /at\s*(.*):\d+:\d+$/;
+    meta.path = Utils.normalizePath(stack[line].match(re)![1]);
 
     return meta.path;
   }
diff --git a/tests/Utils.test.ts b/tests/Utils.test.ts
index c3e9aa1..4d2a209 100644
--- a/tests/Utils.test.ts
+++ b/tests/Utils.test.ts
@@ -256,7 +256,7 @@ describe('Utils', () => {
       '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
       '    at Object.<anonymous> (/usr/local/var/www/my-project/dist/entities/Customer.js:20:9)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
-      '    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Module.load (internal/modules/cjs/loader.js:643:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
     ];
@@ -272,10 +272,25 @@ describe('Utils', () => {
       '    at Object.<anonymous> (/usr/local/var/www/my-project/src/entities/Customer.ts:9:3)',
       '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
       '    at Module.m._compile (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:473:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
       '    at Object.require.extensions.<computed> [as .ts] (/usr/local/var/www/my-project/node_modules/ts-node/src/index.ts:476:12)',
     ];
     expect(Utils.lookupPathFromDecorator({} as any, stack2)).toBe('/usr/local/var/www/my-project/src/entities/Customer.ts');
+
+    // no parens
+    const stack3 = [
+      '    at Function.lookupPathFromDecorator (/usr/local/var/www/my-project/node_modules/mikro-orm/dist/utils/Utils.js:170:23)',
+      '    at /usr/local/var/www/my-project/node_modules/mikro-orm/dist/decorators/PrimaryKey.js:12:23',
+      '    at DecorateProperty (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:553:33)',
+      '    at Object.decorate (/usr/local/var/www/my-project/node_modules/reflect-metadata/Reflect.js:123:24)',
+      '    at Object.__decorate (/usr/local/var/www/my-project/node_modules/tslib/tslib.js:92:96)',
+      '    at /usr/local/var/www/my-project/dist/entities/Customer.js:20:9',
+      '    at Module._compile (internal/modules/cjs/loader.js:776:30)',
+      '    at Object.Module._extensions.js (internal/modules/cjs/loader.js:787:10)',
+      '    at Module.load (internal/modules/cjs/loader.js:643:32)',
+      '    at Function.Module._load (internal/modules/cjs/loader.js:556:12)',
+    ];
+    expect(Utils.lookupPathFromDecorator({} as any, stack3)).toBe('/usr/local/var/www/my-project/dist/entities/Customer.js');
   });
 
   test('lookup path from decorator on windows', () => {
@@ -287,7 +302,7 @@ describe('Utils', () => {
       '    at Object.<anonymous> (C:\\www\\my-project\\src\\entities\\Customer.ts:7:5)',
       '    at Module._compile (internal/modules/cjs/loader.js:936:30)',
       '    at Module.m._compile (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:493:23)',
-      '    at Module._extensions..js (internal/modules/cjs/loader.js:947:10)',
+      '    at Module._extensions.js (internal/modules/cjs/loader.js:947:10)',
       '    at Object.require.extensions.<computed> [as .ts] (C:\\www\\my-project\\node_modules\\ts-node\\src\\index.ts:496:12)',
       '    at Module.load (internal/modules/cjs/loader.js:790:32)',
       '    at Function.Module._load (internal/modules/cjs/loader.js:703:12)',
",3,"[""5d14de6722eb34c6604a124f6f11cb711f16bd44"", ""7f9721dc9bbf66a3712d59352f64ca089da139f0"", ""c5e86dbc00a13a355bffadeb2db197e2fea5640f""]","[""refactor"", ""build"", ""test""]","1. The changes in 'ibis/backends/duckdb/registry.py' refactor backend operation definitions to use lambdas and fixed_arity, improving code structure without changing behavior; 'benchmarks/project/pom.xml' removes a redundant Spotless plugin definition, affecting build configuration; 'lib/utils/Utils.ts' simplifies a regex selection logic, and 'tests/Utils.test.ts' adds new test cases for Utils.lookupPathFromDecorator.
2. The refactoring in the backend registry aligns with the 'refactor' label as it restructures code for clarity and maintainability; the removal of a plugin from the pom.xml aligns with the 'build' label since it changes build configuration; the new test cases in the test file align with the 'test' label as they directly increase test coverage.
3. 'refactor' is appropriate because the Python code changes do not introduce new features or fix bugs but improve code structure; 'build' is correct for the pom.xml change as it is solely related to the build system, not CI or documentation; 'test' is correct for the test file changes as the modifications are dedicated to adding and updating tests, not fixing behavior or adding features.
4. The assigned labels 'refactor', 'build', and 'test' accurately reflect the nature and scope of the changes, each corresponding to a distinct code artifact or motivation as per the classification rules."
"update CI images from docker buster to bullseye

This will break `perf_image` until the new CI image is built due to the
newly required `--all-tags` parameter to `docker push` that isn't
available for the docker version we run on buster.
rename ELECTRON_CACHE env variable to electron_config_cache (#21313)
update version (nightly.0)","diff --git a/.circleci/config.yml b/.circleci/config.yml
index f8a53ba..c378c7e 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -336,7 +336,7 @@ jobs:
           # Disabling for now, and tracked further investigations
           # in https://github.com/influxdata/k8s-idpe/issues/3038
           docker_layer_caching: false
-          version: 19.03.14
+          version: 20.10.7
       - run: |
           sudo apt-get update
           sudo apt-get install -y docker.io
@@ -355,7 +355,7 @@ jobs:
           BRANCH=$(git rev-parse --abbrev-ref HEAD | tr '/' '.')
           COMMIT_SHA=$(git rev-parse --short HEAD)
           docker build -t quay.io/influxdb/iox:$COMMIT_SHA -t quay.io/influxdb/iox:main -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/iox
+          docker push --all-tags quay.io/influxdb/iox
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags
diff --git a/Dockerfile b/Dockerfile
index 8c23ea2..1df1fd2 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -17,7 +17,7 @@ RUN \
   cp /influxdb_iox/target/release/influxdb_iox /root/influxdb_iox && \
   du -cshx /usr/local/cargo/registry /usr/local/cargo/git /influxdb_iox/target
 
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
     && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates --no-install-recommends \
diff --git a/docker/Dockerfile.ci b/docker/Dockerfile.ci
index db0a8ca..cf9cd15 100644
--- a/docker/Dockerfile.ci
+++ b/docker/Dockerfile.ci
@@ -12,7 +12,7 @@
 
 ARG RUST_VERSION
 # Build actual image used for CI pipeline
-FROM rust:${RUST_VERSION}-slim-buster
+FROM rust:${RUST_VERSION}-slim-bullseye
 
 # When https://github.com/rust-lang/rustup/issues/2686 is fixed, run the command added that
 # will install everything in rust-toolchain.toml here so that components are in the container
@@ -42,7 +42,7 @@ COPY docker/redpanda.gpg /tmp/redpanda.gpg
 # Generated from https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/cfg/setup/bash.deb.sh
 RUN apt-key add /tmp/redpanda.gpg \
     && rm /tmp/redpanda.gpg \
-    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=buster&version=10&arch=x86_64"" \
+    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=bullseye&version=10&arch=x86_64"" \
       > /etc/apt/sources.list.d/vectorized-redpanda.list \
     && apt-get update \
     && apt-get install -y redpanda \
diff --git a/docker/Dockerfile.iox b/docker/Dockerfile.iox
index 42414db..ae1f38e 100644
--- a/docker/Dockerfile.iox
+++ b/docker/Dockerfile.iox
@@ -1,7 +1,7 @@
 ###
 # Dockerfile used for deploying IOx
 ##
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
   && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates gettext-base --no-install-recommends \

diff --git a/docs/tutorial/installation.md b/docs/tutorial/installation.md
index d4af120..1a09eea 100644
--- a/docs/tutorial/installation.md
+++ b/docs/tutorial/installation.md
@@ -82,7 +82,7 @@ with the network at all.
 On environments that have been using older versions of Electron, you might find the
 cache also in `~/.electron`.
 
-You can also override the local cache location by providing a `ELECTRON_CACHE`
+You can also override the local cache location by providing a `electron_config_cache`
 environment variable.
 
 The cache contains the version's official zip file as well as a checksum, stored as

diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true
",3,"[""640cd88df3069a97d8244398414338dd317c5470"", ""f2f52c23b513dd857350f3c163f676d37189d0d3"", ""607ecc92b5f8c084304e406eec725b7dcfa0a562""]","[""cicd"", ""docs"", ""build""]","1. The commit updates CI configuration files to use newer Docker images (buster → bullseye), changes Dockerfiles for build and CI, updates dependency versions and workspace versions in Cargo.toml/Cargo.lock, and corrects a documentation environment variable name.
2. The changes to .circleci/config.yml are scoped to CI configuration, matching the 'cicd' label; the Dockerfile and Dockerfile.iox/ci changes update the build environment, aligning with 'build'; the installation.md documentation change is a textual environment variable rename, fitting 'docs'.
3. 'cicd' is correct for CI workflow changes (not 'build' since it's not a build script), 'build' is appropriate for Dockerfile and dependency version updates (not 'cicd' or 'refactor'), and 'docs' is applicable for documentation updates (not 'feat' or 'fix' since no new feature or bug fix is involved); no test logic is involved, so 'test' is ruled out.
4. The assigned labels 'cicd', 'build', and 'docs' are correct because each code unit is fully dedicated to changes in CI configuration, build environment, and documentation, respectively."
"add Expr.equals benchmark
nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index 78305bb..9c7e6d7 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -1,3 +1,4 @@
+import copy
 import functools
 import itertools
 import string
@@ -340,8 +341,9 @@ def test_execute(benchmark, expression_fn, pt):
     benchmark(expr.execute)
 
 
-def test_repr_tpc_h02(benchmark):
-    part = ibis.table(
+@pytest.fixture
+def part():
+    return ibis.table(
         dict(
             p_partkey=""int64"",
             p_size=""int64"",
@@ -350,7 +352,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""part"",
     )
-    supplier = ibis.table(
+
+
+@pytest.fixture
+def supplier():
+    return ibis.table(
         dict(
             s_suppkey=""int64"",
             s_nationkey=""int64"",
@@ -362,7 +368,11 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""supplier"",
     )
-    partsupp = ibis.table(
+
+
+@pytest.fixture
+def partsupp():
+    return ibis.table(
         dict(
             ps_partkey=""int64"",
             ps_suppkey=""int64"",
@@ -370,14 +380,25 @@ def test_repr_tpc_h02(benchmark):
         ),
         name=""partsupp"",
     )
-    nation = ibis.table(
+
+
+@pytest.fixture
+def nation():
+    return ibis.table(
         dict(n_nationkey=""int64"", n_regionkey=""int64"", n_name=""string""),
         name=""nation"",
     )
-    region = ibis.table(
+
+
+@pytest.fixture
+def region():
+    return ibis.table(
         dict(r_regionkey=""int64"", r_name=""string""), name=""region""
     )
 
+
+@pytest.fixture
+def tpc_h02(part, supplier, partsupp, nation, region):
     REGION = ""EUROPE""
     SIZE = 25
     TYPE = ""BRASS""
@@ -420,7 +441,7 @@ def test_repr_tpc_h02(benchmark):
         ]
     )
 
-    expr = q.sort_by(
+    return q.sort_by(
         [
             ibis.desc(q.s_acctbal),
             q.n_name,
@@ -429,7 +450,9 @@ def test_repr_tpc_h02(benchmark):
         ]
     ).limit(100)
 
-    benchmark(repr, expr)
+
+def test_repr_tpc_h02(benchmark, tpc_h02):
+    benchmark(repr, tpc_h02)
 
 
 def test_repr_huge_union(benchmark):
@@ -478,3 +501,7 @@ def test_complex_datatype_builtins(benchmark, func):
         )
     )
     benchmark(func, datatype)
+
+
+def test_large_expr_equals(benchmark, tpc_h02):
+    benchmark(ir.Expr.equals, tpc_h02, copy.deepcopy(tpc_h02))

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",2,"[""b700285c1f27588922d9c56527cee721bb884682"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""test"", ""docs""]","1. The Python test file adds a new benchmark test function (`test_large_expr_equals`) and introduces several pytest fixtures to support benchmark testing; the YAML file adds commented documentation about enabling L7 headers forwarding in nginx config.
2. The changes in the Python file are entirely dedicated to test logic and benchmarking, aligning with the 'test' label, while the YAML file changes are purely documentation comments, aligning with the 'docs' label.
3. 'test' is appropriate for the Python changes as they do not alter app behavior or fix bugs but extend benchmarking coverage, and 'docs' is correct for the YAML since only comments and references were added, not configuration or build logic.
4. The 'test' label captures the addition of new benchmark tests, and 'docs' appropriately describes the documentation comments added to the configuration file."
"add link to roadmap
split release docs build into separate workflow","diff --git a/packages/plugin-core/README.md b/packages/plugin-core/README.md
index 3c25c9b..c7506d4 100644
--- a/packages/plugin-core/README.md
+++ b/packages/plugin-core/README.md
@@ -187,6 +187,10 @@ When the workspace opens, it will show dialogue to install the recommended exten
 
 See [[FAQ]] to answers for common questions.
 
+# Roadmap
+
+Check out our [public roadmap](https://github.com/orgs/dendronhq/projects/1) to see the features we're working on and to vote for what you want to see next. 
+
 
 # Contributing
 

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest
",2,"[""94202f01e44c58bee4419044f8a18ac5f1a50dff"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce""]","[""docs"", ""cicd""]","1. The commit adds a 'Roadmap' section with a link to the public roadmap in the README.md file, and splits the release docs build steps into a new GitHub Actions workflow file, modifying the existing workflow accordingly.
2. The README.md change is entirely documentation, fitting the 'docs' label, while the changes to CI workflow files (splitting and adjusting YAML files for GitHub Actions) are dedicated to CI/CD pipeline configuration, matching the 'cicd' label.
3. 'docs' is appropriate for the README.md update because it is solely a documentation edit, not a code change, and 'cicd' is correct for the workflow file changes because they are not build system or test changes but only affect CI/CD configuration; neither 'feat', 'fix', 'refactor', 'test', nor 'build' apply here.
4. The 'docs' and 'cicd' labels accurately reflect the distinct and dedicated nature of the documentation and CI workflow changes in this commit."
"set name for topology module
add .nullif() example","diff --git a/topology/pom.xml b/topology/pom.xml
index 389508e..ee6239a 100644
--- a/topology/pom.xml
+++ b/topology/pom.xml
@@ -16,6 +16,7 @@
   </parent>
 
   <artifactId>zeebe-cluster-topology</artifactId>
+  <name>Zeebe Cluster Topology</name>
 
   <properties>
     <proto.dir>${maven.multiModuleProjectDirectory}/topology/src/main/resources/proto</proto.dir>

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",2,"[""8911a972222dc80a242f3f1d9b3596321b3fdeaa"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""build"", ""docs""]","1. The first change adds a <name> element to the topology/pom.xml file, and the second change adds example documentation and an explanatory code block to a Python docstring in ibis/expr/types/generic.py.
2. The addition to pom.xml is a build metadata change, aligning with the 'build' label, while the docstring update is purely documentation, fitting the 'docs' label.
3. 'build' is appropriate for the pom.xml modification because it affects build configuration but not code behavior, and 'docs' is correct for the Python change as it only enhances documentation—neither change involves test logic, CI, or code behavior/functionality.
4. The assigned 'build' and 'docs' labels accurately reflect the scope of the changes: one to build metadata, the other to documentation."
"exception for non-executable processes

related to #36
refactor generate_completion
get ip from forwarded header","diff --git a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
index 3c68047..4668708 100644
--- a/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
+++ b/qa/integration-tests/src/test/java/org/camunda/bpm/broker/it/process/DeployBpmnResourceTest.java
@@ -80,4 +80,22 @@ public class DeployBpmnResourceTest
             .execute();
     }
 
+    @Test
+    public void shouldNotDeployNonExecutableModel()
+    {
+        // given
+        final TngpClient client = clientRule.getClient();
+        final WorkflowsClient workflowService = client.workflows();
+
+        // then
+        exception.expect(BrokerRequestException.class);
+        exception.expectMessage(containsString(""ERROR 203""));
+        exception.expect(BrokerRequestExceptionMatcher.brokerException(1, 1));
+
+        // when
+        workflowService.deploy()
+            .bpmnModelInstance(Bpmn.createProcess().startEvent().endEvent().done())
+            .execute();
+    }
+
 }

diff --git a/src/lib.rs b/src/lib.rs
index dfd8014..15850f7 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -1,11 +1,106 @@
 //! Generates [Nushell](https://github.com/nushell/nushell) completions for [`clap`](https://github.com/clap-rs/clap) based CLIs
 
-use clap::Command;
+use clap::{Arg, Command};
 use clap_complete::Generator;
 
 /// Generate Nushell complete file
 pub struct Nushell;
 
+enum Argument {
+    Short(char),
+    Long(String),
+    ShortAndLong(char, String),
+    Positional(String, bool),
+}
+
+struct ArgumentLine {
+    arg: Argument,
+    takes_values: bool,
+    help: Option<String>,
+}
+
+impl From<&Arg> for ArgumentLine {
+    fn from(arg: &Arg) -> Self {
+        let takes_values = arg
+            .get_num_args()
+            .map(|v| v.takes_values())
+            .unwrap_or(false);
+
+        let help = arg.get_help().map(|s| s.to_string());
+
+        if arg.is_positional() {
+            let id = arg.get_id().to_string();
+            let required = arg.is_required_set();
+            let arg = Argument::Positional(id, required);
+
+            return Self {
+                arg,
+                takes_values,
+                help,
+            };
+        }
+
+        let short = arg.get_short();
+        let long = arg.get_long();
+
+        match short {
+            Some(short) => match long {
+                Some(long) => Self {
+                    arg: Argument::ShortAndLong(short, long.into()),
+                    takes_values,
+                    help,
+                },
+                None => Self {
+                    arg: Argument::Short(short),
+                    takes_values,
+                    help,
+                },
+            },
+            None => match long {
+                Some(long) => Self {
+                    arg: Argument::Long(long.into()),
+                    takes_values,
+                    help,
+                },
+                None => unreachable!(""No short or long option found""),
+            },
+        }
+    }
+}
+
+impl ToString for ArgumentLine {
+    fn to_string(&self) -> String {
+        let mut s = String::new();
+
+        match &self.arg {
+            Argument::Short(short) => s.push_str(format!(""    -{}"", short).as_str()),
+            Argument::Long(long) => s.push_str(format!(""    --{}"", long).as_str()),
+            Argument::ShortAndLong(short, long) => {
+                s.push_str(format!(""    --{}(-{})"", long, short).as_str())
+            }
+            Argument::Positional(positional, required) => {
+                s.push_str(format!(""    {}"", positional).as_str());
+
+                if !*required {
+                    s.push('?');
+                }
+            }
+        }
+
+        if self.takes_values {
+            s.push_str("": string"");
+        }
+
+        if let Some(help) = &self.help {
+            s.push_str(format!(""\t# {}"", help).as_str());
+        }
+
+        s.push('\n');
+
+        s
+    }
+}
+
 impl Generator for Nushell {
     fn file_name(&self, name: &str) -> String {
         format!(""{}.nu"", name)
@@ -37,51 +132,18 @@ fn generate_completion(completions: &mut String, cmd: &Command, is_subcommand: b
 
     let bin_name = cmd.get_bin_name().expect(""Failed to get bin name"");
 
-    if is_subcommand {
-        completions.push_str(format!(""  export extern \""{}\"" [\n"", bin_name).as_str());
+    let name = if is_subcommand {
+        format!(r#""""{}""""#, bin_name)
     } else {
-        completions.push_str(format!(""  export extern {} [\n"", bin_name).as_str());
-    }
+        bin_name.into()
+    };
 
-    let mut s = String::new();
-    for arg in cmd.get_arguments() {
-        if arg.is_positional() {
-            s.push_str(format!(""    {}"", arg.get_id()).as_str());
-            if !arg.is_required_set() {
-                s.push('?');
-            }
-        }
-
-        let long = arg.get_long();
-        if let Some(opt) = long {
-            s.push_str(format!(""    --{}"", opt).as_str());
-        }
+    completions.push_str(format!(""  export extern {} [\n"", name).as_str());
 
-        let short = arg.get_short();
-        if let Some(opt) = short {
-            if long.is_some() {
-                s.push_str(format!(""(-{})"", opt).as_str());
-            } else {
-                s.push_str(format!(""    -{}"", opt).as_str());
-            }
-        }
-
-        if let Some(v) = arg.get_num_args() {
-            if v.takes_values() {
-                // TODO: add more types?
-                // TODO: add possible values?
-                s.push_str("": string"");
-            }
-        }
-
-        if let Some(msg) = arg.get_help() {
-            if arg.is_positional() || long.is_some() || short.is_some() {
-                s.push_str(format!(""\t# {}"", msg).as_str());
-            }
-        }
-
-        s.push('\n');
-    }
+    let s: String = cmd
+        .get_arguments()
+        .map(|arg| ArgumentLine::from(arg).to_string())
+        .collect();
 
     completions.push_str(&s);
     completions.push_str(""  ]\n\n"");

diff --git a/kousa/lib/broth/socket_handler.ex b/kousa/lib/broth/socket_handler.ex
index d142135..5828f30 100644
--- a/kousa/lib/broth/socket_handler.ex
+++ b/kousa/lib/broth/socket_handler.ex
@@ -22,7 +22,7 @@ defmodule Broth.SocketHandler do
   ## initialization boilerplate
 
   @impl true
-  def init(request = %{peer: {ip, _reverse_port}}, _state) do
+  def init(request, _state) do
     props = :cowboy_req.parse_qs(request)
 
     compression =
@@ -37,10 +37,16 @@ defmodule Broth.SocketHandler do
         _ -> :json
       end
 
+    ip =
+      case request.headers do
+        %{""x-forwarded-for"" => v} -> v
+        _ -> nil
+      end
+
     state = %__MODULE__{
       awaiting_init: true,
       user_id: nil,
-      ip: IP.to_string(ip),
+      ip: ip,
       encoding: encoding,
       compression: compression,
       callers: get_callers(request)
diff --git a/kousa/test/_support/ws_client.ex b/kousa/test/_support/ws_client.ex
index aeca704..125da17 100644
--- a/kousa/test/_support/ws_client.ex
+++ b/kousa/test/_support/ws_client.ex
@@ -19,7 +19,9 @@ defmodule BrothTest.WsClient do
 
     @api_url
     |> Path.join(""socket"")
-    |> WebSockex.start_link(__MODULE__, nil, extra_headers: [{""user-agent"", ancestors}])
+    |> WebSockex.start_link(__MODULE__, nil,
+      extra_headers: [{""user-agent"", ancestors}, {""x-forwarded-for"", ""127.0.0.1""}]
+    )
   end
 
   ###########################################################################
",3,"[""21c004b3c40bd3d68f0d32d173a29632765666c8"", ""f1bc5a554af4e617c7d7508f7f16f8fd25c78c91"", ""2f5718743a830d40ddf272ad46f253dbb6d08cff""]","[""test"", ""refactor"", ""fix""]","1. The changes include adding a new integration test to ensure non-executable BPMN models are not deployed, a significant refactor to the Rust function for generating completions, and a fix to correctly extract the IP address from the 'x-forwarded-for' header in the Elixir socket handler (with corresponding test adjustment).
2. The new test file content is fully dedicated to testing logic, matching the 'test' object label; the Rust function restructuring alters code structure without changing external behavior, aligning with the 'refactor' purpose label; the Elixir change corrects IP extraction, addressing a functional bug, which fits the 'fix' purpose label.
3. 'test' is appropriate for the Java test addition as it solely adds a test, not production logic; 'refactor' fits the Rust code because it improves structure and readability without changing observable behavior; 'fix' is correct for the Elixir code since it resolves a bug in IP extraction, not introducing new features or just restructuring.
4. The assigned labels ('test', 'refactor', 'fix') accurately represent the nature and motivation of each code unit per the classification instructions."
"autostart feature fixed
skip flaky test","diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",2,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""fix"", ""test""]","1. The commit removes unused imports in two editor files, fixes the logic of the 'firstStart' flag in 'Container.ts', and skips a flaky test in a test file by marking it with 'test.skip'.
2. The change in 'Container.ts' corrects a behavioral bug with autostart (aligns with 'fix'), while the modification in the test file is a direct change to test logic (aligns with 'test').
3. 'fix' is appropriate for the source code bug correction, not 'feat' (no new feature) or 'refactor' (changes behavior); 'test' is correct for skipping a flaky test, as the change is scoped to test code, not a bug or feature in production logic.
4. The 'fix' and 'test' labels are appropriate because the commit both resolves a code bug and modifies test logic, each matching the respective label definitions."
ecma 7 ready,"diff --git a/config/webpack.config.prod.js b/config/webpack.config.prod.js
index f7c6b23..4a00c65 100644
--- a/config/webpack.config.prod.js
+++ b/config/webpack.config.prod.js
@@ -266,7 +266,7 @@ module.exports = {
     : new UglifyJsPlugin({
       uglifyOptions: {
         ie8: false,
-        ecma: 6,
+        ecma: 7,
         compress: {
           warnings: false,
           // Disabled because of an issue with Uglify breaking seemingly valid code:
",1,"[""6aa63c9b8d4dcdbb401743adc3c9a1020d943250""]","[""build""]","1. The code change updates the 'ecma' version from 6 to 7 in the UglifyJsPlugin configuration within the webpack production config file.
2. This change modifies the build configuration to target a newer ECMAScript version, aligning directly with the 'build' label definition for changes affecting the build system.
3. The 'build' label is appropriate because the modification is strictly within a build configuration artifact and does not alter application logic, documentation, tests, or CI/CD scripts; other labels like 'feat', 'fix', or 'refactor' do not apply.
4. The 'build' label correctly reflects that the update pertains solely to build tooling configuration, specifically the JavaScript minification process."
update renovate config,"diff --git a/.github/workflows/renovate.yml b/.github/workflows/renovate.yml
index 710d1f6..c83d681 100644
--- a/.github/workflows/renovate.yml
+++ b/.github/workflows/renovate.yml
@@ -1,7 +1,7 @@
 name: Renovate
 on:
   schedule:
-    - cron: '0/5 * * * *'
+    - cron: '0 */8 * * *'
 jobs:
   renovate:
     runs-on: ubuntu-latest
",1,"[""6132632f7517195c7333308e9c667cdb756bf0af""]","[""cicd""]","1. The change modifies the cron schedule in the '.github/workflows/renovate.yml' file, altering when the Renovate job is triggered.
2. This change is entirely within a GitHub Actions workflow configuration, which is a CI/CD artifact as per the label definitions.
3. The 'cicd' label is appropriate because the modification is strictly to the automation pipeline configuration, not to application code, documentation, tests, or build scripts; other labels like 'build', 'test', or 'feat' do not apply since no code or test logic is involved.
4. Thus, 'cicd' is the correct label as the change is confined to CI workflow configuration."
"increment failing test retries
update basic test with colors
update version (nightly.0)","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/core/src/components/label/test/basic/index.html b/core/src/components/label/test/basic/index.html
index d0b566c..377e58c 100644
--- a/core/src/components/label/test/basic/index.html
+++ b/core/src/components/label/test/basic/index.html
@@ -19,12 +19,32 @@
     </ion-header>
 
     <ion-content>
+      <div padding>
+        <ion-label>Default</ion-label>
+
+        <ion-label color=""secondary"">Secondary</ion-label>
+
+        <ion-label color=""tertiary"">Tertiary</ion-label>
+
+        <ion-label color=""danger"">Danger</ion-label>
+
+        <ion-label class=""custom"">Custom</ion-label>
+      </div>
+
       <ion-list>
         <ion-item>
           <ion-label>Default</ion-label>
           <ion-input></ion-input>
         </ion-item>
         <ion-item>
+          <ion-label color=""tertiary"">Tertiary</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
+          <ion-label class=""custom"">Custom</ion-label>
+          <ion-input></ion-input>
+        </ion-item>
+        <ion-item>
           <ion-label text-wrap>Wrap label this label just goes on and on and on</ion-label>
           <ion-input></ion-input>
         </ion-item>
@@ -42,6 +62,12 @@
         </ion-item>
       </ion-list>
     </ion-content>
+
+    <style>
+      .custom {
+        color: lightblue;
+      }
+    </style>
   </ion-app>
 </body>
 

diff --git a/Cargo.lock b/Cargo.lock
index e6f659c..cf93556 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.23""
+version = ""0.1.24-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index c58299b..6e51b6e 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.11""
+version = ""0.6.12-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.11"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.11"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.11"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.23"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.12-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.24-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index 5f005a1..e1a9964 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.23""
+version = ""0.1.24-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true
",3,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""c3b5dc77ff3d89d389f6f3a868b17d0a8ca63074"", ""92e940efeee199b1e0bbbc3c9eea7f3dc8221619""]","[""cicd"", ""test"", ""build""]","1. The changes update CI scripts to increase test retry counts, modify an HTML test file to add color variations, and increment version numbers in Cargo.toml and Cargo.lock files.
2. The updates to .ci/scripts/distribution/*.sh are changes to CI/CD pipeline scripts, aligning with the 'cicd' label; the HTML file changes are modifications to test artifacts, matching the 'test' label; the version bumps in Cargo.toml and Cargo.lock are build metadata updates, fitting the 'build' label.
3. 'cicd' is appropriate for the shell script changes since they are exclusively CI/CD-related, not general build logic; 'test' is correct for the HTML file as it is a dedicated test artifact and not application code; 'build' is justified for Cargo.toml and Cargo.lock version updates as they pertain to build configuration, not CI/CD or test logic.
4. The assigned labels 'cicd', 'test', and 'build' accurately reflect the distinct artifact categories and purposes of the code changes in this commit."
"small error msg improvement

refs #1005
svg helper","diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index 0f9cb63..ff5e5f0 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -1,4 +1,4 @@
-import { className, m, ns, style } from '../m';
+import { className, m, ns, svg, style } from '../m';
 import { VNode, VProps } from '../structs';
 
 const h = (tag: string, props?: VProps, ...children: VNode[]) =>
@@ -173,6 +173,28 @@ describe('.m', () => {
     });
   });
 
+  it('should attach ns to props using svg helper', () => {
+    const vnode = {
+      tag: 'svg',
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    expect(svg(vnode)).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
+
   it('should move key to distinct property', () => {
     expect(h('div', { key: 'foo' }, 'foo', h('div'))).toEqual({
       tag: 'div',
",2,"[""a62314d9bb632be6af026686615d14b912250512"", ""4aa3e4c438742ef0fe694ffaf6a181874366d777""]","[""refactor"", ""test""]","1. The commit updates an error message in a Go file and adds a new test case for an SVG helper in a TypeScript test file.
2. The error message update improves clarity but does not change behavior, aligning with 'refactor', while the new test case directly modifies test logic, aligning with 'test'.
3. 'refactor' is appropriate for the error message improvement (not 'docs', as it's not documentation, nor 'fix', as it doesn't resolve a bug), and 'test' is correct for the addition of a new test (not 'feat', since it's not a new feature, nor 'refactor', since it focuses on test logic).
4. The 'refactor' and 'test' labels accurately represent the code changes: one improves code readability/maintainability, the other adds to the test suite."
correct width when --no-quotes is used,"diff --git a/src/output/grid.rs b/src/output/grid.rs
index 37f6c57..ce989e5 100644
--- a/src/output/grid.rs
+++ b/src/output/grid.rs
@@ -8,6 +8,8 @@ use crate::output::file_name::{Classify, Options as FileStyle};
 use crate::output::file_name::{EmbedHyperlinks, ShowIcons};
 use crate::theme::Theme;
 
+use super::file_name::QuoteStyle;
+
 #[derive(PartialEq, Eq, Debug, Copy, Clone)]
 pub struct Options {
     pub across: bool,
@@ -55,27 +57,34 @@ impl<'a> Render<'a> {
                 } else {
                     0
                 };
-
-            let space_filename_offset = if file.name.contains(' ') || file.name.contains('\'') {
-                2
-            } else {
-                0
+            let space_filename_offset = match self.file_style.quote_style {
+                QuoteStyle::QuoteSpaces if file.name.contains(' ') => 2,
+                QuoteStyle::NoQuotes => 0,
+                _ => 0, // Default case
             };
-
             let contents = filename.paint();
-            #[rustfmt::skip]
             let width = match (
                 filename.options.embed_hyperlinks,
                 filename.options.show_icons,
             ) {
-                ( EmbedHyperlinks::On, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + classification_width + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::On, ShowIcons::Never )
-                    => filename.bare_width() + classification_width + space_filename_offset,
-                ( EmbedHyperlinks::Off, ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing) )
-                    => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
-                ( EmbedHyperlinks::Off, _ )
-                    => *contents.width(),
+                (
+                    EmbedHyperlinks::On,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => {
+                    filename.bare_width()
+                        + classification_width
+                        + 1
+                        + (spacing as usize)
+                        + space_filename_offset
+                }
+                (EmbedHyperlinks::On, ShowIcons::Never) => {
+                    filename.bare_width() + classification_width + space_filename_offset
+                }
+                (
+                    EmbedHyperlinks::Off,
+                    ShowIcons::Always(spacing) | ShowIcons::Automatic(spacing),
+                ) => filename.bare_width() + 1 + (spacing as usize) + space_filename_offset,
+                (EmbedHyperlinks::Off, _) => *contents.width(),
             };
 
             grid.add(tg::Cell {
",1,"[""61eaa2d0cca9bd27d6c5f0a8f9b34200b77fdbb0""]","[""fix""]","1. The code modifies the calculation of 'space_filename_offset' and the logic for width calculation to correctly handle the '--no-quotes' option, ensuring the grid output width is accurate when filenames are not quoted.
2. This change addresses incorrect grid formatting (a bug) when the '--no-quotes' option is used, which matches the definition of the 'fix' label as it resolves faulty behavior.
3. 'fix' is appropriate because the motivation is to correct an error in output formatting, not to add new features ('feat') or restructure code without changing behavior ('refactor').
4. The 'fix' label accurately reflects that this code change resolves a bug related to width calculation when the '--no-quotes' option is specified."
"verify property exist in row object

Signed-off-by: Pranav C <pranavxc@gmail.com>
offset tests for min and max read cursors
only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/packages/nc-gui/components/smartsheet/Grid.vue b/packages/nc-gui/components/smartsheet/Grid.vue
index 8ff5b1d..e83e2ab 100644
--- a/packages/nc-gui/components/smartsheet/Grid.vue
+++ b/packages/nc-gui/components/smartsheet/Grid.vue
@@ -534,7 +534,7 @@ const saveOrUpdateRecords = async (args: { metaValue?: TableType; viewMetaValue?
       currentRow.rowMeta.changed = false
       for (const field of (args.metaValue || meta.value)?.columns ?? []) {
         if (isVirtualCol(field)) continue
-        if (currentRow.row[field.title!] !== currentRow.oldRow[field.title!]) {
+        if (field.title! in currentRow.row && currentRow.row[field.title!] !== currentRow.oldRow[field.title!]) {
           await updateOrSaveRow(currentRow, field.title!, {}, args)
         }
       }

diff --git a/storage/reads/array_cursor_test.go b/storage/reads/array_cursor_test.go
index 7c7ad0c..c1e6ff9 100644
--- a/storage/reads/array_cursor_test.go
+++ b/storage/reads/array_cursor_test.go
@@ -1541,6 +1541,34 @@ func TestWindowMinArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := (i % 4) * 15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T00:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:30:00Z"").UnixNano(),
+					},
+					Values: []int64{0, 30, 130, 230, 330},
+				},
+			},
+		},
+		{
 			name:  ""window desc values"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1560,6 +1588,34 @@ func TestWindowMinArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset desc values"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := 60 - (i%4)*15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T00:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:45:00Z"").UnixNano(),
+					},
+					Values: []int64{45, 15, 115, 215, 315},
+				},
+			},
+		},
+		{
 			name:  ""window min int"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1693,6 +1749,34 @@ func TestWindowMaxArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := (i % 4) * 15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:45:00Z"").UnixNano(),
+					},
+					Values: []int64{15, 115, 215, 315, 345},
+				},
+			},
+		},
+		{
 			name:  ""window desc values"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1712,6 +1796,34 @@ func TestWindowMaxArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset desc values"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := 60 - (i%4)*15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:30:00Z"").UnixNano(),
+					},
+					Values: []int64{60, 160, 260, 360, 330},
+				},
+			},
+		},
+		{
 			name:  ""window min int"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",3,"[""c6403b62f8dc0e5bfe25a1c6306fb7040ca447ae"", ""b7e2330fa3a8d7b8a9bff01b707c44e64b845c7b"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""fix"", ""test"", ""cicd""]","1. The change in Grid.vue adds a property existence check to prevent errors when accessing properties on the row object, addressing a potential runtime bug; the changes in array_cursor_test.go add new test cases for offset logic in min/max read cursors; the snyk.yml change modifies the CI workflow to schedule Snyk runs once per day instead of on every push.
2. The Grid.vue change aligns with the 'fix' label as it prevents a bug (runtime error) by ensuring property existence; the array_cursor_test.go changes fit the 'test' label as they are entirely new or extended test cases; the snyk.yml update aligns with the 'cicd' label as it is a configuration change to a CI workflow file.
3. 'fix' is appropriate for Grid.vue because the change resolves a bug, not adding features ('feat') or refactoring for structure ('refactor'); 'test' is correct for array_cursor_test.go because all modifications are test logic, not documentation or code behavior; 'cicd' is correct for snyk.yml because it is a CI workflow configuration, not a build script or documentation.
4. The assigned labels 'fix', 'test', and 'cicd' correctly and specifically capture the motivations and artifacts affected by each code unit, following the label definitions and resolution rules."
simplyfy statement,"diff --git a/src/Object/Merge.ts b/src/Object/Merge.ts
index 1f48efb..06caad1 100644
--- a/src/Object/Merge.ts
+++ b/src/Object/Merge.ts
@@ -96,9 +96,11 @@ type ChooseMergeDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _MergeDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? MergeProp<O, O1, K, OOK, style>
-    : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? MergeProp<O, O1, K, OOK, style>
+      : LibStyle<ChooseMergeDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
diff --git a/src/Object/Patch.ts b/src/Object/Patch.ts
index 2d73784..2c8bd42 100644
--- a/src/Object/Patch.ts
+++ b/src/Object/Patch.ts
@@ -89,9 +89,11 @@ type ChoosePatchDeep<OK, O1K, K extends Key, OOK extends Key, style extends Merg
 @hidden
 */
 export type _PatchDeep<O, O1, K extends Key, OOK extends Key, style extends MergeStyle> =
-    Or<Extends<[O], [never]>, Extends<[O1], [never]>> extends 1 // filter never
+    [O] extends [never]
     ? PatchProp<O, O1, K, OOK>
-    : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
+    : [O1] extends [never]
+      ? PatchProp<O, O1, K, OOK>
+      : LibStyle<ChoosePatchDeep<NoList<O>, NoList<O1>, K, OOK, style>, O, O1, style>
 
 /**
 @hidden
",1,"[""f86944ff00b970d7e2da48abbff43e58bdf29b99""]","[""refactor""]","1. The code changes replace a compound conditional using Or<Extends<...>> with a more direct nested conditional check using [O] extends [never] and [O1] extends [never] in both _MergeDeep and _PatchDeep type definitions, simplifying the logic without altering external behavior.
2. This aligns with the 'refactor' label, as the intent is to improve code readability and simplicity without introducing new features or fixing bugs.
3. The 'refactor' label is appropriate because there is no evidence of bug resolution ('fix'), new functionality ('feat'), or changes to documentation, tests, CI, or build artifacts; the changes are purely structural improvements.
4. The 'refactor' label accurately reflects that the commit restructures and simplifies type logic for clarity without affecting functionality."
auto focus inputs in survey form,"diff --git a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
index b2a90d8..dbad824 100644
--- a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
+++ b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
@@ -6,6 +6,7 @@ import {
   DropZoneRef,
   computed,
   onKeyStroke,
+  onMounted,
   provide,
   ref,
   useEventListener,
@@ -85,6 +86,8 @@ function transition(direction: TransitionDirection) {
 
   setTimeout(() => {
     isTransitioning.value = false
+
+    setTimeout(focusInput, 100)
   }, 1000)
 }
 
@@ -113,6 +116,19 @@ async function goPrevious() {
   goToPrevious()
 }
 
+function focusInput() {
+  if (document && typeof document !== 'undefined') {
+    const inputEl =
+      (document.querySelector('.nc-cell input') as HTMLInputElement) ||
+      (document.querySelector('.nc-cell textarea') as HTMLTextAreaElement)
+
+    if (inputEl) {
+      inputEl.select()
+      inputEl.focus()
+    }
+  }
+}
+
 useEventListener('wheel', (event) => {
   if (Math.abs(event.deltaX) < Math.abs(event.deltaY)) {
     // Scrolling more vertically than horizontally
@@ -130,6 +146,8 @@ useEventListener('wheel', (event) => {
 
 onKeyStroke(['ArrowLeft', 'ArrowDown'], goPrevious)
 onKeyStroke(['ArrowRight', 'ArrowUp', 'Enter', 'Space'], goNext)
+
+onMounted(focusInput)
 </script>
 
 <template>
",1,"[""5373c3036866db58b322b424d3be9dedff57a376""]","[""feat""]","1. The code introduces a new focusInput function and hooks it into the survey form's lifecycle to automatically focus and select input fields when the component is mounted or after a transition.
2. This addition provides new behavior for the user interface by enabling auto-focus on survey form inputs, directly aligning with the 'feat' label's definition of introducing new features.
3. 'feat' is appropriate because this is a new interactive capability; it is not fixing a bug ('fix'), restructuring code ('refactor'), or limited to documentation, tests, CI/CD, or build artifacts.
4. The 'feat' label is justified because the primary motivation and effect of the change is the introduction of a new feature for auto-focusing inputs in the survey form."
setup jest and add m.ts tests,"diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",1,"[""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""test""]","1. The code change adds new test cases and updates existing tests in the 'm.spec.ts' file, focusing on the namespace attachment logic for vnode props.
2. These changes are entirely within a test file and pertain solely to test logic, matching the 'test' label definition for modifications to test files.
3. The 'test' label is appropriate because the scope is exclusively test code; no application logic, documentation, build, or CI/CD scripts are affected, ruling out other labels.
4. The 'test' label accurately reflects that the commit is dedicated to adding and enhancing test coverage for the m.ts functionality."
"cue linter: include all CUE files

Signed-off-by: Andrea Luzzardi <aluzzardi@gmail.com>
ensure ""dist"" dirs exist","diff --git a/ci/cue/lint.cue b/ci/cue/lint.cue
index cdda698..6aac265 100644
--- a/ci/cue/lint.cue
+++ b/ci/cue/lint.cue
@@ -39,7 +39,7 @@ import (
 			// CACHE: copy only *.cue files
 			docker.#Copy & {
 				contents: source
-				include: [""*.cue""]
+				include: [""*.cue"", ""**/*.cue""]
 				dest: ""/cue""
 			},
 

diff --git a/scripts/prepare.js b/scripts/prepare.js
index 9eb8cb8..f285825 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -68,6 +68,9 @@ async function prepare() {
     names.push(json.name)
   }
 
+  // Ensure all ""dist"" directories exist.
+  dirs.forEach(dir => fs.ensureDirSync(join(dir, distId)))
+
   log(``)
   for (let i = 0; i < names.length; i++) {
     const dir = dirs[i]
",2,"[""4c44543a3d9eea37e90a2316717feb01c0e0d83a"", ""ca060bf255a55b99000ddf0c67f7422f28b735a6""]","[""cicd"", ""build""]","1. The first change updates a CI linter script to include all CUE files recursively, and the second change in a JavaScript script ensures that 'dist' directories exist before proceeding.
2. The linter script modification is a change to CI configuration logic, aligning with the 'cicd' label, while the update to 'prepare.js' affects the build preparation process, fitting the 'build' label.
3. 'cicd' is appropriate for the CUE linter script since it is a CI artifact, not core build or feature logic; 'build' is appropriate for the script that manages build directories, not 'cicd' (not a CI config) nor a purpose label (not a bug fix, feature, or refactor).
4. The 'cicd' and 'build' labels are correctly assigned, as each change is dedicated to its respective artifact category without overlap into core purpose or other object labels."
"new ShowDebug parameter

calculate each segment timing
new parameter to show/hide segment debug information
set-poshprompt updated with the new showDebug parameter

Force disabled segment to be visible for debug purpose
rebuild when environment variables change (#11471)","diff --git a/engine.go b/engine.go
index 6cc1ff3..4617ceb 100644
--- a/engine.go
+++ b/engine.go
@@ -67,6 +67,9 @@ func (e *engine) renderText(text string) {
 	prefix := e.activeSegment.getValue(Prefix, "" "")
 	postfix := e.activeSegment.getValue(Postfix, "" "")
 	e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""%s%s%s"", prefix, text, postfix))
+	if *e.env.getArgs().Debug {
+		e.renderer.write(e.activeSegment.Background, e.activeSegment.Foreground, fmt.Sprintf(""(%s:%s)"", e.activeSegment.Type, e.activeSegment.timing))
+	}
 }
 
 func (e *engine) renderSegmentText(text string) {
@@ -107,13 +110,11 @@ func (e *engine) setStringValues(segments []*Segment) {
 	wg.Add(len(segments))
 	defer wg.Wait()
 	cwd := e.env.getcwd()
+	debug := *e.env.getArgs().Debug
 	for _, segment := range segments {
 		go func(s *Segment) {
 			defer wg.Done()
-			err := s.mapSegmentWithWriter(e.env)
-			if err == nil && !s.hasValue(IgnoreFolders, cwd) && s.enabled() {
-				s.stringValue = s.string()
-			}
+			s.setStringValue(e.env, cwd, debug)
 		}(segment)
 	}
 }
diff --git a/main.go b/main.go
index 56ae8a5..d67a640 100644
--- a/main.go
+++ b/main.go
@@ -14,6 +14,7 @@ type args struct {
 	Config      *string
 	Shell       *string
 	PWD         *string
+	Debug       *bool
 }
 
 func main() {
@@ -42,6 +43,10 @@ func main() {
 			""pwd"",
 			"""",
 			""the path you are working in""),
+		Debug: flag.Bool(
+			""debug"",
+			false,
+			""Print debug information""),
 	}
 	flag.Parse()
 	env := &environment{
diff --git a/packages/powershell/oh-my-posh/oh-my-posh.psm1 b/packages/powershell/oh-my-posh/oh-my-posh.psm1
index 9234fc6..1450eb3 100644
--- a/packages/powershell/oh-my-posh/oh-my-posh.psm1
+++ b/packages/powershell/oh-my-posh/oh-my-posh.psm1
@@ -5,6 +5,7 @@
 
 $global:PoshSettings = New-Object -TypeName PSObject -Property @{
     Theme = ""$PSScriptRoot\themes\jandedobbeleer.json"";
+    ShowDebug = $false
 }
 
 function Get-PoshCommand {
@@ -36,9 +37,14 @@ function Set-PoshPrompt {
     param(
         [Parameter(Mandatory = $false)]
         [string]
-        $Theme
+        $Theme,
+        [Parameter(Mandatory = $false)]
+        [bool]
+        $ShowDebug = $false
     )
 
+    $global:PoshSettings.ShowDebug = $ShowDebug
+
     if (Test-Path ""$PSScriptRoot/themes/$Theme.json"") {
         $global:PoshSettings.Theme = ""$PSScriptRoot/themes/$Theme.json""
     }
@@ -68,8 +74,9 @@ function Set-PoshPrompt {
         $startInfo = New-Object System.Diagnostics.ProcessStartInfo
         $startInfo.FileName = Get-PoshCommand
         $config = $global:PoshSettings.Theme
+        $showDebug = $global:PoshSettings.ShowDebug
         $cleanPWD = $PWD.ProviderPath.TrimEnd(""\"")
-        $startInfo.Arguments = ""-config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
+        $startInfo.Arguments = ""-debug=""""$showDebug"""" -config=""""$config"""" -error=$errorCode -pwd=""""$cleanPWD""""""
         $startInfo.Environment[""TERM""] = ""xterm-256color""
         $startInfo.CreateNoWindow = $true
         $startInfo.StandardOutputEncoding = [System.Text.Encoding]::UTF8
diff --git a/segment.go b/segment.go
index 27dd416..4015dac 100644
--- a/segment.go
+++ b/segment.go
@@ -1,6 +1,9 @@
 package main
 
-import ""errors""
+import (
+	""errors""
+	""time""
+)
 
 // Segment represent a single segment and it's configuration
 type Segment struct {
@@ -17,6 +20,7 @@ type Segment struct {
 	writer          SegmentWriter
 	stringValue     string
 	active          bool
+	timing          time.Duration
 }
 
 // SegmentWriter is the interface used to define what and if to write to the prompt
@@ -149,3 +153,26 @@ func (segment *Segment) mapSegmentWithWriter(env environmentInfo) error {
 	}
 	return errors.New(""unable to map writer"")
 }
+
+func (segment *Segment) setStringValue(env environmentInfo, cwd string, debug bool) {
+	err := segment.mapSegmentWithWriter(env)
+	if err != nil || segment.hasValue(IgnoreFolders, cwd) {
+		return
+	}
+	// add timing only in debug
+	if debug {
+		start := time.Now()
+		defer (func() {
+			// force segment rendering to display the time it took
+			// to check if the segment is enabled or not
+			// depending on the segement, calling enabled()
+			// can be time consuming
+			segment.active = true
+			elapsed := time.Since(start)
+			segment.timing = elapsed
+		})()
+	}
+	if segment.enabled() {
+		segment.stringValue = segment.string()
+	}
+}

diff --git a/cli/build.rs b/cli/build.rs
index 548fbb5..d7bed21 100644
--- a/cli/build.rs
+++ b/cli/build.rs
@@ -269,8 +269,17 @@ fn main() {
   // To debug snapshot issues uncomment:
   // op_fetch_asset::trace_serializer();
 
-  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  if let Ok(c) = env::var(""DENO_CANARY"") {
+    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
+  }
+  println!(""cargo:rerun-if-env-changed=DENO_CANARY"");
+
   println!(""cargo:rustc-env=GIT_COMMIT_HASH={}"", git_commit_hash());
+  println!(""cargo:rerun-if-env-changed=GIT_COMMIT_HASH"");
+
+  println!(""cargo:rustc-env=TS_VERSION={}"", ts_version());
+  println!(""cargo:rerun-if-env-changed=TS_VERSION"");
+
   println!(
     ""cargo:rustc-env=DENO_CONSOLE_LIB_PATH={}"",
     deno_console::get_declaration().display()
@@ -322,9 +331,6 @@ fn main() {
 
   println!(""cargo:rustc-env=TARGET={}"", env::var(""TARGET"").unwrap());
   println!(""cargo:rustc-env=PROFILE={}"", env::var(""PROFILE"").unwrap());
-  if let Ok(c) = env::var(""DENO_CANARY"") {
-    println!(""cargo:rustc-env=DENO_CANARY={}"", c);
-  }
 
   let c = PathBuf::from(env::var_os(""CARGO_MANIFEST_DIR"").unwrap());
   let o = PathBuf::from(env::var_os(""OUT_DIR"").unwrap());
",2,"[""bea32587586ca08f390c901a95e9b9c25263f4df"", ""63546c15bfb1284ac6d956eee274e6d7cf263a8f""]","[""feat"", ""build""]","1. The changes introduce a new 'Debug' parameter to the CLI and PowerShell integration, update segment timing calculation and debug rendering, and modify build.rs to trigger rebuilds when certain environment variables change.
2. The addition of the debug parameter and segment timing logic constitutes a new feature, aligning with the 'feat' label, while the build.rs updates to track environment variable changes affect the build system, matching the 'build' label.
3. 'feat' is appropriate because the debug parameter and related logic provide new capability to the CLI and prompt rendering; 'build' is correct because the build.rs changes adjust build triggers and environment variable handling, not CI/CD or documentation. No other labels are as directly relevant.
4. The 'feat' and 'build' labels are justified as the commit both introduces a new user-facing debug feature and modifies build system behavior regarding environment variable tracking."
add gitignore.nix to dep update matrix,"diff --git a/.github/workflows/update-deps.yml b/.github/workflows/update-deps.yml
index e0ccd62..1236f58 100644
--- a/.github/workflows/update-deps.yml
+++ b/.github/workflows/update-deps.yml
@@ -13,6 +13,7 @@ jobs:
           - nixpkgs
           - poetry2nix
           - pre-commit-hooks
+          - gitignore.nix
     steps:
       - name: Checkout
         uses: actions/checkout@v2
",1,"[""c444fdb9e85ce44c5c0c99addc777dd7b6085153""]","[""cicd""]","1. The change adds 'gitignore.nix' to the dependency update matrix in the '.github/workflows/update-deps.yml' file, which is a GitHub Actions workflow configuration.
2. Modifying a workflow YAML file directly relates to continuous integration (CI) setup, aligning with the 'cicd' label definition for CI/CD configuration changes.
3. Although the change affects how dependencies are updated (which could be considered a build concern), the modification is scoped solely to a CI workflow file, so 'cicd' is more precise than 'build' or any purpose label.
4. The 'cicd' label is appropriate because the change is entirely within a CI workflow configuration, matching the label's definition and application instructions."
"get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",1,"[""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""refactor""]","1. The code changes update several job processor classes to retrieve the authorized tenants list through a unified method in the job state, eliminate duplicate extraction logic, and refactor the `JobState` interface and its implementation to accept a map of authorizations instead of a list, centralizing and simplifying tenant authorization handling.
2. These changes align with the 'refactor' label definition by restructuring code to reduce duplication and improve maintainability, without altering the external behavior or introducing new features.
3. The 'refactor' label is appropriate because the modifications focus on internal code quality and structure, not on fixing a bug ('fix'), adding new features ('feat'), or exclusively modifying documentation, tests, CI/CD, or build artifacts.
4. The 'refactor' label accurately reflects the motivation and scope of these changes, which are aimed at consolidating and improving code structure for authorization handling."
"add system get version info Fiddle example (#20536)
correctly read new last flushed index
add a branch name to Slack notifications (#14793)","diff --git a/docs/fiddles/system/system-information/get-version-information/index.html b/docs/fiddles/system/system-information/get-version-information/index.html
new file mode 100644
index 0000000..0867bc3
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/index.html
@@ -0,0 +1,26 @@
+<!DOCTYPE html>
+<html>
+  <head>
+    <meta charset=""UTF-8"">
+  </head>
+  <body>
+    <div>
+      <div>
+        <h1>Get version information</h1>
+        <i>Supports: Win, macOS, Linux <span>|</span> Process: Both</i>
+        <div>
+          <div>
+            <button id=""version-info"">View Demo</button>
+            <span id=""got-version-info""></span>
+          </div>
+          <p>The <code>process</code> module is built into Node.js (therefore you can use this in both the main and renderer processes) and in Electron apps this object has a few more useful properties on it.</p>
+          <p>The example below gets the version of Electron in use by the app.</p>
+          <p>See the <a href=""http://electron.atom.io/docs/api/process"">process documentation <span>(opens in new window)</span></a> for more.</p>
+        </div>
+      </div>
+    </div>
+  </body>
+  <script>
+    require('./renderer.js')
+  </script>
+</html>
diff --git a/docs/fiddles/system/system-information/get-version-information/main.js b/docs/fiddles/system/system-information/get-version-information/main.js
new file mode 100644
index 0000000..1f9f917
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/main.js
@@ -0,0 +1,25 @@
+const { app, BrowserWindow } = require('electron')
+
+let mainWindow = null
+
+function createWindow () {
+  const windowOptions = {
+    width: 600,
+    height: 400,
+    title: 'Get version information',
+    webPreferences: {
+      nodeIntegration: true
+    }
+  }
+
+  mainWindow = new BrowserWindow(windowOptions)
+  mainWindow.loadFile('index.html')
+
+  mainWindow.on('closed', () => {
+    mainWindow = null
+  })
+}
+
+app.on('ready', () => {
+  createWindow()
+})
diff --git a/docs/fiddles/system/system-information/get-version-information/renderer.js b/docs/fiddles/system/system-information/get-version-information/renderer.js
new file mode 100644
index 0000000..40f7f2c
--- /dev/null
+++ b/docs/fiddles/system/system-information/get-version-information/renderer.js
@@ -0,0 +1,8 @@
+const versionInfoBtn = document.getElementById('version-info')
+
+const electronVersion = process.versions.electron
+
+versionInfoBtn.addEventListener('click', () => {
+  const message = `This app is using Electron version: ${electronVersion}`
+  document.getElementById('got-version-info').innerHTML = message
+})

diff --git a/restore/src/main/java/io/camunda/zeebe/restore/PartitionRestoreService.java b/restore/src/main/java/io/camunda/zeebe/restore/PartitionRestoreService.java
index 69b06b6..a4fcb77 100644
--- a/restore/src/main/java/io/camunda/zeebe/restore/PartitionRestoreService.java
+++ b/restore/src/main/java/io/camunda/zeebe/restore/PartitionRestoreService.java
@@ -112,7 +112,7 @@ public class PartitionRestoreService {
         SegmentedJournal.builder()
             .withDirectory(dataDirectory.toFile())
             .withName(partition.name())
-            .withLastWrittenIndex(-1)
+            .withLastFlushedIndex(-1)
             .build()) {
 
       resetJournal(checkpointPosition, journal);

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",3,"[""16d4ace80096557fb3fd48396aa09107241c3131"", ""5ffc5794808647de14f945141692be26ad143006"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""docs"", ""fix"", ""cicd""]","1. Added new example files (HTML, JS) for getting version info in Electron to the documentation, corrected a variable name from 'withLastWrittenIndex' to 'withLastFlushedIndex' in a Java class, and updated CI configuration scripts to include the branch name in Slack notifications.
2. The new example files are documentation artifacts, aligning with the 'docs' label; the Java change corrects an incorrect method call, which fits the 'fix' label for resolving a bug; the CI script changes are modifications to notification logic in CI config files, matching the 'cicd' label.
3. 'docs' is appropriate because the added files are usage examples for documentation purposes, not features or tests; 'fix' is correct as it addresses a likely bug in code behavior, not a refactor or new feature; 'cicd' is suitable since the changes are strictly to CI configuration scripts, not build or test logic.
4. The labels 'docs', 'fix', and 'cicd' accurately reflect the distinct documentation addition, bug fix, and CI configuration update present in this commit."
fix pagination spacing,"diff --git a/website/layouts/Base.tsx b/website/layouts/Base.tsx
index 22d36a2..40f7130 100644
--- a/website/layouts/Base.tsx
+++ b/website/layouts/Base.tsx
@@ -399,7 +399,7 @@ export function Base({ children, headings }: BaseProps) {
                     >
                       <a className=""flex items-center space-x-4 group"">
                         <ArrowLeftIcon className=""h-4 transition-transform duration-100 ease-in-out transform group-hover:-translate-x-1"" />
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Previous
                           </span>
@@ -418,7 +418,7 @@ export function Base({ children, headings }: BaseProps) {
                       aria-label={`Go to ${next.resource?.label}`}
                     >
                       <a className=""flex items-center space-x-4 group"">
-                        <div className=""flex flex-col space-x-1"">
+                        <div className=""flex flex-col space-y-1"">
                           <span className=""text-sm text-gray-500 transition-colors duration-100 ease-in-out group-hover:text-gray-700"">
                             Next
                           </span>
",1,"[""1e05a24486f15889ddf6bf1c711ea2bbffc1a88e""]","[""fix""]","1. The code changes update class names in the pagination component from 'space-x-1' to 'space-y-1', adjusting the spacing between elements for correct vertical alignment.
2. This change directly addresses a UI bug where spacing was incorrectly applied horizontally instead of vertically, aligning with the 'fix' label definition for bug resolution.
3. The 'fix' label is appropriate because the motivation is to correct faulty visual behavior, not to add new features ('feat') or only improve code structure without altering behavior ('refactor').
4. The 'fix' label accurately reflects that this change resolves a specific UI spacing issue in the pagination component."
"skip ruff format in pre-commit ci runner
add getter for protocol id","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6193d96..4ba39d6 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -9,6 +9,7 @@ ci:
     - nixpkgs-fmt
     - prettier
     - ruff
+    - ruff-format
     - shellcheck
     - shfmt
     - statix

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",2,"[""9117fdedb9b5ce0345c31b3e1fa22ae8554944d4"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""cicd"", ""feat""]","1. The first change updates the .pre-commit-config.yaml file to skip 'ruff-format' in the CI runner; the second adds a getter method for protocol id in a Java class.
2. The YAML modification changes the CI configuration, matching the 'cicd' label, while the Java addition introduces new API surface, aligning with the 'feat' label for new feature introduction.
3. 'cicd' is appropriate for the CI config change since it only affects pre-commit settings, not build logic or application code; 'feat' is correct for the Java code as it adds new functionality, not a bug fix or refactor.
4. The assigned labels 'cicd' and 'feat' accurately reflect the independent changes to CI configuration and the addition of a new getter method."
"get ip from forwarded header
make jq use compact json for rebase branch query
fix monorepo.dir prop

Signed-off-by: Carlos Alexandro Becker <caarlos0@gmail.com>","diff --git a/kousa/lib/broth/socket_handler.ex b/kousa/lib/broth/socket_handler.ex
index d142135..5828f30 100644
--- a/kousa/lib/broth/socket_handler.ex
+++ b/kousa/lib/broth/socket_handler.ex
@@ -22,7 +22,7 @@ defmodule Broth.SocketHandler do
   ## initialization boilerplate
 
   @impl true
-  def init(request = %{peer: {ip, _reverse_port}}, _state) do
+  def init(request, _state) do
     props = :cowboy_req.parse_qs(request)
 
     compression =
@@ -37,10 +37,16 @@ defmodule Broth.SocketHandler do
         _ -> :json
       end
 
+    ip =
+      case request.headers do
+        %{""x-forwarded-for"" => v} -> v
+        _ -> nil
+      end
+
     state = %__MODULE__{
       awaiting_init: true,
       user_id: nil,
-      ip: IP.to_string(ip),
+      ip: ip,
       encoding: encoding,
       compression: compression,
       callers: get_callers(request)
diff --git a/kousa/test/_support/ws_client.ex b/kousa/test/_support/ws_client.ex
index aeca704..125da17 100644
--- a/kousa/test/_support/ws_client.ex
+++ b/kousa/test/_support/ws_client.ex
@@ -19,7 +19,9 @@ defmodule BrothTest.WsClient do
 
     @api_url
     |> Path.join(""socket"")
-    |> WebSockex.start_link(__MODULE__, nil, extra_headers: [{""user-agent"", ancestors}])
+    |> WebSockex.start_link(__MODULE__, nil,
+      extra_headers: [{""user-agent"", ancestors}, {""x-forwarded-for"", ""127.0.0.1""}]
+    )
   end
 
   ###########################################################################

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 0e284b0..4a3ec7a 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -22,7 +22,7 @@ jobs:
               | cut -d ' ' -f2 \
               | grep -P '\d+\.x\.x' \
               | xargs printf '""%s""' \
-              | jq -s '{branch: .}')
+              | jq -rcMs '{branch: .}')
 
           echo ""::set-output name=matrix::$branches""
 

diff --git a/www/docs/customization/monorepo.md b/www/docs/customization/monorepo.md
index 6d0e857..e45490f 100644
--- a/www/docs/customization/monorepo.md
+++ b/www/docs/customization/monorepo.md
@@ -18,7 +18,7 @@ project_name: subproj1
 
 monorepo:
   tag_prefix: subproject1/
-  folder: subproj1
+  dir: subproj1
 ```
 
 Then, you can release with (from the project's root directory):
@@ -30,11 +30,11 @@ goreleaser release --rm-dist -f ./subproj1/.goreleaser.yml
 Then, the following is different from a ""regular"" run:
 
 - GoReleaser will then look if current commit has a tag prefixed with `subproject1`, and also the previous tag with the same prefix;
-- Changelog will include only commits that contain changes to files within the `subproj1` folder;
+- Changelog will include only commits that contain changes to files within the `subproj1` directory;
 - Release name gets prefixed with `{{ .ProjectName }} ` if empty;
-- All build's `dir` setting get set to `monorepo.folder` if empty;
+- All build's `dir` setting get set to `monorepo.dir` if empty;
   - if yours is not, you might want to change that manually;
-- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.folder`;
+- Extra files on the release, archives, Docker builds, etc are prefixed with `monorepo.dir`;
 - On templates, `{{.PrefixedTag}}` will be `monorepo.prefix/tag` (aka the actual tag name), and `{{.Tag}}` has the prefix stripped;
 
 The rest of the release process should work as usual.
",3,"[""2f5718743a830d40ddf272ad46f253dbb6d08cff"", ""4638dcdf7011e8e42d11fde04f068f22ee20fa1d"", ""9ed3c0c4a72af977fc9150512fb6538f20a94b22""]","[""fix"", ""cicd"", ""docs""]","1. The code changes include: (a) updating Elixir server logic to extract IP from the 'x-forwarded-for' header instead of the socket peer tuple, (b) modifying a test helper to send the 'x-forwarded-for' header, (c) adjusting a GitHub Actions workflow step to use jq compact JSON output, and (d) fixing documentation to use the correct 'monorepo.dir' property instead of 'folder'.
2. The Elixir and test helper changes address how the application retrieves the client's IP, resolving a bug (aligns with 'fix'); the GitHub Actions workflow change is a CI configuration update (aligns with 'cicd'); the documentation changes correct property names and explanations (aligns with 'docs').
3. 'fix' is appropriate for the code and test changes because they alter behavior to resolve incorrect IP handling, not adding new features ('feat') or refactoring structure ('refactor'); 'cicd' is correct for the workflow YAML change as it only affects CI tooling, not build system ('build'); 'docs' is correct for the markdown edits as they strictly update documentation, not code or tests.
4. The labels 'fix', 'cicd', and 'docs' are each justified as the changes are clearly segmented into bugfix, CI config, and documentation update, matching the label definitions and classification rules."
"removing automatic page push on nav
[gn win] link comctl32.lib to fix component build","diff --git a/ionic/components/nav/test/basic/index.ts b/ionic/components/nav/test/basic/index.ts
index 4b1a8ea..2834f68 100644
--- a/ionic/components/nav/test/basic/index.ts
+++ b/ionic/components/nav/test/basic/index.ts
@@ -63,12 +63,6 @@ class FirstPage {
     }
   }
 
-  onPageDidEnter() {
-    setTimeout(() => {
-      this.nav.push(PrimaryHeaderPage);
-    }, 1000);
-  }
-
   setPages() {
     let items = [
       PrimaryHeaderPage

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",2,"[""cd9e6a2ab17c5961b0f977bb8a06f8545da49a97"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""test"", ""build""]","1. The first code unit removes an automatic push to a new page in a test file, and the second code unit updates the Windows build configuration to include 'comctl32.lib' in the linked libraries.
2. The test file change is strictly within a test directory and modifies test logic, aligning with the 'test' label; the build file change is a direct modification of build configuration, fitting the 'build' label.
3. 'test' is appropriate for the first unit as it is not intended to fix a bug or add a feature but only changes test behavior; 'build' is correct for the second unit because it updates build dependencies, not CI/CD scripts, documentation, or source logic.
4. Assigning 'test' and 'build' uniquely reflects the scope of each code unit—test logic changes and build system adjustment—per the labeling rules."
"update sandbox-option.md (#18275)

Co-Authored-By: Mark Lee <malept@users.noreply.github.com>
docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>
updated test to use rows for action items

references #279","diff --git a/docs/api/sandbox-option.md b/docs/api/sandbox-option.md
index 7d24bee..e293d34 100644
--- a/docs/api/sandbox-option.md
+++ b/docs/api/sandbox-option.md
@@ -113,8 +113,8 @@ window.open = customWindowOpen
 Important things to notice in the preload script:
 
 - Even though the sandboxed renderer doesn't have Node.js running, it still has
-  access to a limited node-like environment: `Buffer`, `process`, `setImmediate`
-  and `require` are available.
+  access to a limited node-like environment: `Buffer`, `process`, `setImmediate`,
+  `clearImmediate` and `require` are available.
 - The preload script can indirectly access all APIs from the main process through the
   `remote` and `ipcRenderer` modules.
 - The preload script must be contained in a single script, but it is possible to have
@@ -162,16 +162,17 @@ feature. We are still not aware of the security implications of exposing some
 Electron renderer APIs to the preload script, but here are some things to
 consider before rendering untrusted content:
 
-- A preload script can accidentally leak privileged APIs to untrusted code.
+- A preload script can accidentally leak privileged APIs to untrusted code,
+  unless [`contextIsolation`](../tutorial/security.md#3-enable-context-isolation-for-remote-content)
+  is also enabled.
 - Some bug in V8 engine may allow malicious code to access the renderer preload
   APIs, effectively granting full access to the system through the `remote`
-  module.
+  module. Therefore, it is highly recommended to
+  [disable the `remote` module](../tutorial/security.md#15-disable-the-remote-module).
+  If disabling is not feasible, you should selectively
+  [filter the `remote` module](../tutorial/security.md#16-filter-the-remote-module).
 
 Since rendering untrusted content in Electron is still uncharted territory,
 the APIs exposed to the sandbox preload script should be considered more
 unstable than the rest of Electron APIs, and may have breaking changes to fix
 security issues.
-
-One planned enhancement that should greatly increase security is to block IPC
-messages from sandboxed renderers by default, allowing the main process to
-explicitly define a set of messages the renderer is allowed to send.

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/ionic/components/card/test/advanced/main.html b/ionic/components/card/test/advanced/main.html
index 7c56a7d..c19ea12 100644
--- a/ionic/components/card/test/advanced/main.html
+++ b/ionic/components/card/test/advanced/main.html
@@ -19,16 +19,20 @@
       </p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left>
-        <icon star></icon>
-        Star
-      </button>
-      <button clear item-right class=""activated"">
-        <icon share></icon>
-        Share.activated
-      </button>
-    </ion-item>
+    <ion-row no-padding>
+      <ion-col>
+        <button clear small>
+          <icon star></icon>
+          Star
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small class=""activated"">
+          <icon share></icon>
+          Share.activated
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
@@ -51,19 +55,24 @@
       <p>Hello. I am a paragraph.</p>
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left danger class=""activated"">
-        <icon star></icon>
-        Favorite.activated
-      </button>
-      <button clear item-left danger>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <ion-note item-right>
-        Right Note
-      </ion-note>
-    </ion-item>
+    <ion-row center no-padding>
+      <ion-col width-75>
+        <button clear small danger class=""activated"">
+          <icon star></icon>
+          Favorite.activated
+        </button>
+        <button clear small danger>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col text-right>
+        <button clear small>
+          <icon share></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
   </ion-card>
 
   <ion-card>
@@ -76,20 +85,27 @@
       This card was breaking the border radius.
     </ion-card-content>
 
-    <ion-item>
-      <button clear item-left dark>
-        <icon star></icon>
-        Favorite
-      </button>
-      <button clear item-right dark>
-        <icon musical-notes></icon>
-        Listen
-      </button>
-      <button clear item-right dark>
-        <icon share-alt></icon>
-        Share
-      </button>
-    </ion-item>
+    <ion-row text-center no-padding>
+      <ion-col>
+        <button clear small dark>
+          <icon star></icon>
+          Favorite
+        </button>
+      </ion-col>
+
+      <ion-col>
+        <button clear small dark>
+          <icon musical-notes></icon>
+          Listen
+        </button>
+      </ion-col>
+      <ion-col>
+        <button clear small dark>
+          <icon share-alt></icon>
+          Share
+        </button>
+      </ion-col>
+    </ion-row>
 
   </ion-card>
 
",3,"[""dbb8617214aaa8b56b827deef1265d9ee38765bd"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""19feaea1885eb015759b5c7a5d785521f2b8a212""]","[""docs"", ""build"", ""test""]","1. The changes include updates to a Markdown documentation file, upgrades to Docker Compose files (including a PostgreSQL version change), and modifications to an HTML test fixture for UI layout.
2. The sandbox-option.md file is modified to clarify and expand documentation, aligning with the 'docs' label; the docker-compose.yml files are updated to a new Compose version and PostgreSQL image, which pertains to the build environment and matches the 'build' label; the main.html test file is refactored to use rows and columns for action items, fitting the 'test' label as it is fully scoped to test artifacts.
3. 'docs' is correct for documentation changes, not 'refactor' or 'fix' as no code behavior is altered; 'build' is appropriate for Docker Compose and dependency environment changes, not 'cicd' as these are not CI scripts; 'test' is suitable for changes solely in test artifacts, not 'feat' or 'fix' as no production feature or bug is addressed in those files.
4. The assigned labels 'docs', 'build', and 'test' are appropriate because each code unit is fully scoped to documentation, build configuration, or test artifacts, respectively, with no overlap or ambiguity."
"auto focus inputs in survey form
remove duplicated variables","diff --git a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
index b2a90d8..dbad824 100644
--- a/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
+++ b/packages/nc-gui/pages/[projectType]/form/[viewId]/index/survey.vue
@@ -6,6 +6,7 @@ import {
   DropZoneRef,
   computed,
   onKeyStroke,
+  onMounted,
   provide,
   ref,
   useEventListener,
@@ -85,6 +86,8 @@ function transition(direction: TransitionDirection) {
 
   setTimeout(() => {
     isTransitioning.value = false
+
+    setTimeout(focusInput, 100)
   }, 1000)
 }
 
@@ -113,6 +116,19 @@ async function goPrevious() {
   goToPrevious()
 }
 
+function focusInput() {
+  if (document && typeof document !== 'undefined') {
+    const inputEl =
+      (document.querySelector('.nc-cell input') as HTMLInputElement) ||
+      (document.querySelector('.nc-cell textarea') as HTMLTextAreaElement)
+
+    if (inputEl) {
+      inputEl.select()
+      inputEl.focus()
+    }
+  }
+}
+
 useEventListener('wheel', (event) => {
   if (Math.abs(event.deltaX) < Math.abs(event.deltaY)) {
     // Scrolling more vertically than horizontally
@@ -130,6 +146,8 @@ useEventListener('wheel', (event) => {
 
 onKeyStroke(['ArrowLeft', 'ArrowDown'], goPrevious)
 onKeyStroke(['ArrowRight', 'ArrowUp', 'Enter', 'Space'], goNext)
+
+onMounted(focusInput)
 </script>
 
 <template>

diff --git a/packages/core/src/components/item/item.ios.scss b/packages/core/src/components/item/item.ios.scss
index 4de5455..6c4d11a 100644
--- a/packages/core/src/components/item/item.ios.scss
+++ b/packages/core/src/components/item/item.ios.scss
@@ -47,15 +47,6 @@ $item-ios-detail-push-color:              $list-ios-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-ios-detail-push-svg:                ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-ios-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Background for the divider
-$item-ios-divider-background:             #f7f7f7 !default;
-
-/// @prop - Color for the divider
-$item-ios-divider-color:                  #222 !default;
-
-/// @prop - Padding for the divider
-$item-ios-divider-padding:                5px 15px !default;
-
 
 // iOS Item
 // --------------------------------------------------
diff --git a/packages/core/src/components/item/item.md.scss b/packages/core/src/components/item/item.md.scss
index 1dd1800..3dadbc0 100644
--- a/packages/core/src/components/item/item.md.scss
+++ b/packages/core/src/components/item/item.md.scss
@@ -35,21 +35,6 @@ $item-md-detail-push-color:          $list-md-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-md-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-md-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-md-divider-color:              #858585 !default;
-
-/// @prop - Background for the divider
-$item-md-divider-background:         #fff !default;
-
-/// @prop - Font size for the divider
-$item-md-divider-font-size:          $item-md-body-text-font-size !default;
-
-/// @prop - Border bottom for the divider
-$item-md-divider-border-bottom:      1px solid $list-md-border-color !default;
-
-/// @prop - Padding for the divider
-$item-md-divider-padding:            5px 15px !default;
-
 
 .item-md {
   @include padding-horizontal($item-md-padding-start, 0);
diff --git a/packages/core/src/components/item/item.wp.scss b/packages/core/src/components/item/item.wp.scss
index 2c4aae6..07b9266 100644
--- a/packages/core/src/components/item/item.wp.scss
+++ b/packages/core/src/components/item/item.wp.scss
@@ -41,21 +41,6 @@ $item-wp-detail-push-color:          $input-wp-border-color !default;
 /// @prop - Icon for the detail arrow
 $item-wp-detail-push-svg:            ""<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 12 20'><path d='M2,20l-2-2l8-8L0,2l2-2l10,10L2,20z' fill='#{$item-wp-detail-push-color}'/></svg>"" !default;
 
-/// @prop - Color for the divider
-$item-wp-divider-color:              $list-wp-text-color !default;
-
-/// @prop - Background for the divider
-$item-wp-divider-background:         #fff !default;
-
-/// @prop - Bodrer bottom for the divider
-$item-wp-divider-border-bottom:      1px solid $list-wp-border-color !default;
-
-/// @prop - Font size for the divider
-$item-wp-divider-font-size:          2rem !default;
-
-/// @prop - Padding for the divider
-$item-wp-divider-padding:            5px 15px !default;
-
 
 .item-wp {
   @include padding-horizontal($item-wp-padding-start, 0);
",2,"[""5373c3036866db58b322b424d3be9dedff57a376"", ""cd7e8c3d3549ea05115b3f02586eeba894d86906""]","[""feat"", ""refactor""]","1. The code adds logic to auto-focus inputs in the survey form (survey.vue) and removes duplicated SCSS variables from three style files.
2. The auto-focus logic introduces new behavior to the survey form, aligning with the 'feat' label, while the SCSS changes improve structure by removing redundancy without altering external behavior, aligning with 'refactor'.
3. 'feat' is appropriate for the survey form update because it adds user-facing functionality, not just fixing or restructuring; 'refactor' is correct for the SCSS changes as they streamline code without changing functionality, not introducing features or fixing bugs.
4. The 'feat' and 'refactor' labels together accurately capture the addition of a new feature in the form and the codebase cleanup in the styles, respectively."
"add page balckwhitelist and pdf
set cursor position in setHorizontalRule correctly, fix #2429
update deps","diff --git a/src/_locales/common/messages.json b/src/_locales/common/messages.json
index e8524ac..3a596d6 100644
--- a/src/_locales/common/messages.json
+++ b/src/_locales/common/messages.json
@@ -4,11 +4,21 @@
     ""zh_CN"": ""添加"",
     ""zh_TW"": ""新增""
   },
+  ""blacklist"": {
+    ""en"": ""Blacklist"",
+    ""zh_CN"": ""黑名单"",
+    ""zh_TW"": ""黑名單""
+  },
   ""cancel"": {
     ""en"": ""Cancel"",
     ""zh_CN"": ""取消"",
     ""zh_TW"": ""取消""
   },
+  ""changes_confirm"": {
+    ""en"": ""Changes not saved. Close anyway?"",
+    ""zh_CN"": ""修改未保存。确认关闭？"",
+    ""zh_TW"": ""修改未保存。確定關閉？""
+  },
   ""confirm"": {
     ""en"": ""Confirm"",
     ""zh_CN"": ""确认"",
@@ -93,5 +103,10 @@
     ""en"": ""words"",
     ""zh_CN"": ""个"",
     ""zh_TW"": ""个""
+  },
+  ""whitelist"": {
+    ""en"": ""Whitelist"",
+    ""zh_CN"": ""白名单"",
+    ""zh_TW"": ""白名單""
   }
 }
diff --git a/src/_locales/options/messages.json b/src/_locales/options/messages.json
index ada2488..e7d699a 100644
--- a/src/_locales/options/messages.json
+++ b/src/_locales/options/messages.json
@@ -119,6 +119,11 @@
     ""zh_CN"": ""反馈问题"",
     ""zh_TW"": ""軟體使用疑問和建言""
   },
+  ""match_pattern_description"": {
+    ""en"": ""Specify URLs as match patterns. <a href=\""https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Match_patterns#Examples\"" target=\""_blank\"">Examples</a>. Empty fields will be removed."",
+    ""zh_CN"": ""网址支持匹配模式（<a href=\""https://developer.mozilla.org/zh-CN/Add-ons/WebExtensions/Match_patterns#范例\"" target=\""_blank\"">例子</a>）。留空保存即可清除。"",
+    ""zh_TW"": ""網址支援匹配模式（<a href=\""https://developer.mozilla.org/zh-CN/Add-ons/WebExtensions/Match_patterns#范例\"" target=\""_blank\"">例子</a>）。留空儲存即可清除。""
+  },
   ""msg_updated"": {
     ""en"": ""Successfully updated"",
     ""zh_CN"": ""设置已更新"",
@@ -319,6 +324,21 @@
     ""zh_CN"": ""开启后，本扩展会自动识别输入框以及常见编辑器，如 CodeMirror、ACE 和 Monaco。"",
     ""zh_TW"": ""開啟后，本程式會自動識別輸入框以及常見編輯器，如 CodeMirror、ACE 和 Monaco。""
   },
+  ""opt_pdf_blackwhitelist_help"": {
+    ""en"": ""Blacklisted PDF links will not jump to Saladict PDF Viewer."",
+    ""zh_CN"": ""黑名单匹配的 PDF 链接将不会跳转到 Saladict 打开。"",
+    ""zh_TW"": ""黑名單匹配的 PDF 連結將不會跳轉到 Saladict 開啟。""
+  },
+  ""opt_pdf_sniff"": {
+    ""en"": ""Enable PDF Sniffer"",
+    ""zh_CN"": ""默认用本扩展浏览 PDF"",
+    ""zh_TW"": ""使用本應用程式瀏覽 PDF""
+  },
+  ""opt_pdf_sniff_help"": {
+    ""en"": ""If turned on， PDF links will be automatically captured."",
+    ""zh_CN"": ""开启后所有 PDF 链接将自动跳转到本扩展打开（包括本地，如果在扩展管理页面勾选了允许）。"",
+    ""zh_TW"": ""開啟後所有 PDF 連結將自動跳轉到本擴充套件開啟（包括本地，如果在擴充套件管理頁面勾選了允許）。""
+  },
   ""opt_profile_change"": {
     ""en"": ""This option may change base on \""Profile\""."",
     ""zh_CN"": ""此选项会因「情景模式」而改变。"",
@@ -329,6 +349,16 @@
     ""zh_CN"": ""输入时显示候选"",
     ""zh_TW"": ""輸入時顯示候選""
   },
+  ""opt_sel_blackwhitelist"": {
+    ""en"": ""Selection Black/White List"",
+    ""zh_CN"": ""划词黑白名单"",
+    ""zh_TW"": ""選詞黑白名單""
+  },
+  ""opt_sel_blackwhitelist_help"": {
+    ""en"": ""Saladict will not react to selection in blacklisted pages."",
+    ""zh_CN"": ""黑名单匹配的页面 Saladict 将不会响应鼠标划词。"",
+    ""zh_TW"": ""黑名單匹配的頁面 Saladict 將不會響應滑鼠劃詞。""
+  },
   ""opt_sel_lang"": {
     ""en"": ""Selection Languages"",
     ""zh_CN"": ""划词语言"",
diff --git a/src/options/components/options/BlackWhiteList/index.tsx b/src/options/components/options/BlackWhiteList/index.tsx
new file mode 100644
index 0000000..52708dd
--- /dev/null
+++ b/src/options/components/options/BlackWhiteList/index.tsx
@@ -0,0 +1,69 @@
+import React from 'react'
+import { Props } from '../typings'
+import { formItemLayout } from '../helpers'
+import MatchPatternModal from '../../MatchPatternModal'
+
+import { FormComponentProps } from 'antd/lib/form'
+import { Form, Button } from 'antd'
+
+export type BlackWhiteListProps = Props & FormComponentProps
+
+interface BlackWhiteListState {
+  editingArea: '' | 'pdfWhitelist' | 'pdfBlacklist' | 'whitelist' | 'blacklist'
+}
+
+export class BlackWhiteList extends React.Component<BlackWhiteListProps, BlackWhiteListState> {
+  constructor (props: BlackWhiteListProps) {
+    super(props)
+    this.state = {
+      editingArea: ''
+    }
+  }
+
+  closeModal = () => {
+    this.setState({ editingArea: '' })
+  }
+
+  render () {
+    const { t, config } = this.props
+
+    return (
+      <Form>
+        <Form.Item
+          {...formItemLayout}
+          label={t('opt_sel_blackwhitelist')}
+          help={t('opt_sel_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'blacklist' })}
+          >{t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'whitelist' })}
+          >{t('common:whitelist')}</Button>
+        </Form.Item>
+        <Form.Item
+          {...formItemLayout}
+          label={`PDF ${t('nav_BlackWhiteList')}`}
+          help={t('opt_pdf_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'pdfBlacklist' })}
+          >PDF {t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'pdfWhitelist' })}
+          >PDF {t('common:whitelist')}</Button>
+        </Form.Item>
+        <MatchPatternModal
+          t={t}
+          config={config}
+          area={this.state.editingArea}
+          onClose={this.closeModal}
+        />
+      </Form>
+    )
+  }
+}
+
+export default BlackWhiteList
diff --git a/src/options/components/options/PDF/index.tsx b/src/options/components/options/PDF/index.tsx
new file mode 100644
index 0000000..3e7772d
--- /dev/null
+++ b/src/options/components/options/PDF/index.tsx
@@ -0,0 +1,72 @@
+import React from 'react'
+import { Props } from '../typings'
+import { updateConfigOrProfile, formItemLayout } from '../helpers'
+import MatchPatternModal from '../../MatchPatternModal'
+
+import { FormComponentProps } from 'antd/lib/form'
+import { Form, Switch, Button } from 'antd'
+
+export type PDFProps = Props & FormComponentProps
+
+interface PDFState {
+  editingArea: '' | 'pdfWhitelist' | 'pdfBlacklist'
+}
+
+export class PDF extends React.Component<PDFProps, PDFState> {
+  constructor (props: PDFProps) {
+    super(props)
+
+    this.state = {
+      editingArea: ''
+    }
+  }
+
+  closeModal = () => {
+    this.setState({ editingArea: '' })
+  }
+
+  render () {
+    const { t, config } = this.props
+    const { getFieldDecorator } = this.props.form
+
+    return (
+      <Form>
+        <Form.Item
+          {...formItemLayout}
+          label={t('opt_pdf_sniff')}
+          help={t('opt_pdf_sniff_help')}
+        >{
+          getFieldDecorator('config#pdfSniff', {
+            initialValue: config.pdfSniff,
+            valuePropName: 'checked',
+          })(
+            <Switch />
+          )
+        }</Form.Item>
+        <Form.Item
+          {...formItemLayout}
+          label={t('nav_BlackWhiteList')}
+          help={t('opt_pdf_blackwhitelist_help')}
+        >
+          <Button
+            style={{ marginRight: 10 }}
+            onClick={() => this.setState({ editingArea: 'pdfBlacklist' })}
+          >PDF {t('common:blacklist')}</Button>
+          <Button
+            onClick={() => this.setState({ editingArea: 'pdfWhitelist' })}
+          >PDF {t('common:whitelist')}</Button>
+        </Form.Item>
+        <MatchPatternModal
+          t={t}
+          config={config}
+          area={this.state.editingArea}
+          onClose={this.closeModal}
+        />
+      </Form>
+    )
+  }
+}
+
+export default Form.create<PDFProps>({
+  onValuesChange: updateConfigOrProfile
+})(PDF)

diff --git a/packages/extension-horizontal-rule/src/horizontal-rule.ts b/packages/extension-horizontal-rule/src/horizontal-rule.ts
index 6f583e1..c905b63 100644
--- a/packages/extension-horizontal-rule/src/horizontal-rule.ts
+++ b/packages/extension-horizontal-rule/src/horizontal-rule.ts
@@ -49,15 +49,14 @@ export const HorizontalRule = Node.create<HorizontalRuleOptions>({
           // set cursor after horizontal rule
           .command(({ tr, dispatch }) => {
             if (dispatch) {
-              const { parent, pos } = tr.selection.$from
-              const posAfter = pos + 1
-              const nodeAfter = tr.doc.nodeAt(posAfter)
+              const { $to } = tr.selection
+              const posAfter = $to.end()
 
-              if (nodeAfter) {
-                tr.setSelection(TextSelection.create(tr.doc, posAfter))
+              if ($to.nodeAfter) {
+                tr.setSelection(TextSelection.create(tr.doc, $to.pos))
               } else {
                 // add node after horizontal rule if it’s the end of the document
-                const node = parent.type.contentMatch.defaultType?.create()
+                const node = $to.parent.type.contentMatch.defaultType?.create()
 
                 if (node) {
                   tr.insert(posAfter, node)

diff --git a/package.json b/package.json
index 3696132..ba002d2 100755
--- a/package.json
+++ b/package.json
@@ -34,7 +34,6 @@
     ""koa-router"": ""~7.4.0"",
     ""koa-session"": ""~5.10.1"",
     ""koa-static"": ""~5.0.0"",
-    ""koa2-ratelimit"": ""~0.8.0"",
     ""koa2-swagger-ui"": ""~2.13.2"",
     ""node-fetch"": ""^2.5.0"",
     ""passport-github"": ""~1.1.0"",
diff --git a/src/index.ts b/src/index.ts
index 847e8aa..8c9baff 100755
--- a/src/index.ts
+++ b/src/index.ts
@@ -4,7 +4,6 @@ import * as Koa from 'koa';
 import * as bodyParser from 'koa-bodyparser';
 import * as session from 'koa-session';
 import * as serve from 'koa-static';
-// import { RateLimit } from 'koa2-ratelimit';
 import { Server } from 'net';
 
 import { setupPassport } from './auth';
diff --git a/src/typings/koa-router.d.ts b/src/typings/koa-router.d.ts
deleted file mode 100644
index f891ed8..0000000
--- a/src/typings/koa-router.d.ts
+++ /dev/null
@@ -1,16 +0,0 @@
-import * as koa from 'koa-router';
-import { IUserSession } from '../models';
-import { ILogger } from '../logger';
-
-declare module 'koa-router' {
-  export interface IRouterContext {
-    state: { user: IUserSession | undefined };
-    logger: ILogger;
-  }
-}
-
-declare module 'koa' {
-  export interface Context {
-    logger: ILogger;
-  }
-}
diff --git a/src/typings/koa2-ratelimit/index.d.ts b/src/typings/koa2-ratelimit/index.d.ts
deleted file mode 100644
index cc73228..0000000
--- a/src/typings/koa2-ratelimit/index.d.ts
+++ /dev/null
@@ -1,13 +0,0 @@
-declare module 'koa2-ratelimit' {
-  import * as Koa from 'koa';
-  interface Props {
-    interval: { min?: number; hour?: number }; // 15 minutes = 15*60*1000
-    max: number;
-    message?: string;
-    prefixKey?: string;
-    getUserId?: (ctx: Koa.Context) => Promise<string>;
-  }
-  export namespace RateLimit {
-    function middleware(options: Props): Koa.Middleware;
-  }
-}
diff --git a/src/typings/mockingoose/index.d.ts b/src/typings/mockingoose/index.d.ts
deleted file mode 100644
index 757c4e4..0000000
--- a/src/typings/mockingoose/index.d.ts
+++ /dev/null
@@ -1,5 +0,0 @@
-declare module 'mockingoose' {
-  const mockingoose: any;
-
-  export default mockingoose;
-}
",3,"[""9b1c0fc20b614513384a1e562317dbf076eb8ef0"", ""34d80114704679118e9bb6058e0d6c7aa03fd4b5"", ""f46c6c6c26a14312aa05a77ff2a14aebd74e13ac""]","[""feat"", ""fix"", ""build""]","1. The commit introduces new options and UI components for page black/whitelisting and PDF handling, modifies localization files to support these features, fixes cursor placement after inserting a horizontal rule, and removes the 'koa2-ratelimit' dependency and related typings.
2. The addition of black/whitelist and PDF options is a new feature (aligns with 'feat'), the cursor placement adjustment resolves a specific bug (aligns with 'fix'), and the dependency/typings removal reflects a build system update (aligns with 'build').
3. 'feat' is appropriate for the new functional options and UI, not 'refactor' or 'fix' since these are not bug fixes or structural changes; 'fix' is correct for the cursor logic correction, not 'feat' or 'refactor' since it addresses a bug; 'build' fits the dependency and type removal, not 'cicd' or 'test' as these changes impact the build system and type support, not CI or testing artifacts.
4. The assigned labels 'feat', 'fix', and 'build' are appropriate as they directly correspond to the addition of new features, a targeted bug fix, and build/dependency maintenance respectively."
add --ignore-existing to all npx commands,"diff --git a/docs/getting-started/getting-started.md b/docs/getting-started/getting-started.md
index dc6db37..3ef9d0a 100644
--- a/docs/getting-started/getting-started.md
+++ b/docs/getting-started/getting-started.md
@@ -13,7 +13,7 @@ npm install -g @angular/cli
 **Using `npx`**
 
 ```bash
-npx create-nx-workspace myworkspace
+npx --ignore-existing create-nx-workspace myworkspace
 ```
 
 **Using `npm init`**
diff --git a/docs/guides/react-and-angular.md b/docs/guides/react-and-angular.md
index c1929a2..a5651ff 100644
--- a/docs/guides/react-and-angular.md
+++ b/docs/guides/react-and-angular.md
@@ -11,7 +11,7 @@ To show how Nx does it, let's build two applications (one in Angular, and one in
 Let's start by creating a new Nx workspace. The easiest way to do this is to use npx.
 
 ```bash
-npx create-nx-workspace happynrwl --preset=empty
+npx --ignore-existing create-nx-workspace happynrwl --preset=empty
 ```
 
 ## Creating an Angular Application
diff --git a/docs/guides/react.md b/docs/guides/react.md
index e1647fd..eac848e 100644
--- a/docs/guides/react.md
+++ b/docs/guides/react.md
@@ -16,13 +16,13 @@ Nx has first class support for React: you can create React applications and libr
 Create a new Nx workspace. The easiest way to do it is to use npx.
 
 ```bash
-npx create-nx-workspace happynrwl --preset=empty
+npx --ignore-existing create-nx-workspace happynrwl --preset=empty
 ```
 
 You can also create a workspace with a React application in place by running:
 
 ```bash
-npx create-nx-workspace happynrwl --preset=react
+npx --ignore-existing create-nx-workspace happynrwl --preset=react
 ```
 
 ## Generating a React Application
diff --git a/docs/tutorial/01-create-application.md b/docs/tutorial/01-create-application.md
index ea87ecf..967a56e 100644
--- a/docs/tutorial/01-create-application.md
+++ b/docs/tutorial/01-create-application.md
@@ -7,7 +7,7 @@ In this tutorial you will use Nx to build a full-stack application out of common
 **Start by creating a new workspace.**
 
 ```bash
-npx create-nx-workspace myorg
+npx --ignore-existing create-nx-workspace myorg
 ```
 
 When asked about 'preset', select `empty`.
",1,"[""fc9af4d0b93d69be4e201ffb18da04324e8a4a87""]","[""docs""]","1. The commit updates several documentation files to modify the usage of the 'npx' command by adding the '--ignore-existing' flag in code snippets and instructions.
2. These changes are entirely within markdown files under the 'docs' directory and only affect instructional content, not application logic or test code, which aligns with the 'docs' label definition.
3. The 'docs' label is appropriate because the modifications are purely in documentation text, not code behavior ('fix', 'feat', 'refactor'), tests ('test'), CI/CD files ('cicd'), or build configuration ('build').
4. The 'docs' label accurately describes documentation-only changes that update command usage instructions for users."
"convert to record
fixing deploying to kubernetes

Signed-off-by: Rajesh Rajendran <rjshrjndrn@gmail.com>","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
index cc998c6..65c8550 100755
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/stream/ExporterDirectorDistributionTest.java
@@ -167,13 +167,8 @@ public final class ExporterDirectorDistributionTest {
    * <p>This makes sure that even if we miss one export position event, we distribute the event
    * later again, which makes tests less flaky.
    */
-  private static final class ClockShifter implements ConditionEvaluationListener<Void> {
-
-    private final ControlledActorClock clock;
-
-    public ClockShifter(final ControlledActorClock clock) {
-      this.clock = clock;
-    }
+  private record ClockShifter(ControlledActorClock clock)
+      implements ConditionEvaluationListener<Void> {
 
     @Override
     public void conditionEvaluated(final EvaluatedCondition<Void> condition) {

diff --git a/.github/workflows/frontend.yaml b/.github/workflows/frontend.yaml
index 7e42967..77e4abf 100644
--- a/.github/workflows/frontend.yaml
+++ b/.github/workflows/frontend.yaml
@@ -22,26 +22,22 @@ jobs:
           ${{ runner.OS }}-build-
           ${{ runner.OS }}-
 
+    - uses: azure/k8s-set-context@v1
+      with:
+        method: kubeconfig
+        kubeconfig: ${{ secrets.OSS_KUBECONFIG }} # Use content of kubeconfig in secret.
+      id: setcontext
     - name: Install
       run: npm install
 
-    - name: Build
-      run: npm run build:staging
-      env:
-        ENVIRONMENT: staging
-
-    - name: Deploy
-      env:
-        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
-        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
-        AWS_REGION: eu-central-1
-        AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
+    - name: Build and deploy
       run: |
-        aws configure set default.s3.signature_version s3v4
-        aws --endpoint-url https://${{secrets.DOMAIN_NAME}}/frontend/ s3 cp \
-          --recursive \
-          --region ""$AWS_REGION"" \
-          public s3://$AWS_S3_BUCKET_NAME
+        cd frontend
+        bash build.sh
+        cp -arl public frontend
+        minio_pod=$(kubectl get po -n db -l app.kubernetes.io/name=minio -n db --output custom-columns=name:.metadata.name | tail -n+2)
+        kubectl -n db cp frontend $minio_pod:/data/
+        rm -rf frontend
 
     # - name: Debug Job
     #   if: ${{ failure() }}
",2,"[""3346331a963766c8193170fb130adad2e658ada2"", ""3f2eec37f76c1ad9408e423e49fe5bfe3e17d943""]","[""refactor"", ""cicd""]","1. The code changes include converting a Java inner class to a record in a test file and modifying a GitHub Actions workflow to change the build and deployment process for Kubernetes.
2. The Java test file change is a structural update (class to record) and does not alter behavior, aligning with the 'refactor' label; the GitHub Actions workflow change updates CI/CD deployment steps, which fits the 'cicd' label.
3. 'refactor' is appropriate for the test file because the change is internal code restructuring, not a new feature, bug fix, or test logic change; 'cicd' is correct for the workflow file since it is a CI/CD configuration and not a build, test, or documentation change.
4. The assigned 'refactor' and 'cicd' labels correctly reflect the respective structural code improvement in a test file and the CI/CD pipeline update for Kubernetes deployment."
"remove unnecessary start argument from `range`
ensure checksum persist flushes to disk
allow users to share their playground session","diff --git a/ibis/backends/dask/tests/execution/test_window.py b/ibis/backends/dask/tests/execution/test_window.py
index 75a7331..6bfc5e3 100644
--- a/ibis/backends/dask/tests/execution/test_window.py
+++ b/ibis/backends/dask/tests/execution/test_window.py
@@ -489,7 +489,7 @@ def test_project_list_scalar(npartitions):
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pandas/tests/execution/test_window.py b/ibis/backends/pandas/tests/execution/test_window.py
index 8f292b3..effa372 100644
--- a/ibis/backends/pandas/tests/execution/test_window.py
+++ b/ibis/backends/pandas/tests/execution/test_window.py
@@ -436,7 +436,7 @@ def test_project_list_scalar():
     expr = table.mutate(res=table.ints.quantile([0.5, 0.95]))
     result = expr.execute()
 
-    expected = pd.Series([[1.0, 1.9] for _ in range(0, 3)], name=""res"")
+    expected = pd.Series([[1.0, 1.9] for _ in range(3)], name=""res"")
     tm.assert_series_equal(result.res, expected)
 
 
diff --git a/ibis/backends/pyspark/tests/test_basic.py b/ibis/backends/pyspark/tests/test_basic.py
index 3850919..14fe677 100644
--- a/ibis/backends/pyspark/tests/test_basic.py
+++ b/ibis/backends/pyspark/tests/test_basic.py
@@ -19,7 +19,7 @@ from ibis.backends.pyspark.compiler import _can_be_replaced_by_column_name  # no
 def test_basic(con):
     table = con.table(""basic_table"")
     result = table.compile().toPandas()
-    expected = pd.DataFrame({""id"": range(0, 10), ""str_col"": ""value""})
+    expected = pd.DataFrame({""id"": range(10), ""str_col"": ""value""})
 
     tm.assert_frame_equal(result, expected)
 
@@ -28,9 +28,7 @@ def test_projection(con):
     table = con.table(""basic_table"")
     result1 = table.mutate(v=table[""id""]).compile().toPandas()
 
-    expected1 = pd.DataFrame(
-        {""id"": range(0, 10), ""str_col"": ""value"", ""v"": range(0, 10)}
-    )
+    expected1 = pd.DataFrame({""id"": range(10), ""str_col"": ""value"", ""v"": range(10)})
 
     result2 = (
         table.mutate(v=table[""id""])
@@ -44,8 +42,8 @@ def test_projection(con):
         {
             ""id"": range(0, 20, 2),
             ""str_col"": ""value"",
-            ""v"": range(0, 10),
-            ""v2"": range(0, 10),
+            ""v"": range(10),
+            ""v2"": range(10),
         }
     )
 

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/playground/docker-compose.yml b/playground/docker-compose.yml
new file mode 100644
index 0000000..b8ac6aa
--- /dev/null
+++ b/playground/docker-compose.yml
@@ -0,0 +1,18 @@
+version: '3.3'
+
+services:
+  db:
+    container_name: panda-mysql
+    image: mariadb:10.7.1-focal
+    restart: always
+    ports:
+      - 3310:3306
+    environment:
+      MARIADB_ROOT_PASSWORD: root
+      MARIADB_DATABASE: panda
+    volumes:
+      - panda-mysql:/var/lib/mysql
+
+volumes:
+  panda-mysql:
+    driver: local
diff --git a/playground/package.json b/playground/package.json
index eab6f62..0feccbb 100644
--- a/playground/package.json
+++ b/playground/package.json
@@ -9,6 +9,9 @@
     ""start"": ""next start"",
     ""lint"": ""next lint"",
     ""dev"": ""next dev"",
+    ""db:start"": ""docker-compose up -d"",
+    ""db:stop"": ""docker-compose down"",
+    ""db:push"": ""prisma db push --skip-generate"",
     ""db:generate"": ""prisma generate"",
     ""db:reset"": ""prisma migrate reset"",
     ""db:studio"": ""prisma studio""
diff --git a/playground/prisma/dev.db b/playground/prisma/dev.db
deleted file mode 100644
index aa8281f..0000000
Binary files a/playground/prisma/dev.db and /dev/null differ
diff --git a/playground/prisma/migrations/20230204163131_init/migration.sql b/playground/prisma/migrations/20230204163131_init/migration.sql
deleted file mode 100644
index b3c34f7..0000000
--- a/playground/prisma/migrations/20230204163131_init/migration.sql
+++ /dev/null
@@ -1,8 +0,0 @@
--- CreateTable
-CREATE TABLE ""Session"" (
-    ""id"" TEXT NOT NULL PRIMARY KEY,
-    ""code"" TEXT NOT NULL,
-    ""config"" TEXT NOT NULL,
-    ""view"" TEXT NOT NULL DEFAULT 'code',
-    ""createdAt"" DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
-);
diff --git a/playground/prisma/migrations/20230208183556_/migration.sql b/playground/prisma/migrations/20230208183556_/migration.sql
deleted file mode 100644
index 619fd84..0000000
--- a/playground/prisma/migrations/20230208183556_/migration.sql
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
-  Warnings:
-
-  - You are about to drop the column `config` on the `Session` table. All the data in the column will be lost.
-
-*/
--- RedefineTables
-PRAGMA foreign_keys=OFF;
-CREATE TABLE ""new_Session"" (
-    ""id"" TEXT NOT NULL PRIMARY KEY,
-    ""code"" TEXT NOT NULL,
-    ""theme"" TEXT NOT NULL DEFAULT '',
-    ""view"" TEXT NOT NULL DEFAULT 'code',
-    ""createdAt"" DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
-);
-INSERT INTO ""new_Session"" (""code"", ""createdAt"", ""id"", ""view"") SELECT ""code"", ""createdAt"", ""id"", ""view"" FROM ""Session"";
-DROP TABLE ""Session"";
-ALTER TABLE ""new_Session"" RENAME TO ""Session"";
-PRAGMA foreign_key_check;
-PRAGMA foreign_keys=ON;
diff --git a/playground/prisma/migrations/20230529181831_init/migration.sql b/playground/prisma/migrations/20230529181831_init/migration.sql
new file mode 100644
index 0000000..ffe5546
--- /dev/null
+++ b/playground/prisma/migrations/20230529181831_init/migration.sql
@@ -0,0 +1,9 @@
+-- CreateTable
+CREATE TABLE `Session` (
+    `id` VARCHAR(191) NOT NULL,
+    `code` TEXT NOT NULL,
+    `theme` TEXT NOT NULL,
+    `createdAt` DATETIME(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3),
+
+    PRIMARY KEY (`id`)
+) DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
diff --git a/playground/prisma/migrations/migration_lock.toml b/playground/prisma/migrations/migration_lock.toml
index e5e5c47..e5a788a 100644
--- a/playground/prisma/migrations/migration_lock.toml
+++ b/playground/prisma/migrations/migration_lock.toml
@@ -1,3 +1,3 @@
 # Please do not edit this file manually
 # It should be added in your version-control system (i.e. Git)
-provider = ""sqlite""
\ No newline at end of file
+provider = ""mysql""
\ No newline at end of file
diff --git a/playground/prisma/schema.prisma b/playground/prisma/schema.prisma
index e84678a..9e1281e 100644
--- a/playground/prisma/schema.prisma
+++ b/playground/prisma/schema.prisma
@@ -2,16 +2,14 @@ generator client {
   provider = ""prisma-client-js""
 }
 
-// Using SQLite for local development
 datasource db {
-  provider = ""sqlite""
-  url      = ""file:dev.db""
+  provider = ""mysql""
+  url      = env(""DATABASE_URL"")
 }
 
 model Session {
-  id        String   @id
-  code      String
-  theme     String   @default("""")
-  view      String   @default(""code"")
+  id        String   @id @default(cuid())
+  code      String   @db.Text
+  theme     String   @db.Text
   createdAt DateTime @default(now())
 }
diff --git a/playground/src/app/[id]/page.tsx b/playground/src/app/[id]/page.tsx
index 40c21f0..a88d2b9 100644
--- a/playground/src/app/[id]/page.tsx
+++ b/playground/src/app/[id]/page.tsx
@@ -6,9 +6,9 @@ const Page = async (props: any) => {
     params: { id },
   } = props
 
-  const initialState = await prisma?.session.findFirst({
+  const initialState = await prisma.session.findFirst({
     where: { id },
-    select: { code: true, theme: true, view: true },
+    select: { code: true, theme: true },
   })
 
   return <Playground intialState={initialState} />
diff --git a/playground/src/components/Editor.tsx b/playground/src/components/Editor.tsx
index 8263dba..e82469a 100644
--- a/playground/src/components/Editor.tsx
+++ b/playground/src/components/Editor.tsx
@@ -123,10 +123,7 @@ export const Editor = (props: EditorProps) => {
 
   return (
     <Flex flex=""1"" direction=""column"" align=""flex-start"">
-      <Tabs
-        defaultValue={value.view}
-        className={css({ flex: '1', width: 'full', display: 'flex', flexDirection: 'column' })}
-      >
+      <Tabs defaultValue=""code"" className={css({ flex: '1', width: 'full', display: 'flex', flexDirection: 'column' })}>
         <TabList
           className={css({
             px: '6',
diff --git a/playground/src/components/usePlayground.ts b/playground/src/components/usePlayground.ts
index 74b6069..a959fca 100644
--- a/playground/src/components/usePlayground.ts
+++ b/playground/src/components/usePlayground.ts
@@ -4,7 +4,6 @@ import { Layout } from './LayoutControl'
 export type State = {
   code: string
   theme: string
-  view: string
 }
 
 export type UsePlayGroundProps = {
@@ -51,7 +50,7 @@ export const App = () => {
       body: JSON.stringify(state),
     })
       .then((response) => response.json())
-      .then((data) => {
+      .then(({ data }) => {
         history.pushState({ id: data.id }, '', data.id)
         setIsPristine(true)
       })
diff --git a/playground/src/pages/api/share.ts b/playground/src/pages/api/share.ts
index 23f8b9e..e6f3f26 100644
--- a/playground/src/pages/api/share.ts
+++ b/playground/src/pages/api/share.ts
@@ -7,17 +7,16 @@ import { prisma } from '../../client/prisma'
 const schema = z.object({
   code: z.string(),
   theme: z.string(),
-  view: z.enum(['code', 'config']).optional(),
 })
 
 const handler = async (req: NextApiRequest, res: NextApiResponse) =>
   match(req)
     .with({ method: 'POST' }, async () => {
       try {
-        const { code, theme } = schema.parse(req.body)
+        const data = schema.parse(req.body)
         const id = nanoid(10)
-        await prisma.session.create({ data: { id, code, theme } })
-        return res.status(200).json({ id })
+        const session = await prisma.session.create({ data: { id, ...data }, select: { id: true } })
+        return res.status(200).json({ success: true, data: session })
       } catch (e) {
         console.log(e)
         return res.status(500).json({ success: false })
",3,"[""15f8d95754a0b6865ea475ca9e515272a07bf6ba"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""9c2c7ea1d4935d30e014ca807a4f9cb1665b1e41""]","[""refactor"", ""test"", ""feat""]","1. The changes include removing the unnecessary start argument from range in multiple test files, updating and adding test logic for snapshot checksum persistence, and extensive modifications to the playground application to enable session sharing, migrate database support from SQLite to MySQL, and update schema/models accordingly.
2. The range argument simplification and checksum persistence test are modifications to test files, aligning with the 'test' label, while the playground changes add a new feature (session sharing), update database configuration, and refactor schema/model code, aligning with 'feat' for the new sharing capability and 'refactor' for cleanup/removal of unused fields and migration logic.
3. The session sharing and DB migration introduce new user-facing capabilities ('feat'), the test changes are strictly test logic ('test'), and the removal of unused fields and migration from SQLite to MySQL in schema/model code is a structural improvement without changing core behavior ('refactor'); alternative labels like 'fix' do not apply as there is no direct bug fix, and 'build'/'cicd' are not relevant since no build or CI artifacts are the focus.
4. The assigned labels 'feat', 'refactor', and 'test' are appropriate as they precisely capture the new feature addition, structural code improvement, and test logic updates present in this commit."
"add instruction for finding version
enable recovery test

related to camunda-tngp/zeebe#353","diff --git a/.github/ISSUE_TEMPLATE/_bug_report_chs.md b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
index 42a2e0f..44a33db 100644
--- a/.github/ISSUE_TEMPLATE/_bug_report_chs.md
+++ b/.github/ISSUE_TEMPLATE/_bug_report_chs.md
@@ -36,7 +36,7 @@ assignees: ''
 ## 设备信息
 - 操作系统: [] <!-- 如 [Window10] -->
 - 浏览器版本: [] <!-- 如 [Chrome77] -->
-- 沙拉查词版本: [] <!-- 如 [v7.0.0] -->
+- 沙拉查词版本: [] <!-- 如 [v7.0.0] （在扩展管理页面查看） -->
 
 <!-- 请在下方 ## 开头行之间的空白处填写 -->
 

diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
index 22b8590..db1b553 100644
--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerRecoveryTest.java
@@ -116,7 +116,6 @@ public class BrokerRecoveryTest
         ClockUtil.reset();
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldCreateWorkflowInstanceAfterRestart()
     {
@@ -136,7 +135,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtTaskAfterRestart()
     {
@@ -166,7 +164,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceWithLockedTaskAfterRestart()
     {
@@ -200,7 +197,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldContinueWorkflowInstanceAtSecondTaskAfterRestart()
     {
@@ -237,7 +233,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasWorkflowInstanceEvent(wfInstanceEvent(""WORKFLOW_INSTANCE_COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldDeployNewWorkflowVersionAfterRestart()
     {
@@ -412,7 +407,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""COMPLETED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveIncidentAfterRestart()
     {
@@ -443,7 +437,6 @@ public class BrokerRecoveryTest
         waitUntil(() -> eventRecorder.hasTaskEvent(taskEvent(""CREATED"")));
     }
 
-    @Ignore(""Recovery of workflow deployment event fails - see https://github.com/camunda-tngp/zeebe/issues/353"")
     @Test
     public void shouldResolveFailedIncidentAfterRestart()
     {
",2,"[""af0a5f7ab9d71fe20aa0888f682368f32b26fe18"", ""f2cc48b74bf92fe22cc265cff4224565f910a921""]","[""docs"", ""test""]","1. The first code change updates a documentation template by adding an instruction on where to find the version number; the second code change removes @Ignore annotations from multiple test methods in a test file, thereby enabling those tests.
2. The documentation update directly aligns with the 'docs' label, as it solely modifies instructional text; the test file change aligns with the 'test' label, as it strictly alters test code by enabling tests.
3. 'docs' is appropriate for the template change because it does not affect code behavior, ruling out 'feat', 'fix', or 'refactor'; 'test' is correct for the test file because the modifications are limited to test logic, not production code, so purpose labels are not suitable.
4. The 'docs' and 'test' labels are appropriate because the commit consists of a documentation update and test-related changes, each confined to their respective artifact categories."
"allow disabling dynamic queue
README
do not use scripts and binaries from the libcc repo","diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/README.md b/README.md
index 11a24b3..56e8d2a 100644
--- a/README.md
+++ b/README.md
@@ -16,7 +16,9 @@ oclif: create your own CLI
 
 # Description
 
-This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku). Most CLI tools in Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
+This is a framework for building CLIs in Node.js. This framework was built out of the [Heroku CLI](https://cli.heroku.com) but generalized to build any custom CLI. It's designed both for simple CLIs that can be just a single file with a few flag options, or for very complex CLIs that have many commands (like git or heroku).
+
+Most CLI tools for Node are simple flag parsers but oclif is much more than that—though without the overhead of making simple CLIs quick to write with minimal boilerplate.
 
 # Features
 

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |
",3,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""363f84c7da411468b4103da8e0b39ca48cfd8327"", ""45837af24a33308a70a3454f0f650f9fe728e272""]","[""fix"", ""docs"", ""cicd""]","1. The commit introduces a conditional check in jobs.service.ts to allow disabling dynamic queue pausing/resuming, updates the README for clarity, and modifies CI configuration files (.circleci/config.yml and vsts-gn.yml) to stop using scripts and binaries from the libcc repo.
2. The jobs.service.ts change addresses incorrect queue behavior in certain environments, aligning with the 'fix' label; the README change updates documentation, fitting the 'docs' label; and the CI config changes update CI scripts, matching the 'cicd' label.
3. 'fix' is appropriate for the jobs.service.ts change because it resolves a deployment-specific bug, not a feature addition or a refactor; 'docs' is correct for the README since it only alters documentation; 'cicd' is correct for the CI files as they are dedicated CI configuration updates, not build system or test logic changes.
4. The assigned labels 'fix', 'docs', and 'cicd' accurately reflect the purpose and object of each code unit, following the classification rules for tangled commits."
"added suported tuple types
publish sdks after docs/build","diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/
",2,"[""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244""]","[""refactor"", ""cicd""]","1. The first code unit modifies a TypeScript type definition in `src/List/Tuple.ts` to use a generic parameter and `NonNullable`, improving type safety and clarity without changing runtime behavior; the second code unit updates `.circleci/config.yml` to add a `docs/build` step to CI workflows.
2. The Tuple type change enhances code structure and maintainability, aligning with the 'refactor' label, while the CI config update is a direct modification to a CI/CD pipeline, fitting the 'cicd' label.
3. 'refactor' is appropriate for the Tuple type change since it does not introduce new features or fix bugs, and 'cicd' is correct for the CircleCI config change as it is entirely scoped to CI configuration, not build logic or code features.
4. The labels 'refactor' and 'cicd' accurately reflect the motivation and artifact scope of the respective changes in this commit."
"add link to roadmap
init environ cache
fix node test cases run into infinite loop","diff --git a/packages/plugin-core/README.md b/packages/plugin-core/README.md
index 3c25c9b..c7506d4 100644
--- a/packages/plugin-core/README.md
+++ b/packages/plugin-core/README.md
@@ -187,6 +187,10 @@ When the workspace opens, it will show dialogue to install the recommended exten
 
 See [[FAQ]] to answers for common questions.
 
+# Roadmap
+
+Check out our [public roadmap](https://github.com/orgs/dendronhq/projects/1) to see the features we're working on and to vote for what you want to see next. 
+
 
 # Contributing
 

diff --git a/src/environment.go b/src/environment.go
index ae5e26a..0c961c5 100644
--- a/src/environment.go
+++ b/src/environment.go
@@ -229,6 +229,7 @@ func (env *environment) environ() map[string]string {
 	if env.environCache != nil {
 		return env.environCache
 	}
+	env.environCache = make(map[string]string)
 	const separator = ""=""
 	values := os.Environ()
 	for value := range values {

diff --git a/packages/designer/tests/document/node/node.test.ts b/packages/designer/tests/document/node/node.test.ts
index dd20bd3..113360d 100644
--- a/packages/designer/tests/document/node/node.test.ts
+++ b/packages/designer/tests/document/node/node.test.ts
@@ -26,7 +26,7 @@ import rootHeaderMetadata from '../../fixtures/component-metadata/root-header';
 import rootContentMetadata from '../../fixtures/component-metadata/root-content';
 import rootFooterMetadata from '../../fixtures/component-metadata/root-footer';
 
-describe.skip('Node 方法测试', () => {
+describe('Node 方法测试', () => {
   let editor: Editor;
   let designer: Designer;
   let project: Project;
@@ -474,15 +474,16 @@ describe.skip('Node 方法测试', () => {
   it('didDropIn / didDropOut', () => {
     const form = doc.getNode('node_k1ow3cbo');
     designer.createComponentMeta(divMetadata);
+    designer.createComponentMeta(formMetadata);
     const callbacks = form.componentMeta.getMetadata().configure.advanced?.callbacks;
     const fn1 = callbacks.onNodeAdd = jest.fn();
     const fn2 = callbacks.onNodeRemove = jest.fn();
     const textField = doc.getNode('node_k1ow3cc9');
     form.didDropIn(textField);
-    expect(fn1).toHaveBeenCalledWith(textField, form);
+    expect(fn1).toHaveBeenCalledWith(textField.internalToShellNode(), form.internalToShellNode());
 
     form.didDropOut(textField);
-    expect(fn2).toHaveBeenCalledWith(textField, form);
+    expect(fn2).toHaveBeenCalledWith(textField.internalToShellNode(), form.internalToShellNode());
   });
 
   it('hover', () => {
",3,"[""94202f01e44c58bee4419044f8a18ac5f1a50dff"", ""dc50bd35462a49058c91a939fc8830ae7a9eb692"", ""d2c3f0ba6f85b659b76636a91ea9ab2b5a95a720""]","[""docs"", ""fix"", ""test""]","1. The README.md file was updated to add a link to the public roadmap, the environment.go file was changed to initialize environCache, and node.test.ts was modified to unskip and correct test logic to avoid infinite loops.
2. The README.md change aligns with 'docs' as it updates documentation, the environment.go change aligns with 'fix' as it addresses a bug involving uninitialized cache, and the node.test.ts modifications align with 'test' as they correct and enable test cases.
3. 'docs' is correct because the change is purely to documentation, not code behavior; 'fix' is appropriate for environment.go since it prevents a runtime bug, not a structural refactor or new feature; 'test' is correct for changes to test logic, as they are scoped to test files and concern test execution, not feature or bug logic in production code.
4. The assigned labels 'docs', 'fix', and 'test' are accurate because each code unit exclusively matches one of these categories according to the classification rules."
make sure root is being watched and setRoot called when it changes,"diff --git a/packages/core/src/components/nav/nav.tsx b/packages/core/src/components/nav/nav.tsx
index 5aaacb6..27241ee 100644
--- a/packages/core/src/components/nav/nav.tsx
+++ b/packages/core/src/components/nav/nav.tsx
@@ -1,4 +1,4 @@
-import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
+import { Component, Element, Event, EventEmitter, Listen, Method, Prop, Watch } from '@stencil/core';
 import {
   Animation,
   AnimationController,
@@ -103,10 +103,19 @@ export class Nav implements PublicNav, NavContainer {
     }
     this.init = true;
     if (!this.useRouter) {
+      console.log('componentDidLoadImpl: ', this.root);
       componentDidLoadImpl(this);
     }
   }
 
+  @Watch('root')
+  updateRootComponent(): any {
+    console.log('updateRootComponent: ', this.root);
+    if (this.init) {
+      return this.setRoot(this.root);
+    }
+  }
+
   getViews(): PublicViewController[] {
     return getViews(this);
   }
diff --git a/packages/core/src/components/nav/test/set-root/index.html b/packages/core/src/components/nav/test/set-root/index.html
new file mode 100644
index 0000000..823c9ed
--- /dev/null
+++ b/packages/core/src/components/nav/test/set-root/index.html
@@ -0,0 +1,110 @@
+<!DOCTYPE html>
+<html dir=""ltr"">
+<head>
+  <meta charset=""UTF-8"">
+  <title>Nav</title>
+  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"">
+  <script src=""/dist/ionic.js""></script>
+</head>
+<body onload=""initiaize()"">
+  <ion-app>
+    <ion-nav root=""page-one""></ion-nav>
+  </ion-app>
+</body>
+
+<script>
+
+  class PageOne extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+      <ion-page>
+        <ion-header>
+          <ion-toolbar>
+            <ion-title>Page One</ion-title>
+          </ion-toolbar>
+        </ion-header>
+        <ion-content padding>
+          <h1>Page One</h1>
+          <ion-button class=""next"">Go to Page Two</ion-button>
+        </ion-content>
+      </ion-page>`;
+
+      const button = this.querySelector('ion-button');
+      button.addEventListener('click', async () => {
+        this.closest('ion-nav').push('page-two');
+      });
+    }
+  }
+
+  class PageTwo extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Two</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Two</h1>
+            <ion-button class=""next"">Go to Page Three</ion-button>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+
+      const nextButton = this.querySelector('ion-button.next');
+      nextButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').push('page-three');
+      });
+    }
+  }
+
+  class PageThree extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Three</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Three</h1>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+    }
+  }
+
+  customElements.define('page-one', PageOne);
+  customElements.define('page-two', PageTwo);
+  customElements.define('page-three', PageThree);
+
+  async function initiaize() {
+    const nav = document.querySelector('ion-nav');
+    await nav.componentOnReady();
+    nav.root = 'page-one';
+
+    setInterval(() => {
+      if (nav.root === 'page-one') {
+        nav.root = 'page-two';
+      } else if ( nav.root === 'page-two') {
+        nav.root = 'page-three';
+      } else {
+        nav.root = 'page-one';
+      }
+    }, 1000);
+  }
+
+</script>
+</html>
",1,"[""4be836f5655fb5356fde5ddd7437125f8574705d""]","[""refactor""]","1. The code changes include adding a @Watch decorator and handler for the 'root' property in a component for better state management, and introducing a new HTML test file that exercises dynamic root changes in the nav component.
2. The @Watch addition and related logic in the TypeScript file restructure how state changes are observed and handled, matching the definition of 'refactor' as it improves internal code structure without changing external behavior; the new HTML file is a test artifact dedicated to test logic.
3. Although the @Watch logic might appear as a bug fix, there is no explicit indication of a bug being resolved—rather, it enhances maintainability and internal consistency, so 'refactor' is more precise than 'fix' or 'feat'; the new HTML file is purely a test and should be labeled 'test', not 'refactor' or 'feat'.
4. The appropriate labels are 'refactor' for the TypeScript structural change and 'test' for the new test file, since each code unit is fully dedicated to improving code structure and adding test logic, respectively."
"use an action for issue assignment
add method to extract snapshot name from filename

also corrected pattern, where the period was meant to match a period, not any
character.

related to zeebe-io/zeebe#876
verify the replay mode

* write a test to verify the different replay modes","diff --git a/.github/workflows/assign.yml b/.github/workflows/assign.yml
index 29d92a8..758874e 100644
--- a/.github/workflows/assign.yml
+++ b/.github/workflows/assign.yml
@@ -8,8 +8,6 @@ jobs:
     runs-on: ubuntu-latest
     if: ${{ github.event.comment.body == '/take' }}
     steps:
-      - uses: actions/checkout@v2
-      - name: Assign issue ${{ github.event.issue.number }} to ${{ github.event.comment.user.login }}
-        run: gh issue edit ${{ github.event.issue.number }} --add-assignee ""${{ github.event.comment.user.login }}""
-        env:
-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+      - uses: pozil/auto-assign-issue@v1.1.0
+        with:
+          assignees: ${{ github.event.comment.user.login }}

diff --git a/logstreams/src/main/java/io/zeebe/logstreams/impl/snapshot/fs/FsSnapshotStorageConfiguration.java b/logstreams/src/main/java/io/zeebe/logstreams/impl/snapshot/fs/FsSnapshotStorageConfiguration.java
index d8f4d89..e54e85a 100644
--- a/logstreams/src/main/java/io/zeebe/logstreams/impl/snapshot/fs/FsSnapshotStorageConfiguration.java
+++ b/logstreams/src/main/java/io/zeebe/logstreams/impl/snapshot/fs/FsSnapshotStorageConfiguration.java
@@ -23,8 +23,9 @@ public class FsSnapshotStorageConfiguration
 {
     protected static final String CHECKSUM_ALGORITHM = ""SHA1"";
 
-    protected static final String SNAPSHOT_FILE_NAME_TEMPLATE = ""%s"" + File.separatorChar + ""%s-%d.snapshot"";
-    protected static final String SNAPSHOT_FILE_NAME_PATTERN = ""%s-(\\d+).snapshot"";
+    protected static final String SNAPSHOT_FILE_NAME_TEMPLATE = ""%s-%d.snapshot"";
+    protected static final String SNAPSHOT_FILE_PATH_TEMPLATE = ""%s"" + File.separatorChar + SNAPSHOT_FILE_NAME_TEMPLATE;
+    protected static final String SNAPSHOT_FILE_NAME_PATTERN = ""%s-(\\d+)\\.snapshot"";
 
     protected static final String CHECKSUM_FILE_NAME_TEMPLATE = ""%s"" + File.separatorChar + ""%s-%d."" + CHECKSUM_ALGORITHM.toLowerCase();
 
@@ -50,7 +51,7 @@ public class FsSnapshotStorageConfiguration
 
     public String snapshotFileName(String name, long logPosition)
     {
-        return String.format(SNAPSHOT_FILE_NAME_TEMPLATE, rootPath, name, logPosition);
+        return String.format(SNAPSHOT_FILE_PATH_TEMPLATE, rootPath, name, logPosition);
     }
 
     public String checksumFileName(String name, long logPosition)
@@ -86,7 +87,7 @@ public class FsSnapshotStorageConfiguration
         return String.format(CHECKSUM_CONTENT_TEMPLATE, checksum, dataFileName);
     }
 
-    public String extractDigetsFromChecksumContent(String content)
+    public String extractDigestFromChecksumContent(String content)
     {
         final int indexOfSeparator = content.indexOf(CHECKSUM_CONTENT_SEPARATOR);
         if (indexOfSeparator < 0)
@@ -108,9 +109,18 @@ public class FsSnapshotStorageConfiguration
         return content.substring(indexOfSeparator + CHECKSUM_CONTENT_SEPARATOR.length());
     }
 
+    public String getSnapshotNameFromFileName(final String fileName)
+    {
+        final String suffixPattern = String.format(SNAPSHOT_FILE_NAME_PATTERN, """");
+        final Pattern pattern = Pattern.compile(suffixPattern);
+        final String[] parts = pattern.split(fileName);
+
+        return parts[0];
+    }
+
     public String getSnapshotFileNameTemplate()
     {
-        return SNAPSHOT_FILE_NAME_TEMPLATE;
+        return SNAPSHOT_FILE_PATH_TEMPLATE;
     }
 
     public String getChecksumFileNameTemplate()

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
index 167444c..7494014 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/ContinuouslyReplayTest.java
@@ -11,6 +11,9 @@ import io.camunda.zeebe.engine.state.ZbColumnFamilies;
 import io.camunda.zeebe.engine.util.EngineRule;
 import io.camunda.zeebe.engine.util.ListLogStorage;
 import io.camunda.zeebe.model.bpmn.Bpmn;
+import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
+import io.camunda.zeebe.protocol.record.value.BpmnElementType;
+import io.camunda.zeebe.test.util.record.RecordingExporter;
 import org.assertj.core.api.SoftAssertions;
 import org.awaitility.Awaitility;
 import org.junit.Rule;
@@ -27,16 +30,22 @@ public class ContinuouslyReplayTest {
   @Rule public final EngineRule processing = EngineRule.withSharedStorage(sharedStorage);
 
   @Test
-  public void shouldEndUpWithTheSameState() {
+  public void shouldBuildTheSameStateOnProcessingAndReplay() {
     // given
-
-    // when
     processing
         .deployment()
-        .withXmlResource(Bpmn.createExecutableProcess().startEvent().endEvent().done())
+        .withXmlResource(Bpmn.createExecutableProcess(""process"").startEvent().endEvent().done())
         .deploy();
 
+    // when
+    final var processInstanceKey = processing.processInstance().ofBpmnProcessId(""process"").create();
+
     // then
+    RecordingExporter.processInstanceRecords(ProcessInstanceIntent.ELEMENT_COMPLETED)
+        .withProcessInstanceKey(processInstanceKey)
+        .withElementType(BpmnElementType.PROCESS)
+        .await();
+
     assertStates();
   }
 
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
new file mode 100644
index 0000000..9dd9f4c
--- /dev/null
+++ b/engine/src/test/java/io/camunda/zeebe/engine/processing/streamprocessor/StreamProcessorReplayModeTest.java
@@ -0,0 +1,121 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.engine.processing.streamprocessor;
+
+import static io.camunda.zeebe.engine.util.RecordToWrite.command;
+import static io.camunda.zeebe.engine.util.RecordToWrite.event;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ACTIVATE_ELEMENT;
+import static io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent.ELEMENT_ACTIVATING;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyLong;
+import static org.mockito.ArgumentMatchers.eq;
+import static org.mockito.Mockito.inOrder;
+import static org.mockito.Mockito.never;
+import static org.mockito.Mockito.timeout;
+
+import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor.Phase;
+import io.camunda.zeebe.engine.state.EventApplier;
+import io.camunda.zeebe.engine.util.Records;
+import io.camunda.zeebe.engine.util.StreamProcessorRule;
+import io.camunda.zeebe.protocol.impl.record.value.processinstance.ProcessInstanceRecord;
+import io.camunda.zeebe.protocol.record.ValueType;
+import org.junit.Rule;
+import org.junit.Test;
+import org.mockito.InOrder;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnit;
+import org.mockito.junit.MockitoRule;
+import org.mockito.verification.VerificationWithTimeout;
+
+public final class StreamProcessorReplayModeTest {
+
+  private static final long TIMEOUT_MILLIS = 2_000L;
+  private static final VerificationWithTimeout TIMEOUT = timeout(TIMEOUT_MILLIS);
+
+  private static final int PARTITION_ID = 1;
+
+  private static final ProcessInstanceRecord RECORD = Records.processInstance(1);
+
+  @Rule
+  public final StreamProcessorRule replayUntilEnd =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.UNTIL_END);
+
+  @Rule
+  public final StreamProcessorRule replayContinuously =
+      new StreamProcessorRule(PARTITION_ID).withReplayMode(ReplayMode.CONTINUOUSLY);
+
+  @Rule public MockitoRule mockitoRule = MockitoJUnit.rule();
+
+  @Mock private TypedRecordProcessor<?> typedRecordProcessor;
+  @Mock private EventApplier eventApplier;
+
+  @Test
+  public void shouldReplayUntilEnd() {
+    // given
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayUntilEnd);
+
+    replayUntilEnd.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder.verify(eventApplier, TIMEOUT).applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, TIMEOUT.times(1)).onRecovered(any());
+    inOrder
+        .verify(typedRecordProcessor, TIMEOUT)
+        .processRecord(anyLong(), any(), any(), any(), any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayUntilEnd)).isEqualTo(Phase.PROCESSING);
+  }
+
+  @Test
+  public void shouldReplayContinuously() {
+    // given
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // when
+    startStreamProcessor(replayContinuously);
+
+    replayContinuously.writeBatch(
+        command().processInstance(ACTIVATE_ELEMENT, RECORD),
+        event().processInstance(ELEMENT_ACTIVATING, RECORD).causedBy(0));
+
+    // then
+    final InOrder inOrder = inOrder(typedRecordProcessor, eventApplier);
+    inOrder
+        .verify(eventApplier, TIMEOUT.times(2))
+        .applyState(anyLong(), eq(ELEMENT_ACTIVATING), any());
+    inOrder.verify(typedRecordProcessor, never()).onRecovered(any());
+    inOrder.verifyNoMoreInteractions();
+
+    assertThat(getCurrentPhase(replayContinuously)).isEqualTo(Phase.REPROCESSING);
+  }
+
+  private void startStreamProcessor(final StreamProcessorRule streamProcessorRule) {
+    streamProcessorRule
+        .withEventApplierFactory(zeebeState -> eventApplier)
+        .startTypedStreamProcessor(
+            (processors, context) ->
+                processors.onCommand(
+                    ValueType.PROCESS_INSTANCE, ACTIVATE_ELEMENT, typedRecordProcessor));
+  }
+
+  private Phase getCurrentPhase(final StreamProcessorRule streamProcessorRule) {
+    return streamProcessorRule.getStreamProcessor(PARTITION_ID).getCurrentPhase().join();
+  }
+}
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
index f626ed4..cf07b5c 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/EngineRule.java
@@ -101,7 +101,6 @@ public final class EngineRule extends ExternalResource {
       new Int2ObjectHashMap<>();
 
   private long lastProcessedPosition = -1L;
-  private ReplayMode replayMode;
 
   private EngineRule(final int partitionCount) {
     this(partitionCount, null);
@@ -176,7 +175,7 @@ public final class EngineRule extends ExternalResource {
   }
 
   public EngineRule withReplayMode(final ReplayMode replayMode) {
-    this.replayMode = replayMode;
+    environmentRule.withReplayMode(replayMode);
     return this;
   }
 
@@ -194,7 +193,6 @@ public final class EngineRule extends ExternalResource {
               (processingContext) ->
                   EngineProcessors.createEngineProcessors(
                           processingContext
-                              .replayMode(replayMode)
                               .onProcessedListener(
                                   record -> {
                                     lastProcessedPosition = record.getPosition();
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
index ab44773..1f9fe26 100755
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/StreamProcessorRule.java
@@ -10,6 +10,7 @@ package io.camunda.zeebe.engine.util;
 import static io.camunda.zeebe.engine.util.StreamProcessingComposite.getLogName;
 
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecordProcessorFactory;
@@ -64,6 +65,7 @@ public final class StreamProcessorRule implements TestRule {
   private TestStreams streams;
   private StreamProcessingComposite streamProcessingComposite;
   private ListLogStorage sharedStorage = null;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public StreamProcessorRule() {
     this(new TemporaryFolder());
@@ -125,6 +127,11 @@ public final class StreamProcessorRule implements TestRule {
     return this;
   }
 
+  public StreamProcessorRule withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+    return this;
+  }
+
   public LogStreamRecordWriter getLogStreamRecordWriter(final int partitionId) {
     return streamProcessingComposite.getLogStreamRecordWriter(partitionId);
   }
@@ -317,6 +324,7 @@ public final class StreamProcessorRule implements TestRule {
     @Override
     protected void before() {
       streams = new TestStreams(tempFolder, closeables, actorSchedulerRule.get());
+      streams.withReplayMode(replayMode);
 
       int partitionId = startPartitionId;
       for (int i = 0; i < partitionCount; i++) {
diff --git a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
index 18696b2..176c405 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/util/TestStreams.java
@@ -17,6 +17,7 @@ import static org.mockito.Mockito.when;
 
 import io.camunda.zeebe.db.ZeebeDb;
 import io.camunda.zeebe.db.ZeebeDbFactory;
+import io.camunda.zeebe.engine.processing.streamprocessor.ReplayMode;
 import io.camunda.zeebe.engine.processing.streamprocessor.StreamProcessor;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedEventRegistry;
 import io.camunda.zeebe.engine.processing.streamprocessor.TypedRecord;
@@ -79,6 +80,7 @@ public final class TestStreams {
   private boolean snapshotWasTaken = false;
 
   private Function<MutableZeebeState, EventApplier> eventApplierFactory = EventAppliers::new;
+  private ReplayMode replayMode = ReplayMode.UNTIL_END;
 
   public TestStreams(
       final TemporaryFolder dataDirectory,
@@ -107,6 +109,10 @@ public final class TestStreams {
     this.eventApplierFactory = eventApplierFactory;
   }
 
+  public void withReplayMode(final ReplayMode replayMode) {
+    this.replayMode = replayMode;
+  }
+
   public CommandResponseWriter getMockedResponseWriter() {
     return mockCommandResponseWriter;
   }
@@ -252,6 +258,7 @@ public final class TestStreams {
             .onProcessedListener(mockOnProcessedListener)
             .streamProcessorFactory(factory)
             .eventApplierFactory(eventApplierFactory)
+            .replayMode(replayMode)
             .build();
     final var openFuture = streamProcessor.openAsync(false);
 
",3,"[""fb3a231b29bc8bff9270b99dd4aff9dad599f21f"", ""7ab965c55d0e98fdb6179577d0db56599675e400"", ""48d5d573886e9fdd0cca1cea47112c4a2f6edf52""]","[""cicd"", ""feat"", ""test""]","1. The change to `.github/workflows/assign.yml` replaces manual issue assignment steps with a prebuilt GitHub Action, modifying only the CI workflow configuration.
2. This aligns directly with the 'cicd' label, as it is an update to CI/CD configuration files without affecting application or test logic.
3. No other label is appropriate here: it is not 'build' (not a build script), nor 'feat'/'fix'/'refactor' (not code or logic changes), nor 'test'/'docs'.
4. The 'cicd' label is correct for this code unit as it exclusively updates CI configuration.

1. The changes to `FsSnapshotStorageConfiguration.java` add a method to extract a snapshot name from a filename, correct a filename pattern, and adjust file naming templates.
2. These are new capabilities and improvements to logic, aligning with 'feat' for adding a utility method and correcting filename handling.
3. 'feat' is appropriate because the main motivation is to introduce a new method and correct/extend functionality; it is not solely a bugfix ('fix') nor a non-functional change ('refactor').
4. The 'feat' label is justified as this code unit introduces new public logic and corrects a pattern for enhanced functionality.

1. The addition of `StreamProcessorReplayModeTest.java` and the updates to test utility classes (`EngineRule.java`, `StreamProcessorRule.java`, `TestStreams.java`, and `ContinuouslyReplayTest.java`) add or modify test logic to verify replay mode behavior.
2. These changes are fully dedicated to test logic, either by introducing new tests or extending test utilities to support new test scenarios, thus matching the 'test' label.
3. 'test' is correct because all modifications are within test files or test-supporting code and do not introduce production features or fix bugs outside of tests.
4. The 'test' label is appropriate as these changes are exclusively focused on testing new replay mode scenarios and supporting test infrastructure.

Final set: cicd, feat, test."
"pass absolute burnchain block height to pox sync watchdog so we correctly infer ibd status
make jq use compact json for rebase branch query","diff --git a/testnet/stacks-node/src/run_loop/neon.rs b/testnet/stacks-node/src/run_loop/neon.rs
index 677749b..dc4a7bd 100644
--- a/testnet/stacks-node/src/run_loop/neon.rs
+++ b/testnet/stacks-node/src/run_loop/neon.rs
@@ -411,7 +411,6 @@ impl RunLoop {
 
         let mut burnchain_height = sortition_db_height;
         let mut num_sortitions_in_last_cycle = 1;
-        let mut learned_burnchain_height = false;
 
         // prepare to fetch the first reward cycle!
         target_burnchain_block_height = burnchain_height + pox_constants.reward_cycle_length as u64;
@@ -439,18 +438,16 @@ impl RunLoop {
                 break;
             }
 
+            let remote_chain_height = burnchain.get_headers_height();
+
             // wait for the p2p state-machine to do at least one pass
-            debug!(""Wait until we reach steady-state before processing more burnchain blocks..."");
+            debug!(""Wait until we reach steady-state before processing more burnchain blocks (chain height is {}, we are at {})..."", remote_chain_height, burnchain_height);
 
             // wait until it's okay to process the next sortitions
             let ibd = match pox_watchdog.pox_sync_wait(
                 &burnchain_config,
                 &burnchain_tip,
-                if learned_burnchain_height {
-                    Some(burnchain_height)
-                } else {
-                    None
-                },
+                Some(remote_chain_height),
                 num_sortitions_in_last_cycle,
             ) {
                 Ok(ibd) => ibd,
@@ -478,7 +475,6 @@ impl RunLoop {
                     };
 
                 // *now* we know the burnchain height
-                learned_burnchain_height = true;
                 burnchain_tip = next_burnchain_tip;
                 burnchain_height = cmp::min(burnchain_height + 1, target_burnchain_block_height);
 

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 0e284b0..4a3ec7a 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -22,7 +22,7 @@ jobs:
               | cut -d ' ' -f2 \
               | grep -P '\d+\.x\.x' \
               | xargs printf '""%s""' \
-              | jq -s '{branch: .}')
+              | jq -rcMs '{branch: .}')
 
           echo ""::set-output name=matrix::$branches""
 
",2,"[""5b70e008c57efc89da4061f9adb7d0491b2ea644"", ""4638dcdf7011e8e42d11fde04f068f22ee20fa1d""]","[""fix"", ""cicd""]","1. The code changes in `neon.rs` update the logic for passing the burnchain block height to the PoX sync watchdog, affecting how IBD status is inferred, while the change in `.github/workflows/ibis-rebase-nightly.yml` modifies a jq command to use compact JSON output for a rebase branch query in a GitHub Actions workflow.
2. The Rust code update addresses a logic issue in the node's synchronization process—aligning with the 'fix' label, which is for correcting faulty behavior; the GitHub Actions change is a modification to a CI workflow file, which fits the 'cicd' label for CI-related artifact edits.
3. 'fix' is appropriate for the Rust code because it resolves an incorrect inference of IBD status rather than introducing features ('feat') or just restructuring code ('refactor'); 'cicd' is correct for the workflow file because the change is entirely within a CI configuration and does not affect build scripts ('build') or documentation ('docs').
4. The assigned labels 'fix' and 'cicd' are appropriate as they respectively capture the behavioral bug fix in core logic and the CI workflow adjustment, following the classification rules for purpose and object labels."
"add remote [skip ci]
autostart feature fixed","diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",2,"[""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""cicd"", ""fix""]","1. The commit modifies a GitHub Actions workflow file to add a remote and change the rebase logic, removes unused imports from two TypeScript files, and fixes an autostart bug in the Container class by setting 'firstStart' to true instead of false.
2. The workflow file update is a change to CI/CD configuration, aligning with the 'cicd' label, while the change in Container.ts corrects application behavior, matching the 'fix' label; the import removals are minor cleanups but are incidental to the main bug fix.
3. 'cicd' is appropriate for the workflow file because it relates solely to CI configuration, not build or test logic; 'fix' is correct for the Container.ts change since it resolves incorrect autostart behavior, not introducing new features ('feat') or just restructuring code ('refactor').
4. The assigned labels 'cicd' and 'fix' are appropriate because the commit contains a CI configuration update and a direct bug fix in application logic."
"better tested publishing flow
Improved Config Loading #423","diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 76dd749..2087803 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 ## [Unreleased]
 * Fix the tab '(Sync)' suffix in named tabs (https://github.com/zellij-org/zellij/pull/410)
 * Improve performance when multiple panes are open (https://github.com/zellij-org/zellij/pull/318)
+* Improve error reporting and tests of configuration (https://github.com/zellij-org/zellij/pull/423)
 
 ## [0.6.0] - 2021-04-29
 * Doesn't quit anymore on single `q` press while in tab mode  (https://github.com/zellij-org/zellij/pull/342)
",2,"[""65574eea5da54bf4722ecb551b42f8ff6088f33b"", ""099861ff5b0f83773ca0af4c70e6e39be3b0336c""]","[""build"", ""docs""]","1. The changes include updates to the Makefile.toml, altering build and publish task configurations, and a single-line addition to the CHANGELOG.md documenting improved error reporting and tests for configuration.
2. The Makefile.toml changes directly affect the build and release process by modifying environment variables, task dependencies, and command scripts, aligning with the 'build' label; the CHANGELOG.md update is strictly documentation, matching the 'docs' label.
3. 'build' is appropriate for the Makefile.toml because all modifications are to build and publish automation, not code or tests themselves, and 'docs' is appropriate for the CHANGELOG.md since it only updates release documentation; no code behavior, feature, or test logic is directly changed, ruling out other labels.
4. The 'build' and 'docs' labels are correct because the commit exclusively modifies build system configuration and project documentation, with no changes to application logic or tests."
"offset tests for min and max read cursors
fix ""types"" field in dist
permission check","diff --git a/storage/reads/array_cursor_test.go b/storage/reads/array_cursor_test.go
index 7c7ad0c..c1e6ff9 100644
--- a/storage/reads/array_cursor_test.go
+++ b/storage/reads/array_cursor_test.go
@@ -1541,6 +1541,34 @@ func TestWindowMinArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := (i % 4) * 15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T00:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:30:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:30:00Z"").UnixNano(),
+					},
+					Values: []int64{0, 30, 130, 230, 330},
+				},
+			},
+		},
+		{
 			name:  ""window desc values"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1560,6 +1588,34 @@ func TestWindowMinArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset desc values"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := 60 - (i%4)*15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T00:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:45:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:45:00Z"").UnixNano(),
+					},
+					Values: []int64{45, 15, 115, 215, 315},
+				},
+			},
+		},
+		{
 			name:  ""window min int"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1693,6 +1749,34 @@ func TestWindowMaxArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := (i % 4) * 15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:15:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:45:00Z"").UnixNano(),
+					},
+					Values: []int64{15, 115, 215, 315, 345},
+				},
+			},
+		},
+		{
 			name:  ""window desc values"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{
@@ -1712,6 +1796,34 @@ func TestWindowMaxArrayCursor(t *testing.T) {
 			},
 		},
 		{
+			name:   ""window offset desc values"",
+			every:  time.Hour,
+			offset: 30 * time.Minute,
+			inputArrays: []*cursors.IntegerArray{
+				makeIntegerArray(
+					16,
+					mustParseTime(""2010-01-01T00:00:00Z""), 15*time.Minute,
+					func(i int64) int64 {
+						base := (i / 4) * 100
+						m := 60 - (i%4)*15
+						return base + m
+					},
+				),
+			},
+			want: []*cursors.IntegerArray{
+				{
+					Timestamps: []int64{
+						mustParseTime(""2010-01-01T00:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T01:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T02:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:00:00Z"").UnixNano(),
+						mustParseTime(""2010-01-01T03:30:00Z"").UnixNano(),
+					},
+					Values: []int64{60, 160, 260, 360, 330},
+				},
+			},
+		},
+		{
 			name:  ""window min int"",
 			every: time.Hour,
 			inputArrays: []*cursors.IntegerArray{

diff --git a/scripts/prepare.js b/scripts/prepare.js
index 4bab09b..55f459b 100644
--- a/scripts/prepare.js
+++ b/scripts/prepare.js
@@ -96,7 +96,6 @@ async function prepare() {
     delete json.private
     delete json.scripts
     delete json.devDependencies
-    delete json.types
 
     // Add ""postinstall"" script for donations.
     if (/(native|core)$/.test(name))
@@ -128,6 +127,7 @@ async function prepare() {
     else {
       json.main = json.main.replace(/^dist\//, '')
       if (json.main.endsWith('.cjs.js')) {
+        json.types = json.main.replace('.cjs.js', '.d.ts')
         json.module = json.main.replace('.cjs', '')
       }
     }

diff --git a/server/src/routes/course/index.ts b/server/src/routes/course/index.ts
index 557f5fb..bc0e490 100644
--- a/server/src/routes/course/index.ts
+++ b/server/src/routes/course/index.ts
@@ -209,7 +209,7 @@ function addStudentApi(router: Router, logger: ILogger) {
   router.post('/student/:githubId/status', ...mentorValidators, updateStudentStatus(logger));
   router.post('/student/:githubId/status-self', courseGuard, selfUpdateStudentStatus(logger));
   router.get('/student/:githubId/score', courseGuard, getScoreByStudent(logger));
-  router.post('/student/:githubId/certificate', courseManagerGuard, ...validators, postStudentCertificate(logger));
+  router.post('/student/:githubId/certificate', courseManagerGuard, validateGithubId, postStudentCertificate(logger));
 
   router.get('/students', courseSupervisorGuard, getStudents(logger));
   router.get('/students/csv', courseSupervisorGuard, getStudentsCsv(logger));
",3,"[""b7e2330fa3a8d7b8a9bff01b707c44e64b845c7b"", ""f14ef3809f456aadd73523e47cb16c5d15e9a9df"", ""33c25b2f59c931a7f4af994365522221a7821dca""]","[""test"", ""build"", ""fix""]","1. The first code unit adds new test cases to 'array_cursor_test.go' for offset behavior in min and max read cursors.
2. These changes are exclusively additions to test logic, which matches the 'test' label definition.
3. 'test' is appropriate because the modifications are limited to test files, not production code or documentation, ruling out 'feat', 'fix', or 'docs'.
4. The 'test' label is correct as the code unit is fully dedicated to expanding test coverage.

1. The second code unit in 'prepare.js' fixes the handling of the 'types' field in the generated package distribution by ensuring it is correctly set when using '.cjs.js' main files.
2. This change addresses a build artifact issue, aligning with the 'build' label, as it alters the packaging script to produce correct output.
3. 'build' is more accurate than 'fix' or 'feat' since the change is strictly related to the build system and distribution artifacts, not application logic or new capabilities.
4. The 'build' label is appropriate because the script change is solely concerned with packaging configuration for distribution.

1. The third code unit in 'index.ts' modifies a route to add a 'validateGithubId' middleware, improving permission checks on a POST endpoint.
2. This resolves a likely security or validation bug, directly matching the 'fix' label definition for correcting faulty or missing behavior.
3. 'fix' is correct because the change addresses a bug in permission validation, not a new feature ('feat') or code restructuring ('refactor').
4. The 'fix' label is justified as the change corrects a flaw in access control logic.

Unique labels: test, build, fix."
"group example
reset padding first on PadLog

Signed-off-by: Carlos A Becker <caarlos0@users.noreply.github.com>
implement array flatten support","diff --git a/src/build/arg_group.rs b/src/build/arg_group.rs
index 5201e97..e1b1991 100644
--- a/src/build/arg_group.rs
+++ b/src/build/arg_group.rs
@@ -43,7 +43,7 @@ use crate::util::{Id, Key};
 ///     .arg(""--minor         'auto increase minor'"")
 ///     .arg(""--patch         'auto increase patch'"")
 ///     .group(ArgGroup::with_name(""vers"")
-///          .args(&[""set-ver"", ""major"", ""minor"",""patch""])
+///          .args(&[""set-ver"", ""major"", ""minor"", ""patch""])
 ///          .required(true))
 ///     .try_get_matches_from(vec![""app"", ""--major"", ""--patch""]);
 /// // Because we used two args in the group it's an error

diff --git a/internal/middleware/logging/logging.go b/internal/middleware/logging/logging.go
index 1a3adc7..92c8eb5 100644
--- a/internal/middleware/logging/logging.go
+++ b/internal/middleware/logging/logging.go
@@ -35,6 +35,7 @@ func Log(title string, next middleware.Action) middleware.Action {
 func PadLog(title string, next middleware.Action) middleware.Action {
 	return func(ctx *context.Context) error {
 		defer log.ResetPadding()
+		log.ResetPadding()
 		log.IncreasePadding()
 		log.Infof(bold.Render(title))
 		log.IncreasePadding()

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 2373dd7..4ce03b0 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -422,6 +422,7 @@ operation_registry.update(
         ops.ArrayZip: _array_zip,
         ops.ArraySort: unary(sa.func.array_sort),
         ops.ArrayRepeat: fixed_arity(sa.func.ibis_udfs.public.array_repeat, 2),
+        ops.ArrayFlatten: fixed_arity(sa.func.array_flatten, 1),
         ops.StringSplit: fixed_arity(sa.func.split, 2),
         # snowflake typeof only accepts VARIANT, so we cast
         ops.TypeOf: unary(lambda arg: sa.func.typeof(sa.func.to_variant(arg))),
",3,"[""9849430b11b92ae58d94cfe4d0b06313c7eab550"", ""c5904a9004fca1e438168ca7334a0deefab536ff"", ""d3c754f09502be979e5dcc79f968b15052590bd0""]","[""docs"", ""fix"", ""feat""]","1. The changes include: (a) fixing a formatting issue in Rust documentation comments, (b) resetting padding before increasing it in Go's PadLog (potential bug fix), and (c) adding ArrayFlatten support in a Python registry (new feature).
2. The doc comment change aligns with 'docs' as it only fixes spacing in documentation; the PadLog change aligns with 'fix' as it corrects behavior by ensuring padding is reset first; the registry addition aligns with 'feat' as it introduces new array flattening capability.
3. 'docs' is correct for the doc comment as it does not affect code logic; 'fix' is appropriate for PadLog since it addresses a probable bug rather than adding new features or refactoring; 'feat' is justified for ArrayFlatten since it adds new functionality, not just restructuring or fixing.
4. The assigned labels 'docs', 'fix', and 'feat' each directly correspond to the primary intent and artifact type of their respective changes, matching the labeling guidelines precisely."
"support react@17 in peer deps

resolves #1478","diff --git a/packages/animated/package.json b/packages/animated/package.json
index 2249a2f..e35a1fd 100644
--- a/packages/animated/package.json
+++ b/packages/animated/package.json
@@ -33,6 +33,6 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/core/package.json b/packages/core/package.json
index 584bbc2..c934253 100644
--- a/packages/core/package.json
+++ b/packages/core/package.json
@@ -36,7 +36,7 @@
     ""react-layout-effect"": ""^1.0.1""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   },
   ""devDependencies"": {
     ""rafz"": ""^0.1.13""
diff --git a/packages/parallax/package.json b/packages/parallax/package.json
index 49f8391..5a181fe 100644
--- a/packages/parallax/package.json
+++ b/packages/parallax/package.json
@@ -31,6 +31,6 @@
     ""@react-spring/web"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/packages/shared/package.json b/packages/shared/package.json
index 67d286c..12f7db3 100644
--- a/packages/shared/package.json
+++ b/packages/shared/package.json
@@ -33,6 +33,6 @@
     ""rafz"": ""^0.1.13""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8""
+    ""react"": ""^16.8.0  || ^17.0.0""
   }
 }
diff --git a/targets/konva/package.json b/targets/konva/package.json
index 17675ac..271d58c 100644
--- a/targets/konva/package.json
+++ b/targets/konva/package.json
@@ -34,7 +34,7 @@
   },
   ""peerDependencies"": {
     ""konva"": "">=2.6"",
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-konva"": "">=16.8""
   },
   ""devDependencies"": {
diff --git a/targets/native/package.json b/targets/native/package.json
index e97aa97..802a66c 100644
--- a/targets/native/package.json
+++ b/targets/native/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-native"": "">=0.58""
   },
   ""devDependencies"": {
diff --git a/targets/web/package.json b/targets/web/package.json
index d74c25c..f7ac000 100644
--- a/targets/web/package.json
+++ b/targets/web/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8""
   }
 }
diff --git a/targets/zdog/package.json b/targets/zdog/package.json
index aa57890..f65945a 100644
--- a/targets/zdog/package.json
+++ b/targets/zdog/package.json
@@ -33,7 +33,7 @@
     ""@react-spring/types"": ""~9.2.0-beta.0""
   },
   ""peerDependencies"": {
-    ""react"": "">=16.8"",
+    ""react"": ""^16.8.0  || ^17.0.0"",
     ""react-dom"": "">=16.8"",
     ""react-zdog"": "">=1.0"",
     ""zdog"": "">=1.0""
",1,"[""27169897c0e58bc4fbca724f290ad54fa39abec7""]","[""build""]","1. The code changes update the 'peerDependencies' field for 'react' in multiple package.json files to allow React v17 as a valid peer dependency.
2. This aligns with the 'build' label, as it modifies build configuration and dependency metadata to support a new compatible version.
3. The changes do not add new features ('feat'), fix bugs ('fix'), or restructure code ('refactor'), nor do they modify documentation ('docs'), tests ('test'), or CI scripts ('cicd'); the updates are strictly to build/dependency configuration.
4. The 'build' label is appropriate because the commit exclusively adjusts package build metadata to support React 17, fitting the definition for build-related changes."
"remove broken link

Fixes #1785","diff --git a/docs/content/Caching/Caching.md b/docs/content/Caching/Caching.md
index d873a52..9706dda 100644
--- a/docs/content/Caching/Caching.md
+++ b/docs/content/Caching/Caching.md
@@ -135,8 +135,9 @@ If nothing is found in the cache, the query is executed in the database and the 
 is returned as well as updating the cache.
 
 If an existing value is present in the cache and the `refreshKey` value for
-the query hasn't changed, the cached value will be returned. Otherwise, a
-[query renewal](#in-memory-cache-force-query-renewal) will be performed.
+the query hasn't changed, the cached value will be returned. Otherwise, a SQL query will be executed either against the pre-aggregations storage or the source database to populate the cache with the results and return them.
+
+
 
 ### Refresh Keys
 
",1,"[""c351088bce98594c740a39546ce3655c91554a5d""]","[""docs""]","1. The change removes a broken documentation link and updates the surrounding explanation in a Markdown file under the docs directory.
2. This aligns with the 'docs' label, as the modification is entirely within documentation content and does not affect code, tests, or configuration.
3. 'docs' is appropriate because the change is purely textual and documentation-focused; it does not add features ('feat'), fix code bugs ('fix'), restructure code ('refactor'), affect tests ('test'), CI/CD ('cicd'), or build systems ('build').
4. The 'docs' label is correct because the change solely updates documentation by removing a broken link and clarifying text."
"group example
initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/build/arg_group.rs b/src/build/arg_group.rs
index 5201e97..e1b1991 100644
--- a/src/build/arg_group.rs
+++ b/src/build/arg_group.rs
@@ -43,7 +43,7 @@ use crate::util::{Id, Key};
 ///     .arg(""--minor         'auto increase minor'"")
 ///     .arg(""--patch         'auto increase patch'"")
 ///     .group(ArgGroup::with_name(""vers"")
-///          .args(&[""set-ver"", ""major"", ""minor"",""patch""])
+///          .args(&[""set-ver"", ""major"", ""minor"", ""patch""])
 ///          .required(true))
 ///     .try_get_matches_from(vec![""app"", ""--major"", ""--patch""]);
 /// // Because we used two args in the group it's an error

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",2,"[""9849430b11b92ae58d94cfe4d0b06313c7eab550"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""docs"", ""fix""]","1. The code changes include fixing a typo in a Rust doc comment, updating TypeScript types to make several fields required instead of optional, and initializing default Three.js objects in a default context to prevent undefined errors.
2. The doc comment spacing fix in `arg_group.rs` aligns with the 'docs' label, while the TypeScript changes address runtime errors caused by undefined values, which matches the 'fix' label definition.
3. 'docs' is appropriate for the Rust doc comment change since it only affects documentation, not behavior. 'fix' is appropriate for the TypeScript changes because they resolve actual type and runtime errors, not just code style or structure ('refactor'), and do not introduce new features ('feat').
4. The 'docs' label captures the documentation correction, and the 'fix' label correctly reflects the resolution of undefined errors by initializing required objects and updating types."
refactor generate_completion,"diff --git a/src/lib.rs b/src/lib.rs
index dfd8014..15850f7 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -1,11 +1,106 @@
 //! Generates [Nushell](https://github.com/nushell/nushell) completions for [`clap`](https://github.com/clap-rs/clap) based CLIs
 
-use clap::Command;
+use clap::{Arg, Command};
 use clap_complete::Generator;
 
 /// Generate Nushell complete file
 pub struct Nushell;
 
+enum Argument {
+    Short(char),
+    Long(String),
+    ShortAndLong(char, String),
+    Positional(String, bool),
+}
+
+struct ArgumentLine {
+    arg: Argument,
+    takes_values: bool,
+    help: Option<String>,
+}
+
+impl From<&Arg> for ArgumentLine {
+    fn from(arg: &Arg) -> Self {
+        let takes_values = arg
+            .get_num_args()
+            .map(|v| v.takes_values())
+            .unwrap_or(false);
+
+        let help = arg.get_help().map(|s| s.to_string());
+
+        if arg.is_positional() {
+            let id = arg.get_id().to_string();
+            let required = arg.is_required_set();
+            let arg = Argument::Positional(id, required);
+
+            return Self {
+                arg,
+                takes_values,
+                help,
+            };
+        }
+
+        let short = arg.get_short();
+        let long = arg.get_long();
+
+        match short {
+            Some(short) => match long {
+                Some(long) => Self {
+                    arg: Argument::ShortAndLong(short, long.into()),
+                    takes_values,
+                    help,
+                },
+                None => Self {
+                    arg: Argument::Short(short),
+                    takes_values,
+                    help,
+                },
+            },
+            None => match long {
+                Some(long) => Self {
+                    arg: Argument::Long(long.into()),
+                    takes_values,
+                    help,
+                },
+                None => unreachable!(""No short or long option found""),
+            },
+        }
+    }
+}
+
+impl ToString for ArgumentLine {
+    fn to_string(&self) -> String {
+        let mut s = String::new();
+
+        match &self.arg {
+            Argument::Short(short) => s.push_str(format!(""    -{}"", short).as_str()),
+            Argument::Long(long) => s.push_str(format!(""    --{}"", long).as_str()),
+            Argument::ShortAndLong(short, long) => {
+                s.push_str(format!(""    --{}(-{})"", long, short).as_str())
+            }
+            Argument::Positional(positional, required) => {
+                s.push_str(format!(""    {}"", positional).as_str());
+
+                if !*required {
+                    s.push('?');
+                }
+            }
+        }
+
+        if self.takes_values {
+            s.push_str("": string"");
+        }
+
+        if let Some(help) = &self.help {
+            s.push_str(format!(""\t# {}"", help).as_str());
+        }
+
+        s.push('\n');
+
+        s
+    }
+}
+
 impl Generator for Nushell {
     fn file_name(&self, name: &str) -> String {
         format!(""{}.nu"", name)
@@ -37,51 +132,18 @@ fn generate_completion(completions: &mut String, cmd: &Command, is_subcommand: b
 
     let bin_name = cmd.get_bin_name().expect(""Failed to get bin name"");
 
-    if is_subcommand {
-        completions.push_str(format!(""  export extern \""{}\"" [\n"", bin_name).as_str());
+    let name = if is_subcommand {
+        format!(r#""""{}""""#, bin_name)
     } else {
-        completions.push_str(format!(""  export extern {} [\n"", bin_name).as_str());
-    }
+        bin_name.into()
+    };
 
-    let mut s = String::new();
-    for arg in cmd.get_arguments() {
-        if arg.is_positional() {
-            s.push_str(format!(""    {}"", arg.get_id()).as_str());
-            if !arg.is_required_set() {
-                s.push('?');
-            }
-        }
-
-        let long = arg.get_long();
-        if let Some(opt) = long {
-            s.push_str(format!(""    --{}"", opt).as_str());
-        }
+    completions.push_str(format!(""  export extern {} [\n"", name).as_str());
 
-        let short = arg.get_short();
-        if let Some(opt) = short {
-            if long.is_some() {
-                s.push_str(format!(""(-{})"", opt).as_str());
-            } else {
-                s.push_str(format!(""    -{}"", opt).as_str());
-            }
-        }
-
-        if let Some(v) = arg.get_num_args() {
-            if v.takes_values() {
-                // TODO: add more types?
-                // TODO: add possible values?
-                s.push_str("": string"");
-            }
-        }
-
-        if let Some(msg) = arg.get_help() {
-            if arg.is_positional() || long.is_some() || short.is_some() {
-                s.push_str(format!(""\t# {}"", msg).as_str());
-            }
-        }
-
-        s.push('\n');
-    }
+    let s: String = cmd
+        .get_arguments()
+        .map(|arg| ArgumentLine::from(arg).to_string())
+        .collect();
 
     completions.push_str(&s);
     completions.push_str(""  ]\n\n"");
",1,"[""f1bc5a554af4e617c7d7508f7f16f8fd25c78c91""]","[""refactor""]","1. The code replaces ad-hoc logic in the `generate_completion` function with a new structure using `Argument` and `ArgumentLine` types, encapsulating argument formatting and improving code organization without changing functionality.
2. These changes align with the 'refactor' label definition, as they restructure code for clarity and maintainability, but do not alter external behavior or add features.
3. The 'refactor' label is appropriate because the motivation is to improve code structure; 'feat' and 'fix' are ruled out since no new features are added and no bugs are fixed, and 'object' labels like 'docs' or 'test' do not apply since this is core logic.
4. The 'refactor' label accurately captures the intent and scope of this commit, which is to improve code organization without affecting functionality."
"add important to override paragraphs in items
Handle different events.
abort parallel stages if one failed","diff --git a/packages/core/src/components/text/text.ios.scss b/packages/core/src/components/text/text.ios.scss
index a3c58e2..2a020ab 100644
--- a/packages/core/src/components/text/text.ios.scss
+++ b/packages/core/src/components/text/text.ios.scss
@@ -9,8 +9,9 @@
 @each $color-name, $color-base, $color-contrast in get-colors($colors-ios) {
 
   .text-ios-#{$color-name},
-  .text-ios-#{$color-name} a {
-    color: $color-base;
+  .text-ios-#{$color-name} a,
+  .text-ios-#{$color-name} p {
+    color: $color-base !important
   }
 
 }
diff --git a/packages/core/src/components/text/text.md.scss b/packages/core/src/components/text/text.md.scss
index b397acb..050af1a 100644
--- a/packages/core/src/components/text/text.md.scss
+++ b/packages/core/src/components/text/text.md.scss
@@ -9,8 +9,9 @@
 @each $color-name, $color-base, $color-contrast in get-colors($colors-md) {
 
   .text-md-#{$color-name},
-  .text-md-#{$color-name} a {
-    color: $color-base;
+  .text-md-#{$color-name} a,
+  .text-md-#{$color-name} p {
+    color: $color-base !important;
   }
 
 }

diff --git a/src/notebook/epics/kernel-launch.js b/src/notebook/epics/kernel-launch.js
index 9075d7c..9f16e67 100644
--- a/src/notebook/epics/kernel-launch.js
+++ b/src/notebook/epics/kernel-launch.js
@@ -113,6 +113,12 @@ export function newKernelObservable(kernelSpec: KernelInfo, cwd: string) {
           observer.error({ type: 'ERROR', payload: error, err: true });
           observer.complete();
         });
+        spawn.on('exit', () => {
+          observer.complete();
+        });
+        spawn.on('disconnect', () => {
+          observer.complete();
+        });
       });
   });
 }

diff --git a/Jenkinsfile b/Jenkinsfile
index 168f446..a4da961 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -28,6 +28,7 @@ pipeline {
         }
 
         stage('Verify') {
+            failFast true
             parallel {
                 stage('Tests') {
                     steps {
",3,"[""7ab363f7ba2807b3eb9895e47f4fcd058f43ae5e"", ""a280a52c8309465276c3509848ddcddbe19732b6"", ""28e623b294816c4e070971782a75c8697a11966f""]","[""test"", ""fix"", ""cicd""]","1. The SCSS files were updated to add '!important' to paragraph color rules, the kernel-launch.js file added handlers for 'exit' and 'disconnect' events to ensure observer completion, and the Jenkinsfile added 'failFast true' to abort parallel stages on failure.
2. The SCSS changes address CSS specificity issues (fix), the JS changes handle missed process events to prevent hangs (fix), and the Jenkinsfile change is a CI configuration update (cicd).
3. 'fix' is appropriate for the SCSS and JS changes since both resolve unintended or faulty behavior, not adding features or just restructuring; 'cicd' correctly covers the Jenkinsfile change as it is a CI pipeline configuration, not a build or test artifact.
4. The 'fix' and 'cicd' labels precisely match the motivations and artifact types of these changes, while 'test' is not appropriate as no test logic or files were modified."
"rework RaftCommittedEntryListener

Iterate over RaftCommittedEntryListener and refactor the listener such it serves the actual need.

We have some services (to be specific the AsyncSnapshotDirector) which need the committed position, and
want to listen to new updates. In raft we know which record we are committing and whether it was an application record so we can pass this information threw the listeners.

This avoids to pass in the whole IndexedRecord object, and reduce the potential of going out of OOM because of keeping to much data in heap (when commit is not possible).
set name for topology module","diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
new file mode 100644
index 0000000..57c28a9
--- /dev/null
+++ b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright 2016-present Open Networking Foundation
+ * Copyright © 2020 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.atomix.raft;
+
+/**
+ * This listener will only be called by the Leader, when it commits an application entry.
+ *
+ * <p>If RAFT is currently running in a follower role, it will not call this listener.
+ */
+@FunctionalInterface
+public interface RaftApplicationEntryCommittedPositionListener {
+
+  /**
+   * @param committedPosition the new committed position which is related to the application entries
+   */
+  void onCommit(long committedPosition);
+}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
deleted file mode 100644
index 3d11d75..0000000
--- a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- * Copyright 2016-present Open Networking Foundation
- * Copyright © 2020 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.atomix.raft;
-
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
-
-/**
- * This listener will only be called by the Leader, when it commits an entry. If RAFT is currently
- * running in a follower role, it will not call this listener.
- */
-@FunctionalInterface
-public interface RaftCommittedEntryListener {
-
-  /**
-   * @param indexedRaftLogEntry the new committed entry
-   */
-  void onCommit(IndexedRaftLogEntry indexedRaftLogEntry);
-}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
index 1f4ee98..c177cb1 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
@@ -27,8 +27,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.MessagingException.NoRemoteHandler;
 import io.atomix.cluster.messaging.MessagingException.NoSuchMemberException;
 import io.atomix.raft.ElectionTimer;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftError;
 import io.atomix.raft.RaftException.ProtocolException;
 import io.atomix.raft.RaftRoleChangeListener;
@@ -61,7 +61,6 @@ import io.atomix.raft.roles.PromotableRole;
 import io.atomix.raft.roles.RaftRole;
 import io.atomix.raft.storage.RaftStorage;
 import io.atomix.raft.storage.StorageException;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
 import io.atomix.raft.storage.log.RaftLog;
 import io.atomix.raft.storage.system.MetaStore;
 import io.atomix.raft.utils.StateUtil;
@@ -115,7 +114,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
   private final Set<Consumer<State>> stateChangeListeners = new CopyOnWriteArraySet<>();
   private final Set<Consumer<RaftMember>> electionListeners = new CopyOnWriteArraySet<>();
   private final Set<RaftCommitListener> commitListeners = new CopyOnWriteArraySet<>();
-  private final Set<RaftCommittedEntryListener> committedEntryListeners =
+  private final Set<RaftApplicationEntryCommittedPositionListener> committedEntryListeners =
       new CopyOnWriteArraySet<>();
   private final Set<SnapshotReplicationListener> snapshotReplicationListeners =
       new CopyOnWriteArraySet<>();
@@ -433,21 +432,23 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    * <p>Note that it will be called on the Raft thread, and as such should not perform any heavy
    * computation.
    *
-   * @param raftCommittedEntryListener the listener to add
+   * @param raftApplicationEntryCommittedPositionListener the listener to add
    */
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.add(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.add(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
    * Removes registered committedEntryListener
    *
-   * @param raftCommittedEntryListener the listener to remove
+   * @param raftApplicationEntryCommittedPositionListener the listener to remove
    */
   public void removeCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.remove(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.remove(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
@@ -464,7 +465,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    *
    * @param committedEntry the most recently committed entry
    */
-  public void notifyCommittedEntryListeners(final IndexedRaftLogEntry committedEntry) {
+  public void notifyApplicationEntryCommittedPositionListeners(final long committedEntry) {
     committedEntryListeners.forEach(listener -> listener.onCommit(committedEntry));
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
index 56c7172..d075fca 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
@@ -21,8 +21,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.ClusterCommunicationService;
 import io.atomix.primitive.partition.Partition;
 import io.atomix.primitive.partition.PartitionMetadata;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftRoleChangeListener;
 import io.atomix.raft.RaftServer;
 import io.atomix.raft.RaftServer.Role;
@@ -205,16 +205,20 @@ public class RaftPartitionServer implements HealthMonitorable {
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void addCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void addCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().addCommittedEntryListener(commitListener);
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void removeCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void removeCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().removeCommittedEntryListener(commitListener);
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
index e54df1a..fcfd177 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
@@ -630,27 +630,47 @@ public final class LeaderRole extends ActiveRole implements ZeebeLogAppender {
 
   private void replicate(final IndexedRaftLogEntry indexed, final AppendListener appendListener) {
     raft.checkThread();
-    appender
-        .appendEntries(indexed.index())
-        .whenCompleteAsync(
-            (commitIndex, commitError) -> {
-              if (!isRunning()) {
-                return;
-              }
+    final var appendEntriesFuture = appender.appendEntries(indexed.index());
+
+    final boolean applicationEntryWasCommitted = indexed.isApplicationEntry();
+    if (applicationEntryWasCommitted) {
+      // We have some services which are waiting for the application records, especially position
+      // to be committed. This is our glue code to notify them, instead of
+      // passing the complete object (IndexedRaftLogEntry) threw the listeners and
+      // keep them in heap until they are committed. This had the risk of going out of OOM
+      // if records can't be committed, see https://github.com/camunda/zeebe/issues/14275
+      final var committedPosition = indexed.getApplicationEntry().highestPosition();
+      appendEntriesFuture.whenCompleteAsync(
+          (commitIndex, commitError) -> {
+            if (!isRunning()) {
+              return;
+            }
+
+            if (commitError == null) {
+              raft.notifyApplicationEntryCommittedPositionListeners(committedPosition);
+            }
+          },
+          raft.getThreadContext());
+    }
 
-              // have the state machine apply the index which should do nothing but ensures it keeps
-              // up to date with the latest entries, so it can handle configuration and initial
-              // entries properly on fail over
-              if (commitError == null) {
-                appendListener.onCommit(indexed.index());
-                raft.notifyCommittedEntryListeners(indexed);
-              } else {
-                appendListener.onCommitError(indexed.index(), commitError);
-                // replicating the entry will be retried on the next append request
-                log.error(""Failed to replicate entry: {}"", indexed, commitError);
-              }
-            },
-            raft.getThreadContext());
+    appendEntriesFuture.whenCompleteAsync(
+        (commitIndex, commitError) -> {
+          if (!isRunning()) {
+            return;
+          }
+
+          // have the state machine apply the index which should do nothing but ensures it keeps
+          // up to date with the latest entries, so it can handle configuration and initial
+          // entries properly on fail over
+          if (commitError == null) {
+            appendListener.onCommit(indexed.index());
+          } else {
+            appendListener.onCommitError(indexed.index(), commitError);
+            // replicating the entry will be retried on the next append request
+            log.error(""Failed to replicate entry: {}"", indexed, commitError);
+          }
+        },
+        raft.getThreadContext());
   }
 
   public synchronized void onInitialEntriesCommitted(final Runnable runnable) {
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
index b217586..8029766 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
@@ -82,7 +82,7 @@ public class RaftAppendTest {
   @Test
   public void shouldNotifyCommittedEntryListenerOnLeaderOnly() throws Throwable {
     // given
-    final var committedEntryListener = mock(RaftCommittedEntryListener.class);
+    final var committedEntryListener = mock(RaftApplicationEntryCommittedPositionListener.class);
     raftRule.addCommittedEntryListener(committedEntryListener);
 
     // when
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
index 8f73cba..193a176 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
@@ -644,9 +644,12 @@ public final class RaftRule extends ExternalResource {
   }
 
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
     servers.forEach(
-        (id, raft) -> raft.getContext().addCommittedEntryListener(raftCommittedEntryListener));
+        (id, raft) ->
+            raft.getContext()
+                .addCommittedEntryListener(raftApplicationEntryCommittedPositionListener));
   }
 
   public void partition(final RaftServer follower) {
diff --git a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
index a61571f..6c082d7 100644
--- a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
+++ b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
@@ -7,8 +7,7 @@
  */
 package io.camunda.zeebe.broker.system.partitions.impl;
 
-import io.atomix.raft.RaftCommittedEntryListener;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.camunda.zeebe.broker.system.partitions.NoEntryAtSnapshotPosition;
 import io.camunda.zeebe.broker.system.partitions.StateController;
 import io.camunda.zeebe.logstreams.impl.Loggers;
@@ -36,7 +35,7 @@ import java.util.function.Consumer;
 import org.slf4j.Logger;
 
 public final class AsyncSnapshotDirector extends Actor
-    implements RaftCommittedEntryListener, HealthMonitorable {
+    implements RaftApplicationEntryCommittedPositionListener, HealthMonitorable {
 
   public static final Duration MINIMUM_SNAPSHOT_PERIOD = Duration.ofMinutes(1);
 
@@ -115,7 +114,7 @@ public final class AsyncSnapshotDirector extends Actor
   @Override
   protected void handleFailure(final Throwable failure) {
     LOG.error(
-        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}. {}"",
+        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}."",
         actorName,
         snapshotRate,
         failure);
@@ -407,13 +406,8 @@ public final class AsyncSnapshotDirector extends Actor
   }
 
   @Override
-  public void onCommit(final IndexedRaftLogEntry indexedRaftLogEntry) {
-    // is called by the Leader Role and gives the last committed entry, where we
-    // can extract the highest position, which corresponds to the last committed position
-    if (indexedRaftLogEntry.isApplicationEntry()) {
-      final var committedPosition = indexedRaftLogEntry.getApplicationEntry().highestPosition();
-      newPositionCommitted(committedPosition);
-    }
+  public void onCommit(final long committedPosition) {
+    newPositionCommitted(committedPosition);
   }
 
   public void newPositionCommitted(final long currentCommitPosition) {

diff --git a/topology/pom.xml b/topology/pom.xml
index 389508e..ee6239a 100644
--- a/topology/pom.xml
+++ b/topology/pom.xml
@@ -16,6 +16,7 @@
   </parent>
 
   <artifactId>zeebe-cluster-topology</artifactId>
+  <name>Zeebe Cluster Topology</name>
 
   <properties>
     <proto.dir>${maven.multiModuleProjectDirectory}/topology/src/main/resources/proto</proto.dir>
",2,"[""323cf81961cdd3748a7ba6ba470ecb13e5374e9f"", ""8911a972222dc80a242f3f1d9b3596321b3fdeaa""]","[""refactor"", ""build""]","1. The main code change involves replacing the RaftCommittedEntryListener interface with a new, more focused RaftApplicationEntryCommittedPositionListener, updating all usages, simplifying listener notification logic, and cleaning up related code, plus a minor addition of a <name> tag in the topology module's pom.xml.
2. The listener/interface replacement and related logic changes are structural improvements to code organization and memory usage, matching the 'refactor' purpose label, while the pom.xml edit is a build metadata change fitting the 'build' object label.
3. 'refactor' is appropriate because the code's external behavior is not functionally changed—only the internal structure and efficiency are improved; 'feat' and 'fix' do not apply as there is no new feature or bug fix, and 'build' is correct for the pom.xml update, not 'cicd' or 'docs'.
4. The assigned labels 'refactor' and 'build' accurately reflect the restructuring of core logic and the modification of build configuration, respectively, with no overlap or misclassification."
"add missing region to cloudformation_stack_set
better tested publishing flow
pin version of actionlint used","diff --git a/internal/providers/terraform/aws/cloudformation_stack_set.go b/internal/providers/terraform/aws/cloudformation_stack_set.go
index 6720caa..e752b79 100644
--- a/internal/providers/terraform/aws/cloudformation_stack_set.go
+++ b/internal/providers/terraform/aws/cloudformation_stack_set.go
@@ -12,7 +12,7 @@ func getCloudFormationStackSetRegistryItem() *schema.RegistryItem {
 	}
 }
 func NewCloudformationStackSet(d *schema.ResourceData, u *schema.UsageData) *schema.Resource {
-	r := &aws.CloudformationStackSet{Address: strPtr(d.Address)}
+	r := &aws.CloudformationStackSet{Address: strPtr(d.Address), Region: strPtr(d.Get(""region"").String())}
 	if !d.IsEmpty(""template_body"") {
 		r.TemplateBody = strPtr(d.Get(""template_body"").String())
 	}

diff --git a/Makefile.toml b/Makefile.toml
index e7d2b20..490d6e2 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -82,7 +82,7 @@ end
 '''
 
 [tasks.build-plugins-release]
-env = { ""CARGO_MAKE_WORKSPACE_SKIP_MEMBERS"" = ["".""] }
+env = { ""CARGO_MAKE_WORKSPACE_INCLUDE_MEMBERS"" = [""default-plugins/status-bar"", ""default-plugins/strider"", ""default-plugins/tab-bar""] }
 run_task = { name = ""build-release"", fork = true }
 
 [tasks.wasm-opt-plugins]
@@ -129,15 +129,16 @@ args = [""install"", ""cross""]
 [tasks.publish]
 clear = true
 workspace = false
-dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit"", ""build-release"", ""publish-zellij-tile"", ""publish-zellij-tile-utils"", ""publish-zellij-utils"", ""publish-zellij-client"", ""publish-zellij-server""]
+dependencies = [""build-plugins-release"", ""wasm-opt-plugins"", ""release-commit""]
 run_task = ""publish-zellij""
 
 [tasks.release-commit]
 dependencies = [""commit-all"", ""tag-release""]
 command = ""git""
-args = [""push"", ""--atomic"", ""upstream"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
+args = [""push"", ""--atomic"", ""origin"", ""main"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 
 [tasks.commit-all]
+ignore_errors = true
 command = ""git""
 args = [""commit"", ""-aem"", ""chore(release): v${CARGO_MAKE_CRATE_VERSION}""]
 
@@ -148,31 +149,32 @@ args = [""tag"", ""v${CARGO_MAKE_CRATE_VERSION}""]
 [tasks.publish-zellij-tile]
 ignore_errors = true
 cwd = ""zellij-tile""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-client]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-client""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-server]
+ignore_errors = true
 dependencies = [""publish-zellij-utils""]
 cwd = ""zellij-server""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-utils]
+ignore_errors = true
 dependencies = [""publish-zellij-tile""]
 cwd = ""zellij-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij-tile-utils]
 ignore_errors = true
 cwd = ""zellij-tile-utils""
-command = ""cargo publish && sleep 15""
+script = ""cargo publish && sleep 15""
 
 [tasks.publish-zellij]
 dependencies = [""publish-zellij-client"", ""publish-zellij-server"", ""publish-zellij-utils""]
 command = ""cargo""
 args = [""publish""]
-
-

diff --git a/.github/workflows/introspect.yml b/.github/workflows/introspect.yml
index b6d9125..82d22a5 100644
--- a/.github/workflows/introspect.yml
+++ b/.github/workflows/introspect.yml
@@ -25,5 +25,5 @@ jobs:
       # From https://github.com/rhysd/actionlint/blob/main/docs/usage.md#use-actionlint-on-github-actions
       - name: Check workflow files
         run: |
-          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash)
+          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/590d3bd9dde0c91f7a66071d40eb84716526e5a6/scripts/download-actionlint.bash) 1.6.25
           ./actionlint -color -shellcheck=""""
",3,"[""304d0588f634e9e72087a706367c53af9c7f7180"", ""65574eea5da54bf4722ecb551b42f8ff6088f33b"", ""b702adc245f679ae20d84de39f0d63b14aabed5d""]","[""fix"", ""build"", ""cicd""]","1. The commit modifies a Go file to add a missing 'region' property to the CloudFormationStackSet resource, updates Makefile.toml with changes to publishing and build task logic, and pins the version of 'actionlint' in a GitHub Actions workflow.
2. The Go file change addresses a missing required property, which is a bug fix (aligns with 'fix'); the Makefile.toml changes alter build and publishing tasks, which directly impact the build system (aligns with 'build'); the workflow file change updates CI configuration by pinning a linter version (aligns with 'cicd').
3. 'fix' is appropriate for the Go file because it corrects erroneous behavior, not adding new features or refactoring; 'build' fits for Makefile.toml because the changes are to build and publish scripts, not CI or test code; 'cicd' is correct for the workflow update as it changes CI configuration, not build logic or documentation.
4. The assigned labels 'fix', 'build', and 'cicd' are appropriate because each code unit is exclusively focused on bug fixing, build system updates, or CI configuration, respectively, with no overlap or misclassification."
remove duplicated code,"diff --git a/packages/core/src/components/action-sheet/action-sheet.tsx b/packages/core/src/components/action-sheet/action-sheet.tsx
index 7166508..dad7daf 100644
--- a/packages/core/src/components/action-sheet/action-sheet.tsx
+++ b/packages/core/src/components/action-sheet/action-sheet.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, isDef, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -23,15 +23,15 @@ import mdLeaveAnimation from './animations/md.leave';
 })
 export class ActionSheet implements OverlayInterface {
 
+  private presented = false;
+
   mode: string;
   color: string;
-
-  private presented = false;
-  private animation: Animation | null = null;
+  animation: Animation;
 
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -178,25 +178,8 @@ export class ActionSheet implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      // Check if prop animate is false or if the config for animate is defined/false
-      if (!this.willAnimate || (isDef(this.config.get('willAnimate')) && this.config.get('willAnimate') === false)) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        this.animation = animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   protected buttonClick(button: ActionSheetButton) {
diff --git a/packages/core/src/components/alert/alert.tsx b/packages/core/src/components/alert/alert.tsx
index 800b77b..bdf4fc5 100644
--- a/packages/core/src/components/alert/alert.tsx
+++ b/packages/core/src/components/alert/alert.tsx
@@ -1,8 +1,8 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync, autoFocus } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync, autoFocus } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,18 +21,19 @@ import mdLeaveAnimation from './animations/md.leave';
   }
 })
 export class Alert implements OverlayInterface {
-  mode: string;
-  color: string;
 
   private presented = false;
-  private animation: Animation | null = null;
   private activeId: string;
   private inputType: string | null = null;
   private hdrId: string;
 
+  animation: Animation;
+  mode: string;
+  color: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -264,25 +265,10 @@ export class Alert implements OverlayInterface {
     return values;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
-
   private renderCheckbox(inputs: AlertInput[]) {
     if (inputs.length === 0) return null;
 
diff --git a/packages/core/src/components/loading/loading.tsx b/packages/core/src/components/loading/loading.tsx
index f45eaf1..cc4f511 100644
--- a/packages/core/src/components/loading/loading.tsx
+++ b/packages/core/src/components/loading/loading.tsx
@@ -1,13 +1,13 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
 import mdEnterAnimation from './animations/md.enter';
 import mdLeaveAnimation from './animations/md.leave';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 @Component({
   tag: 'ion-loading',
@@ -21,16 +21,17 @@ import { OverlayInterface, BACKDROP } from '../../utils/overlays';
 })
 
 export class Loading implements OverlayInterface {
-  color: string;
-  mode: string;
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
 
+  animation: Animation;
+  color: string;
+  mode: string;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -199,24 +200,8 @@ export class Loading implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        // if the duration is 0, it won't actually animate I don't think
-        // TODO - validate this
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   hostData() {
diff --git a/packages/core/src/components/modal/modal.tsx b/packages/core/src/components/modal/modal.tsx
index af50d63..2b7510c 100644
--- a/packages/core/src/components/modal/modal.tsx
+++ b/packages/core/src/components/modal/modal.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -25,14 +25,16 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Modal implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
+
   @Prop() overlayId: number;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
 
@@ -208,22 +210,8 @@ export class Modal implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   @Method()
diff --git a/packages/core/src/components/picker/picker.tsx b/packages/core/src/components/picker/picker.tsx
index 13faa3e..d70381e 100644
--- a/packages/core/src/components/picker/picker.tsx
+++ b/packages/core/src/components/picker/picker.tsx
@@ -1,9 +1,9 @@
 import { Component, CssClassMap, Element, Event, EventEmitter, Listen, Method, Prop, State } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -21,16 +21,17 @@ import iosLeaveAnimation from './animations/ios.leave';
 export class Picker implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private durationTimeout: any;
   private mode: string;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
   @State() private showSpinner: boolean = null;
   @State() private spinner: string;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -231,22 +232,8 @@ export class Picker implements OverlayInterface {
     return this.columns;
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, undefined);
   }
 
   private buttonClick(button: PickerButton) {
diff --git a/packages/core/src/components/popover/popover.tsx b/packages/core/src/components/popover/popover.tsx
index 65031ff..6a47bf6 100644
--- a/packages/core/src/components/popover/popover.tsx
+++ b/packages/core/src/components/popover/popover.tsx
@@ -1,10 +1,10 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, DomController, FrameworkDelegate, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
 import { DomFrameworkDelegate } from '../../utils/dom-framework-delegate';
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses } from '../../utils/theme';
-import { OverlayInterface, BACKDROP } from '../../utils/overlays';
+import { OverlayInterface, BACKDROP, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,12 +24,13 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Popover implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation;
   private usersComponentElement: HTMLElement;
 
+  animation: Animation;
+
   @Element() private el: HTMLElement;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop({ mutable: true }) delegate: FrameworkDelegate;
@@ -224,22 +225,8 @@ export class Popover implements OverlayInterface {
     });
   }
 
-  private playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.ev).then((animation) => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then(animation => {
-      animation.destroy();
-      this.animation = null;
-    })
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.ev);
   }
 
   hostData() {
diff --git a/packages/core/src/components/toast/toast.tsx b/packages/core/src/components/toast/toast.tsx
index 1afa318..372070a 100644
--- a/packages/core/src/components/toast/toast.tsx
+++ b/packages/core/src/components/toast/toast.tsx
@@ -1,9 +1,9 @@
 import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
-import { Animation, AnimationBuilder, AnimationController, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
+import { Animation, AnimationBuilder, Config, CssClassMap, DomController, OverlayDismissEvent, OverlayDismissEventDetail } from '../../index';
 
-import { domControllerAsync, playAnimationAsync } from '../../utils/helpers';
+import { domControllerAsync } from '../../utils/helpers';
 import { createThemedClasses, getClassMap } from '../../utils/theme';
-import { OverlayInterface } from '../../utils/overlays';
+import { OverlayInterface, overlayAnimation } from '../../utils/overlays';
 
 import iosEnterAnimation from './animations/ios.enter';
 import iosLeaveAnimation from './animations/ios.leave';
@@ -24,14 +24,14 @@ import mdLeaveAnimation from './animations/md.leave';
 export class Toast implements OverlayInterface {
 
   private presented = false;
-  private animation: Animation | null;
 
   @Element() private el: HTMLElement;
 
   mode: string;
   color: string;
+  animation: Animation | null;
 
-  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: AnimationController;
+  @Prop({ connect: 'ion-animation-controller' }) animationCtrl: HTMLIonAnimationControllerElement;
   @Prop({ context: 'config' }) config: Config;
   @Prop({ context: 'dom' }) dom: DomController;
   @Prop() overlayId: number;
@@ -123,6 +123,22 @@ export class Toast implements OverlayInterface {
    */
   @Event() ionToastDidUnload: EventEmitter<ToastEventDetail>;
 
+  componentDidLoad() {
+    this.ionToastDidLoad.emit();
+  }
+
+  componentDidUnload() {
+    this.ionToastDidUnload.emit();
+  }
+
+  @Listen('ionDismiss')
+  protected onDismiss(ev: UIEvent) {
+    ev.stopPropagation();
+    ev.preventDefault();
+
+    this.dismiss();
+  }
+
   /**
    * Present the toast overlay after it has been created.
    */
@@ -169,38 +185,8 @@ export class Toast implements OverlayInterface {
     });
   }
 
-  playAnimation(animationBuilder: AnimationBuilder) {
-    if (this.animation) {
-      this.animation.destroy();
-      this.animation = null;
-    }
-
-    return this.animationCtrl.create(animationBuilder, this.el, this.position).then(animation => {
-      this.animation = animation;
-      if (!this.willAnimate) {
-        animation.duration(0);
-      }
-      return playAnimationAsync(animation);
-    }).then((animation) => {
-      animation.destroy();
-      this.animation = null;
-    });
-  }
-
-  componentDidLoad() {
-    this.ionToastDidLoad.emit();
-  }
-
-  componentDidUnload() {
-    this.ionToastDidUnload.emit();
-  }
-
-  @Listen('ionDismiss')
-  protected onDismiss(ev: UIEvent) {
-    ev.stopPropagation();
-    ev.preventDefault();
-
-    this.dismiss();
+  private playAnimation(animationBuilder: AnimationBuilder): Promise<void> {
+    return overlayAnimation(this, animationBuilder, this.willAnimate, this.el, this.position);
   }
 
   private wrapperClass(): CssClassMap {
diff --git a/packages/core/src/utils/overlays.ts b/packages/core/src/utils/overlays.ts
index 8926544..634df43 100644
--- a/packages/core/src/utils/overlays.ts
+++ b/packages/core/src/utils/overlays.ts
@@ -1,3 +1,5 @@
+import { AnimationBuilder, Animation } from "".."";
+import { playAnimationAsync } from ""./helpers"";
 
 let lastId = 1;
 
@@ -56,8 +58,33 @@ export function removeLastOverlay(overlays: OverlayMap) {
   return toRemove ? toRemove.dismiss() : Promise.resolve();
 }
 
+export function overlayAnimation(
+  overlay: OverlayInterface,
+  animationBuilder: AnimationBuilder,
+  animate: boolean,
+  baseEl: HTMLElement,
+  opts: any
+): Promise<void> {
+  if (overlay.animation) {
+    overlay.animation.destroy();
+    overlay.animation = null;
+  }
+  return overlay.animationCtrl.create(animationBuilder, baseEl, opts).then(animation => {
+    overlay.animation = animation;
+    if (!animate) {
+      animation.duration(0);
+    }
+    return playAnimationAsync(animation);
+  }).then((animation) => {
+    animation.destroy();
+    overlay.animation = null;
+  });
+}
+
 export interface OverlayInterface {
   overlayId: number;
+  animation: Animation;
+  animationCtrl: HTMLIonAnimationControllerElement;
 
   present(): Promise<void>;
   dismiss(data?: any, role?: string): Promise<void>;
",1,"[""9e3f295bbfd4098ffda1ae6656699f60b86c1f92""]","[""refactor""]","1. The code changes remove duplicated animation logic from several overlay components and centralize it into a new 'overlayAnimation' utility function, updating all relevant components to use this shared function.
2. This aligns with the 'refactor' label because the motivation is to improve code structure, reduce duplication, and promote reuse without changing external behavior or adding new features.
3. 'refactor' is appropriate as no new features are introduced ('feat' does not apply), no bugs are being fixed ('fix' does not apply), and the changes are not limited to documentation, tests, CI/CD, or build artifacts (so object labels are not relevant).
4. The 'refactor' label correctly captures that this commit restructures code for maintainability by deduplicating and centralizing animation logic."
"autostart feature fixed
make sure root is being watched and setRoot called when it changes
add ability to get all encoded values","diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/packages/core/src/components/nav/nav.tsx b/packages/core/src/components/nav/nav.tsx
index 5aaacb6..27241ee 100644
--- a/packages/core/src/components/nav/nav.tsx
+++ b/packages/core/src/components/nav/nav.tsx
@@ -1,4 +1,4 @@
-import { Component, Element, Event, EventEmitter, Listen, Method, Prop } from '@stencil/core';
+import { Component, Element, Event, EventEmitter, Listen, Method, Prop, Watch } from '@stencil/core';
 import {
   Animation,
   AnimationController,
@@ -103,10 +103,19 @@ export class Nav implements PublicNav, NavContainer {
     }
     this.init = true;
     if (!this.useRouter) {
+      console.log('componentDidLoadImpl: ', this.root);
       componentDidLoadImpl(this);
     }
   }
 
+  @Watch('root')
+  updateRootComponent(): any {
+    console.log('updateRootComponent: ', this.root);
+    if (this.init) {
+      return this.setRoot(this.root);
+    }
+  }
+
   getViews(): PublicViewController[] {
     return getViews(this);
   }
diff --git a/packages/core/src/components/nav/test/set-root/index.html b/packages/core/src/components/nav/test/set-root/index.html
new file mode 100644
index 0000000..823c9ed
--- /dev/null
+++ b/packages/core/src/components/nav/test/set-root/index.html
@@ -0,0 +1,110 @@
+<!DOCTYPE html>
+<html dir=""ltr"">
+<head>
+  <meta charset=""UTF-8"">
+  <title>Nav</title>
+  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"">
+  <script src=""/dist/ionic.js""></script>
+</head>
+<body onload=""initiaize()"">
+  <ion-app>
+    <ion-nav root=""page-one""></ion-nav>
+  </ion-app>
+</body>
+
+<script>
+
+  class PageOne extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+      <ion-page>
+        <ion-header>
+          <ion-toolbar>
+            <ion-title>Page One</ion-title>
+          </ion-toolbar>
+        </ion-header>
+        <ion-content padding>
+          <h1>Page One</h1>
+          <ion-button class=""next"">Go to Page Two</ion-button>
+        </ion-content>
+      </ion-page>`;
+
+      const button = this.querySelector('ion-button');
+      button.addEventListener('click', async () => {
+        this.closest('ion-nav').push('page-two');
+      });
+    }
+  }
+
+  class PageTwo extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Two</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Two</h1>
+            <ion-button class=""next"">Go to Page Three</ion-button>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+
+      const nextButton = this.querySelector('ion-button.next');
+      nextButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').push('page-three');
+      });
+    }
+  }
+
+  class PageThree extends HTMLElement {
+    async connectedCallback() {
+      this.innerHTML = `
+        <ion-page>
+          <ion-header>
+            <ion-toolbar>
+              <ion-title>Page Three</ion-title>
+            </ion-toolbar>
+          </ion-header>
+          <ion-content padding>
+            <h1>Page Three</h1>
+            <ion-button class=""previous"">Go Back</ion-button>
+          </ion-content>
+        </ion-page>`;
+
+      const previousButton = this.querySelector('ion-button.previous');
+      previousButton.addEventListener('click', async () => {
+        await this.closest('ion-nav').pop();
+      });
+    }
+  }
+
+  customElements.define('page-one', PageOne);
+  customElements.define('page-two', PageTwo);
+  customElements.define('page-three', PageThree);
+
+  async function initiaize() {
+    const nav = document.querySelector('ion-nav');
+    await nav.componentOnReady();
+    nav.root = 'page-one';
+
+    setInterval(() => {
+      if (nav.root === 'page-one') {
+        nav.root = 'page-two';
+      } else if ( nav.root === 'page-two') {
+        nav.root = 'page-three';
+      } else {
+        nav.root = 'page-one';
+      }
+    }, 1000);
+  }
+
+</script>
+</html>

diff --git a/delorean_mem_qe/src/column.rs b/delorean_mem_qe/src/column.rs
index bc89cb2..b3df18e 100644
--- a/delorean_mem_qe/src/column.rs
+++ b/delorean_mem_qe/src/column.rs
@@ -537,6 +537,22 @@ impl Column {
         }
     }
 
+    /// Materialise all of the encoded values.
+    pub fn all_encoded_values(&self) -> Vector {
+        match self {
+            Column::String(c) => {
+                let now = std::time::Instant::now();
+                let v = c.all_encoded_values();
+                log::debug!(""time getting all encoded values {:?}"", now.elapsed());
+
+                log::debug!(""dictionary {:?}"", c.data.dictionary());
+                Vector::Integer(v)
+            }
+            Column::Float(c) => Vector::Float(c.all_encoded_values()),
+            Column::Integer(c) => Vector::Integer(c.all_encoded_values()),
+        }
+    }
+
     /// Given an encoded value for a row, materialise and return the decoded
     /// version.
     ///
@@ -986,6 +1002,10 @@ impl String {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -1037,6 +1057,10 @@ impl Float {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<f64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[f64] {
         self.data.scan_from(row_id)
     }
@@ -1106,6 +1130,10 @@ impl Integer {
         self.data.encoded_values(row_ids)
     }
 
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        self.data.all_encoded_values()
+    }
+
     pub fn scan_from(&self, row_id: usize) -> &[i64] {
         self.data.scan_from(row_id)
     }
diff --git a/delorean_mem_qe/src/encoding.rs b/delorean_mem_qe/src/encoding.rs
index d6a865a..4b057cf 100644
--- a/delorean_mem_qe/src/encoding.rs
+++ b/delorean_mem_qe/src/encoding.rs
@@ -68,6 +68,12 @@ where
         self.values(row_ids)
     }
 
+    /// Return all encoded values. For this encoding this is just the decoded
+    /// values
+    pub fn all_encoded_values(&self) -> Vec<T> {
+        self.values.clone()
+    }
+
     // TODO(edd): fix this when added NULL support
     pub fn scan_from_until_some(&self, _row_id: usize) -> Option<T> {
         unreachable!(""to remove"");
@@ -485,6 +491,26 @@ impl DictionaryRLE {
         out
     }
 
+    // values materialises a vector of references to all logical values in the
+    // encoding.
+    pub fn all_values(&mut self) -> Vec<Option<&String>> {
+        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
+
+        // build reverse mapping.
+        let mut idx_value = BTreeMap::new();
+        for (k, v) in &self.entry_index {
+            idx_value.insert(v, k);
+        }
+        assert_eq!(idx_value.len(), self.entry_index.len());
+
+        for (idx, rl) in &self.run_lengths {
+            // TODO(edd): fix unwrap - we know that the value exists in map...
+            let v = idx_value.get(&idx).unwrap().as_ref();
+            out.extend(iter::repeat(v).take(*rl as usize));
+        }
+        out
+    }
+
     /// Return the decoded value for an encoded ID.
     ///
     /// Panics if there is no decoded value for the provided id
@@ -528,22 +554,13 @@ impl DictionaryRLE {
         out
     }
 
-    // values materialises a vector of references to all logical values in the
-    // encoding.
-    pub fn all_values(&mut self) -> Vec<Option<&String>> {
-        let mut out: Vec<Option<&String>> = Vec::with_capacity(self.total as usize);
-
-        // build reverse mapping.
-        let mut idx_value = BTreeMap::new();
-        for (k, v) in &self.entry_index {
-            idx_value.insert(v, k);
-        }
-        assert_eq!(idx_value.len(), self.entry_index.len());
+    // all_encoded_values materialises a vector of all encoded values for the
+    // column.
+    pub fn all_encoded_values(&self) -> Vec<i64> {
+        let mut out: Vec<i64> = Vec::with_capacity(self.total as usize);
 
         for (idx, rl) in &self.run_lengths {
-            // TODO(edd): fix unwrap - we know that the value exists in map...
-            let v = idx_value.get(&idx).unwrap().as_ref();
-            out.extend(iter::repeat(v).take(*rl as usize));
+            out.extend(iter::repeat(*idx as i64).take(*rl as usize));
         }
         out
     }
diff --git a/delorean_mem_qe/src/segment.rs b/delorean_mem_qe/src/segment.rs
index c058df0..f8c5005 100644
--- a/delorean_mem_qe/src/segment.rs
+++ b/delorean_mem_qe/src/segment.rs
@@ -228,7 +228,7 @@ impl Segment {
         group_columns: &[String],
         aggregates: &[(String, AggregateType)],
         window: i64,
-    ) -> BTreeMap<Vec<String>, Vec<(String, Option<column::Aggregate>)>> {
+    ) -> BTreeMap<Vec<i64>, Vec<(&String, &AggregateType, Option<column::Aggregate>)>> {
         // Build a hash table - essentially, scan columns for matching row ids,
         // emitting the encoded value for each column and track those value
         // combinations in a hashmap with running aggregates.
@@ -242,6 +242,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -263,7 +267,12 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
+
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -325,10 +334,10 @@ impl Segment {
             .collect::<Vec<_>>();
 
         // hashMap is about 20% faster than BTreeMap in this case
-        let mut hash_table: HashMap<
+        let mut hash_table: BTreeMap<
             Vec<i64>,
             Vec<(&String, &AggregateType, Option<column::Aggregate>)>,
-        > = HashMap::new();
+        > = BTreeMap::new();
 
         let mut aggregate_row: Vec<(&str, Option<column::Scalar>)> =
             std::iter::repeat_with(|| ("""", None))
@@ -406,8 +415,10 @@ impl Segment {
             }
             processed_rows += 1;
         }
+        // println!(""groups: {:?}"", hash_table.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, hash_table);
         BTreeMap::new()
+        // hash_table
     }
 
     pub fn aggregate_by_group_using_sort(
@@ -451,7 +462,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -557,6 +572,10 @@ impl Segment {
             assert_ne!(group_columns[group_columns.len() - 1], ""time"");
         }
 
+        // TODO(edd): Perf - if there is no predicate and we want entire segment
+        // then it will be a lot faster to not build filtered_row_ids and just
+        // get all encoded values for each grouping column...
+
         // filter on predicates and time
         let filtered_row_ids: croaring::Bitmap;
         if let Some(row_ids) = self.filter_by_predicates_eq(time_range, predicates) {
@@ -577,7 +596,11 @@ impl Segment {
         let mut group_column_encoded_values = Vec::with_capacity(group_columns.len());
         for group_column in group_columns {
             if let Some(column) = self.column(&group_column) {
-                let encoded_values = column.encoded_values(&filtered_row_ids_vec);
+                let encoded_values = if filtered_row_ids_vec.len() == self.meta.rows {
+                    column.all_encoded_values()
+                } else {
+                    column.encoded_values(&filtered_row_ids_vec)
+                };
                 assert_eq!(
                     filtered_row_ids.cardinality() as usize,
                     encoded_values.len()
@@ -709,6 +732,7 @@ impl Segment {
             aggregates: group_key_aggregates,
         });
 
+        // println!(""groups: {:?}"", results.len());
         log::debug!(""({:?} rows processed) {:?}"", processed_rows, results);
         // results
         vec![]
",3,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""4be836f5655fb5356fde5ddd7437125f8574705d"", ""cad5e45208346528ad02cd04dcac863f90faa037""]","[""fix"", ""refactor"", ""feat""]","1. The changes include: (a) fixing autostart logic in Container.ts by correcting a boolean assignment, (b) adding a @Watch decorator and updateRootComponent method to nav.tsx to observe root changes and trigger setRoot, (c) introducing a new test HTML file for nav component root-setting behavior, (d) implementing a new all_encoded_values method and related plumbing in delorean_mem_qe's column.rs, encoding.rs, and segment.rs, and (e) removing unused imports and making minor code cleanups.
2. The fix label applies to the correction in Container.ts (autostart bug) and nav.tsx (ensuring setRoot is called on root change), the feat label applies to the addition of all_encoded_values retrieval methods and the new nav test file, and the refactor label applies to minor code cleanups and import removals.
3. 'fix' is appropriate for changes that repair incorrect behavior (autostart, root watching), 'feat' is appropriate for new capabilities (all_encoded_values API, new nav test), and 'refactor' is appropriate for cleanup that does not alter behavior; object labels like 'test' are not used because the new test is part of a broader feature addition rather than a standalone test logic change.
4. The fix, feat, and refactor labels are justified because the commit simultaneously corrects bugs, adds new functionality, and improves code structure without changing behavior."
"skip if related view/hook/column of a filter is not found

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
index 1515f88..6c250bd 100644
--- a/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
+++ b/packages/nocodb/src/lib/version-upgrader/ncFilterUpgrader.ts
@@ -21,7 +21,13 @@ export default async function ({ ncMeta }: NcUpgraderCtx) {
     } else {
       continue;
     }
-    if (filter.project_id != model.project_id) {
+
+    // skip if related model is not found
+    if (!model) {
+      continue;
+    }
+
+    if (filter.project_id !== model.project_id) {
       await ncMeta.metaUpdate(
         null,
         null,
",1,"[""ab1e60a97c6d5c688dacbd23bca40cb8f20c4ac3""]","[""fix""]","1. The code adds a conditional check to skip processing if the related model for a filter is not found, preventing further operations in such cases.
2. This change directly addresses a scenario where missing data could cause errors or unintended behavior, which aligns with the 'fix' label's definition of resolving bugs or faults.
3. The 'fix' label is appropriate because the change prevents a bug (processing with undefined models), while 'feat' would only apply for new features and 'refactor' for non-behavioral improvements, neither of which fit here.
4. The 'fix' label accurately reflects that this change corrects faulty logic by handling a missing dependency case."
"only restart if pages directory itself is changed

resolves #429
switch QA to new testbench-1.x-prod

In order to use the new Testbench that is compatible with Zeebe 1.x
versions, this switches the client id and secrets used by the QA stage.
use module path alias","diff --git a/packages/cli/src/commands/dev.ts b/packages/cli/src/commands/dev.ts
index 35d859e..d6d91ed 100644
--- a/packages/cli/src/commands/dev.ts
+++ b/packages/cli/src/commands/dev.ts
@@ -1,4 +1,4 @@
-import { resolve } from 'upath'
+import { resolve, relative } from 'upath'
 import chokidar from 'chokidar'
 import debounce from 'debounce-promise'
 import type { Nuxt } from '@nuxt/kit'
@@ -27,9 +27,9 @@ export default defineNuxtCommand({
     const { loadNuxt, buildNuxt } = requireModule('@nuxt/kit', rootDir) as typeof import('@nuxt/kit')
 
     let currentNuxt: Nuxt
-    const load = async (isRestart: boolean) => {
+    const load = async (isRestart: boolean, reason?: string) => {
       try {
-        const message = `${isRestart ? 'Restarting' : 'Starting'} nuxt...`
+        const message = `${reason ? reason + '. ' : ''}${isRestart ? 'Restarting' : 'Starting'} nuxt...`
         server.setApp(createLoadingHandler(message))
         if (isRestart) {
           console.log(message)
@@ -59,12 +59,8 @@ export default defineNuxtCommand({
     const dLoad = debounce(load, 250)
     const watcher = chokidar.watch([rootDir], { ignoreInitial: true, depth: 1 })
     watcher.on('all', (_event, file) => {
-      // Ignore any changes to files within the Nuxt build directory
-      if (file.includes(currentNuxt.options.buildDir)) {
-        return
-      }
-      if (file.includes('nuxt.config') || file.includes('modules') || file.includes('pages')) {
-        dLoad(true)
+      if (file.match(/nuxt\.config\.(js|ts|mjs|cjs)$|pages$/)) {
+        dLoad(true, `${relative(rootDir, file)} updated`)
       }
     })
 

diff --git a/Jenkinsfile b/Jenkinsfile
index 176ab58..bead402 100644
--- a/Jenkinsfile
+++ b/Jenkinsfile
@@ -326,7 +326,7 @@ pipeline {
                 TAG = ""${env.VERSION}-${env.GIT_COMMIT}""
                 DOCKER_GCR = credentials(""zeebe-gcr-serviceaccount-json"")
                 ZEEBE_AUTHORIZATION_SERVER_URL = 'https://login.cloud.ultrawombat.com/oauth/token'
-                ZEEBE_CLIENT_ID = 'W5a4JUc3I1NIetNnodo3YTvdsRIFb12w'
+                ZEEBE_CLIENT_ID = 'ELL8eP0qDkl6dxXVps0t51x2VkCkWf~p'
                 QA_RUN_VARIABLES = ""{\""zeebeImage\"": \""${env.IMAGE}:${env.TAG}\"", \""generationTemplate\"": \""${params.GENERATION_TEMPLATE}\"", "" +
                                     ""\""channel\"": \""Internal Dev\"", \""branch\"": \""${env.BRANCH_NAME}\"", \""build\"": \""${currentBuild.absoluteUrl}\"", "" +
                                     ""\""businessKey\"": \""${currentBuild.absoluteUrl}\"", \""processId\"": \""qa-protocol\""}""
@@ -341,7 +341,7 @@ pipeline {
                     withVault(
                         [vaultSecrets:
                              [
-                                 [path        : 'secret/common/ci-zeebe/testbench-secrets-int',
+                                 [path        : 'secret/common/ci-zeebe/testbench-secrets-1.x-prod',
                                   secretValues:
                                       [
                                           [envVar: 'ZEEBE_CLIENT_SECRET', vaultKey: 'clientSecret'],

diff --git a/src/background/audio-manager.ts b/src/background/audio-manager.ts
index 54e8b24..11c5fba 100644
--- a/src/background/audio-manager.ts
+++ b/src/background/audio-manager.ts
@@ -2,7 +2,7 @@
  * To make sure only one audio plays at a time
  */
 
-import { timeout } from '../_helpers/promise-more'
+import { timeout } from '@/_helpers/promise-more'
 
 declare global {
   interface Window {
diff --git a/src/background/context-menus.ts b/src/background/context-menus.ts
index 994b59e..7036362 100644
--- a/src/background/context-menus.ts
+++ b/src/background/context-menus.ts
@@ -1,5 +1,5 @@
-import { storage, openURL } from '../_helpers/browser-api'
-import { AppConfig } from '../app-config'
+import { storage, openURL } from '@/_helpers/browser-api'
+import { AppConfig } from '@/app-config'
 
 import { Observable } from 'rxjs/Observable'
 import { fromPromise } from 'rxjs/observable/fromPromise'
diff --git a/src/background/initialization.ts b/src/background/initialization.ts
index 0e5b3ad..001ee73 100644
--- a/src/background/initialization.ts
+++ b/src/background/initialization.ts
@@ -1,6 +1,6 @@
-import { storage, openURL } from '../_helpers/browser-api'
-import checkUpdate from '../_helpers/check-update'
-import { AppConfig } from '../app-config'
+import { storage, openURL } from '@/_helpers/browser-api'
+import checkUpdate from '@/_helpers/check-update'
+import { AppConfig } from '@/app-config'
 import { mergeConfig } from './merge-config'
 import { init as initMenus } from './context-menus'
 import { init as initPdf } from './pdf-sniffer'
diff --git a/src/background/merge-config.ts b/src/background/merge-config.ts
index afa1800..afdbd63 100644
--- a/src/background/merge-config.ts
+++ b/src/background/merge-config.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import _ from 'lodash'
 
 /**
@@ -24,7 +24,7 @@ function initConfig (): Promise<AppConfig> {
   const storageObj = { config: appConfigFactory() }
 
   Object.keys(storageObj.config.dicts.all).forEach(id => {
-    storageObj[id] = require('../components/dictionaries/' + id + '/config')
+    storageObj[id] = require('@/components/dictionaries/' + id + '/config')
   })
 
   return browser.storage.sync.set(storageObj)
@@ -70,7 +70,7 @@ function mergeHistorical (config): Promise<AppConfig> {
 
   const storageObj = { config: base }
   Object.keys(base.dicts.all).forEach(id => {
-    storageObj[id] = config.dicts.all[id] || require('../components/dictionaries/' + id + '/config')
+    storageObj[id] = config.dicts.all[id] || require('@/components/dictionaries/' + id + '/config')
   })
 
   return browser.storage.sync.set(storageObj)
diff --git a/src/background/pdf-sniffer.ts b/src/background/pdf-sniffer.ts
index 6ba27cf..70aa38f 100644
--- a/src/background/pdf-sniffer.ts
+++ b/src/background/pdf-sniffer.ts
@@ -2,8 +2,8 @@
  * Open pdf link directly
  */
 
-import { storage } from '../_helpers/browser-api'
-import { AppConfig } from '../app-config'
+import { storage } from '@/_helpers/browser-api'
+import { AppConfig } from '@/app-config'
 
 export function init (pdfSniff: boolean) {
   if (browser.webRequest.onBeforeRequest.hasListener(otherPdfListener)) {
diff --git a/src/background/server.ts b/src/background/server.ts
index 73b34b6..66ed5c0 100644
--- a/src/background/server.ts
+++ b/src/background/server.ts
@@ -1,7 +1,7 @@
-import { DictID } from '../app-config'
-import { message, openURL } from '../_helpers/browser-api'
+import { DictID } from '@/app-config'
+import { message, openURL } from '@/_helpers/browser-api'
 import { play } from './audio-manager'
-import { chsToChz } from '../_helpers/chs-to-chz'
+import { chsToChz } from '@/_helpers/chs-to-chz'
 
 interface MessageOpenUrlWithEscape {
   type: 'OPEN_URL'
@@ -63,7 +63,7 @@ function fetchDictResult (data: MessageFetchDictResult): Promise<void> {
   let search
 
   try {
-    search = require('../components/dictionaries/' + data.dict + '/engine.js')
+    search = require('@/components/dictionaries/' + data.dict + '/engine.js')
   } catch (err) {
     return Promise.reject(err)
   }
diff --git a/test/unit/_helpers/browser-api.spec.ts b/test/unit/_helpers/browser-api.spec.ts
index 1f39145..e327169 100644
--- a/test/unit/_helpers/browser-api.spec.ts
+++ b/test/unit/_helpers/browser-api.spec.ts
@@ -1,4 +1,4 @@
-import { message, storage, openURL } from '../../../src/_helpers/browser-api'
+import { message, storage, openURL } from '@/_helpers/browser-api'
 
 beforeEach(() => {
   browser.flush()
diff --git a/test/unit/_helpers/check-update.spec.ts b/test/unit/_helpers/check-update.spec.ts
index 2abfc57..fd0b678 100644
--- a/test/unit/_helpers/check-update.spec.ts
+++ b/test/unit/_helpers/check-update.spec.ts
@@ -1,4 +1,4 @@
-import checkUpdate from '../../../src/_helpers/check-update'
+import checkUpdate from '@/_helpers/check-update'
 import fetchMock from 'jest-fetch-mock'
 
 describe('Check Update', () => {
diff --git a/test/unit/_helpers/chs-to-chz.spec.ts b/test/unit/_helpers/chs-to-chz.spec.ts
index 295c6ad..21d5229 100644
--- a/test/unit/_helpers/chs-to-chz.spec.ts
+++ b/test/unit/_helpers/chs-to-chz.spec.ts
@@ -1,4 +1,4 @@
-import chsToChz from '../../../src/_helpers/chs-to-chz'
+import chsToChz from '@/_helpers/chs-to-chz'
 
 describe('Chs to Chz', () => {
   it('should convert chs to chz', () => {
diff --git a/test/unit/_helpers/fetch-dom.spec.ts b/test/unit/_helpers/fetch-dom.spec.ts
index a79dda0..bbfbf10 100644
--- a/test/unit/_helpers/fetch-dom.spec.ts
+++ b/test/unit/_helpers/fetch-dom.spec.ts
@@ -1,4 +1,4 @@
-import fetchDom from '../../../src/_helpers/fetch-dom'
+import fetchDom from '@/_helpers/fetch-dom'
 
 class XMLHttpRequestMock {
   static queue: XMLHttpRequestMock[] = []
diff --git a/test/unit/_helpers/lang-check.spec.ts b/test/unit/_helpers/lang-check.spec.ts
index f3e668a..09f30bb 100644
--- a/test/unit/_helpers/lang-check.spec.ts
+++ b/test/unit/_helpers/lang-check.spec.ts
@@ -1,4 +1,4 @@
-import { isContainChinese, isContainEnglish } from '../../../src/_helpers/lang-check'
+import { isContainChinese, isContainEnglish } from '@/_helpers/lang-check'
 
 describe('Language Check', () => {
   it('isContainChinese should return ture if text contains Chinese', () => {
diff --git a/test/unit/_helpers/promise-more.spec.ts b/test/unit/_helpers/promise-more.spec.ts
index 9601c7d..66dc8d9 100644
--- a/test/unit/_helpers/promise-more.spec.ts
+++ b/test/unit/_helpers/promise-more.spec.ts
@@ -1,4 +1,4 @@
-import * as pm from '../../../src/_helpers/promise-more'
+import * as pm from '@/_helpers/promise-more'
 
 describe('Promise More', () => {
   beforeAll(() => {
diff --git a/test/unit/_helpers/selection.spec.ts b/test/unit/_helpers/selection.spec.ts
index 370239a..06812cf 100644
--- a/test/unit/_helpers/selection.spec.ts
+++ b/test/unit/_helpers/selection.spec.ts
@@ -1,4 +1,4 @@
-import selection from '../../../src/_helpers/selection'
+import selection from '@/_helpers/selection'
 
 describe('Selection', () => {
   const bakSelection = window.getSelection
diff --git a/test/unit/_helpers/strip-script.spec.ts b/test/unit/_helpers/strip-script.spec.ts
index cce558f..355b382 100644
--- a/test/unit/_helpers/strip-script.spec.ts
+++ b/test/unit/_helpers/strip-script.spec.ts
@@ -1,4 +1,4 @@
-import stripScript from '../../../src/_helpers/strip-script'
+import stripScript from '@/_helpers/strip-script'
 
 describe('Strip Script', () => {
   const expectedEl = document.createElement('div') as HTMLDivElement
diff --git a/test/unit/background/audio-manager.spec.ts b/test/unit/background/audio-manager.spec.ts
index b0096a6..b1266d7 100644
--- a/test/unit/background/audio-manager.spec.ts
+++ b/test/unit/background/audio-manager.spec.ts
@@ -1,4 +1,4 @@
-import audio from '../../../src/background/audio-manager'
+import audio from '@/background/audio-manager'
 
 describe('Audio Manager', () => {
   const bakAudio = (window as any).Audio
diff --git a/test/unit/background/context-menus.spec.ts b/test/unit/background/context-menus.spec.ts
index 39e249c..d9049dc 100644
--- a/test/unit/background/context-menus.spec.ts
+++ b/test/unit/background/context-menus.spec.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import sinon from 'sinon'
 
 function specialConfig () {
@@ -11,7 +11,7 @@ describe('Context Menus', () => {
   beforeAll(() => {
     browser.flush()
     jest.resetModules()
-    require('../../../src/background/context-menus')
+    require('@/background/context-menus')
   })
   afterAll(() => browser.flush())
 
@@ -93,7 +93,7 @@ describe('Context Menus', () => {
       browser.contextMenus.create.callsFake((_, cb) => cb())
       config = specialConfig()
       jest.resetModules()
-      const { init } = require('../../../src/background/context-menus')
+      const { init } = require('@/background/context-menus')
       init(config.contextMenus)
     })
 
@@ -110,7 +110,7 @@ describe('Context Menus', () => {
     it('should not init setup when called multiple times', () => {
       expect(browser.contextMenus.removeAll.calledOnce).toBeTruthy()
 
-      const { init } = require('../../../src/background/context-menus')
+      const { init } = require('@/background/context-menus')
       init(config.contextMenus)
       init(config.contextMenus)
 
diff --git a/test/unit/background/initialization.spec.ts b/test/unit/background/initialization.spec.ts
index 7bc0972..56a6389 100644
--- a/test/unit/background/initialization.spec.ts
+++ b/test/unit/background/initialization.spec.ts
@@ -1,4 +1,4 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
+import { appConfigFactory, AppConfig } from '@/app-config'
 import fetchMock from 'jest-fetch-mock'
 import sinon from 'sinon'
 
@@ -11,12 +11,12 @@ describe('Initialization', () => {
   const checkUpdate = jest.fn().mockReturnValue(Promise.resolve())
 
   beforeAll(() => {
-    const { message, storage } = require('../../../src/_helpers/browser-api')
+    const { message, storage } = require('@/_helpers/browser-api')
     window.fetch = fetchMock
 
     browser.flush()
     jest.resetModules()
-    jest.doMock('../../../src/background/merge-config', () => {
+    jest.doMock('@/background/merge-config', () => {
       return {
         mergeConfig (config) {
           mergeConfig(config)
@@ -24,16 +24,16 @@ describe('Initialization', () => {
         }
       }
     })
-    jest.doMock('../../../src/background/context-menus', () => {
+    jest.doMock('@/background/context-menus', () => {
       return { init: initMenus }
     })
-    jest.doMock('../../../src/background/pdf-sniffer', () => {
+    jest.doMock('@/background/pdf-sniffer', () => {
       return { init: initPdf }
     })
-    jest.doMock('../../../src/_helpers/check-update', () => {
+    jest.doMock('@/_helpers/check-update', () => {
       return checkUpdate
     })
-    jest.doMock('../../../src/_helpers/browser-api', () => {
+    jest.doMock('@/_helpers/browser-api', () => {
       return {
         message,
         storage,
@@ -41,13 +41,13 @@ describe('Initialization', () => {
       }
     })
 
-    require('../../../src/background/initialization')
+    require('@/background/initialization')
   })
   afterAll(() => {
     browser.flush()
-    jest.dontMock('../../../src/background/merge-config')
-    jest.dontMock('../../../src/background/context-menus')
-    jest.dontMock('../../../src/_helpers/browser-api')
+    jest.dontMock('@/background/merge-config')
+    jest.dontMock('@/background/context-menus')
+    jest.dontMock('@/_helpers/browser-api')
     window.fetch = bakFetch
   })
 
diff --git a/test/unit/background/merge-config.spec.ts b/test/unit/background/merge-config.spec.ts
index 73c047d..c0dce26 100644
--- a/test/unit/background/merge-config.spec.ts
+++ b/test/unit/background/merge-config.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig, AppConfigMutable } from '../../../src/app-config'
-import mergeConfig from '../../../src/background/merge-config'
+import { appConfigFactory, AppConfig, AppConfigMutable } from '@/app-config'
+import mergeConfig from '@/background/merge-config'
 import sinon from 'sinon'
 
 describe('Merge Config', () => {
diff --git a/test/unit/background/pdf-sniffer.spec.ts b/test/unit/background/pdf-sniffer.spec.ts
index a0219d2..bb7726f 100644
--- a/test/unit/background/pdf-sniffer.spec.ts
+++ b/test/unit/background/pdf-sniffer.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
-import { init as initPdf } from '../../../src/background/pdf-sniffer'
+import { appConfigFactory, AppConfig } from '@/app-config'
+import { init as initPdf } from '@/background/pdf-sniffer'
 import sinon from 'sinon'
 
 function hasListenerPatch (fn) {
diff --git a/test/unit/background/server.spec.ts b/test/unit/background/server.spec.ts
index b8ef065..aa04525 100644
--- a/test/unit/background/server.spec.ts
+++ b/test/unit/background/server.spec.ts
@@ -1,5 +1,5 @@
-import { appConfigFactory, AppConfig } from '../../../src/app-config'
-import * as browserWrap from '../../../src/_helpers/browser-api'
+import { appConfigFactory, AppConfig } from '@/app-config'
+import * as browserWrap from '@/_helpers/browser-api'
 import sinon from 'sinon'
 
 describe('Server', () => {
@@ -13,26 +13,26 @@ describe('Server', () => {
   browserWrap.openURL = openURL
 
   beforeAll(() => {
-    jest.doMock('../../../src/_helpers/chs-to-chz', () => {
+    jest.doMock('@/_helpers/chs-to-chz', () => {
       return { chsToChz }
     })
-    jest.doMock('../../../src/background/audio-manager', () => {
+    jest.doMock('@/background/audio-manager', () => {
       return { play }
     })
-    jest.doMock('../../../src/_helpers/browser-api', () => {
+    jest.doMock('@/_helpers/browser-api', () => {
       return browserWrap
     })
-    jest.doMock('../../../src/components/dictionaries/bing/engine.js', () => {
+    jest.doMock('@/components/dictionaries/bing/engine.js', () => {
       return bingSearch
     })
   })
 
   afterAll(() => {
     browser.flush()
-    jest.dontMock('../../../src/_helpers/chs-to-chz')
-    jest.dontMock('../../../src/background/audio-manager')
-    jest.dontMock('../../../src/_helpers/browser-api')
-    jest.dontMock('../../../src/components/dictionaries/bing/engine.js')
+    jest.dontMock('@/_helpers/chs-to-chz')
+    jest.dontMock('@/background/audio-manager')
+    jest.dontMock('@/_helpers/browser-api')
+    jest.dontMock('@/components/dictionaries/bing/engine.js')
   })
 
   beforeEach(() => {
@@ -46,7 +46,7 @@ describe('Server', () => {
     bingSearch.mockReset()
     bingSearch.mockImplementation(() => Promise.resolve())
     jest.resetModules()
-    require('../../../src/background/server')
+    require('@/background/server')
   })
 
   it('should properly init', () => {
",3,"[""cbce777addb3dd118232a9f28db9d425d4c937b2"", ""c81a0c2999454c859b4bf4da5779712960d239be"", ""8246d024f21d93cc092e19bede5f7b3a5325c8dc""]","[""fix"", ""cicd"", ""refactor""]","1. The commit includes changes to the Jenkinsfile (updating secrets and IDs for QA), code logic in packages/cli/src/commands/dev.ts (modifying restart conditions), refactoring import paths across src/background/*, and updating import paths in test/unit/* files.
2. The Jenkinsfile changes are CI/CD configuration updates, aligning with the 'cicd' label; the dev.ts edit changes the logic for when Nuxt restarts, which fixes an over-eager restart bug and aligns with 'fix'; the import path changes across background and test files improve maintainability and code structure without altering behavior, aligning with 'refactor'.
3. 'cicd' is appropriate for Jenkinsfile because it modifies CI configuration, not build or feature logic; 'fix' is appropriate for dev.ts because it corrects faulty restart triggers rather than adding features or refactoring; 'refactor' is correct for the import path updates since they restructure code for clarity/maintainability without changing external behavior—these are not bug fixes or new features.
4. The assigned labels 'cicd', 'fix', and 'refactor' precisely reflect the functional roles and motivations of the respective changes in this commit according to the labeling rules."
"rework RaftCommittedEntryListener

Iterate over RaftCommittedEntryListener and refactor the listener such it serves the actual need.

We have some services (to be specific the AsyncSnapshotDirector) which need the committed position, and
want to listen to new updates. In raft we know which record we are committing and whether it was an application record so we can pass this information threw the listeners.

This avoids to pass in the whole IndexedRecord object, and reduce the potential of going out of OOM because of keeping to much data in heap (when commit is not possible).","diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
new file mode 100644
index 0000000..57c28a9
--- /dev/null
+++ b/atomix/cluster/src/main/java/io/atomix/raft/RaftApplicationEntryCommittedPositionListener.java
@@ -0,0 +1,31 @@
+/*
+ * Copyright 2016-present Open Networking Foundation
+ * Copyright © 2020 camunda services GmbH (info@camunda.com)
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package io.atomix.raft;
+
+/**
+ * This listener will only be called by the Leader, when it commits an application entry.
+ *
+ * <p>If RAFT is currently running in a follower role, it will not call this listener.
+ */
+@FunctionalInterface
+public interface RaftApplicationEntryCommittedPositionListener {
+
+  /**
+   * @param committedPosition the new committed position which is related to the application entries
+   */
+  void onCommit(long committedPosition);
+}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java b/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
deleted file mode 100644
index 3d11d75..0000000
--- a/atomix/cluster/src/main/java/io/atomix/raft/RaftCommittedEntryListener.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- * Copyright 2016-present Open Networking Foundation
- * Copyright © 2020 camunda services GmbH (info@camunda.com)
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package io.atomix.raft;
-
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
-
-/**
- * This listener will only be called by the Leader, when it commits an entry. If RAFT is currently
- * running in a follower role, it will not call this listener.
- */
-@FunctionalInterface
-public interface RaftCommittedEntryListener {
-
-  /**
-   * @param indexedRaftLogEntry the new committed entry
-   */
-  void onCommit(IndexedRaftLogEntry indexedRaftLogEntry);
-}
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
index 1f4ee98..c177cb1 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/impl/RaftContext.java
@@ -27,8 +27,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.MessagingException.NoRemoteHandler;
 import io.atomix.cluster.messaging.MessagingException.NoSuchMemberException;
 import io.atomix.raft.ElectionTimer;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftError;
 import io.atomix.raft.RaftException.ProtocolException;
 import io.atomix.raft.RaftRoleChangeListener;
@@ -61,7 +61,6 @@ import io.atomix.raft.roles.PromotableRole;
 import io.atomix.raft.roles.RaftRole;
 import io.atomix.raft.storage.RaftStorage;
 import io.atomix.raft.storage.StorageException;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
 import io.atomix.raft.storage.log.RaftLog;
 import io.atomix.raft.storage.system.MetaStore;
 import io.atomix.raft.utils.StateUtil;
@@ -115,7 +114,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
   private final Set<Consumer<State>> stateChangeListeners = new CopyOnWriteArraySet<>();
   private final Set<Consumer<RaftMember>> electionListeners = new CopyOnWriteArraySet<>();
   private final Set<RaftCommitListener> commitListeners = new CopyOnWriteArraySet<>();
-  private final Set<RaftCommittedEntryListener> committedEntryListeners =
+  private final Set<RaftApplicationEntryCommittedPositionListener> committedEntryListeners =
       new CopyOnWriteArraySet<>();
   private final Set<SnapshotReplicationListener> snapshotReplicationListeners =
       new CopyOnWriteArraySet<>();
@@ -433,21 +432,23 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    * <p>Note that it will be called on the Raft thread, and as such should not perform any heavy
    * computation.
    *
-   * @param raftCommittedEntryListener the listener to add
+   * @param raftApplicationEntryCommittedPositionListener the listener to add
    */
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.add(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.add(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
    * Removes registered committedEntryListener
    *
-   * @param raftCommittedEntryListener the listener to remove
+   * @param raftApplicationEntryCommittedPositionListener the listener to remove
    */
   public void removeCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
-    committedEntryListeners.remove(raftCommittedEntryListener);
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
+    committedEntryListeners.remove(raftApplicationEntryCommittedPositionListener);
   }
 
   /**
@@ -464,7 +465,7 @@ public class RaftContext implements AutoCloseable, HealthMonitorable {
    *
    * @param committedEntry the most recently committed entry
    */
-  public void notifyCommittedEntryListeners(final IndexedRaftLogEntry committedEntry) {
+  public void notifyApplicationEntryCommittedPositionListeners(final long committedEntry) {
     committedEntryListeners.forEach(listener -> listener.onCommit(committedEntry));
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
index 56c7172..d075fca 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/partition/impl/RaftPartitionServer.java
@@ -21,8 +21,8 @@ import io.atomix.cluster.MemberId;
 import io.atomix.cluster.messaging.ClusterCommunicationService;
 import io.atomix.primitive.partition.Partition;
 import io.atomix.primitive.partition.PartitionMetadata;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.atomix.raft.RaftCommitListener;
-import io.atomix.raft.RaftCommittedEntryListener;
 import io.atomix.raft.RaftRoleChangeListener;
 import io.atomix.raft.RaftServer;
 import io.atomix.raft.RaftServer.Role;
@@ -205,16 +205,20 @@ public class RaftPartitionServer implements HealthMonitorable {
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#addCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void addCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void addCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().addCommittedEntryListener(commitListener);
   }
 
   /**
-   * @see io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftCommittedEntryListener)
+   * @see
+   *     io.atomix.raft.impl.RaftContext#removeCommittedEntryListener(RaftApplicationEntryCommittedPositionListener)
    */
-  public void removeCommittedEntryListener(final RaftCommittedEntryListener commitListener) {
+  public void removeCommittedEntryListener(
+      final RaftApplicationEntryCommittedPositionListener commitListener) {
     server.getContext().removeCommittedEntryListener(commitListener);
   }
 
diff --git a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
index e54df1a..fcfd177 100644
--- a/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
+++ b/atomix/cluster/src/main/java/io/atomix/raft/roles/LeaderRole.java
@@ -630,27 +630,47 @@ public final class LeaderRole extends ActiveRole implements ZeebeLogAppender {
 
   private void replicate(final IndexedRaftLogEntry indexed, final AppendListener appendListener) {
     raft.checkThread();
-    appender
-        .appendEntries(indexed.index())
-        .whenCompleteAsync(
-            (commitIndex, commitError) -> {
-              if (!isRunning()) {
-                return;
-              }
+    final var appendEntriesFuture = appender.appendEntries(indexed.index());
+
+    final boolean applicationEntryWasCommitted = indexed.isApplicationEntry();
+    if (applicationEntryWasCommitted) {
+      // We have some services which are waiting for the application records, especially position
+      // to be committed. This is our glue code to notify them, instead of
+      // passing the complete object (IndexedRaftLogEntry) threw the listeners and
+      // keep them in heap until they are committed. This had the risk of going out of OOM
+      // if records can't be committed, see https://github.com/camunda/zeebe/issues/14275
+      final var committedPosition = indexed.getApplicationEntry().highestPosition();
+      appendEntriesFuture.whenCompleteAsync(
+          (commitIndex, commitError) -> {
+            if (!isRunning()) {
+              return;
+            }
+
+            if (commitError == null) {
+              raft.notifyApplicationEntryCommittedPositionListeners(committedPosition);
+            }
+          },
+          raft.getThreadContext());
+    }
 
-              // have the state machine apply the index which should do nothing but ensures it keeps
-              // up to date with the latest entries, so it can handle configuration and initial
-              // entries properly on fail over
-              if (commitError == null) {
-                appendListener.onCommit(indexed.index());
-                raft.notifyCommittedEntryListeners(indexed);
-              } else {
-                appendListener.onCommitError(indexed.index(), commitError);
-                // replicating the entry will be retried on the next append request
-                log.error(""Failed to replicate entry: {}"", indexed, commitError);
-              }
-            },
-            raft.getThreadContext());
+    appendEntriesFuture.whenCompleteAsync(
+        (commitIndex, commitError) -> {
+          if (!isRunning()) {
+            return;
+          }
+
+          // have the state machine apply the index which should do nothing but ensures it keeps
+          // up to date with the latest entries, so it can handle configuration and initial
+          // entries properly on fail over
+          if (commitError == null) {
+            appendListener.onCommit(indexed.index());
+          } else {
+            appendListener.onCommitError(indexed.index(), commitError);
+            // replicating the entry will be retried on the next append request
+            log.error(""Failed to replicate entry: {}"", indexed, commitError);
+          }
+        },
+        raft.getThreadContext());
   }
 
   public synchronized void onInitialEntriesCommitted(final Runnable runnable) {
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
index b217586..8029766 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftAppendTest.java
@@ -82,7 +82,7 @@ public class RaftAppendTest {
   @Test
   public void shouldNotifyCommittedEntryListenerOnLeaderOnly() throws Throwable {
     // given
-    final var committedEntryListener = mock(RaftCommittedEntryListener.class);
+    final var committedEntryListener = mock(RaftApplicationEntryCommittedPositionListener.class);
     raftRule.addCommittedEntryListener(committedEntryListener);
 
     // when
diff --git a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
index 8f73cba..193a176 100644
--- a/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
+++ b/atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java
@@ -644,9 +644,12 @@ public final class RaftRule extends ExternalResource {
   }
 
   public void addCommittedEntryListener(
-      final RaftCommittedEntryListener raftCommittedEntryListener) {
+      final RaftApplicationEntryCommittedPositionListener
+          raftApplicationEntryCommittedPositionListener) {
     servers.forEach(
-        (id, raft) -> raft.getContext().addCommittedEntryListener(raftCommittedEntryListener));
+        (id, raft) ->
+            raft.getContext()
+                .addCommittedEntryListener(raftApplicationEntryCommittedPositionListener));
   }
 
   public void partition(final RaftServer follower) {
diff --git a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
index a61571f..6c082d7 100644
--- a/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
+++ b/broker/src/main/java/io/camunda/zeebe/broker/system/partitions/impl/AsyncSnapshotDirector.java
@@ -7,8 +7,7 @@
  */
 package io.camunda.zeebe.broker.system.partitions.impl;
 
-import io.atomix.raft.RaftCommittedEntryListener;
-import io.atomix.raft.storage.log.IndexedRaftLogEntry;
+import io.atomix.raft.RaftApplicationEntryCommittedPositionListener;
 import io.camunda.zeebe.broker.system.partitions.NoEntryAtSnapshotPosition;
 import io.camunda.zeebe.broker.system.partitions.StateController;
 import io.camunda.zeebe.logstreams.impl.Loggers;
@@ -36,7 +35,7 @@ import java.util.function.Consumer;
 import org.slf4j.Logger;
 
 public final class AsyncSnapshotDirector extends Actor
-    implements RaftCommittedEntryListener, HealthMonitorable {
+    implements RaftApplicationEntryCommittedPositionListener, HealthMonitorable {
 
   public static final Duration MINIMUM_SNAPSHOT_PERIOD = Duration.ofMinutes(1);
 
@@ -115,7 +114,7 @@ public final class AsyncSnapshotDirector extends Actor
   @Override
   protected void handleFailure(final Throwable failure) {
     LOG.error(
-        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}. {}"",
+        ""No snapshot was taken due to failure in '{}'. Will try to take snapshot after snapshot period {}."",
         actorName,
         snapshotRate,
         failure);
@@ -407,13 +406,8 @@ public final class AsyncSnapshotDirector extends Actor
   }
 
   @Override
-  public void onCommit(final IndexedRaftLogEntry indexedRaftLogEntry) {
-    // is called by the Leader Role and gives the last committed entry, where we
-    // can extract the highest position, which corresponds to the last committed position
-    if (indexedRaftLogEntry.isApplicationEntry()) {
-      final var committedPosition = indexedRaftLogEntry.getApplicationEntry().highestPosition();
-      newPositionCommitted(committedPosition);
-    }
+  public void onCommit(final long committedPosition) {
+    newPositionCommitted(committedPosition);
   }
 
   public void newPositionCommitted(final long currentCommitPosition) {
",1,"[""323cf81961cdd3748a7ba6ba470ecb13e5374e9f""]","[""refactor""]","1. The code changes replace the RaftCommittedEntryListener interface with a more specific RaftApplicationEntryCommittedPositionListener, update all usages throughout the codebase, and streamline how committed position information is propagated, without changing external behavior or adding features.
2. These changes align with the 'refactor' label as they focus on improving the structure and clarity of the listener mechanism, reducing memory risk, and simplifying the interface, without introducing new features or fixing a defect.
3. The 'refactor' label is appropriate because the motivation is to improve maintainability and efficiency by restructuring code, not to add functionality (so not 'feat'), fix a bug (so not 'fix'), or modify tests, docs, or CI/build artifacts (so not 'test', 'docs', 'cicd', or 'build').
4. The 'refactor' label is justified as the commit exclusively restructures internal interfaces and logic for better clarity and efficiency, without altering external behavior or functional outcomes."
Improved Config Loading #423,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 76dd749..2087803 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,6 +7,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 ## [Unreleased]
 * Fix the tab '(Sync)' suffix in named tabs (https://github.com/zellij-org/zellij/pull/410)
 * Improve performance when multiple panes are open (https://github.com/zellij-org/zellij/pull/318)
+* Improve error reporting and tests of configuration (https://github.com/zellij-org/zellij/pull/423)
 
 ## [0.6.0] - 2021-04-29
 * Doesn't quit anymore on single `q` press while in tab mode  (https://github.com/zellij-org/zellij/pull/342)
",1,"[""099861ff5b0f83773ca0af4c70e6e39be3b0336c""]","[""docs""]","1. The code change adds a new entry to the CHANGELOG.md file describing improvements in error reporting and tests for configuration.
2. This change is limited to modifying documentation, specifically a changelog, which aligns directly with the 'docs' label definition.
3. The 'docs' label is appropriate because no source code, tests, CI/CD, or build files are altered—only documentation is updated; 'feat', 'fix', 'refactor', 'test', 'cicd', and 'build' are not applicable as there are no behavioral or artifact changes outside documentation.
4. The 'docs' label accurately categorizes this commit as it solely involves updating project documentation."
"[gn] fix include_dirs ordering error
better layout for block and segment","diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",2,"[""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""build"", ""docs""]","1. The changes include a reordering and deduplication of the `include_dirs` assignment in the `BUILD.gn` file, and extensive modifications, additions, and reorganizations of Markdown documentation files under the `docs/` directory, including new files and edits to sidebars.
2. The `BUILD.gn` change directly affects build configuration by correcting the order and placement of `include_dirs`, which aligns with the `build` label as it modifies build system logic. All changes under `docs/`—including new documentation files, updates to existing Markdown, and changes to documentation navigation—are strictly documentation-focused, aligning with the `docs` label.
3. The `build` label is appropriate for the `BUILD.gn` change because it is neither a code behavior change (not `fix`, `feat`, or `refactor`) nor documentation or test logic. The `docs` label is correct for all `docs/` directory changes, as these files are dedicated to documentation and do not impact code, build, tests, or CI/CD logic. No other labels fit these artifacts based on their content and location.
4. The final label assignments are justified: `build` for the build system correction in `BUILD.gn`, and `docs` for all documentation-related modifications and additions."
fix `memtable` docstrings,"diff --git a/ibis/expr/api.py b/ibis/expr/api.py
index 93fabaa..66a2ea9 100644
--- a/ibis/expr/api.py
+++ b/ibis/expr/api.py
@@ -403,15 +403,21 @@ def memtable(
     >>> import ibis
     >>> t = ibis.memtable([{""a"": 1}, {""a"": 2}])
     >>> t
+    PandasInMemoryTable
+      data:
+        DataFrameProxy:
+             a
+          0  1
+          1  2
 
     >>> t = ibis.memtable([{""a"": 1, ""b"": ""foo""}, {""a"": 2, ""b"": ""baz""}])
     >>> t
     PandasInMemoryTable
       data:
-        ((1, 'foo'), (2, 'baz'))
-      schema:
-        a int8
-        b string
+        DataFrameProxy:
+             a    b
+          0  1  foo
+          1  2  baz
 
     Create a table literal without column names embedded in the data and pass
     `columns`
@@ -420,10 +426,22 @@ def memtable(
     >>> t
     PandasInMemoryTable
       data:
-        ((1, 'foo'), (2, 'baz'))
-      schema:
-        a int8
-        b string
+        DataFrameProxy:
+             a    b
+          0  1  foo
+          1  2  baz
+
+    Create a table literal without column names embedded in the data. Ibis
+    generates column names if none are provided.
+
+    >>> t = ibis.memtable([(1, ""foo""), (2, ""baz"")])
+    >>> t
+    PandasInMemoryTable
+      data:
+        DataFrameProxy:
+             col0 col1
+          0     1  foo
+          1     2  baz
     """"""
     if columns is not None and schema is not None:
         raise NotImplementedError(
",1,"[""72bc0f5172c0a3d17bde29cfc00db4c60d2fee3a""]","[""docs""]","1. The code changes update the docstrings in the `memtable` function by improving and expanding the usage examples and clarifying output representations.
2. These changes align with the 'docs' label because they exclusively modify documentation content within the code (docstrings), without affecting logic or behavior.
3. The 'docs' label is appropriate as there are no changes to executable code, tests, CI/CD, or build scripts, ruling out other labels like 'fix', 'feat', or 'refactor'.
4. The 'docs' label is justified because the commit is fully dedicated to improving documentation by updating and clarifying docstrings."
"update CI images from docker buster to bullseye

This will break `perf_image` until the new CI image is built due to the
newly required `--all-tags` parameter to `docker push` that isn't
available for the docker version we run on buster.
return Animated nodes passed to ""getAnimated""

...instead of undefined.

Also, stop using instanceof in ""isAnimated"" for perf.
update version (nightly.0)","diff --git a/.circleci/config.yml b/.circleci/config.yml
index f8a53ba..c378c7e 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -336,7 +336,7 @@ jobs:
           # Disabling for now, and tracked further investigations
           # in https://github.com/influxdata/k8s-idpe/issues/3038
           docker_layer_caching: false
-          version: 19.03.14
+          version: 20.10.7
       - run: |
           sudo apt-get update
           sudo apt-get install -y docker.io
@@ -355,7 +355,7 @@ jobs:
           BRANCH=$(git rev-parse --abbrev-ref HEAD | tr '/' '.')
           COMMIT_SHA=$(git rev-parse --short HEAD)
           docker build -t quay.io/influxdb/iox:$COMMIT_SHA -t quay.io/influxdb/iox:main -f docker/Dockerfile.iox .
-          docker push quay.io/influxdb/iox
+          docker push --all-tags quay.io/influxdb/iox
           echo ""export COMMIT_SHA=${COMMIT_SHA}"" >> $BASH_ENV
       - run:
           name: Deploy tags
diff --git a/Dockerfile b/Dockerfile
index 8c23ea2..1df1fd2 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -17,7 +17,7 @@ RUN \
   cp /influxdb_iox/target/release/influxdb_iox /root/influxdb_iox && \
   du -cshx /usr/local/cargo/registry /usr/local/cargo/git /influxdb_iox/target
 
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
     && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates --no-install-recommends \
diff --git a/docker/Dockerfile.ci b/docker/Dockerfile.ci
index db0a8ca..cf9cd15 100644
--- a/docker/Dockerfile.ci
+++ b/docker/Dockerfile.ci
@@ -12,7 +12,7 @@
 
 ARG RUST_VERSION
 # Build actual image used for CI pipeline
-FROM rust:${RUST_VERSION}-slim-buster
+FROM rust:${RUST_VERSION}-slim-bullseye
 
 # When https://github.com/rust-lang/rustup/issues/2686 is fixed, run the command added that
 # will install everything in rust-toolchain.toml here so that components are in the container
@@ -42,7 +42,7 @@ COPY docker/redpanda.gpg /tmp/redpanda.gpg
 # Generated from https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/cfg/setup/bash.deb.sh
 RUN apt-key add /tmp/redpanda.gpg \
     && rm /tmp/redpanda.gpg \
-    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=buster&version=10&arch=x86_64"" \
+    && curl ${CURL_FLAGS} ""https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/config.deb.txt?distro=debian&codename=bullseye&version=10&arch=x86_64"" \
       > /etc/apt/sources.list.d/vectorized-redpanda.list \
     && apt-get update \
     && apt-get install -y redpanda \
diff --git a/docker/Dockerfile.iox b/docker/Dockerfile.iox
index 42414db..ae1f38e 100644
--- a/docker/Dockerfile.iox
+++ b/docker/Dockerfile.iox
@@ -1,7 +1,7 @@
 ###
 # Dockerfile used for deploying IOx
 ##
-FROM debian:buster-slim
+FROM debian:bullseye-slim
 
 RUN apt-get update \
   && apt-get install -y libssl1.1 libgcc1 libc6 ca-certificates gettext-base --no-install-recommends \

diff --git a/packages/animated/src/Animated.ts b/packages/animated/src/Animated.ts
index 00daa96..05ff7f9 100644
--- a/packages/animated/src/Animated.ts
+++ b/packages/animated/src/Animated.ts
@@ -4,7 +4,7 @@ import { AnimatedValue } from './AnimatedValue'
 const $node: any = Symbol.for('Animated:node')
 
 export const isAnimated = (value: any): value is Animated =>
-  value instanceof Animated
+  !!value && value[$node] === value
 
 /** Get the owner's `Animated` node. */
 export const getAnimated = (owner: any): Animated | undefined =>
@@ -23,6 +23,10 @@ export abstract class Animated<T = any> {
   protected payload?: Payload
 
   /** Returns every value of the node. Pass true for only the animated values. */
+  constructor() {
+    setAnimated(this, this)
+  }
+
   abstract getValue(animated?: boolean): T
 
   abstract setValue(value: T): void

diff --git a/Cargo.lock b/Cargo.lock
index f949506..6a10219 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -94,7 +94,7 @@ dependencies = [
 
 [[package]]
 name = ""els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_compiler"",
@@ -105,7 +105,7 @@ dependencies = [
 
 [[package]]
 name = ""erg""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""els"",
  ""erg_common"",
@@ -115,7 +115,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_common""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""backtrace-on-stack-overflow"",
  ""crossterm"",
@@ -126,7 +126,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_compiler""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""erg_parser"",
@@ -134,7 +134,7 @@ dependencies = [
 
 [[package]]
 name = ""erg_parser""
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 dependencies = [
  ""erg_common"",
  ""unicode-xid"",
diff --git a/Cargo.toml b/Cargo.toml
index 04fdad7..ecc45e5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -20,7 +20,7 @@ members = [
 ]
 
 [workspace.package]
-version = ""0.6.10""
+version = ""0.6.11-nightly.0""
 authors = [""erg-lang team <moderation.erglang@gmail.com>""]
 license = ""MIT OR Apache-2.0""
 edition = ""2021""
@@ -64,10 +64,10 @@ full-repl = [""erg_common/full-repl""]
 full = [""els"", ""full-repl"", ""unicode"", ""pretty""]
 
 [workspace.dependencies]
-erg_common = { version = ""0.6.10"", path = ""./crates/erg_common"" }
-erg_parser = { version = ""0.6.10"", path = ""./crates/erg_parser"" }
-erg_compiler = { version = ""0.6.10"", path = ""./crates/erg_compiler"" }
-els = { version = ""0.1.22"", path = ""./crates/els"" }
+erg_common = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_common"" }
+erg_parser = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_parser"" }
+erg_compiler = { version = ""0.6.11-nightly.0"", path = ""./crates/erg_compiler"" }
+els = { version = ""0.1.23-nightly.0"", path = ""./crates/els"" }
 
 [dependencies]
 erg_common = { workspace = true }
diff --git a/crates/els/Cargo.toml b/crates/els/Cargo.toml
index bc031e6..7c9455f 100644
--- a/crates/els/Cargo.toml
+++ b/crates/els/Cargo.toml
@@ -2,7 +2,7 @@
 name = ""els""
 description = ""An Erg compiler frontend for IDEs, implements LSP.""
 documentation = ""http://docs.rs/els""
-version = ""0.1.22""
+version = ""0.1.23-nightly.0""
 authors.workspace = true
 license.workspace = true
 edition.workspace = true
",3,"[""640cd88df3069a97d8244398414338dd317c5470"", ""eb513f7eeea7865f15e5bd561a471d1f4381ea70"", ""607ecc92b5f8c084304e406eec725b7dcfa0a562""]","[""cicd"", ""fix"", ""build""]","1. The commit updates Docker images and related tags from Debian buster to bullseye in CI and Dockerfiles, updates the Docker version and push command in the CI config, changes version numbers in Cargo.toml and Cargo.lock, and modifies logic in packages/animated/src/Animated.ts to avoid 'instanceof' and ensure getAnimated returns Animated nodes.
2. The .circleci/config.yml changes are directly related to CI configuration and Docker versioning, which aligns with the 'cicd' label; Dockerfile and Dockerfile.iox/ci updates relate to the build environment, fitting the 'build' label; the change in Animated.ts corrects runtime behavior (avoiding instanceof and fixing getAnimated return value), matching the 'fix' label.
3. 'cicd' is more appropriate than 'build' for .circleci/config.yml as it is a CI script, while Dockerfile changes are not CI scripts but core build artifacts, so 'build' fits; the Animated.ts change is a bug fix, not a new feature or refactor. Version bumps in Cargo.toml/Cargo.lock are build-related, not feature or fix.
4. The assigned labels 'cicd', 'build', and 'fix' are correct because the commit contains distinct changes to CI configuration, build system artifacts, and a runtime bug fix, each matching their respective label definitions."
"simplify loadFiles code
update renovate config
disable edit/delete if primary key missing

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/frontend/app/player/web/network/loadFiles.ts b/frontend/app/player/web/network/loadFiles.ts
index ec174fc..d164333 100644
--- a/frontend/app/player/web/network/loadFiles.ts
+++ b/frontend/app/player/web/network/loadFiles.ts
@@ -1,43 +1,33 @@
 import APIClient from 'App/api_client';
 
-const NO_NTH_FILE = ""nnf""
-const NO_UNPROCESSED_FILES = ""nuf""
+const NO_FILE_OK = ""No-file-but-this-is-ok""
+const NO_BACKUP_FILE = ""No-efs-file""
 
 export const loadFiles = (
   urls: string[],
   onData: (data: Uint8Array) => void,
 ): Promise<void> => {
-  const firstFileURL = urls[0]
-  urls = urls.slice(1)
-  if (!firstFileURL) {
+  if (!urls.length) {
     return Promise.reject(""No urls provided"")
   }
-  return window.fetch(firstFileURL)
-  .then(r => {
-    return processAPIStreamResponse(r, true)
-  })
-  .then(onData)
-  .then(() =>
-    urls.reduce((p, url) =>
-      p.then(() =>
-        window.fetch(url)
-        .then(r => {
-          return processAPIStreamResponse(r, false)
-        })
-        .then(onData)
-      ),
-      Promise.resolve(),
-    )
+  return urls.reduce((p, url, index) =>
+    p.then(() =>
+      window.fetch(url)
+      .then(r => {
+        return processAPIStreamResponse(r, index===0)
+      })
+      .then(onData)
+    ),
+    Promise.resolve(),
   )
   .catch(e => {
-    if (e === NO_NTH_FILE) {
+    if (e === NO_FILE_OK) {
       return
     }
     throw e
   })
 }
 
-
 export async function requestEFSDom(sessionId: string) {
   return await requestEFSMobFile(sessionId + ""/dom.mob"")
 }
@@ -50,21 +40,18 @@ async function requestEFSMobFile(filename: string) {
   const api = new APIClient()
   const res = await api.fetch('/unprocessed/' + filename)
   if (res.status >= 400) {
-    throw NO_UNPROCESSED_FILES
+    throw NO_BACKUP_FILE
   }
   return await processAPIStreamResponse(res, false)
 }
 
-const processAPIStreamResponse = (response: Response, isFirstFile: boolean) => {
+const processAPIStreamResponse = (response: Response, canBeMissed: boolean) => {
   return new Promise<ArrayBuffer>((res, rej) => {
-    if (response.status === 404 && !isFirstFile) {
-      return rej(NO_NTH_FILE)
+    if (response.status === 404 && canBeMissed) {
+      return rej(NO_FILE_OK)
     }
     if (response.status >= 400) {
-      return rej(
-        isFirstFile ? `no start file. status code ${ response.status }`
-        : `Bad endfile status code ${response.status}`
-      )
+      return rej(`Bad file status code ${response.status}. Url: ${response.url}`)
     }
     res(response.arrayBuffer())
   }).then(buffer => new Uint8Array(buffer))

diff --git a/.github/workflows/renovate.yml b/.github/workflows/renovate.yml
index 710d1f6..c83d681 100644
--- a/.github/workflows/renovate.yml
+++ b/.github/workflows/renovate.yml
@@ -1,7 +1,7 @@
 name: Renovate
 on:
   schedule:
-    - cron: '0/5 * * * *'
+    - cron: '0 */8 * * *'
 jobs:
   renovate:
     runs-on: ubuntu-latest

diff --git a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
index 5f9841f..c414c8c 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/expandedForm.vue
@@ -413,6 +413,9 @@ export default {
 
           await this.reload()
         } else if (Object.keys(updatedObj).length) {
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
           await this.api.update(id, updatedObj, this.oldRow)
         } else {
           return this.$toast.info('No columns to update').goAway(3000)
diff --git a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
index c2b4b81..1b9d6a0 100644
--- a/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
+++ b/packages/nc-gui/components/project/spreadsheet/rowsXcDataTable.vue
@@ -62,7 +62,15 @@
       <v-spacer class=""h-100"" @dblclick=""debug=true"" />
 
       <debug-metas v-if=""debug"" class=""mr-3"" />
-
+      <v-tooltip bottom>
+        <template #activator=""{on}"">
+          <v-icon v-if=""!isPkAvail"" color=""warning"" small class=""mr-3"" v-on=""on"">
+            mdi-information-outline
+          </v-icon>
+        </template>
+        <span class=""caption"">          Update & Delete not allowed since the table doesn't have any primary key
+        </span>
+      </v-tooltip>
       <lock-menu v-if=""_isUIAllowed('view-type')"" v-model=""viewStatus.type"" />
       <x-btn tooltip=""Reload view data"" outlined small text @click=""reload"">
         <v-icon small class=""mr-1"" color=""grey  darken-3"">
@@ -208,6 +216,7 @@
               :meta=""meta""
               :is-virtual=""selectedView.type === 'vtable'""
               :api=""api""
+              :is-pk-avail=""isPkAvail""
               @onNewColCreation=""onNewColCreation""
               @onCellValueChange=""onCellValueChange""
               @insertNewRow=""insertNewRow""
@@ -631,8 +640,8 @@ export default {
       if (
         !this.meta || (
           (this.meta.hasMany && this.meta.hasMany.length) ||
-        (this.meta.manyToMany && this.meta.manyToMany.length) ||
-        (this.meta.belongsTo && this.meta.belongsTo.length))
+          (this.meta.manyToMany && this.meta.manyToMany.length) ||
+          (this.meta.belongsTo && this.meta.belongsTo.length))
       ) {
         return this.$toast.info('Please delete relations before deleting table.').goAway(3000)
       }
@@ -817,6 +826,10 @@ export default {
 
           const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
 
+          if (!id) {
+            return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           const newData = await this.api.update(id, {
             [column._cn]: rowObj[column._cn]
           }, { [column._cn]: oldRow[column._cn] })
@@ -841,6 +854,11 @@ export default {
         const rowObj = this.rowContextMenu.row
         if (!this.rowContextMenu.rowMeta.new) {
           const id = this.meta && this.meta.columns && this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+          if (!id) {
+            return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+          }
+
           await this.api.delete(id)
         }
         this.data.splice(this.rowContextMenu.index, 1)
@@ -859,6 +877,11 @@ export default {
           }
           if (!rowMeta.new) {
             const id = this.meta.columns.filter(c => c.pk).map(c => rowObj[c._cn]).join('___')
+
+            if (!id) {
+              return this.$toast.info('Delete not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             await this.api.delete(id)
           }
           this.data.splice(row, 1)
@@ -991,6 +1014,9 @@ export default {
     }
   },
   computed: {
+    isPkAvail() {
+      return this.meta && this.meta.columns.some(c => c.pk)
+    },
     isGallery() {
       return this.selectedView && this.selectedView.show_as === 'gallery'
     },
diff --git a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
index 5497d05..c198784 100644
--- a/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
+++ b/packages/nc-gui/components/project/spreadsheet/views/xcGridView.vue
@@ -27,7 +27,7 @@
             @xcresized=""resizingCol = null""
           >
             <!--            :style=""columnsWidth[col._cn]  ? `min-width:${columnsWidth[col._cn]}; max-width:${columnsWidth[col._cn]}` : ''""
-    -->
+-->
 
             <virtual-header-cell
               v-if=""col.virtual""
@@ -136,13 +136,13 @@
             :key=""row + columnObj.alias""
             class=""cell pointer""
             :class=""{
-              'active' : !isPublicView && selected.col === col && selected.row === row && isEditable ,
+              'active' :!isPublicView && selected.col === col && selected.row === row && isEditable ,
               'primary-column' : primaryValueColumn === columnObj._cn,
               'text-center': isCentrallyAligned(columnObj),
               'required': isRequired(columnObj,rowObj)
             }""
             :data-col=""columnObj.alias""
-            @dblclick=""makeEditable(col,row,columnObj.ai)""
+            @dblclick=""makeEditable(col,row,columnObj.ai,rowMeta)""
             @click=""makeSelected(col,row);""
             @contextmenu=""showRowContextMenu($event,rowObj,rowMeta,row,col, columnObj)""
           >
@@ -162,7 +162,8 @@
 
             <editable-cell
               v-else-if=""
-                !isLocked
+                (isPkAvail ||rowMeta.new) &&
+                  !isLocked
                   && !isPublicView
                   && (editEnabled.col === col && editEnabled.row === row)
                   || enableEditable(columnObj)
@@ -190,11 +191,11 @@
               :db-alias=""nodes.dbAlias""
               :value=""rowObj[columnObj._cn]""
               :sql-ui=""sqlUi""
-              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai)""
+              @enableedit=""makeSelected(col,row);makeEditable(col,row,columnObj.ai, rowMeta)""
             />
           </td>
         </tr>
-        <tr v-if=""!isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
+        <tr v-if=""isPkAvail && !isLocked && !isPublicView && isEditable && relationType !== 'bt'"">
           <td :colspan=""visibleColLength + 1"" class=""text-left pointer"" @click=""insertNewRow(true)"">
             <v-tooltip top>
               <template #activator=""{on}"">
@@ -214,7 +215,9 @@
     <!--    <div is=""style"" v-html=""resizeColStyle"" />-->
     <dynamic-style>
       <template v-if=""resizingCol"">
-        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{ resizingColWidth }};width:{{ resizingColWidth }};}
+        [data-col=""{{ resizingCol }}""]{min-width:{{ resizingColWidth }};max-width:{{
+          resizingColWidth
+        }};width:{{ resizingColWidth }};}
       </template>
     </dynamic-style>
   </div>
@@ -261,7 +264,8 @@ export default {
     table: String,
     isVirtual: Boolean,
     isLocked: Boolean,
-    columnsWidth: { type: Object }
+    columnsWidth: { type: Object },
+    isPkAvail: Boolean
   },
   data: () => ({
     resizingCol: null,
@@ -426,6 +430,10 @@ export default {
             return
           }
           if (e.key && e.key.length === 1) {
+            if (!this.isPkAvail && !this.data[this.selected.row].rowMeta.new) {
+              return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+            }
+
             this.$set(this.data[this.selected.row].row, this.availableColumns[this.selected.col]._cn, '')
             this.editEnabled = { ...this.selected }
           }
@@ -466,10 +474,14 @@ export default {
         this.editEnabled = {}
       }
     },
-    makeEditable(col, row) {
+    makeEditable(col, row, _, rowMeta) {
       if (this.isPublicView || !this.isEditable) {
         return
       }
+
+      if (!this.isPkAvail && !rowMeta.new) {
+        return this.$toast.info('Update not allowed for table which doesn\'t have primary Key').goAway(3000)
+      }
       if (this.availableColumns[col].ai) {
         return this.$toast.info('Auto Increment field is not editable').goAway(3000)
       }
",3,"[""983fef55ef08ca2ca25349bb2d5bdff10ecf89f4"", ""6132632f7517195c7333308e9c667cdb756bf0af"", ""4d92f352741b04c8709319dfe5c8419654f3682c""]","[""refactor"", ""cicd"", ""feat""]","1. The commit consists of three main changes: (a) simplifying and refactoring the 'loadFiles' logic in a TypeScript file, (b) updating the schedule in the Renovate GitHub Actions workflow YAML, and (c) introducing UI logic to disable edit/delete operations in the spreadsheet components if a primary key is missing, with user feedback.
2. The refactor label is appropriate for the 'loadFiles.ts' changes because the logic is streamlined and variable names are clarified without altering external behavior; the cicd label is correct for the Renovate workflow YAML modification, as it only adjusts the CI configuration schedule; the feat label is justified for the spreadsheet UI changes, as new user-facing capability is added to prevent updates/deletes without a primary key and to provide user feedback.
3. Alternative labels are not appropriate: the loadFiles.ts change does not add features or fix bugs but restructures code (so not feat or fix); the Renovate YAML is a CI config, not build or docs; the spreadsheet component changes are not bug fixes (fix) because the previous absence of this feature was not a bug but a missing safeguard, and the changes add new UI logic and restrictions, so feat is correct, not refactor.
4. The combination of refactor, cicd, and feat accurately covers the three distinct, non-overlapping changes in this commit, each matching the respective label definitions and classification rules."
